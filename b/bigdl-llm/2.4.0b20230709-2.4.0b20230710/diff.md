# Comparing `tmp/bigdl_llm-2.4.0b20230709-py3-none-win_amd64.whl.zip` & `tmp/bigdl_llm-2.4.0b20230710-py3-none-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,71 +1,72 @@
-Zip file size: 1643545 bytes, number of entries: 69
--rw-------  2.0 unx      956 b- defN 23-Jul-07 09:31 bigdl/__init__.py
--rw-------  2.0 unx      914 b- defN 23-Jul-07 09:31 bigdl/llm/__init__.py
--rw-------  2.0 unx     6782 b- defN 23-Jul-07 09:31 bigdl/llm/convert_model.py
--rw-------  2.0 unx     1067 b- defN 23-Jul-07 09:31 bigdl/llm/models.py
--rw-rw-r--  2.0 unx     2399 b- defN 23-Jul-07 09:31 bigdl/llm/cli/llm-chat.ps1
--rwxrwxr-x  2.0 unx     2501 b- defN 23-Jul-07 09:31 bigdl/llm/cli/llm-cli.ps1
--rw-rw-r--  2.0 unx      216 b- defN 23-Jul-07 09:31 bigdl/llm/cli/prompts/chat-with-llm.txt
--rw-------  2.0 unx      994 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/__init__.py
--rw-------  2.0 unx     5254 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/convert.py
--rw-------  2.0 unx     5958 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/convert_model.py
--rw-------  2.0 unx     4822 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/quantize.py
--rw-------  2.0 unx      874 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/__init__.py
--rw-------  2.0 unx      900 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/bloom/__init__.py
--rw-------  2.0 unx    17893 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/bloom/bloom.py
--rw-------  2.0 unx     7965 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/bloom/bloom_cpp.py
--rw-------  2.0 unx      910 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/generation/__init__.py
--rw-------  2.0 unx     6107 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/generation/utils.py
--rw-------  2.0 unx      925 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/gptneox/__init__.py
--rw-------  2.0 unx    46964 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/gptneox/gptneox.py
--rw-------  2.0 unx    26490 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/gptneox/gptneox_cpp.py
--rw-------  2.0 unx     4194 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/gptneox/gptneox_types.py
--rw-------  2.0 unx      921 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/llama/__init__.py
--rw-------  2.0 unx    54566 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/llama/llama.py
--rw-------  2.0 unx    33279 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/llama/llama_cpp.py
--rw-------  2.0 unx     4207 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/llama/llama_types.py
--rw-------  2.0 unx      908 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/starcoder/__init__.py
--rw-------  2.0 unx    18334 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/starcoder/starcoder.py
--rw-------  2.0 unx     8133 b- defN 23-Jul-07 09:31 bigdl/llm/ggml/model/starcoder/starcoder_cpp.py
--rw-------  2.0 unx      874 b- defN 23-Jul-07 09:31 bigdl/llm/gptq/__init__.py
--rw-------  2.0 unx      874 b- defN 23-Jul-07 09:31 bigdl/llm/gptq/convert/__init__.py
--rw-------  2.0 unx    10737 b- defN 23-Jul-07 09:31 bigdl/llm/gptq/convert/convert_gptq_to_ggml.py
--rw-------  2.0 unx      874 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/__init__.py
--rw-------  2.0 unx     1051 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/embeddings/__init__.py
--rw-------  2.0 unx     7039 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/embeddings/bigdlllm.py
--rw-------  2.0 unx     5917 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/embeddings/transformersembeddings.py
--rw-------  2.0 unx     1414 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/llms/__init__.py
--rw-------  2.0 unx    12672 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/llms/bigdlllm.py
--rw-------  2.0 unx     5651 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/llms/transformersllm.py
--rw-------  2.0 unx     7371 b- defN 23-Jul-07 09:31 bigdl/llm/langchain/llms/transformerspipelinellm.py
--rw-------  2.0 unx   410112 b- defN 23-Jul-09 11:32 bigdl/llm/libs/bloom.dll
--rw-------  2.0 unx   427008 b- defN 23-Jul-09 11:32 bigdl/llm/libs/gptneox.dll
--rw-------  2.0 unx   421376 b- defN 23-Jul-09 11:32 bigdl/llm/libs/llama.dll
--rw-------  2.0 unx   222720 b- defN 23-Jul-09 11:32 bigdl/llm/libs/main-bloom.exe
--rw-------  2.0 unx   335360 b- defN 23-Jul-09 11:32 bigdl/llm/libs/main-gptneox.exe
--rw-------  2.0 unx   338432 b- defN 23-Jul-09 11:32 bigdl/llm/libs/main-llama.exe
--rw-------  2.0 unx   295424 b- defN 23-Jul-09 11:32 bigdl/llm/libs/main-starcoder.exe
--rw-------  2.0 unx   112128 b- defN 23-Jul-09 11:32 bigdl/llm/libs/quantize-bloom.exe
--rw-------  2.0 unx    97792 b- defN 23-Jul-09 11:32 bigdl/llm/libs/quantize-gptneox.exe
--rw-------  2.0 unx   101888 b- defN 23-Jul-09 11:32 bigdl/llm/libs/quantize-llama.exe
--rw-------  2.0 unx   119296 b- defN 23-Jul-09 11:32 bigdl/llm/libs/quantize-starcoder.exe
--rw-------  2.0 unx   535040 b- defN 23-Jul-09 11:32 bigdl/llm/libs/starcoder.dll
--rw-------  2.0 unx      729 b- defN 23-Jul-07 09:31 bigdl/llm/transformers/__init__.py
--rw-------  2.0 unx     4023 b- defN 23-Jul-07 09:31 bigdl/llm/transformers/convert.py
--rw-------  2.0 unx     7114 b- defN 23-Jul-07 09:31 bigdl/llm/transformers/linear_int4.py
--rw-------  2.0 unx     1331 b- defN 23-Jul-07 09:31 bigdl/llm/transformers/model.py
--rw-------  2.0 unx     3609 b- defN 23-Jul-07 09:31 bigdl/llm/transformers/modelling_bigdl.py
--rw-------  2.0 unx      896 b- defN 23-Jul-07 09:31 bigdl/llm/utils/__init__.py
--rw-------  2.0 unx    63692 b- defN 23-Jul-07 09:31 bigdl/llm/utils/convert_util.py
--rw-------  2.0 unx     1043 b- defN 23-Jul-07 09:31 bigdl/llm/utils/utils.py
--rw-------  2.0 unx      974 b- defN 23-Jul-07 09:31 bigdl/llm/utils/common/__init__.py
--rw-------  2.0 unx     2874 b- defN 23-Jul-07 09:31 bigdl/llm/utils/common/lazyimport.py
--rw-------  2.0 unx     1378 b- defN 23-Jul-07 09:31 bigdl/llm/utils/common/log4Error.py
--rwxrwxr-x  2.0 unx     2399 b- defN 23-Jul-07 09:31 bigdl_llm-2.4.0b20230709.data/scripts/llm-chat.ps1
--rwxrwxr-x  2.0 unx     2501 b- defN 23-Jul-07 09:31 bigdl_llm-2.4.0b20230709.data/scripts/llm-cli.ps1
--rw-------  2.0 unx      802 b- defN 23-Jul-09 11:32 bigdl_llm-2.4.0b20230709.dist-info/METADATA
--rw-------  2.0 unx       98 b- defN 23-Jul-09 11:32 bigdl_llm-2.4.0b20230709.dist-info/WHEEL
--rw-------  2.0 unx       62 b- defN 23-Jul-09 11:32 bigdl_llm-2.4.0b20230709.dist-info/entry_points.txt
--rw-------  2.0 unx        6 b- defN 23-Jul-09 11:32 bigdl_llm-2.4.0b20230709.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6337 b- defN 23-Jul-09 11:32 bigdl_llm-2.4.0b20230709.dist-info/RECORD
-69 files, 3836351 bytes uncompressed, 1633379 bytes compressed:  57.4%
+Zip file size: 1646263 bytes, number of entries: 70
+-rw-r--r--  2.0 unx      956 b- defN 23-May-25 11:32 bigdl/__init__.py
+-rw-r--r--  2.0 unx      914 b- defN 23-Jun-19 11:32 bigdl/llm/__init__.py
+-rw-r--r--  2.0 unx     6782 b- defN 23-Jun-28 11:31 bigdl/llm/convert_model.py
+-rw-r--r--  2.0 unx     1067 b- defN 23-Jun-21 11:32 bigdl/llm/models.py
+-rw-r--r--  2.0 unx     2399 b- defN 23-Jul-07 11:31 bigdl/llm/cli/llm-chat.ps1
+-rwxr-xr-x  2.0 unx     2501 b- defN 23-Jun-21 11:32 bigdl/llm/cli/llm-cli.ps1
+-rw-r--r--  2.0 unx      216 b- defN 23-Jul-07 11:31 bigdl/llm/cli/prompts/chat-with-llm.txt
+-rw-r--r--  2.0 unx      994 b- defN 23-Jun-09 11:32 bigdl/llm/ggml/__init__.py
+-rw-r--r--  2.0 unx     5254 b- defN 23-Jun-20 11:32 bigdl/llm/ggml/convert.py
+-rw-r--r--  2.0 unx     5958 b- defN 23-Jun-20 11:32 bigdl/llm/ggml/convert_model.py
+-rw-r--r--  2.0 unx     4822 b- defN 23-Jun-20 11:32 bigdl/llm/ggml/quantize.py
+-rw-r--r--  2.0 unx      874 b- defN 23-Jun-02 11:32 bigdl/llm/ggml/model/__init__.py
+-rw-r--r--  2.0 unx      900 b- defN 23-Jun-02 11:32 bigdl/llm/ggml/model/bloom/__init__.py
+-rw-r--r--  2.0 unx    17893 b- defN 23-Jul-07 11:31 bigdl/llm/ggml/model/bloom/bloom.py
+-rw-r--r--  2.0 unx     7965 b- defN 23-Jun-14 11:32 bigdl/llm/ggml/model/bloom/bloom_cpp.py
+-rw-r--r--  2.0 unx      910 b- defN 23-Jun-06 11:32 bigdl/llm/ggml/model/generation/__init__.py
+-rw-r--r--  2.0 unx     6107 b- defN 23-Jul-07 11:31 bigdl/llm/ggml/model/generation/utils.py
+-rw-r--r--  2.0 unx      925 b- defN 23-Jun-02 11:32 bigdl/llm/ggml/model/gptneox/__init__.py
+-rw-r--r--  2.0 unx    46964 b- defN 23-Jun-14 11:32 bigdl/llm/ggml/model/gptneox/gptneox.py
+-rw-r--r--  2.0 unx    26490 b- defN 23-Jun-05 11:32 bigdl/llm/ggml/model/gptneox/gptneox_cpp.py
+-rw-r--r--  2.0 unx     4194 b- defN 23-Jun-02 11:32 bigdl/llm/ggml/model/gptneox/gptneox_types.py
+-rw-r--r--  2.0 unx      921 b- defN 23-Jun-01 11:32 bigdl/llm/ggml/model/llama/__init__.py
+-rw-r--r--  2.0 unx    54566 b- defN 23-Jun-14 11:32 bigdl/llm/ggml/model/llama/llama.py
+-rw-r--r--  2.0 unx    33279 b- defN 23-Jun-25 11:32 bigdl/llm/ggml/model/llama/llama_cpp.py
+-rw-r--r--  2.0 unx     4207 b- defN 23-Jun-01 11:32 bigdl/llm/ggml/model/llama/llama_types.py
+-rw-r--r--  2.0 unx      908 b- defN 23-Jun-21 11:32 bigdl/llm/ggml/model/starcoder/__init__.py
+-rw-r--r--  2.0 unx    18334 b- defN 23-Jul-07 11:31 bigdl/llm/ggml/model/starcoder/starcoder.py
+-rw-r--r--  2.0 unx     8133 b- defN 23-Jun-21 11:32 bigdl/llm/ggml/model/starcoder/starcoder_cpp.py
+-rw-r--r--  2.0 unx      874 b- defN 23-Jun-19 11:32 bigdl/llm/gptq/__init__.py
+-rw-r--r--  2.0 unx      874 b- defN 23-Jun-19 11:32 bigdl/llm/gptq/convert/__init__.py
+-rw-r--r--  2.0 unx    10737 b- defN 23-Jun-27 11:32 bigdl/llm/gptq/convert/convert_gptq_to_ggml.py
+-rw-r--r--  2.0 unx      874 b- defN 23-Jun-12 11:32 bigdl/llm/langchain/__init__.py
+-rw-r--r--  2.0 unx     1051 b- defN 23-Jul-07 11:31 bigdl/llm/langchain/embeddings/__init__.py
+-rw-r--r--  2.0 unx     7039 b- defN 23-Jul-07 11:31 bigdl/llm/langchain/embeddings/bigdlllm.py
+-rw-r--r--  2.0 unx     5917 b- defN 23-Jul-07 11:31 bigdl/llm/langchain/embeddings/transformersembeddings.py
+-rw-r--r--  2.0 unx     1414 b- defN 23-Jul-07 11:31 bigdl/llm/langchain/llms/__init__.py
+-rw-r--r--  2.0 unx    12672 b- defN 23-Jul-07 11:31 bigdl/llm/langchain/llms/bigdlllm.py
+-rw-r--r--  2.0 unx     5651 b- defN 23-Jul-07 11:31 bigdl/llm/langchain/llms/transformersllm.py
+-rw-r--r--  2.0 unx     7371 b- defN 23-Jul-07 11:31 bigdl/llm/langchain/llms/transformerspipelinellm.py
+-rw-r--r--  2.0 unx   410112 b- defN 23-Jul-10 11:38 bigdl/llm/libs/bloom.dll
+-rw-r--r--  2.0 unx   427008 b- defN 23-Jul-10 11:37 bigdl/llm/libs/gptneox.dll
+-rw-r--r--  2.0 unx   421376 b- defN 23-Jul-10 11:36 bigdl/llm/libs/llama.dll
+-rw-r--r--  2.0 unx   222720 b- defN 23-Jul-10 11:43 bigdl/llm/libs/main-bloom.exe
+-rw-r--r--  2.0 unx   335360 b- defN 23-Jul-10 11:42 bigdl/llm/libs/main-gptneox.exe
+-rw-r--r--  2.0 unx   338432 b- defN 23-Jul-10 11:41 bigdl/llm/libs/main-llama.exe
+-rw-r--r--  2.0 unx   295424 b- defN 23-Jul-10 11:45 bigdl/llm/libs/main-starcoder.exe
+-rw-r--r--  2.0 unx   112128 b- defN 23-Jul-10 11:40 bigdl/llm/libs/quantize-bloom.exe
+-rw-r--r--  2.0 unx    97792 b- defN 23-Jul-10 11:40 bigdl/llm/libs/quantize-gptneox.exe
+-rw-r--r--  2.0 unx   101888 b- defN 23-Jul-10 11:39 bigdl/llm/libs/quantize-llama.exe
+-rw-r--r--  2.0 unx   119296 b- defN 23-Jul-10 11:44 bigdl/llm/libs/quantize-starcoder.exe
+-rw-r--r--  2.0 unx   535040 b- defN 23-Jul-10 11:44 bigdl/llm/libs/starcoder.dll
+-rw-r--r--  2.0 unx      729 b- defN 23-Jul-07 11:31 bigdl/llm/transformers/__init__.py
+-rw-r--r--  2.0 unx     4205 b- defN 23-Jul-10 11:32 bigdl/llm/transformers/convert.py
+-rw-r--r--  2.0 unx     7314 b- defN 23-Jul-10 11:32 bigdl/llm/transformers/linear_int4.py
+-rw-r--r--  2.0 unx     3443 b- defN 23-Jul-10 11:32 bigdl/llm/transformers/model.py
+-rw-r--r--  2.0 unx     3609 b- defN 23-Jul-07 11:31 bigdl/llm/transformers/modelling_bigdl.py
+-rw-r--r--  2.0 unx     3983 b- defN 23-Jul-10 11:32 bigdl/llm/transformers/utils.py
+-rw-r--r--  2.0 unx      896 b- defN 23-Jun-02 11:32 bigdl/llm/utils/__init__.py
+-rw-r--r--  2.0 unx    63692 b- defN 23-Jun-21 11:32 bigdl/llm/utils/convert_util.py
+-rw-r--r--  2.0 unx     1043 b- defN 23-Jun-02 11:32 bigdl/llm/utils/utils.py
+-rw-r--r--  2.0 unx      974 b- defN 23-Jun-09 11:32 bigdl/llm/utils/common/__init__.py
+-rw-r--r--  2.0 unx     2874 b- defN 23-Jun-09 11:32 bigdl/llm/utils/common/lazyimport.py
+-rw-r--r--  2.0 unx     1378 b- defN 23-May-26 11:32 bigdl/llm/utils/common/log4Error.py
+-rwxr-xr-x  2.0 unx     2399 b- defN 23-Jul-07 11:31 bigdl_llm-2.4.0b20230710.data/scripts/llm-chat.ps1
+-rwxr-xr-x  2.0 unx     2501 b- defN 23-Jun-21 11:32 bigdl_llm-2.4.0b20230710.data/scripts/llm-cli.ps1
+-rw-r--r--  2.0 unx      811 b- defN 23-Jul-10 11:45 bigdl_llm-2.4.0b20230710.dist-info/METADATA
+-rw-r--r--  2.0 unx       98 b- defN 23-Jul-10 11:45 bigdl_llm-2.4.0b20230710.dist-info/WHEEL
+-rw-r--r--  2.0 unx       62 b- defN 23-Jul-10 11:45 bigdl_llm-2.4.0b20230710.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        6 b- defN 23-Jul-10 11:45 bigdl_llm-2.4.0b20230710.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     6425 b- defN 23-Jul-10 11:45 bigdl_llm-2.4.0b20230710.dist-info/RECORD
+70 files, 3842925 bytes uncompressed, 1635959 bytes compressed:  57.4%
```

## zipnote {}

```diff
@@ -162,14 +162,17 @@
 
 Filename: bigdl/llm/transformers/model.py
 Comment: 
 
 Filename: bigdl/llm/transformers/modelling_bigdl.py
 Comment: 
 
+Filename: bigdl/llm/transformers/utils.py
+Comment: 
+
 Filename: bigdl/llm/utils/__init__.py
 Comment: 
 
 Filename: bigdl/llm/utils/convert_util.py
 Comment: 
 
 Filename: bigdl/llm/utils/utils.py
@@ -180,29 +183,29 @@
 
 Filename: bigdl/llm/utils/common/lazyimport.py
 Comment: 
 
 Filename: bigdl/llm/utils/common/log4Error.py
 Comment: 
 
-Filename: bigdl_llm-2.4.0b20230709.data/scripts/llm-chat.ps1
+Filename: bigdl_llm-2.4.0b20230710.data/scripts/llm-chat.ps1
 Comment: 
 
-Filename: bigdl_llm-2.4.0b20230709.data/scripts/llm-cli.ps1
+Filename: bigdl_llm-2.4.0b20230710.data/scripts/llm-cli.ps1
 Comment: 
 
-Filename: bigdl_llm-2.4.0b20230709.dist-info/METADATA
+Filename: bigdl_llm-2.4.0b20230710.dist-info/METADATA
 Comment: 
 
-Filename: bigdl_llm-2.4.0b20230709.dist-info/WHEEL
+Filename: bigdl_llm-2.4.0b20230710.dist-info/WHEEL
 Comment: 
 
-Filename: bigdl_llm-2.4.0b20230709.dist-info/entry_points.txt
+Filename: bigdl_llm-2.4.0b20230710.dist-info/entry_points.txt
 Comment: 
 
-Filename: bigdl_llm-2.4.0b20230709.dist-info/top_level.txt
+Filename: bigdl_llm-2.4.0b20230710.dist-info/top_level.txt
 Comment: 
 
-Filename: bigdl_llm-2.4.0b20230709.dist-info/RECORD
+Filename: bigdl_llm-2.4.0b20230710.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## bigdl/llm/transformers/convert.py

```diff
@@ -37,15 +37,16 @@
 import torch
 import torch.nn as nn
 from accelerate import init_empty_weights
 from bigdl.llm.transformers.linear_int4 import LinearInt4, ParamsInt4
 import warnings
 
 
-def _replace_with_int4_linear(model, modules_to_not_convert=None, current_key_name=None):
+def _replace_with_int4_linear(model, modules_to_not_convert=None,
+                              current_key_name=None, convert_shape_only=False):
     has_been_replaced = False
     for name, module in model.named_children():
         if current_key_name is None:
             current_key_name = []
 
         if isinstance(module, nn.Linear) and name not in modules_to_not_convert:
             # Check if the current key is not in the `modules_to_not_convert`
@@ -55,18 +56,20 @@
                     new_linear = LinearInt4(
                         module.in_features,
                         module.out_features,
                         module.bias is not None,
                     )
 
                     # Copy the weights
-                    new_linear._parameters['weight'] = ParamsInt4(data=module.weight.data,
-                                                                  requires_grad=False,
-                                                                  quantized=False,
-                                                                  _shape=None).to("cpu")
+                    paramsint4 = ParamsInt4(data=module.weight.data,
+                                            requires_grad=False,
+                                            quantized=False,
+                                            convert_shape_only=convert_shape_only,
+                                            _shape=None).to("cpu")
+                    new_linear._parameters['weight'] = paramsint4
                     if module.bias is not None:
                         new_linear._parameters['bias'] = nn.Parameter(module.bias.data).to("cpu")
 
                     model._modules[name] = new_linear
                     has_been_replaced = True
                     # Force requires grad to False to avoid unexpected errors
                     model._modules[name].requires_grad_(False)
@@ -79,18 +82,18 @@
                 module,
                 modules_to_not_convert,
                 current_key_name,
             )
     return model, has_been_replaced
 
 
-def ggml_convert_int4(model):
+def ggml_convert_int4(model, convert_shape_only=False):
     modules_to_not_convert = []  # ["lm_head"]
     model, has_been_replaced = _replace_with_int4_linear(
-        model, modules_to_not_convert, None
+        model, modules_to_not_convert, None, convert_shape_only=convert_shape_only
     )
     if not has_been_replaced:
         warnings.warn(
             "No linear modules were found in "
             "your model. This can happen for some architectures such as gpt2 that uses Conv1D "
             "instead of Linear layers. Please double check your model architecture, or submit "
             "an issue on github if you think this is a bug."
```

## bigdl/llm/transformers/linear_int4.py

```diff
@@ -56,15 +56,15 @@
 import ctypes
 
 QK = 64  # todo read this value from libllama.so
 scale_size_in_bytes = 4
 block_size_in_bytes = QK // 2 + scale_size_in_bytes
 
 
-def ggml_convert_int4(tensor: torch.Tensor):
+def ggml_convert_int4(tensor: torch.Tensor, convert_shape_only=False):
 
     invalidInputError(tensor.dtype == torch.float,
                       "Input tensor must be float32")
     src = tensor.data.data_ptr()
     src = ctypes.cast(src, ctypes.POINTER(ctypes.c_float))
     n = tensor.numel()
     invalidInputError(n % QK == 0,
@@ -75,34 +75,37 @@
 
     dst_size = (n // QK) * block_size_in_bytes
     dst_tensor = torch.empty(dst_size, dtype=torch.uint8)
     dst = ctypes.c_void_p(dst_tensor.data.data_ptr())
 
     hist = (ctypes.c_int64 * 16)()
 
-    ggml.ggml_quantize_q4_0(src, dst, n, k, hist)
+    if not convert_shape_only:
+        ggml.ggml_quantize_q4_0(src, dst, n, k, hist)
     return dst_tensor
 
 
 class ParamsInt4(torch.nn.Parameter):
-    def __new__(cls, data=None, requires_grad=True, old_data=None, quantized=False, _shape=None):
+    def __new__(cls, data=None, requires_grad=True, old_data=None,
+                quantized=False, _shape=None, convert_shape_only=False):
         if data is None:
             data = torch.empty(0)
 
         self = torch.Tensor._make_subclass(cls, data, requires_grad)
         self.data = data
         self.quantized = quantized
         self._shape = _shape
+        self.convert_shape_only = convert_shape_only
         return self
 
     def quantize(self, device):
         if not self.quantized:
             w = self.data.contiguous().float()
             # self.old_data = self.data
-            w_4bit = ggml_convert_int4(w)
+            w_4bit = ggml_convert_int4(w, convert_shape_only=self.convert_shape_only)
             self.data = w_4bit
             self.quantized = True
             self._shape = w.shape
         return self
 
     def get_shape(self):
         return self._shape
```

## bigdl/llm/transformers/model.py

```diff
@@ -11,34 +11,74 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 
 import transformers
-import torch
+from transformers.configuration_utils import PretrainedConfig
+from .utils import extract_local_archive_file, load_state_dict, load
 
 
 class _BaseAutoModelClass:
 
     HF_MODEL = None
 
     @classmethod
     def from_pretrained(cls,
                         *args,
                         **kwargs):
         load_in_4bit = kwargs.pop("load_in_4bit", False)
         if load_in_4bit:
             kwargs["low_cpu_mem_usage"] = True
-        model = cls.HF_Model.from_pretrained(*args, **kwargs)
 
-        if load_in_4bit:
+        subfolder = kwargs.get("subfolder", "")
+        variant = kwargs.get("variant", None)
+        pretrained_model_name_or_path = kwargs.get("pretrained_model_name_or_path", None) \
+            if len(args) == 0 else args[0]
+
+        # For huggingface transformers cls.HF_Model.from_pretrained could only restore the model
+        # in the original format, which is not quantized,
+        # we can convert the model to quantized later.
+        model = None
+
+        # Read bigdl_transformers_int4 from config.json
+        config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path)
+
+        bigdl_transformers_int4 = config_dict.pop("bigdl_transformers_int4", False)
+        if bigdl_transformers_int4:
+            # Avoid KeyError
+            kwargs["ignore_mismatched_sizes"] = True
+
+        model = cls.HF_Model.from_pretrained(*args, **kwargs)
+        print("Note: If there are warnings about mismatched during the loading process, "
+              "please ignore them as it is part of the normal flow. "
+              "The model will be reconverted to the format of BigDL after loading.")
+
+        # Note that the ggml_matmul_src1_x_src0_t operation cannot currently
+        # be recorded in AutoConfig,
+        # and this operation is not included in the core Hugging Face infrastructure.
+        if bigdl_transformers_int4:
+            from .convert import ggml_convert_int4
+            # We forcefully modify the model's definition
+            # and the tensor shape of int4 weights without quantization.
+            model = ggml_convert_int4(model, convert_shape_only=True)
+            # Load the quantized model at last.
+            archive_file = extract_local_archive_file(pretrained_model_name_or_path,
+                                                      subfolder,
+                                                      variant)
+            state_dict = load_state_dict(archive_file)
+            load(model, state_dict)
+            del state_dict
+        elif load_in_4bit:
             from .convert import ggml_convert_int4
             model = model.to("cpu")
             model = ggml_convert_int4(model)
+            model.config.update({"bigdl_transformers_int4": True})
+
         return model
 
 
 class AutoModelForCausalLM(_BaseAutoModelClass):
     HF_Model = transformers.AutoModelForCausalLM
```

## Comparing `bigdl_llm-2.4.0b20230709.data/scripts/llm-chat.ps1` & `bigdl_llm-2.4.0b20230710.data/scripts/llm-chat.ps1`

 * *Files identical despite different names*

## Comparing `bigdl_llm-2.4.0b20230709.data/scripts/llm-cli.ps1` & `bigdl_llm-2.4.0b20230710.data/scripts/llm-cli.ps1`

 * *Files identical despite different names*

## Comparing `bigdl_llm-2.4.0b20230709.dist-info/METADATA` & `bigdl_llm-2.4.0b20230710.dist-info/METADATA`

 * *Files 13% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 Metadata-Version: 2.1
 Name: bigdl-llm
-Version: 2.4.0b20230709
+Version: 2.4.0b20230710
 Summary: Large Language Model Develop Toolkit
 Home-page: https://github.com/intel-analytics/BigDL
 Author: BigDL Authors
 Author-email: bigdl-user-group@googlegroups.com
 License: Apache License, Version 2.0
 Platform: windows
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Description-Content-Type: text/markdown
 Provides-Extra: all
-Requires-Dist: numpy ; extra == 'all'
+Requires-Dist: numpy (>=1.22) ; extra == 'all'
 Requires-Dist: torch ; extra == 'all'
 Requires-Dist: transformers ; extra == 'all'
 Requires-Dist: sentencepiece ; extra == 'all'
 Requires-Dist: accelerate ; extra == 'all'
 
 
 BigDL LLM
```

## Comparing `bigdl_llm-2.4.0b20230709.dist-info/RECORD` & `bigdl_llm-2.4.0b20230710.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -46,24 +46,25 @@
 bigdl/llm/libs/main-starcoder.exe,sha256=KOLDV9evgl3msP7bO4nPRXnu6Z0tH0LYUfhVRNDZjW4,295424
 bigdl/llm/libs/quantize-bloom.exe,sha256=26bjJz9q0yeFjFMirWHdYX6cJEYq1wB6Z8HX1M1JC8s,112128
 bigdl/llm/libs/quantize-gptneox.exe,sha256=TCF6uiVx-dIxy-CIunTklH1kYmifs_NANT6Xt7CG9dE,97792
 bigdl/llm/libs/quantize-llama.exe,sha256=BYL_OqRQKJydXdLXCJnWLNknEG5WPH7mp1MY6bL-oUw,101888
 bigdl/llm/libs/quantize-starcoder.exe,sha256=eRsq_8vDXjzOBRrz-8xg5C5GTlEFXYM4ZyLABmurO2I,119296
 bigdl/llm/libs/starcoder.dll,sha256=DcoSXSSRKpXvJpPkB82_gdOztE333U-UpA_XXus_t9Y,535040
 bigdl/llm/transformers/__init__.py,sha256=ZHUx8LHTaN9Iw-cW_ecy28uNLw7aDYuEylQoP9WGuQw,729
-bigdl/llm/transformers/convert.py,sha256=IwYedkeEORY2hyMnIBxNi6uJz_8mBUwiTBX2gjF4IyQ,4023
-bigdl/llm/transformers/linear_int4.py,sha256=Im2kiw0--wKI0MROk01jEYtCc5XC-iUFYy9Qd9K-Daw,7114
-bigdl/llm/transformers/model.py,sha256=GGFbTE4BcLA2OlNYQpc3d6JpBuKzfwZd5kGm7YCEUw0,1331
+bigdl/llm/transformers/convert.py,sha256=g13WHt5dEze-SxoRahVVi6t9iaArN4eJc2mHDWLtSzE,4205
+bigdl/llm/transformers/linear_int4.py,sha256=dDqPwIO5Y8mQN2yWpReS0x92xlxftbMcLhSqQD7kZO4,7314
+bigdl/llm/transformers/model.py,sha256=4oK_BWqSjpc4t4VIbywAvPKb6_rmTtbBOuctnBe1RKA,3443
 bigdl/llm/transformers/modelling_bigdl.py,sha256=uxkU1C1dxPNh4g7NDae7AC-07pbZa7bA7T1uKI0vP0g,3609
+bigdl/llm/transformers/utils.py,sha256=CA8YJf1xLqkjWNdDZAzaTVmgzgmT5m6w0rsMHrqaseI,3983
 bigdl/llm/utils/__init__.py,sha256=f_oavwQog8Wd1fSIebb-KgA61UKSzcOgw4cBxMHyS_w,896
 bigdl/llm/utils/convert_util.py,sha256=hAdFSjHzdD0cGZY4n8t-gWjRuE-TKXgMRjszfrKRgfI,63692
 bigdl/llm/utils/utils.py,sha256=hKzroKKjlMead-Xtj3D2oWKG-Sjw4BJ2MR0-U3I-tPc,1043
 bigdl/llm/utils/common/__init__.py,sha256=4RHJ8vO-C1rhOMeU2X7ZSY_9RSCYXdM2tceIIcdy7u4,974
 bigdl/llm/utils/common/lazyimport.py,sha256=TVDp-rtc6IHopmlS9WEIgP5GKg5i0iWGm8khPwG4jTo,2874
 bigdl/llm/utils/common/log4Error.py,sha256=tVYLVKyPvqOphUBdV9hZRr6yJgQpDLAAq8OlW-5Xcto,1378
-bigdl_llm-2.4.0b20230709.data/scripts/llm-chat.ps1,sha256=s_VT1AlH-adsiRCKsrmhETOMVoASxhkKSvUBQFhoww8,2399
-bigdl_llm-2.4.0b20230709.data/scripts/llm-cli.ps1,sha256=qrOMg7fWiUJ61VhrUHbeibNYre_HE1hwj0E8GmyJfLM,2501
-bigdl_llm-2.4.0b20230709.dist-info/METADATA,sha256=IH812cbaNxtjAsEwpl1gtMrrBKT-5gore0aUwwbab5E,802
-bigdl_llm-2.4.0b20230709.dist-info/WHEEL,sha256=bC8mYJUOJCh5KnyEeT6W_BCQYi3v39D3z64Vy_sFvVg,98
-bigdl_llm-2.4.0b20230709.dist-info/entry_points.txt,sha256=FClDfgRtVDhPPUsMDgDOZvqNZTS_vBpqhJvYkv0YzLM,62
-bigdl_llm-2.4.0b20230709.dist-info/top_level.txt,sha256=iGuLfZARD_qANcIMfy0tbbrC3EtCg6BSiH8icc3dLWs,6
-bigdl_llm-2.4.0b20230709.dist-info/RECORD,,
+bigdl_llm-2.4.0b20230710.data/scripts/llm-chat.ps1,sha256=s_VT1AlH-adsiRCKsrmhETOMVoASxhkKSvUBQFhoww8,2399
+bigdl_llm-2.4.0b20230710.data/scripts/llm-cli.ps1,sha256=qrOMg7fWiUJ61VhrUHbeibNYre_HE1hwj0E8GmyJfLM,2501
+bigdl_llm-2.4.0b20230710.dist-info/METADATA,sha256=vezLxIDhPifDJE3hRKuSLjW8ShrWeRQQPychUOYuPIk,811
+bigdl_llm-2.4.0b20230710.dist-info/WHEEL,sha256=i9qQj8KaD8_YEW0Vc2oS56fKju23RkQ-FVz-QmzVakQ,98
+bigdl_llm-2.4.0b20230710.dist-info/entry_points.txt,sha256=FClDfgRtVDhPPUsMDgDOZvqNZTS_vBpqhJvYkv0YzLM,62
+bigdl_llm-2.4.0b20230710.dist-info/top_level.txt,sha256=iGuLfZARD_qANcIMfy0tbbrC3EtCg6BSiH8icc3dLWs,6
+bigdl_llm-2.4.0b20230710.dist-info/RECORD,,
```

