# Comparing `tmp/duplicity-1.2.3.dev43.tar.gz` & `tmp/duplicity-2.0.0rc0.tar.gz`

## Comparing `duplicity-1.2.3.dev43.tar` & `duplicity-2.0.0rc0.tar`

### file list

```diff
@@ -1,314 +1,307 @@
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/
--rw-r--r--   0 ken       (1000) ken       (1000)    95895 2023-03-16 18:49:20.000000 duplicity-1.2.3.dev43/CHANGELOG.md
--rw-r--r--   0 ken       (1000) ken       (1000)      101 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/setup.cfg
--rw-r--r--   0 ken       (1000) ken       (1000)      651 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/pylintrc
--rw-r--r--   0 ken       (1000) ken       (1000)     1390 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/CONTRIBUTING.md
--rw-r--r--   0 ken       (1000) ken       (1000)     2814 2023-03-07 16:20:30.000000 duplicity-1.2.3.dev43/tox.ini
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/bin/
--rwxr-xr-x   0 ken       (1000) ken       (1000)     5215 2023-03-07 16:20:30.000000 duplicity-1.2.3.dev43/bin/duplicity
--rw-r--r--   0 ken       (1000) ken       (1000)     3108 2023-04-05 14:51:14.000000 duplicity-1.2.3.dev43/bin/rdiffdir.1
--rw-r--r--   0 ken       (1000) ken       (1000)    98253 2023-04-05 14:51:14.000000 duplicity-1.2.3.dev43/bin/duplicity.1
--rwxr-xr-x   0 ken       (1000) ken       (1000)     9127 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/bin/rdiffdir
--rw-r--r--   0 ken       (1000) ken       (1000)     1053 2023-04-05 14:50:34.000000 duplicity-1.2.3.dev43/requirements.txt
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/snap/
--rw-r--r--   0 ken       (1000) ken       (1000)     5723 2023-04-05 14:51:14.000000 duplicity-1.2.3.dev43/snap/snapcraft.yaml
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/snap/local/
--rwxr-xr-x   0 ken       (1000) ken       (1000)      186 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/snap/local/debug.sh
--rwxr-xr-x   0 ken       (1000) ken       (1000)      110 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/snap/local/launcher.sh
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/testing/
--rw-r--r--   0 ken       (1000) ken       (1000)   319661 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/testfiles.tar.gz
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/testing/unit/
--rw-r--r--   0 ken       (1000) ken       (1000)     8373 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_gpginterface.py
--rw-r--r--   0 ken       (1000) ken       (1000)    11911 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_patchdir.py
--rw-r--r--   0 ken       (1000) ken       (1000)     6777 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_dup_time.py
--rw-r--r--   0 ken       (1000) ken       (1000)    12146 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_lazy.py
--rw-r--r--   0 ken       (1000) ken       (1000)     5751 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_statistics.py
--rw-r--r--   0 ken       (1000) ken       (1000)    14365 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_globmatch.py
--rw-r--r--   0 ken       (1000) ken       (1000)     5848 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_manifest.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1027 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/__init__.py
--rw-r--r--   0 ken       (1000) ken       (1000)    12014 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_collections.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2566 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_dup_temp.py
--rw-r--r--   0 ken       (1000) ken       (1000)     6028 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_file_naming.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1287 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_tarfile.py
--rw-r--r--   0 ken       (1000) ken       (1000)    13493 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_diffdir.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2596 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_tempdir.py
--rw-r--r--   0 ken       (1000) ken       (1000)    10376 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_backend_instance.py
--rw-r--r--   0 ken       (1000) ken       (1000)     3877 2023-03-07 16:20:30.000000 duplicity-1.2.3.dev43/testing/unit/test_path.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1546 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_util.py
--rw-r--r--   0 ken       (1000) ken       (1000)     8686 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_gpg.py
--rw-r--r--   0 ken       (1000) ken       (1000)    12435 2023-04-03 18:52:11.000000 duplicity-1.2.3.dev43/testing/unit/test_backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    67031 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/unit/test_selection.py
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/testing/overrides/
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/testing/overrides/bin/
--rwxr-xr-x   0 ken       (1000) ken       (1000)      226 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/overrides/bin/ncftpget
--rwxr-xr-x   0 ken       (1000) ken       (1000)      593 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/overrides/bin/lftp
--rwxr-xr-x   0 ken       (1000) ken       (1000)      226 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/overrides/bin/ncftpput
--rwxr-xr-x   0 ken       (1000) ken       (1000)      494 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/overrides/bin/hsi
--rwxr-xr-x   0 ken       (1000) ken       (1000)      487 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/overrides/bin/tahoe
--rwxr-xr-x   0 ken       (1000) ken       (1000)      628 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/overrides/bin/ncftpls
--rw-r--r--   0 ken       (1000) ken       (1000)      318 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/overrides/__init__.py
--rw-r--r--   0 ken       (1000) ken       (1000)     5228 2023-04-05 14:50:34.000000 duplicity-1.2.3.dev43/testing/__init__.py
--rwxr-xr-x   0 ken       (1000) ken       (1000)      878 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/run-tests
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/testing/functional/
--rw-r--r--   0 ken       (1000) ken       (1000)     2641 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/functional/test_log.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9764 2023-04-05 14:50:34.000000 duplicity-1.2.3.dev43/testing/functional/test_final.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1724 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/functional/test_badupload.py
--rw-r--r--   0 ken       (1000) ken       (1000)     3513 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/functional/test_cleanup.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9513 2023-04-05 14:50:34.000000 duplicity-1.2.3.dev43/testing/functional/__init__.py
--rw-r--r--   0 ken       (1000) ken       (1000)     3514 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/functional/test_replicate.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9126 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/functional/test_verify.py
--rw-r--r--   0 ken       (1000) ken       (1000)    20273 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/functional/test_restart.py
--rw-r--r--   0 ken       (1000) ken       (1000)     3936 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/functional/test_rdiffdir.py
--rw-r--r--   0 ken       (1000) ken       (1000)   111376 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/testing/functional/test_selection.py
--rwxr-xr-x   0 ken       (1000) ken       (1000)     3614 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/fix_unadorned_strings.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1083 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/conftest.py
--rw-r--r--   0 ken       (1000) ken       (1000)     6236 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/test_code.py
--rwxr-xr-x   0 ken       (1000) ken       (1000)     2979 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/find_unadorned_strings.py
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/testing/gnupg/
--rw-r--r--   0 ken       (1000) ken       (1000)      145 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/gnupg/gpg-agent.conf
--rw-r--r--   0 ken       (1000) ken       (1000)     3567 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/gnupg/pubring.gpg
--rw-r--r--   0 ken       (1000) ken       (1000)     7549 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/gnupg/secring.gpg
--rw-r--r--   0 ken       (1000) ken       (1000)      425 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/gnupg/gpg.conf
--rw-r--r--   0 ken       (1000) ken       (1000)      255 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/gnupg/README
--rw-r--r--   0 ken       (1000) ken       (1000)     1440 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/testing/gnupg/trustdb.gpg
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity/
--rw-r--r--   0 ken       (1000) ken       (1000)    11648 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/dup_time.py
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity/backends/
--rw-r--r--   0 ken       (1000) ken       (1000)     3033 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/localbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    16858 2023-03-07 16:20:30.000000 duplicity-1.2.3.dev43/duplicity/backends/onedrivebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    17385 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/adbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     8839 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/megav2backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    10572 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/swiftbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     4474 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/rclonebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9599 2023-03-16 15:21:39.000000 duplicity-1.2.3.dev43/duplicity/backends/b2backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2645 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/tahoebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    16496 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/gdrivebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    13658 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/ssh_pexpect_backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9393 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/gdocsbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     8216 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/giobackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     6895 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/megabackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    13014 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/pydrivebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     5620 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/azurebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1116 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/__init__.py
--rw-r--r--   0 ken       (1000) ken       (1000)    19552 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/idrivedbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    15865 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/multibackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    20414 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/dpbxbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     7160 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/boxbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1154 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/cfbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    20735 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/webdavbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    10349 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/megav3backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2439 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/hubicbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    10027 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/lftpbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     6672 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/rsyncbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     5710 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/ncftpbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     4824 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/mediafirebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1327 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/s3_boto_backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2732 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/hsibackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9859 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/_boto_multi.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9178 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/par2backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    20341 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/ssh_paramiko_backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    12787 2023-03-07 16:20:30.000000 duplicity-1.2.3.dev43/duplicity/backends/pcabackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     9999 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/s3_boto3_backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     5693 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/jottacloudbackend.py
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity/backends/pyrax_identity/
--rw-r--r--   0 ken       (1000) ken       (1000)    10241 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/pyrax_identity/hubic.py
--rw-r--r--   0 ken       (1000) ken       (1000)      903 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/pyrax_identity/__init__.py
--rw-r--r--   0 ken       (1000) ken       (1000)    10199 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/imapbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     3948 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/_cf_cloudfiles.py
--rw-r--r--   0 ken       (1000) ken       (1000)     5243 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/_cf_pyrax.py
--rw-r--r--   0 ken       (1000) ken       (1000)    15676 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/_boto_single.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2579 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/README
--rw-r--r--   0 ken       (1000) ken       (1000)     2368 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backends/sxbackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    12292 2023-04-03 18:52:11.000000 duplicity-1.2.3.dev43/duplicity/backends/xorrisobackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     6631 2023-03-15 14:35:48.000000 duplicity-1.2.3.dev43/duplicity/backends/slatebackend.py
--rw-r--r--   0 ken       (1000) ken       (1000)     8735 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/dup_threading.py
--rw-r--r--   0 ken       (1000) ken       (1000)    68721 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/dup_main.py
--rw-r--r--   0 ken       (1000) ken       (1000)    27197 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/backend.py
--rw-r--r--   0 ken       (1000) ken       (1000)    11553 2023-03-12 17:52:34.000000 duplicity-1.2.3.dev43/duplicity/config.py
--rw-r--r--   0 ken       (1000) ken       (1000)     7714 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/globmatch.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1165 2023-04-05 14:51:14.000000 duplicity-1.2.3.dev43/duplicity/__init__.py
--rw-r--r--   0 ken       (1000) ken       (1000)     8762 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/librsync.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2789 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/errors.py
--rw-r--r--   0 ken       (1000) ken       (1000)    10812 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/tempdir.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1303 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/tarfile.py
--rw-r--r--   0 ken       (1000) ken       (1000)    13906 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/progress.py
--rw-r--r--   0 ken       (1000) ken       (1000)    17508 2023-03-07 18:50:39.000000 duplicity-1.2.3.dev43/duplicity/gpg.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2708 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/filechunkio.py
--rw-r--r--   0 ken       (1000) ken       (1000)    22629 2023-03-07 18:50:39.000000 duplicity-1.2.3.dev43/duplicity/patchdir.py
--rw-r--r--   0 ken       (1000) ken       (1000)    18558 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/manifest.py
--rw-r--r--   0 ken       (1000) ken       (1000)    17200 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/file_naming.py
--rw-r--r--   0 ken       (1000) ken       (1000)    14510 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/_librsyncmodule.c
--rw-r--r--   0 ken       (1000) ken       (1000)    47632 2023-03-12 18:11:30.000000 duplicity-1.2.3.dev43/duplicity/dup_collections.py
--rw-r--r--   0 ken       (1000) ken       (1000)     2514 2023-03-24 17:54:59.000000 duplicity-1.2.3.dev43/duplicity/robust.py
--rw-r--r--   0 ken       (1000) ken       (1000)    58255 2023-03-12 19:33:36.000000 duplicity-1.2.3.dev43/duplicity/commandline.py
--rw-r--r--   0 ken       (1000) ken       (1000)    27140 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/diffdir.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1698 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/cached_ops.py
--rw-r--r--   0 ken       (1000) ken       (1000)    12804 2023-03-28 15:21:45.000000 duplicity-1.2.3.dev43/duplicity/util.py
--rw-r--r--   0 ken       (1000) ken       (1000)     8286 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/dup_temp.py
--rw-r--r--   0 ken       (1000) ken       (1000)    10812 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/asyncscheduler.py
--rw-r--r--   0 ken       (1000) ken       (1000)    13348 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/statistics.py
--rw-r--r--   0 ken       (1000) ken       (1000)    15187 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/lazy.py
--rw-r--r--   0 ken       (1000) ken       (1000)    29244 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/path.py
--rw-r--r--   0 ken       (1000) ken       (1000)    29548 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/duplicity/selection.py
--rw-r--r--   0 ken       (1000) ken       (1000)    16103 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/duplicity/log.py
--rw-r--r--   0 ken       (1000) ken       (1000)    23813 2023-03-15 14:35:48.000000 duplicity-1.2.3.dev43/duplicity/gpginterface.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1284 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/README-LOG.md
--rw-rw-r--   0 ken       (1000) ken       (1000)     2770 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/PKG-INFO
--rw-r--r--   0 ken       (1000) ken       (1000)    18028 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/COPYING
--rw-r--r--   0 ken       (1000) ken       (1000)      164 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/crowdin.yml
--rw-r--r--   0 ken       (1000) ken       (1000)     3250 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/README-SNAP.md
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/
--rw-r--r--   0 ken       (1000) ken       (1000)    43314 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/fi_FI.po
--rw-r--r--   0 ken       (1000) ken       (1000)    62584 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ru_MD.po
--rw-r--r--   0 ken       (1000) ken       (1000)    57878 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/es_ES.po
--rw-r--r--   0 ken       (1000) ken       (1000)    54340 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/pt_BR.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/uk_UA/
--rw-rw-r--   0 ken       (1000) ken       (1000)    32646 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/uk_UA/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    44636 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/en_GB.po
--rw-r--r--   0 ken       (1000) ken       (1000)    52949 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/zh_CN.po
--rw-r--r--   0 ken       (1000) ken       (1000)    43316 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/no_NO.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/nl_NL/
--rw-rw-r--   0 ken       (1000) ken       (1000)      512 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/nl_NL/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    54422 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/it_IT.po
--rw-r--r--   0 ken       (1000) ken       (1000)    58422 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/cs_CZ.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/hu_HU/
--rw-rw-r--   0 ken       (1000) ken       (1000)    25308 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/hu_HU/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    59909 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/de_DE.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_ES/
--rw-rw-r--   0 ken       (1000) ken       (1000)    33152 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_ES/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_HK/
--rw-rw-r--   0 ken       (1000) ken       (1000)      533 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_HK/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43313 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/da_DK.po
--rw-r--r--   0 ken       (1000) ken       (1000)    55236 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/pl_PL.po
--rw-r--r--   0 ken       (1000) ken       (1000)    43325 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/nl_SR.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/vi_VN/
--rw-rw-r--   0 ken       (1000) ken       (1000)      510 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/vi_VN/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43314 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ca_ES.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/nl_BE/
--rw-rw-r--   0 ken       (1000) ken       (1000)      524 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/nl_BE/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43735 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/el_GR.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/it_IT/
--rw-rw-r--   0 ken       (1000) ken       (1000)    25347 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/it_IT/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43333 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/zh_HK.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_UA/
--rw-rw-r--   0 ken       (1000) ken       (1000)    32877 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_UA/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_EM/
--rw-rw-r--   0 ken       (1000) ken       (1000)    33161 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_EM/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43308 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ja_JP.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/pt_PT/
--rw-rw-r--   0 ken       (1000) ken       (1000)      520 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/pt_PT/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_TW/
--rw-rw-r--   0 ken       (1000) ken       (1000)      522 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_TW/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    59921 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/de_AT.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_GB/
--rw-rw-r--   0 ken       (1000) ken       (1000)     3375 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_GB/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/cs_CZ/
--rw-rw-r--   0 ken       (1000) ken       (1000)    34670 2023-04-05 14:51:12.000000 duplicity-1.2.3.dev43/po/cs_CZ/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/pl_PL/
--rw-rw-r--   0 ken       (1000) ken       (1000)    26950 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/pl_PL/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43332 2023-03-20 16:30:59.000000 duplicity-1.2.3.dev43/po/en_US.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_US/
--rw-rw-r--   0 ken       (1000) ken       (1000)    33167 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_US/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/he_IL/
--rw-rw-r--   0 ken       (1000) ken       (1000)      964 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/he_IL/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43312 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/nl_NL.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_BY/
--rw-rw-r--   0 ken       (1000) ken       (1000)    32877 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_BY/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_US/
--rw-rw-r--   0 ken       (1000) ken       (1000)      532 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_US/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ar_SA/
--rw-rw-r--   0 ken       (1000) ken       (1000)      598 2023-04-05 14:51:12.000000 duplicity-1.2.3.dev43/po/ar_SA/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/pt_BR/
--rw-rw-r--   0 ken       (1000) ken       (1000)    24541 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/pt_BR/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/tr_TR/
--rw-rw-r--   0 ken       (1000) ken       (1000)     4256 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/tr_TR/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/af_ZA/
--rw-rw-r--   0 ken       (1000) ken       (1000)      516 2023-04-05 14:51:12.000000 duplicity-1.2.3.dev43/po/af_ZA/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)     1184 2023-01-25 19:30:41.000000 duplicity-1.2.3.dev43/po/POTFILES.skip
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/nl_SR/
--rw-rw-r--   0 ken       (1000) ken       (1000)      525 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/nl_SR/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_RU/
--rw-rw-r--   0 ken       (1000) ken       (1000)    32865 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_RU/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    62584 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ru_BY.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ca_ES/
--rw-rw-r--   0 ken       (1000) ken       (1000)      514 2023-04-05 14:51:12.000000 duplicity-1.2.3.dev43/po/ca_ES/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43399 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/sr_SP.po
--rw-r--r--   0 ken       (1000) ken       (1000)    43322 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/zh_TW.po
--rw-r--r--   0 ken       (1000) ken       (1000)    62584 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ru_UA.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ko_KR/
--rw-rw-r--   0 ken       (1000) ken       (1000)     7034 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ko_KR/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43727 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/en_AU.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/fi_FI/
--rw-rw-r--   0 ken       (1000) ken       (1000)      514 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/fi_FI/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    62186 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/uk_UA.po
--rw-r--r--   0 ken       (1000) ken       (1000)     2285 2023-01-25 19:29:23.000000 duplicity-1.2.3.dev43/po/POTFILES.in
--rwxr-xr-x   0 ken       (1000) ken       (1000)      361 2023-01-13 18:29:53.000000 duplicity-1.2.3.dev43/po/update-pot
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/sr_SP/
--rw-rw-r--   0 ken       (1000) ken       (1000)      599 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/sr_SP/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/de_DE/
--rw-rw-r--   0 ken       (1000) ken       (1000)    36226 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/de_DE/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/de_AT/
--rw-rw-r--   0 ken       (1000) ken       (1000)    36238 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/de_AT/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    62572 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ru_RU.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/sv_SE/
--rw-rw-r--   0 ken       (1000) ken       (1000)    24543 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/sv_SE/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    57344 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/fr_FR.po
--rw-r--r--   0 ken       (1000) ken       (1000)    43320 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/pt_PT.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ro_RO/
--rw-rw-r--   0 ken       (1000) ken       (1000)      559 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ro_RO/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43398 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ar_SA.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/el_GR/
--rw-rw-r--   0 ken       (1000) ken       (1000)     1574 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/el_GR/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43549 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/he_IL.po
--rw-r--r--   0 ken       (1000) ken       (1000)    54689 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/hu_HU.po
--rw-r--r--   0 ken       (1000) ken       (1000)    43324 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/nl_BE.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_AU/
--rw-rw-r--   0 ken       (1000) ken       (1000)     1412 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_AU/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43329 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/zh_MO.po
--rw-r--r--   0 ken       (1000) ken       (1000)    44655 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/tr_TR.po
--rw-r--r--   0 ken       (1000) ken       (1000)      276 2023-01-25 19:29:23.000000 duplicity-1.2.3.dev43/po/LINGUAS
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/da_DK/
--rw-rw-r--   0 ken       (1000) ken       (1000)      513 2023-04-05 14:51:12.000000 duplicity-1.2.3.dev43/po/da_DK/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_MO/
--rw-rw-r--   0 ken       (1000) ken       (1000)      529 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_MO/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_PR/
--rw-rw-r--   0 ken       (1000) ken       (1000)    33165 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_PR/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_SG/
--rw-rw-r--   0 ken       (1000) ken       (1000)      533 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_SG/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ja_JP/
--rw-rw-r--   0 ken       (1000) ken       (1000)      508 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ja_JP/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    57893 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/es_US.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_MX/
--rw-rw-r--   0 ken       (1000) ken       (1000)    33160 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/es_MX/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_MD/
--rw-rw-r--   0 ken       (1000) ken       (1000)    32877 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/ru_MD/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43333 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/zh_SG.po
--rw-r--r--   0 ken       (1000) ken       (1000)    57886 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/es_MX.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_CN/
--rw-rw-r--   0 ken       (1000) ken       (1000)    25656 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/zh_CN/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43330 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/en_PR.po
--rw-r--r--   0 ken       (1000) ken       (1000)    43310 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/vi_VN.po
--rw-r--r--   0 ken       (1000) ken       (1000)    53746 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/sv_SE.po
--rw-r--r--   0 ken       (1000) ken       (1000)    57887 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/es_EM.po
--rw-r--r--   0 ken       (1000) ken       (1000)    43316 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/af_ZA.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/no_NO/
--rw-rw-r--   0 ken       (1000) ken       (1000)      516 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/no_NO/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    57891 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/es_PR.po
--rw-r--r--   0 ken       (1000) ken       (1000)     1174 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/po/Makevars
--rw-r--r--   0 ken       (1000) ken       (1000)    46050 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ko_KR.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_PR/
--rw-rw-r--   0 ken       (1000) ken       (1000)      530 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/en_PR/duplicity.mo
--rw-r--r--   0 ken       (1000) ken       (1000)    43559 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/duplicity.pot
--rw-r--r--   0 ken       (1000) ken       (1000)    43359 2023-02-06 15:48:19.000000 duplicity-1.2.3.dev43/po/ro_RO.po
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/fr_FR/
--rw-rw-r--   0 ken       (1000) ken       (1000)    29965 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/po/fr_FR/duplicity.mo
-drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity.egg-info/
--rw-rw-r--   0 ken       (1000) ken       (1000)       18 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity.egg-info/top_level.txt
--rw-rw-r--   0 ken       (1000) ken       (1000)       17 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity.egg-info/requires.txt
--rw-rw-r--   0 ken       (1000) ken       (1000)     2770 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity.egg-info/PKG-INFO
--rw-rw-r--   0 ken       (1000) ken       (1000)        1 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity.egg-info/dependency_links.txt
--rw-rw-r--   0 ken       (1000) ken       (1000)     7689 2023-04-05 14:51:13.000000 duplicity-1.2.3.dev43/duplicity.egg-info/SOURCES.txt
--rwxr-xr-x   0 ken       (1000) ken       (1000)    13544 2023-02-21 16:03:23.000000 duplicity-1.2.3.dev43/setup.py
--rw-r--r--   0 ken       (1000) ken       (1000)     1514 2023-03-21 18:05:37.000000 duplicity-1.2.3.dev43/README.md
--rw-r--r--   0 ken       (1000) ken       (1000)     1357 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/README-REPO.md
--rw-r--r--   0 ken       (1000) ken       (1000)     5364 2022-12-27 19:32:15.000000 duplicity-1.2.3.dev43/README-TESTING.md
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/
+-rw-r--r--   0 ken       (1000) ken       (1000)   109850 2023-07-10 16:11:39.000000 duplicity-2.0.0rc0/CHANGELOG.md
+-rw-r--r--   0 ken       (1000) ken       (1000)      101 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/setup.cfg
+-rw-r--r--   0 ken       (1000) ken       (1000)     1390 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/CONTRIBUTING.md
+-rw-r--r--   0 ken       (1000) ken       (1000)     2783 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/tox.ini
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/bin/
+-rwxr-xr-x   0 ken       (1000) ken       (1000)     4186 2023-07-04 20:13:43.000000 duplicity-2.0.0rc0/bin/duplicity
+-rw-r--r--   0 ken       (1000) ken       (1000)    97668 2023-07-10 18:01:50.000000 duplicity-2.0.0rc0/bin/duplicity.1
+-rw-r--r--   0 ken       (1000) ken       (1000)      753 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/requirements.txt
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/snap/
+-rw-r--r--   0 ken       (1000) ken       (1000)     4386 2023-07-10 18:01:50.000000 duplicity-2.0.0rc0/snap/snapcraft.yaml
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/snap/local/
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      186 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/snap/local/debug.sh
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      110 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/snap/local/launcher.sh
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/testing/
+-rw-r--r--   0 ken       (1000) ken       (1000)   319661 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/testfiles.tar.gz
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/testing/unit/
+-rw-r--r--   0 ken       (1000) ken       (1000)     8120 2023-07-09 16:03:55.000000 duplicity-2.0.0rc0/testing/unit/test_gpginterface.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    11294 2023-07-08 15:56:58.000000 duplicity-2.0.0rc0/testing/unit/test_patchdir.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     6077 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/unit/test_dup_time.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    11572 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_lazy.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    11157 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_cli_main.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     5578 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/unit/test_statistics.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    13945 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/unit/test_globmatch.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     5703 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_manifest.py
+-rw-r--r--   0 ken       (1000) ken       (1000)      918 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/unit/__init__.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    11690 2023-07-08 16:29:35.000000 duplicity-2.0.0rc0/testing/unit/test_collections.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2447 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_dup_temp.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     5402 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/unit/test_file_naming.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1178 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_tarfile.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12711 2023-07-08 19:32:57.000000 duplicity-2.0.0rc0/testing/unit/test_diffdir.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2483 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_tempdir.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10385 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/unit/test_backend_instance.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2887 2023-07-08 16:58:12.000000 duplicity-2.0.0rc0/testing/unit/test_path.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1432 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_util.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8284 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/unit/test_gpg.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12151 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    65210 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/unit/test_selection.py
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/testing/overrides/
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/testing/overrides/bin/
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      155 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/overrides/bin/ncftpget
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      512 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/overrides/bin/lftp
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      155 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/overrides/bin/ncftpput
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      423 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/overrides/bin/hsi
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      416 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/overrides/bin/tahoe
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      558 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/overrides/bin/ncftpls
+-rw-r--r--   0 ken       (1000) ken       (1000)       75 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/testing/overrides/__init__.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     4634 2023-07-08 15:56:58.000000 duplicity-2.0.0rc0/testing/__init__.py
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      878 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/run-tests
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/testing/functional/
+-rw-r--r--   0 ken       (1000) ken       (1000)     2385 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/functional/test_log.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     9537 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/functional/test_final.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1612 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/functional/test_badupload.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     3287 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/functional/test_cleanup.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8328 2023-07-08 18:48:11.000000 duplicity-2.0.0rc0/testing/functional/__init__.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8640 2023-07-07 20:21:14.000000 duplicity-2.0.0rc0/testing/functional/test_verify.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    18677 2023-07-09 17:25:58.000000 duplicity-2.0.0rc0/testing/functional/test_restart.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    96829 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/functional/test_selection.py
+-rw-r--r--   0 ken       (1000) ken       (1000)      941 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/testing/conftest.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     3196 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/testing/test_code.py
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/testing/gnupg/
+-rw-r--r--   0 ken       (1000) ken       (1000)      145 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/gnupg/gpg-agent.conf
+-rw-r--r--   0 ken       (1000) ken       (1000)     3567 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/gnupg/pubring.gpg
+-rw-r--r--   0 ken       (1000) ken       (1000)     7549 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/gnupg/secring.gpg
+-rw-r--r--   0 ken       (1000) ken       (1000)      425 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/gnupg/gpg.conf
+-rw-r--r--   0 ken       (1000) ken       (1000)      255 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/gnupg/README
+-rw-r--r--   0 ken       (1000) ken       (1000)     1440 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/testing/gnupg/trustdb.gpg
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity/
+-rw-r--r--   0 ken       (1000) ken       (1000)    34532 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/cli_data.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10701 2023-07-09 16:18:42.000000 duplicity-2.0.0rc0/duplicity/dup_time.py
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity/backends/
+-rw-r--r--   0 ken       (1000) ken       (1000)     3040 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/backends/localbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    16080 2023-07-09 17:15:07.000000 duplicity-2.0.0rc0/duplicity/backends/onedrivebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    16591 2023-07-09 17:11:10.000000 duplicity-2.0.0rc0/duplicity/backends/adbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8565 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/megav2backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10233 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/swiftbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     4284 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/backends/rclonebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8757 2023-07-09 17:03:47.000000 duplicity-2.0.0rc0/duplicity/backends/b2backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2572 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/backends/tahoebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    16132 2023-07-09 16:25:43.000000 duplicity-2.0.0rc0/duplicity/backends/gdrivebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12971 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/ssh_pexpect_backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     9159 2023-07-09 17:16:51.000000 duplicity-2.0.0rc0/duplicity/backends/gdocsbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8117 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/backends/giobackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     6624 2023-07-09 16:25:43.000000 duplicity-2.0.0rc0/duplicity/backends/megabackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12793 2023-07-09 17:10:30.000000 duplicity-2.0.0rc0/duplicity/backends/pydrivebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     5652 2023-07-09 17:03:47.000000 duplicity-2.0.0rc0/duplicity/backends/azurebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1115 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/backends/__init__.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    19138 2023-07-09 17:03:47.000000 duplicity-2.0.0rc0/duplicity/backends/idrivedbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    15477 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/multibackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    19777 2023-07-09 16:51:34.000000 duplicity-2.0.0rc0/duplicity/backends/dpbxbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     7103 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/backends/boxbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1152 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/backends/cfbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    19213 2023-07-09 17:03:47.000000 duplicity-2.0.0rc0/duplicity/backends/webdavbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10028 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/megav3backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2399 2023-07-09 16:51:34.000000 duplicity-2.0.0rc0/duplicity/backends/hubicbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     9387 2023-07-09 17:03:47.000000 duplicity-2.0.0rc0/duplicity/backends/lftpbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     6455 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/backends/rsyncbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     5393 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/ncftpbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     4719 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/duplicity/backends/mediafirebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2628 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/duplicity/backends/hsibackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8822 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/par2backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    19474 2023-07-09 16:44:03.000000 duplicity-2.0.0rc0/duplicity/backends/ssh_paramiko_backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12468 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/pcabackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10535 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/duplicity/backends/s3_boto3_backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     5695 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/duplicity/backends/jottacloudbackend.py
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity/backends/pyrax_identity/
+-rw-r--r--   0 ken       (1000) ken       (1000)     9699 2023-07-09 17:03:47.000000 duplicity-2.0.0rc0/duplicity/backends/pyrax_identity/hubic.py
+-rw-r--r--   0 ken       (1000) ken       (1000)      903 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/duplicity/backends/pyrax_identity/__init__.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     9732 2023-07-09 16:42:24.000000 duplicity-2.0.0rc0/duplicity/backends/imapbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     3905 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/backends/_cf_cloudfiles.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     5141 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/backends/_cf_pyrax.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2579 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/duplicity/backends/README
+-rw-r--r--   0 ken       (1000) ken       (1000)     2310 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/backends/sxbackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12227 2023-07-07 20:19:43.000000 duplicity-2.0.0rc0/duplicity/backends/xorrisobackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     6461 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/backends/slatebackend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     7237 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/dup_threading.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    62036 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/dup_main.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    26344 2023-07-09 16:18:42.000000 duplicity-2.0.0rc0/duplicity/backend.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10934 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/config.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     7525 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/globmatch.py
+-rw-r--r--   0 ken       (1000) ken       (1000)      995 2023-07-10 18:01:50.000000 duplicity-2.0.0rc0/duplicity/__init__.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8427 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/librsync.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2752 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/errors.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10624 2023-07-08 15:56:57.000000 duplicity-2.0.0rc0/duplicity/tempdir.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1262 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/tarfile.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    13789 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/progress.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    17370 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/gpg.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2627 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/filechunkio.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    21775 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/patchdir.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    18003 2023-07-09 16:18:42.000000 duplicity-2.0.0rc0/duplicity/manifest.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    14877 2023-07-08 19:15:08.000000 duplicity-2.0.0rc0/duplicity/file_naming.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    14510 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/duplicity/_librsyncmodule.c
+-rw-r--r--   0 ken       (1000) ken       (1000)    46560 2023-07-09 17:10:30.000000 duplicity-2.0.0rc0/duplicity/dup_collections.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     2476 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/robust.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    26076 2023-07-08 15:56:57.000000 duplicity-2.0.0rc0/duplicity/diffdir.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1668 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/cached_ops.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     9893 2023-07-07 20:19:41.000000 duplicity-2.0.0rc0/duplicity/util.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     8088 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/dup_temp.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12444 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/cli_util.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    10093 2023-07-09 16:18:42.000000 duplicity-2.0.0rc0/duplicity/asyncscheduler.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     9046 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/cli_main.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    12913 2023-07-09 16:03:54.000000 duplicity-2.0.0rc0/duplicity/statistics.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    15046 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/lazy.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    28629 2023-07-07 20:19:42.000000 duplicity-2.0.0rc0/duplicity/path.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    28636 2023-07-09 16:25:43.000000 duplicity-2.0.0rc0/duplicity/selection.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    15815 2023-07-09 16:18:42.000000 duplicity-2.0.0rc0/duplicity/log.py
+-rw-r--r--   0 ken       (1000) ken       (1000)    23296 2023-07-04 20:13:41.000000 duplicity-2.0.0rc0/duplicity/gpginterface.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1284 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/README-LOG.md
+-rw-rw-r--   0 ken       (1000) ken       (1000)     2360 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/PKG-INFO
+-rw-r--r--   0 ken       (1000) ken       (1000)    18028 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/COPYING
+-rw-r--r--   0 ken       (1000) ken       (1000)      164 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/crowdin.yml
+-rw-r--r--   0 ken       (1000) ken       (1000)     3250 2023-06-30 18:00:21.000000 duplicity-2.0.0rc0/README-SNAP.md
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/
+-rw-r--r--   0 ken       (1000) ken       (1000)    43776 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/fi_FI.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    63046 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ru_MD.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    58340 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/es_ES.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    54802 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/pt_BR.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/uk_UA/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    32646 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/uk_UA/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    45098 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/en_GB.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    53411 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/zh_CN.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    43778 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/no_NO.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/nl_NL/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    11565 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/nl_NL/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    54884 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/it_IT.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    58884 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/cs_CZ.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/hu_HU/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    25308 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/hu_HU/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    60371 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/de_DE.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_ES/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    33152 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/es_ES/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/zh_HK/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      533 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/zh_HK/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43775 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/da_DK.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    55698 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/pl_PL.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    43787 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/nl_SR.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/vi_VN/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      510 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/vi_VN/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43775 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/po/ca_ES.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/nl_BE/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      524 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/nl_BE/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    44197 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/el_GR.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/it_IT/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    25347 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/it_IT/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43795 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/zh_HK.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ru_UA/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    32879 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/ru_UA/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_EM/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    33161 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_EM/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43770 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ja_JP.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/pt_PT/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      520 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/pt_PT/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/zh_TW/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      522 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/zh_TW/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    60383 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/de_AT.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/en_GB/
+-rw-rw-r--   0 ken       (1000) ken       (1000)     3375 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/en_GB/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/cs_CZ/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    34670 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/cs_CZ/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/pl_PL/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    26950 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/pl_PL/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43794 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/en_US.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_US/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    33167 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_US/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/he_IL/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      964 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/he_IL/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    48337 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/nl_NL.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ru_BY/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    32877 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/ru_BY/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/en_US/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      532 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/en_US/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ar_SA/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      598 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/ar_SA/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/pt_BR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    24541 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/pt_BR/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/tr_TR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)     4256 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/tr_TR/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/af_ZA/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      516 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/af_ZA/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)     1184 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/POTFILES.skip
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/nl_SR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      525 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/nl_SR/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ru_RU/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    32928 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/ru_RU/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    63046 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ru_BY.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ca_ES/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      514 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/ca_ES/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43861 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/sr_SP.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    43784 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/zh_TW.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    63048 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ru_UA.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ko_KR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)     7034 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ko_KR/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    44189 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/en_AU.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/fi_FI/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      514 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/fi_FI/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    62648 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/uk_UA.po
+-rw-r--r--   0 ken       (1000) ken       (1000)     2322 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/POTFILES.in
+-rwxr-xr-x   0 ken       (1000) ken       (1000)      361 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/update-pot
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/sr_SP/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      599 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/sr_SP/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/de_DE/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    36226 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/de_DE/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/de_AT/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    36238 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/de_AT/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    63048 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ru_RU.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/sv_SE/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    24543 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/sv_SE/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    57806 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/fr_FR.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    43782 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/pt_PT.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ro_RO/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      559 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ro_RO/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43860 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ar_SA.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/el_GR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)     1574 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/el_GR/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    44011 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/he_IL.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    55151 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/hu_HU.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    43786 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/nl_BE.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/en_AU/
+-rw-rw-r--   0 ken       (1000) ken       (1000)     1412 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/en_AU/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43791 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/zh_MO.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    45117 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/tr_TR.po
+-rw-r--r--   0 ken       (1000) ken       (1000)      276 2023-05-26 15:53:32.000000 duplicity-2.0.0rc0/po/LINGUAS
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/da_DK/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      513 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/da_DK/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/zh_MO/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      529 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/zh_MO/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_PR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    33165 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_PR/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/zh_SG/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      533 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/zh_SG/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ja_JP/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      508 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/ja_JP/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    58355 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/es_US.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_MX/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    33160 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/es_MX/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/ru_MD/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    32877 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/ru_MD/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43795 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/zh_SG.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    58348 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/es_MX.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/zh_CN/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    25656 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/zh_CN/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    43792 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/en_PR.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    43771 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/po/vi_VN.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    54208 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/sv_SE.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    58349 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/es_EM.po
+-rw-r--r--   0 ken       (1000) ken       (1000)    43778 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/af_ZA.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/no_NO/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      516 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/no_NO/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    58353 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/es_PR.po
+-rw-r--r--   0 ken       (1000) ken       (1000)     1174 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/po/Makevars
+-rw-r--r--   0 ken       (1000) ken       (1000)    46512 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ko_KR.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/en_PR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)      530 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/en_PR/duplicity.mo
+-rw-r--r--   0 ken       (1000) ken       (1000)    44024 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/duplicity.pot
+-rw-r--r--   0 ken       (1000) ken       (1000)    43821 2023-06-30 18:02:20.000000 duplicity-2.0.0rc0/po/ro_RO.po
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/po/fr_FR/
+-rw-rw-r--   0 ken       (1000) ken       (1000)    29965 2023-07-10 18:01:48.000000 duplicity-2.0.0rc0/po/fr_FR/duplicity.mo
+drwxrwxr-x   0 ken       (1000) ken       (1000)        0 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity.egg-info/
+-rw-r--r--   0 ken       (1000) ken       (1000)       18 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity.egg-info/top_level.txt
+-rw-r--r--   0 ken       (1000) ken       (1000)       10 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity.egg-info/requires.txt
+-rw-r--r--   0 ken       (1000) ken       (1000)     2360 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity.egg-info/PKG-INFO
+-rw-r--r--   0 ken       (1000) ken       (1000)        1 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity.egg-info/dependency_links.txt
+-rw-r--r--   0 ken       (1000) ken       (1000)     7481 2023-07-10 18:01:49.000000 duplicity-2.0.0rc0/duplicity.egg-info/SOURCES.txt
+-rwxr-xr-x   0 ken       (1000) ken       (1000)    12544 2023-07-08 19:08:19.000000 duplicity-2.0.0rc0/setup.py
+-rw-r--r--   0 ken       (1000) ken       (1000)     1399 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/README.md
+-rw-r--r--   0 ken       (1000) ken       (1000)     1315 2023-07-01 15:25:28.000000 duplicity-2.0.0rc0/README-REPO.md
+-rw-r--r--   0 ken       (1000) ken       (1000)     5364 2023-04-24 17:35:53.000000 duplicity-2.0.0rc0/README-TESTING.md
```

### Comparing `duplicity-1.2.3.dev43/CHANGELOG.md` & `duplicity-2.0.0rc0/CHANGELOG.md`

 * *Files 13% similar despite different names*

```diff
@@ -1,29 +1,523 @@
-## (unreleased)
+## rel.2.0.0rc0 (2023-07-09)
+
+### Fix
+
+* Finish conversions to f-strings. [Kenneth Loafman]
+
+  See https://github.com/ikamensh/flynt/issues/185
+
+* Convert to f-strings via 'flynt -tc -tj'. [Kenneth Loafman]
+
+* With py2 gone remove unicode string adornments. [Kenneth Loafman]
+
+* Fix implied command when target is empty. [Kenneth Loafman]
+
+
+## rel.2.0.0b2 (2023-07-02)
+
+### Changes
+
+* Update CHANGELOG.md. [Kenneth Loafman]
+
+* Fix syntax error in .gitlab-ci.yml. [Kenneth Loafman]
+
+* Fix website to only run with WEBSITE\_TRIGGER\_TOKEN. [Kenneth Loafman]
+
+* Fix PEP8 issue.  Update CHANGELOG.md. [Kenneth Loafman]
+
+* Resolve some minor merge issues. [Kenneth Loafman]
+
+* Whoops, used f-string to fix #716. Fixed. [Kenneth Loafman]
+
+* Fix #716.  Print filename on read error. [Kenneth Loafman]
+
+* Fix #709.  Add docs on passphrase encryption used. [Kenneth Loafman]
+
+* Fixes for handling snaps again. [Kenneth Loafman]
+
+  Use requirements.txt instead of internal list.
+
+* Fix #707 for test\_get\_stats\_string. [Kenneth Loafman]
+
+  Move UTC set/unset to testing.__init__.
+
+* Fix #707 for test\_get\_stats\_string. [Kenneth Loafman]
+
+  Base time on UTC rather than where the test is run.
+
+* Fix #707 for test\_get\_stats\_string. [Kenneth Loafman]
+
+  Base time on UTC rather than where the test is run.
+
+* Fix #707 for rclone backend testing. [Kenneth Loafman]
+
+  Create 'duptest' config if needed, then remove after   tests are
+  complete.
+  Add some more pytest options to tox.ini.
+
+* Comment out test\_path:test\_compare, flaky. [Kenneth Loafman]
+
+  Fixes #707 - 1.2.3 test failure
+
+* Force cryptography<3.4 for py2 support. [Kenneth Loafman]
+
+* Test if requirements.txt changes. [Kenneth Loafman]
+
+* Revert back to tox < 4.0. [Kenneth Loafman]
+
+### Fix
+
+* Fix #710. Missing Content-Type header on webdav. [Kenneth Loafman]
+
+* S3 filename encoding. [Thomas Laubrock]
+
+* Fix #712 "if cache lost. `*.sigtar.gpg` files not accessible" [Thomas Laubrock]
+
+  solution, do not add signature files to glacier
+
+* Handle read-only remote parent folder better in gio backend. [Michael Terry]
+
+
+## rel.2.0.0b1 (2023-06-30)
+
+### Changes
+
+* Update CHANGELOG.md. [Kenneth Loafman]
+
+* Some basic PEP8 and code cleanup. [Kenneth Loafman]
+
+* Set socket default timeout in CLI. [Kenneth Loafman]
+
+* Fixes for deprecated/changed options. [Kenneth Loafman]
+
+
+## rel.2.0.0b0 (2023-06-24)
+
+### Changes
+
+* Misc changes for compatibility. [Kenneth Loafman]
+
+* Fix #24.  Allow users to tune copy block size. [Kenneth Loafman]
+
+  - Added --copy-blocksize, default 128k to options.   - Added tests for
+  same and improved other testss.
+
+* Fix .gitlab-ci.yml to skip website step if no token. [Kenneth Loafman]
+
+
+## rel.2.0.0a2 (2023-06-14)
+
+### Changes
+
+* Remove pathvalidate from use.  Fixes #27. [Kenneth Loafman]
+
+
+## rel.2.0.0a1 (2023-06-14)
+
+### Changes
+
+* More CLI improvements. [Kenneth Loafman]
+
+  - Improve error message for implied commands.   - Code and testing
+  clean up.   - Remove deprecated option handling.
+
+* Add implied backup/restore back. [Kenneth Loafman]
+
+* CLI improvements and cleanup. [Kenneth Loafman]
+
+  - Remove 'backup' command.   - Preparse options for config.
+
+* Minor cleanup, rm dead code. [Kenneth Loafman]
+
+* RcloneBackendTest now creates its own config. [Kenneth Loafman]
+
+* "--ignore-errors" gets proper handling in CLI. [Kenneth Loafman]
+
+### Fix
+
+* Fix #22, “--no-compression” doesn't have effect. [Kenneth Loafman]
+
+* Fix .gitlab-ci.yml file syntax error. [Kenneth Loafman]
+
+
+## rel.2.0.0a0 (2023-06-01)
+
+### Changes
+
+* Fix initial version. [Kenneth Loafman]
+
+* Give up. Let setup mangle as it will. [Kenneth Loafman]
+
+* Use semver tags, let setup mangle. [Kenneth Loafman]
+
+* Make PEP 440 compatible, not semver yet. [Kenneth Loafman]
+
+* Changes to allow alpha, beta, rc prerelease. [Kenneth Loafman]
+
+* Update gitlab-ci.yml. [Kenneth Loafman]
+
+* Update gitlab-ci.yml. [Kenneth Loafman]
+
+* Remove 'rdiffdir'.  Not used. [Kenneth Loafman]
+
+* Add 'make sdist' to Makefile. [Kenneth Loafman]
+
+* Update .gitignore. [Kenneth Loafman]
+
+* Setuptools\_scm.get\_version now uses 'fallback\_version'. [Kenneth Loafman]
+
+* Remove old s3\_boto\_backend.py. [Kenneth Loafman]
+
+  Deprecated options:   --s3-multipart-max-timeout   --s3-use-
+  multiprocessing   --s3-use-server-side-encryption   --s3-use-server-
+  side-kms-encryption
+  Retired error codes:   boto_old_style = 24   boto_lib_too_old = 25
+  boto_calling_format = 26
+
+* Remove spaces in version specs. [Kenneth Loafman]
+
+* Cleanup py2 cruft and more. [Kenneth Loafman]
+
+* Cleanup py2 cruft and more. [Kenneth Loafman]
+
+* Uncomment log.test\_command\_line\_error. [Kenneth Loafman]
+
+* Raise CommandLineError on deprecated/changed options. [Kenneth Loafman]
+
+* Whoops, don't move import\_backends. [Kenneth Loafman]
+
+* Fix code, tests, and do cleanup. [Kenneth Loafman]
+
+* Requirements and code cleanup. [Kenneth Loafman]
+
+* Whoops, fix code style. [Kenneth Loafman]
+
+* Add error/ignored msg for deprecated options. [Kenneth Loafman]
+
+* Some cli cleanup for subcommands. [Kenneth Loafman]
+
+* Normalize error handling in cli\_util.py. [Kenneth Loafman]
+
+* Some small command line fixes. [Michael Terry]
+
+  - Fix --verbosity   - Fix --log-fd   - Fix list-current-files
+
+* Clean out the last py2 cruft, I hope. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Some py2 to py3 cleanup. [Kenneth Loafman]
+
+  Ran '2to3 -f filter -f map -f xrange -f zip -f idioms'.  It put some
+  list calls around some of the stuff that returns iterators (redundant
+  in most cases I think).  Mainly it converted code to idiomatic python.
+
+* Update a couple of lists in conf.py. [Kenneth Loafman]
+
+* Whoops, still need Makefile in docs. [Kenneth Loafman]
+
+* Port ReadTheDocs changes from main branch. [Kenneth Loafman]
+
+* Port ReadTheDocs changes from main branch. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Fix version and required python version. [Kenneth Loafman]
+
+* Fix version and required python version. [Kenneth Loafman]
+
+* More refactoring and cleanup after merge. [Kenneth Loafman]
+
+* Change optparse to argparse.  Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse.  Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse.  Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse.  Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse.  Checkpoint. [Kenneth Loafman]
+
+* Change optparse to argparse. Checkpoint. [Kenneth Loafman]
+
+* Fix version and required python version. [Kenneth Loafman]
+
+* More refactoring and cleanup after merge. [Kenneth Loafman]
+
+* Change optparse to argparse.  Checkpoint. [Kenneth Loafman]
+
+  chg:usr: Change optparse to argparse.  Checkpoint.
+  chg:usr: Change optparse to argparse.  Checkpoint.
+  chg:usr: Change optparse to argparse.  Checkpoint.
+  chg:usr: Change optparse to argparse.  Checkpoint.
+
+* Add Note on --time-separator in manpage. [Kenneth Loafman]
+
+* Remove refs to --old/short-filenames.  Fix CI. [Kenneth Loafman]
+
+* Remove deprecated --short-filenames code. [Kenneth Loafman]
+
+* Remove deprecated --old-filenames code. [Kenneth Loafman]
+
+* Remove deprecated --gio code. [Kenneth Loafman]
+
+* Remove globbing deprecated code. [Kenneth Loafman]
+
+* Remove stdin deprecated code. [Kenneth Loafman]
+
+* Remove incomplete replicate command. [Kenneth Loafman]
+
+* Remove LINGUAS.  Replace with globbing. [Kenneth Loafman]
+
+* More cleanup from inspections. [Kenneth Loafman]
+
+* Util.fsdecode ==> os.fsdecode. [Kenneth Loafman]
+
+* Remove par2+ from target schema.  Does not matter. [Kenneth Loafman]
+
+* Add limits to chardet and urlllib to keep requests quiet. [Kenneth Loafman]
+
+* Lower test to ulimit 2048 and reverse filename order. [Kenneth Loafman]
+
+### Fix
+
+* Add a missing super() call in path.py. [Kenneth Loafman]
+
+* Add a missing method to some super calls. [Michael Terry]
+
+* Add missing ':''. [Kenneth Loafman]
+
+* Remove requirement for kerberos. [Kenneth Loafman]
+
+  - it's an optional package in webdavbackend.py   - it does not install
+  properly under Docker
+
+* Remove most 'pylint: disable=import-error'. [Kenneth Loafman]
+
+  - add packages to requirements   - 'gi' is not available on PyPi
+
+* Fix more py3 problems. [Kenneth Loafman]
+
+  - remove import future in some places,   - fix azurebackend.py to use
+  new azure.
+
+* Recurse glob to include duplicity/backends. [Kenneth Loafman]
+
+* Remove extra print statement. [Kenneth Loafman]
+
+* Add back test\_unadorned...  Cleanup. [Kenneth Loafman]
+
+* Fix pylint code issue. [Kenneth Loafman]
+
+* Fix case where gpg return code is None. [Kenneth Loafman]
+
+* Add pydevd-pycharm to requirements.txt. [Kenneth Loafman]
+
+* Fix to allow using PyCharm or LiClipse pydevd. [Kenneth Loafman]
+
+* Fix doctests to run again. [Kenneth Loafman]
+
+* Remove redundant code. [Kenneth Loafman]
+
+* Print stderr on gpg fail plus error code and string. [Kenneth Loafman]
+
+* Fix handling of gpg\_error\_codes. [Kenneth Loafman]
+
+  - return an 'unknown error code' message if not found   - ignore error
+  2 GPG_ERR_UNKNOWN_PACKET, was "invalid packet (ctb=14)"
+
+* Add \_() for translations of msgs in gpg\_error\_codes.py. [Kenneth Loafman]
+
+* Add stderr\_fp back in.  Too much noise otherwise. [Kenneth Loafman]
+
+* Remove stderr\_fp and use process return code to report errors. [Kenneth Loafman]
+
+  - Added file make_gpg_error_codes.py which creates gpg_error_codes.py.
+  - Modded gpg.py to remove use of stderr_fp, thus reducing FDs used.
+
+* Remove status\_fd if no sign\_key in gpg.py. [Kenneth Loafman]
+
+  - updated issue125.sh to use testing/gnupg keys   - issue125.sh passes
+  with `ulimit 1024`
+
+* Cleanup, remove all uses of logger\_fd. [Kenneth Loafman]
+
+* Add back status\_fd for signature verification. [Kenneth Loafman]
+
+* Remove unused GPG file handles. [Kenneth Loafman]
+
+  - removed status and logger filehandles for decrypt   -
+  testing/manual/issue125 now runs with 'ulimit -n 1536'
+
+* Fix indentation cause by adorning. [Kenneth Loafman]
+
+* Adorn python strings to make merges easier. [Kenneth Loafman]
+
+* Remove extra newline in print. [Kenneth Loafman]
+
+* Add list\_python\_files to tools. [Kenneth Loafman]
+
+* Move find/fix un/adorned to tools. [Kenneth Loafman]
+
+* Unadorn bin/duplicity and bin/rdiffdir. [Kenneth Loafman]
+
+* Recover and add find/fix un/adorned strings. [Kenneth Loafman]
+
+* Fix PEP8 issue. [Kenneth Loafman]
+
+* Optimize imports. [Kenneth Loafman]
+
+  - Remove 'from __future__ import .*'   - Remove 'from past.utils
+  import old_div'   - Replace old_div with / or // as needed.
+
+* Optimize imports. [Kenneth Loafman]
+
+* Use os modules fsencode/fsdecode not ours. [Kenneth Loafman]
+
+* Cleanup, remove test\_2to3. [Kenneth Loafman]
+
+* Remove support for Python 2.7.  Second pass. [Kenneth Loafman]
+
+  - remove test_unadorned_string_literals   - remove
+  find/fix_unadorned_strings.py   - fix u'string' to be just 'string'
+
+* Remove support for Python 2.7.  First pass. [Kenneth Loafman]
+
+  - remove 'import future' and its call   - remove 'import builtin *'
+  - remove conditionals based on sys.version_info   - remove mentions in
+  readme and other docs
+
+### Other
+
+* Merge remote-tracking branch 'alpha/duplicity-py3' into duplicity-py3. [Kenneth Loafman]
+
+  # Conflicts:   #     duplicity/cli_main.py
+
+* Merge branch 'main' into branch 'duplicity-py3' [Kenneth Loafman]
+
+* Merge branch 'main' into branch 'duplicity-py3' [Kenneth Loafman]
+
+* Merge branch main into branch duplicity-py3. [Kenneth Loafman]
+
+* Merge branch cleanup into branch duplicity-py3. [Kenneth Loafman]
+
+* Merge main into duplicity-py3. [Kenneth Loafman]
+
+* Merge main into branch duplicity-py3. [Kenneth Loafman]
+
+
+## rel.1.2.3 (2023-05-09)
 
 ### New
 
+* Xorriso backend for optical media. [T. K]
+
 * Onedrive for Business Support. [Tobias Simetsreiter]
 
 ### Changes
 
+* Fix tools release-prep & makechangelog. [Kenneth Loafman]
+
+* Fix tools/release-prep. [Kenneth Loafman]
+
+* Run po/update-pot. [Kenneth Loafman]
+
+* Update readthedocs.yaml. [Kenneth Loafman]
+
+* More ReadTheDocs changes. [Kenneth Loafman]
+
+* More ReadTheDocs changes. [Kenneth Loafman]
+
+* More ReadTheDocs changes. [Kenneth Loafman]
+
+* More ReadTheDocs changes. [Kenneth Loafman]
+
+* More ReadTheDocs changes. [Kenneth Loafman]
+
+* More ReadTheDocs changes. [Kenneth Loafman]
+
+* More ReadTheDocs changes. [Kenneth Loafman]
+
+* Change readthedocs.yaml. [Kenneth Loafman]
+
+* Change readthedocs.yaml. [Kenneth Loafman]
+
+* Update CHANGELOG.md. [Kenneth Loafman]
+
 * Fix spelling errors. [Barak A. Pearlmutter]
 
 * Chg:pkg:  Cleanup.  Add 'unsquashfs -l' test from @ede. [Kenneth Loafman]
 
 * Update Makefile 'make clean' list. [Kenneth Loafman]
 
 * Fix run website ci call after pushes/releases. [ede]
 
   [skip_tests]
 
 * Update version for Launchpad. [Kenneth Loafman]
 
 ### Fix
 
+* Use cryptography == 3.4.8. [Kenneth Loafman]
+
+  Fixes #703 - use same version as python3-cryptography in apt.
+
+* Warn rather than fail on op-not-supported restore errors. [Michael Terry]
+
 * Fixes #701 - unable to resume full backup to B2. [Kenneth Loafman]
 
   Now tries .name and .uc_name before failing.
 
 * Fixes #698 - backups without GPG decryption key. [Kenneth Loafman]
 
   Added option --no-check-remote to skip checking the   remote manifest.
@@ -118,16 +612,14 @@
 
 ### Changes
 
 * \_runtest\_dir on Darwin may use TMPDIR for testing. [Kenneth Loafman]
 
 * Update duplicity.pot. [Kenneth Loafman]
 
-* More changes to get release process working. [Kenneth Loafman]
-
 ### Fix
 
 * Fix to work with b2sdk 1.19.0. [Adam Jacobs]
 
 * Fix #692.  Redundant --encrypt option added in gpg.py. [Kenneth Loafman]
 
   Been around forever.  GPG 2.2.x is the first to detect.  Added   only
@@ -149,14 +641,16 @@
 * Add detailed step-by-step instructions. [ede]
 
 
 ## rel.1.2.1 (2022-12-02)
 
 ### Changes
 
+* More changes to get release process working. [Kenneth Loafman]
+
 * Fix for setuptools changes.  Add testing data files to mix. [Kenneth Loafman]
 
 
 ## rel.1.2.0 (2022-12-01)
 
 ### New
 
@@ -807,15 +1301,15 @@
 
 * Fix data\_files AUTHORS to CONTRIBUTING.md. [Kenneth Loafman]
 
 ### Other
 
 * Revert "chg:dev:core20 usess py38, not py36." [Kenneth Loafman]
 
-  This reverts commit 05eda5828c7bdde1003357439cfcb4d93124a377.
+  This reverts commit b5e4baac09b4533c2395aa392a0b8c170fb1a052.
 
 * Slate Backend. [Shr1ftyy]
 
 * Skip tests for ppc64le also. [Mikel Olasagasti Uranga]
 
 
 ## rel.0.8.21 (2021-11-09)
@@ -952,18 +1446,14 @@
 
 ## rel.0.8.20 (2021-06-26)
 
 ### New
 
 * Better looping.  Increase to 100 loops. [Kenneth Loafman]
 
-* Repeating test for LP bug 487720. [Kenneth Loafman]
-
-  Restore fails with "Invalid data - SHA1 hash mismatch"
-
 ### Changes
 
 * Build\_ext now builds inplace for development ease. [Kenneth Loafman]
 
 * Log difftar filename where kill happened. [Kenneth Loafman]
 
 * Remove lockfile to avoid user confusion. [Kenneth Loafman]
@@ -1051,16 +1541,14 @@
 
 * Fix error message on gdrivebackend. [Kenneth Loafman]
 
 * Fix issue #57 SSH backends - IndexError: list index out of range. [Kenneth Loafman]
 
 ### Other
 
-* Remove backup file. [kenneth@loafman.com]
-
 * Don't skip CI. [Kenneth Loafman]
 
 * Add support for new b2sdk V2 API. [Adam Jacobs]
 
 * Have duplicity retry validate\_block so object storage can report
 correct size. [Doug Thompson]
 
@@ -1179,15 +1667,15 @@
 * Fixed code smells. [Erwin Bovendeur]
 
 * Azure v12 support. [Erwin Bovendeur]
 
 * Revert "fix:pkg:Remove requirement for python3-pytest-runner.  Not
 used." [Kenneth Loafman]
 
-  This reverts commit 90e7e2acb6d158437cab3210114da46df72a7c85.
+  This reverts commit c7cbc6bd531f90be1ea9a65cc237e1017dd935f4.
 
 * List required volumes when called with 'restore --dry-run' [Matthias Blankertz]
 
   When restoring in dry-run mode, and with the manifest available, list
   the volumes that would be gotten from the backend when actually
   performing the operation.   This is intended to aid users of e.g. the
   S3 backend with (deep) glacier   storage, allowing the following
@@ -1479,16 +1967,16 @@
 
 * Update README.md. [Kenneth Loafman]
 
 * Paperwork. [Kenneth Loafman]
 
 * Revert "Merge branch 's3-boto3-region-and-endpoint' into 'master'" [Kenneth Loafman]
 
-  This reverts commit f25e9740e17d24cf309aee136953d8fd51a7bf9b,
-  reversing   changes made to 2890326dfd7a5bf9ea340aca76d96ebcd25aa8b6.
+  This reverts commit 16947e6aa490fd0cb96f1954b410c003c6a5b101,
+  reversing   changes made to cf8bb66e8b87cf8b57680d6ab7a8a83ca9c955f9.
 
 * Bump version for LP dev build. [Kenneth Loafman]
 
 
 ## rel.0.8.15 (2020-07-27)
 
 ### Other
@@ -1501,15 +1989,15 @@
   name     --s3-endpoint-url   to specify these parameters. This allows
   using s3 compatible providers   like Scaleway or OVH.
   It is probably useful for Amazon accounts, too, to have more fine
   grained influence on the region to use.
 
 * Fix missing FileNotUploadedError in pydrive backend. [Martin Sucha]
 
-  Since dadbe2d2c22751f68f179833d36c94f2777ba425, FileNotUploadedError
+  Since 69eb0376ef6a1b32b8d6bf0f075247d49f06719e, FileNotUploadedError
   is not imported anymore, resulting in an exception in case   some of
   the files failed to upload. Adding the import back.
 
 * Fixed indentation. [Joshua Chan]
 
 * Added shared drive support to existing `pydrive` backend instead of a
 new backend. [Joshua Chan]
```

### Comparing `duplicity-1.2.3.dev43/CONTRIBUTING.md` & `duplicity-2.0.0rc0/CONTRIBUTING.md`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/tox.ini` & `duplicity-2.0.0rc0/tox.ini`

 * *Files 7% similar despite different names*

```diff
@@ -16,16 +16,21 @@
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 
 [tox]
-envlist = code,py27,py35,py36,py37,py38,py39,py310,py311
-skip_missing_interpreters = false
+envlist =
+    code
+    py38
+    py39
+    py310
+    py311
+skip_missing_interpreters = true
 toxworkdir = {env:TOXWORKDIR:{toxinidir}/.tox}
 setenv =
     RUN_CODE_TESTS=0
     RUN_COVERAGE=0
 
 
 [testenv]
@@ -94,21 +99,20 @@
 skip_install = true
 commands =
     - coverage combine testing
     - coverage html
 
 
 [pytest]
-addopts = --failed-first --junitxml=report.xml
+addopts = --failed-first --junitxml=report.xml --showlocals
 markers = slow: test runs >= 10 secs
 testpaths = testing/unit testing/functional
 
 
 [pycodestyle]
 # E402 module level import not at top of file: for python stdlib aliases
 # W503 warnings for break before a binary operator. For new code, PEP8 prefers this and this warning should be ignored.
 # W504 warnings for break after a binary operator. For new code, PEP8 prefers before, so these should be fixed -- TODO
-# E722 do not use bare except -- TODO
 # E731 do not assign a lambda expression, use a def -- TODO
 # E741 ambiguous variable name -- TODO
-ignore = E402,W503,W504,E722,E731,E741
+ignore = E402,W503,W504,E731,E741
 max-line-length = 120
```

### Comparing `duplicity-1.2.3.dev43/bin/duplicity` & `duplicity-2.0.0rc0/bin/duplicity`

 * *Files 20% similar despite different names*

```diff
@@ -22,129 +22,99 @@
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 #
 # See http://www.nongnu.org/duplicity for more information.
 # Please send mail to me or the mailing list if you find bugs or have
 # any suggestions.
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-
-import json
-import os
 import sys
 
-from duplicity.dup_main import main
 import duplicity.errors
-
 from duplicity import gpg
 from duplicity import log
 from duplicity import tempdir
 from duplicity import util
+from duplicity.dup_main import main
 
-
-if sys.version_info[:2] >= (3, 7):
-    sys.stdout.reconfigure(errors=u'surrogateescape')
-    sys.stderr.reconfigure(errors=u'surrogateescape')
-elif sys.version_info.major == 3:
-    import codecs
-    sys.stdout = codecs.getwriter(u'utf-8')(sys.stdout.buffer, u'surrogateescape')
-    sys.stderr = codecs.getwriter(u'utf-8')(sys.stderr.buffer, u'surrogateescape')
-elif sys.version_info.major == 2:
-    import codecs
-    sys.stdout = codecs.getwriter(u'utf-8')(sys.stdout, u'replace')
-    sys.stderr = codecs.getwriter(u'utf-8')(sys.stderr, u'replace')
+sys.stdout.reconfigure(errors='surrogateescape')
+sys.stderr.reconfigure(errors='surrogateescape')
 
 
 def with_tempdir(fn):
-    u"""
+    """
     Execute function and guarantee cleanup of tempdir is called
 
     @type fn: callable function
     @param fn: function to execute
 
     @return: void
     @rtype: void
     """
     try:
         fn()
     finally:
         tempdir.default().cleanup()
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     try:
-
-        #         import cProfile
-        #         import pstats
-        #         import StringIO
-        #         prof = cProfile.Profile()
-        #         prof.enable(subcalls=True, builtins=True)
-
         log.setup()
         util.start_debugger()
         with_tempdir(main)
 
-        #         prof.disable()
-        #         s = StringIO.StringIO()
-        #         ps = pstats.Stats(prof, stream=s).sort_stats('cumulative')
-        #         ps.print_stats(20)
-        #         print s.getvalue()
-
     # Don't move this lower.  In order to get an exit
     # status out of the system, you have to call the
     # sys.exit() function.  Python handles this by
     # raising the SystemExit exception.  Cleanup code
     # goes here, if needed.
     except SystemExit as e:
         # No traceback, just get out
         util.release_lockfile()
         sys.exit(e.code)
 
     except KeyboardInterrupt as e:
         # No traceback, just get out
-        log.Info(_(u"INT intercepted...exiting."))
+        log.Info(_("INT intercepted...exiting."))
         util.release_lockfile()
         sys.exit(4)
 
     except gpg.GPGError as e:
         # For gpg errors, don't show an ugly stack trace by
         # default. But do with sufficient verbosity.
         util.release_lockfile()
-        log.Info(_(u"GPG error detail: %s")
+        log.Info(_("GPG error detail: %s")
                  % util.exception_traceback())
-        log.FatalError(u"%s: %s" % (e.__class__.__name__, e.args[0]),
+        log.FatalError("%s: %s" % (e.__class__.__name__, e.args[0]),
                        log.ErrorCode.gpg_failed,
                        e.__class__.__name__)
 
     except duplicity.errors.UserError as e:
         util.release_lockfile()
         # For user errors, don't show an ugly stack trace by
         # default. But do with sufficient verbosity.
-        log.Info(_(u"User error detail: %s")
+        log.Info(_("User error detail: %s")
                  % util.exception_traceback())
-        log.FatalError(u"%s: %s" % (e.__class__.__name__, util.uexc(e)),
+        log.FatalError("%s: %s" % (e.__class__.__name__, util.uexc(e)),
                        log.ErrorCode.user_error,
                        e.__class__.__name__)
 
     except duplicity.errors.BackendException as e:
         util.release_lockfile()
         # For backend errors, don't show an ugly stack trace by
         # default. But do with sufficient verbosity.
-        log.Info(_(u"Backend error detail: %s")
+        log.Info(_("Backend error detail: %s")
                  % util.exception_traceback())
-        log.FatalError(u"%s: %s" % (e.__class__.__name__, util.uexc(e)),
+        log.FatalError("%s: %s" % (e.__class__.__name__, util.uexc(e)),
                        log.ErrorCode.user_error,
                        e.__class__.__name__)
 
     except Exception as e:
         util.release_lockfile()
-        if u"Forced assertion for testing" in util.uexc(e):
-            log.FatalError(u"%s: %s" % (e.__class__.__name__, util.uexc(e)),
+        if "Forced assertion for testing" in util.uexc(e):
+            log.FatalError("%s: %s" % (e.__class__.__name__, util.uexc(e)),
                            log.ErrorCode.exception,
                            e.__class__.__name__)
         else:
             # Traceback and that mess
             log.FatalError(util.exception_traceback(),
                            log.ErrorCode.exception,
                            e.__class__.__name__)
```

### Comparing `duplicity-1.2.3.dev43/bin/duplicity.1` & `duplicity-2.0.0rc0/bin/duplicity.1`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-.TH DUPLICITY 1 "April 05, 2023" "Version 1.2.3.dev43" "User Manuals" \"  -*- nroff -*-
+.TH DUPLICITY 1 "July 10, 2023" "Version 2.0.0rc0" "User Manuals" \"  -*- nroff -*-
 .\" disable justification (adjust text to left margin only)
 .\" command line examples stay readable through that
 .ad l
 .\" disable hyphenation
 .nh
 
 .SH NAME
@@ -13,27 +13,27 @@
 .BR ACTIONS .
 
 .B duplicity [full|incremental]
 .I [options]
 source_directory target_url
 
 .B duplicity verify
-.I [options] [--compare-data] [--file-to-restore <relpath>] [--time time]
+.I [options] [--compare-data] [--path-to-restore <relpath>] [--time time]
 source_url target_directory
 
 .B duplicity collection-status
 .I [options] [--file-changed <relpath>] [--show-changes-in-set <index>]
 target_url
 
 .B duplicity list-current-files
 .I [options] [--time time]
 target_url
 
 .B duplicity [restore]
-.I [options] [--file-to-restore <relpath>] [--time time]
+.I [options] [--path-to-restore <relpath>] [--time time]
 source_url target_directory
 
 .B duplicity remove-older-than <time>
 .I [options] [--force]
 target_url
 
 .B duplicity remove-all-but-n-full  <count>
@@ -44,18 +44,14 @@
 .I [options] [--force]
 target_url
 
 .B duplicity cleanup
 .I [options] [--force]
 target_url
 
-.B duplicity replicate
-.I [options] [--time time]
-source_url target_url
-
 .SH DESCRIPTION
 Duplicity incrementally backs up files and folders into
 tar-format volumes encrypted with GnuPG and places them to a
 remote (or local) storage backend.  See chapter
 .B URL FORMAT
 for a list of all supported backends and how to address them.
 Because duplicity uses librsync, incremental backups are space efficient
@@ -100,15 +96,15 @@
 .PP
 .RE
 Duplicity enters restore mode because the URL comes before the local
 directory.  If we wanted to restore just the file "Mail/article" in
 /home/me as it was three days ago into /home/me/restored_file:
 .PP
 .RS
-duplicity -t 3D --file-to-restore Mail/article sftp://uid@other.host/some_dir /home/me/restored_file
+duplicity -t 3D --path-to-restore Mail/article sftp://uid@other.host/some_dir /home/me/restored_file
 .PP
 .RE
 The following command compares the latest backup with the current files:
 .PP
 .RS
 duplicity verify sftp://uid@other.host/some_dir /home/me
 .PP
@@ -163,27 +159,27 @@
 
 .TP
 .BI "incr " "<folder> <url>"
 If this is requested an incremental backup will be performed.
 Duplicity will abort if no old signatures can be found.
 
 .TP
-.BI "verify " "[--compare-data] [--time <time>] [--file-to-restore <rel_path>] <url> <local_path>"
+.BI "verify " "[--compare-data] [--time <time>] [--path-to-restore <rel_path>] <url> <local_path>"
 Verify tests the integrity of the backup archives at the remote location by downloading each file
 and checking both that it can restore the archive and that the restored file matches the signature
 of that file stored in the backup, i.e. compares the archived file with its hash value from archival
 time. Verify does not actually restore and will not overwrite any local files. Duplicity
 will exit with a non-zero error level if any files do not match the signature stored in the archive
 for that file. On verbosity level 4 or higher, it will log a message for each file that differs
 from the stored signature. Files must be downloaded to the local machine in order to compare them.
 Verify does not compare the backed-up version of the file to the current local copy of the files
 unless the --compare-data option is used (see below).
 .br
 The
-.I --file-to-restore
+.I --path-to-restore
 option restricts verify to that file or folder.
 The
 .I --time
 option allows one to select a backup to verify.
 The
 .I --compare-data
 option enables data comparison (see below).
@@ -205,15 +201,15 @@
 Lists the files contained in the most current backup or backup at time.
 The information will be extracted from the signature files, not the archive data
 itself. Thus the whole archive does not have to be downloaded, but on
 the other hand if the archive has been deleted or corrupted, this
 command will not detect it.
 
 .TP
-.BI "restore " "[--file-to-restore <relpath>] [--time <time>] <url> <target_folder>"
+.BI "restore " "[--path-to-restore <relpath>] [--time <time>] <url> <target_folder>"
 You can restore the full monty or selected folders/files from a specific time.
 Use the relative path as it is printed by
 .BR list-current-files .
 Usually not needed as duplicity enters restore mode when it detects that the URL
 comes before the local folder.
 
 .TP
@@ -255,27 +251,14 @@
 Delete the extraneous duplicity files on the given backend.
 Non-duplicity files, or files in complete data sets will not be
 deleted.  This should only be necessary after a duplicity session
 fails or is aborted prematurely.  Note that
 .I --force
 will be needed to delete the files instead of just listing them.
 
-.TP
-.BI "replicate " "[--time time] <source_url> <target_url>"
-Replicate backup sets from source to target backend. Files will be
-(re)-encrypted and (re)-compressed depending on normal backend
-options. Signatures and volumes will not get recomputed, thus options like
-.BI --volsize
-or
-.BI --max-blocksize
-have no effect.
-When
-.I --time time
-is given, only backup sets older than time will be replicated.
-
 .SH OPTIONS
 
 .TP
 .BI --allow-source-mismatch
 Do not abort on attempts to use the same archive dir or remote backend
 to back up different directories. duplicity will tell you if you need
 this switch.
@@ -509,20 +492,23 @@
 It is not necessary to include the parent directory of listed files, their
 inclusion is implied. However, the content of any explicitly listed directories
 is not implied. All required files must be listed when this option is used.
 
 .TP
 .BI "--file-prefix " prefix
 .PD 0
+
 .TP
 .BI "--file-prefix-manifest " prefix
 .PD 0
+
 .TP
 .BI "--file-prefix-archive " prefix
 .PD 0
+
 .TP
 .BI "--file-prefix-signature " prefix
 .RS
 Adds a prefix to either all files or only manifest, archive, signature files.
 
 The same set of prefixes must be passed in on backup and restore.
 
@@ -530,15 +516,15 @@
 type-specific prefixes.
 
 See also
 .B "A NOTE ON FILENAME PREFIXES"
 .RE
 
 .TP
-.BI "--file-to-restore " path
+.BI "--path-to-restore " path
 This option may be given in restore mode, causing only
 .I path
 to be restored instead of the entire contents of the backup archive.
 .I path
 should be given relative to the root of the directory backed up.
 
 .TP
@@ -765,29 +751,24 @@
 .BI --numeric-owner
 On restore always use the numeric uid/gid from the archive and not the
 archived user/group names, which is the default behaviour.
 Recommended for restoring from live cds which might have the users with
 identical names but different uids/gids.
 
 .TP
-.BI --do-not-restore-ownership
+.BI --no-restore-ownership
 Ignores the uid/gid from the archive and keeps the current user's one.
 Recommended for restoring data to mounted filesystem which do not
 support Unix ownership or when root privileges are not available.
 
 .TP
 .BI "--num-retries " number
 Number of retries to make on errors before giving up.
 
 .TP
-.BI --old-filenames
-Use the old filename format (incompatible with Windows/Samba) rather than
-the new filename format.
-
-.TP
 .BI "--par2-options " options
 Verbatim options to pass to par2.
 
 .TP
 .BI "--par2-redundancy " percent
 Adjust the level of redundancy in
 .I percent
@@ -1063,17 +1044,19 @@
 .TP
 .BI "--s3-use-server-side-encryption"
 Allow use of server side encryption in S3
 
 .TP
 .B --s3-use-server-side-kms-encryption
 .PD 0
+
 .TP
 .BI "--s3-kms-key-id " key_id
 .PD 0
+
 .TP
 .BI "--s3-kms-grant " grant
 Enable server-side encryption using key management service.
 
 .TP
 .BI "--scp-command " command
 .B (only ssh pexpect backend with --use-scp enabled)
@@ -1096,21 +1079,14 @@
 .br
 See also
 .B "A NOTE ON SSH BACKENDS"
 section
 .BR "SSH pexpect backend" .
 
 .TP
-.BI --short-filenames
-If this option is specified, the names of the files duplicity writes
-will be shorter (about 30 chars) but less understandable.  This may be
-useful when backing up to MacOS or another OS or FS that doesn't
-support long filenames.
-
-.TP
 .BI "--sign-key " key-id
 This option can be used when backing up, restoring or verifying.
 When backing up, all backup files will be signed with keyid
 .IR key .
 When restoring, duplicity will signal an error if any remote file is
 not signed with the given key-id. The key-id can be given in any of
 the formats supported by GnuPG; see
@@ -1234,14 +1210,19 @@
 
 .TP
 .BI "--time-separator " char
 Use
 .IR char
 as the time separator in filenames instead of colon (":").
 
+.B NOTE:
+This option only applies to recovery and status style commands.
+We no longer create or write filenames with time separators,
+but will read older backups that may need this option.
+
 .TP
 .BI "--timeout " seconds
 Use
 .IR seconds
 as the socket timeout value if duplicity begins to timeout during
 network operations.  The default is 30 seconds.
 
@@ -1317,33 +1298,37 @@
 .TP
 .B TMPDIR, TEMP, TMP
 In decreasing order of importance, specifies the directory to use for
 temporary files (inherited from Python's tempfile module).
 Eventually the option
 .BI --tempdir
 supersedes any of these.
+
 .TP
 .B FTP_PASSWORD
 Supported by most backends which are password capable. More secure than
 setting it in the backend url (which might be readable in the operating
 systems process listing to other users on the same machine).
+
 .TP
 .B PASSPHRASE
 This passphrase is passed to GnuPG. If this is not set, the user will be
-prompted for the passphrase.
+prompted for the passphrase.  GPG uses the AES encryption method for passphrase encryption.
+
 .TP
 .B SIGN_PASSPHRASE
 The passphrase to be used for
 .BR --sign-key .
 If omitted
 .B and
 sign key is also one of the keys to encrypt against
 .B PASSPHRASE
 will be reused instead.
 Otherwise, if passphrase is needed but not set the user will be prompted for it.
+GPG uses the AES encryption method for passphrase encryption.
 
 Other environment variables may be used to configure specific backends.
 See the notes for the particular backend.
 
 .SH URL FORMAT
 Duplicity uses the URL format (as standard as possible) to define data locations.
 Major difference is that the whole host section is optional for some backends.
@@ -1912,15 +1897,15 @@
 options, should the directory portion of the path (/usr/bin) contain any
 uppercase characters.
 
 If the pattern starts with "ignorecase:" (case insensitive), then
 this prefix will be removed and any character in the string can be
 replaced with an upper- or lowercase version of itself. This prefix is a
 legacy feature supported for shell globbing selection conditions only,
-but for backward compatibility reasons is otherwise considered part of
+but for backward compatability reasons is otherwise considered part of
 the pattern itself (use
 .B --filter-ignorecase
 instead).
 
 Remember that you may need to quote patterns when typing them
 into a shell, so the shell does not interpret the globbing patterns
 or whitespace characters before duplicity sees them.
@@ -2632,32 +2617,36 @@
 multi:///path/to/config.json?mode=stripe&onfail=continue
 multi:///path/to/config.json?onfail=abort&mode=stripe
 multi:///path/to/config.json?onfail=abort
 .fi
 .RE
 Order does not matter, however unrecognized parameters are considered
 an error.
+
 .TP
 .BI "mode=" stripe
 This mode (the default) performs round-robin access to the list of
 backends. In this mode, all backends must be reliable as a loss of one
 means a loss of one of the archive files.
+
 .TP
 .BI "mode=" mirror
 This mode accesses backends as a RAID1-store, storing every file in
 every backend and reading files from the first-successful backend.
 A loss of any backend should result in no failure. Note that backends
 added later will only get new files and may require a manual sync
 with one of the other operating ones.
+
 .TP
 .BI "onfail=" continue
 This setting (the default) continues all write operations in as
 best-effort. Any failure results in the next backend tried. Failure
 is reported only when all backends fail a given operation with the
 error result from the last failure.
+
 .TP
 .BI "onfail=" abort
 This setting considers any backend write failure as a terminating
 condition and reports the error.
 Data reading and listing operations are independent of this and
 will try with the next backend on failure.
 .SS JSON File Example
@@ -3090,16 +3079,15 @@
 
 .SH OPERATION AND DATA FORMATS
 This section describes duplicity's basic operation and the format of
 its data files.  It should not necessary to read this section to use
 duplicity.
 
 The files used by duplicity to store backup data are tarfiles in GNU
-tar format.  They can be produced independently by
-.BR rdiffdir (1).
+tar format.
 For incremental backups, new files are saved normally in the tarfile.
 But when a file changes, instead of storing a complete copy of the
 file, only a diff is stored, as generated by
 .BR rdiff (1).
 If a file is deleted, a 0 length file is stored in the tar.  It is
 possible to restore a duplicity archive "manually" by using
 .B tar
@@ -3151,155 +3139,184 @@
 .SH REQUIREMENTS
 Duplicity requires a POSIX-like operating system with a
 .B python
 interpreter version 2.6+ installed.
 It is best used under GNU/Linux.
 
 Some backends also require additional components (probably available as packages for your specific platform):
+
 .TP
 .BR "Amazon Drive backend"
 .B python-requests
 - http://python-requests.org
 .br
 .B python-requests-oauthlib
 - https://github.com/requests/requests-oauthlib
+
 .TP
 .BR "azure backend" " (Azure Storage Blob Service)"
 .B Microsoft Azure Storage Blobs client library for Python
 - https://pypi.org/project/azure-storage-blob/
+
 .TP
 .BR "boto backend" " (S3 Amazon Web Services, Google Cloud Storage) (legacy)"
 .B boto version 2.49 (2018/07/11)
 - http://github.com/boto/boto
+
 .TP
 .BR "boto3 backend" " (S3 Amazon Web Services, Google Cloud Storage) (default)"
 .B boto3 version 1.x
 - https://github.com/boto/boto3
+
 .TP
 .BR "box backend" " (box.com)"
 .B boxsdk
 - https://github.com/box/box-python-sdk
+
 .TP
 .BR "cfpyrax backend" " (Rackspace Cloud) and " "hubic backend" " (hubic.com)"
 .B Rackspace CloudFiles Pyrax API
 - http://docs.rackspace.com/sdks/guide/content/python.html
+
 .TP
 .BR "dpbx backend" " (Dropbox)"
 .B Dropbox Python SDK
 - https://www.dropbox.com/developers/reference/sdk
+
 .TP
 .BR "gdocs gdata backend" " (legacy)"
 .B Google Data APIs Python Client Library
 - http://code.google.com/p/gdata-python-client/
+
 .TP
 .BR "gdocs pydrive backend" "(default)"
 see pydrive backend
+
 .TP
 .BR "gio backend" " (Gnome VFS API)"
 .B PyGObject
 - http://live.gnome.org/PyGObject
 .br
 .B D-Bus
 (dbus)- http://www.freedesktop.org/wiki/Software/dbus
+
 .TP
 .BR "lftp backend" " (needed for ftp, ftps, fish [over ssh] - also supports sftp, webdav[s])"
 .B LFTP Client
 - http://lftp.yar.ru/
+
 .TP
 .BR "MEGA backend (only works for accounts created prior to November 2018)" " (mega.nz)"
 .B megatools client
 - https://github.com/megous/megatools
+
 .TP
 .BR "MEGA v2 and v3 backend (works for all MEGA accounts)" " (mega.nz)"
 .B MEGAcmd client
 - https://mega.nz/cmd
+
 .TP
 .BR "multi backend"
 .B Multi -- store to more than one backend
 .br
 (also see
 .BR "A NOTE ON MULTI BACKEND"
 ) below.
+
 .TP
 .BR "ncftp backend" " (ftp, select via ncftp+ftp://)"
 .B NcFTP
 - http://www.ncftp.com/
+
 .TP
 .BR "OneDrive backend" " (Microsoft OneDrive)"
 .B python-requests-oauthlib
 - https://github.com/requests/requests-oauthlib
+
 .TP
 .B "Par2 Wrapper Backend"
 .B par2cmdline
 - http://parchive.sourceforge.net/
+
 .TP
 .BR "pydrive backend"
 .B PyDrive -- a wrapper library of google-api-python-client
 - https://pypi.python.org/pypi/PyDrive
 .br
 (also see
 .BR "A NOTE ON PYDRIVE BACKEND"
 ) below.
+
 .TP
 .B "rclone backend"
 .B rclone
 - https://rclone.org/
+
 .TP
 .B "rsync backend"
 .B rsync client binary
 - http://rsync.samba.org/
+
 .TP
 .BR "ssh paramiko backend" " (default)"
 .B paramiko
 (SSH2 for python)
 - http://pypi.python.org/pypi/paramiko (downloads); http://github.com/paramiko/paramiko (project page)
 .br
 .B pycrypto
 (Python Cryptography Toolkit)
 - http://www.dlitz.net/software/pycrypto/
+
 .TP
 .BR "ssh pexpect backend" "(legacy)"
 .B sftp/scp client binaries
 OpenSSH - http://www.openssh.com/
 .br
 .B Python pexpect module
 - http://pexpect.sourceforge.net/pexpect.html
+
 .TP
 .BR "swift backend (OpenStack Object Storage)"
 .B Python swiftclient module
 - https://github.com/openstack/python-swiftclient/
 .br
 .B Python keystoneclient module
 - https://github.com/openstack/python-keystoneclient/
+
 .TP
 .B "webdav backend"
 .B certificate authority database file
 for ssl certificate verification of HTTPS connections
 - http://curl.haxx.se/docs/caextract.html
 .br
 (also see
 .BR "A NOTE ON SSL CERTIFICATE VERIFICATION" ).
 .br
 .B Python kerberos module
 for kerberos authentication
 - https://github.com/02strich/pykerberos
+
 .TP
 .BR "MediaFire backend"
 .B MediaFire Python Open SDK
 - https://pypi.python.org/pypi/mediafire/
+
 .TP
 .BR "xorriso backend"
 .B xorriso
 - https://www.gnu.org/software/xorriso/
 
 .SH AUTHOR
+
 .TP
 .BR "Original Author" " - Ben Escoto <bescoto@stanford.edu>"
+
 .TP
 .BR "Current Maintainer" " - Kenneth Loafman <kenneth@loafman.com>"
+
 .TP
 .B "Continuous Contributors"
 Edgar Soldin, Mike Terry
 .PP
 Most backends were contributed individually.
 Information about their authorship may be found in the according file's header.
 .PP
@@ -3309,11 +3326,10 @@
 .PP
 A special thanks goes to rsync.net, a Cloud Storage provider with explicit
 support for duplicity, for several monetary donations and for providing a
 special "duplicity friends" rate for their offsite backup service.  Email
 info@rsync.net for details.
 
 .SH SEE ALSO
-.BR rdiffdir (1),
 .BR python (1),
 .BR rdiff (1),
 .BR rdiff-backup (1).
```

### Comparing `duplicity-1.2.3.dev43/snap/snapcraft.yaml` & `duplicity-2.0.0rc0/snap/snapcraft.yaml`

 * *Files 20% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 name: duplicity
-version: 1.2.3.dev43
+version: 2.0.0rc0
 license: GPL-2.0
 summary: Efficient, encrypted backup to local or remote hosts
 description: |
   Duplicity backs directories by producing encrypted tar-format volumes and uploading
   them to a remote or local file server. Because duplicity uses librsync, the incremental
   archives are space efficient and only record the parts of files that have changed since
   the last backup. Because duplicity uses GnuPG to encrypt and/or sign these archives,
@@ -21,22 +21,14 @@
             PATH: "$SNAP/usr/sbin:$SNAP/usr/bin:$SNAP/sbin:$SNAP/bin:$PATH:/snap/core20/current/usr/bin"
             # fixup pythonpath to find modules, for some reason
             # 'lib/python3.8/site-packages' is not added by default
             # add two more host paths for users to install modules in
             PYTHONPATH: "$SNAP/lib/python3.8/site-packages:\
                          $HOME/.local/lib/python3.8/site-packages:\
                          /lib/python3.8/site-packages"
-    rdiffdir:
-        command: bin/rdiffdir.sh
-        environment:
-            # see above
-            PATH: "$SNAP/usr/sbin:$SNAP/usr/bin:$SNAP/sbin:$SNAP/bin:$PATH:/snap/core20/current/usr/bin"
-            PYTHONPATH: "$SNAP/lib/python3.8/site-packages:\
-                         $HOME/.local/lib/python3.8/site-packages:\
-                         /lib/python3.8/site-packages"
     # printing env in snap for debug purposes, help's pinning snap startup issues (missing libs, _rsync ...)
     debug:
         command: bin/debug.sh
     debug2:
         command: bin/debug.sh
         environment:
             # see above
@@ -44,110 +36,76 @@
             PYTHONPATH: "$SNAP/lib/python3.8/site-packages:\
                          $HOME/.local/lib/python3.8/site-packages:\
                          /lib/python3.8/site-packages"
 
 parts:
     duplicity:
         plugin: python
+        requirements:
+            - requirements.txt
         override-pull: |
             snapcraftctl pull
         override-build: |
             # add pip upgrade install location to path
             export PATH="$SNAPCRAFT_PART_INSTALL/usr/local/bin/:$PATH"
             # show env vars for debugging
             #env
             # upgrade pip to latest
-            pip install --upgrade pip
+            apt install curl -y
+            curl -s https://bootstrap.pypa.io/get-pip.py -o get-pip.py
+            python3 get-pip.py
             snapcraftctl build
             # python module tahoe-lafs dies trying to compile really old pycddl 
             # on other archs than amd64, as python plugin does not support 
             # conditions we only include it in amd64 snaps manually here
             if [ "$SNAPCRAFT_BUILD_FOR" != "amd64" ]; then
                 echo "Skipping tahoe-lafs integration on arch '$SNAPCRAFT_BUILD_FOR'!='amd64'"
             else
                 pip install tahoe-lafs
             fi
             rm -rfv "$SNAPCRAFT_PART_INSTALL/usr/lib/python3.9"
         override-prime: |
             snapcraftctl prime
             cp -v "$SNAPCRAFT_PROJECT_DIR"/snap/local/launcher.sh "$SNAPCRAFT_PRIME"/bin/duplicity.sh
-            cp -v "$SNAPCRAFT_PROJECT_DIR"/snap/local/launcher.sh "$SNAPCRAFT_PRIME"/bin/rdiffdir.sh
             cp -v "$SNAPCRAFT_PROJECT_DIR"/snap/local/debug.sh "$SNAPCRAFT_PRIME"/bin/
         build-environment:
             - PYTHONPATH: "$SNAPCRAFT_PART_INSTALL/usr/lib/python3.8/dist-packages:\
                            $SNAPCRAFT_PART_INSTALL/usr/lib/python3/dist-packages:\
                            $PYTHONPATH"
         build-packages:
             - build-essential
             - ieee-data
             - intltool
             - librsync-dev
             - python3-dev
             # dependencies needed to build missing pip wheels on non amd64 archs
+            - cargo
             - libffi-dev
             - libxslt1-dev
             - libxml2-dev
             - libssl-dev
-            - cargo
+            - python3-cryptography
+            - python3-openssl
+            - pkg-config
         stage-packages:
             - gnupg
             - lftp
             - libatm1
+            - libpython3-stdlib
+            - libpython3.8-minimal
+            - libpython3.8-stdlib
             - librsync2
             - ncftp
             - openssh-client
-            - python3-gi
-            - rsync
-            - rclone
-            - libpython3-stdlib
-            - libpython3.8-stdlib
-            - libpython3.8-minimal
-            - python3-minimal
-            - python3.8-minimal
             - python3-dev
-            - python3-pip
-            - python3-setuptools
             - python3-distutils
-            - python3-wheel
-            - python3-pkg-resources
+            - python3-gi
+            - python3-minimal
             - python3-venv
-            # some libraries needed on not amd64 archs
+            - python3.8-minimal
+            - rclone
+            - rsync
+            # some libraries needed on non amd64 archs
             - libicu66
             - libxml2
             - libxslt1.1
-        python-packages:
-            # libs needed to avoid some version dependencies.
-            # use latest version available while still py38.
-            - grpcio-tools
-            - pbr
-            - requests
-            # normally included libs
-            - azure-core
-            - azure-storage-blob
-            - b2sdk
-            - boto
-            - boto3
-            - boxsdk[jwt]
-            - dropbox
-            - fasteners
-            - future
-            - gdata-python3
-            - google-api-python-client
-            - google-auth-oauthlib
-            - httplib2
-            - jottalib
-            - keyring
-            - mediafire
-            - megatools
-            - paramiko
-            - pexpect
-            - psutil
-            - pydrive2
-            - pyrax
-            - python-swiftclient
-            - requests-oauthlib
-            - setuptools
-            - setuptools-scm
-            - sx
-            - urllib3
-            - wheel
         source: .
```

### Comparing `duplicity-1.2.3.dev43/testing/testfiles.tar.gz` & `duplicity-2.0.0rc0/testing/testfiles.tar.gz`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_gpginterface.py` & `duplicity-2.0.0rc0/testing/unit/test_gpginterface.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
-u"""py-unit tests for GnuPG
+"""py-unit tests for GnuPG
 
 COPYRIGHT:
 
 Copyright (C) 2001  Frank J. Tobin, ftobin@neverending.org
 
 LICENSE:
 
@@ -20,241 +20,234 @@
 
 You should have received a copy of the GNU Lesser General Public
 License along with this library; if not, write to the Free Software
 Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 or see http://www.gnu.org/copyleft/lesser.html
 """
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-
-import unittest
 
 import tempfile
+import unittest
 
 from duplicity import gpginterface
 
-__author__ = u"Frank J. Tobin, ftobin@neverending.org"
-__version__ = u"0.2.2"
-__revision__ = u"$Id: GnuPGInterfacetest.py,v 1.11 2009/06/06 17:35:19 loafman Exp $"
+__author__ = "Frank J. Tobin, ftobin@neverending.org"
+__version__ = "0.2.2"
+__revision__ = "$Id: GnuPGInterfacetest.py,v 1.11 2009/06/06 17:35:19 loafman Exp $"
 
 
 class BasicTest(unittest.TestCase):
-    u"""an initializer superclass"""
+    """an initializer superclass"""
 
     def __init__(self, methodName=None):
         self.gnupg = gpginterface.GnuPG()
         unittest.TestCase.__init__(self, methodName)
 
 
 class GnuPGTests(BasicTest):
-    u"""Tests for GnuPG class"""
+    """Tests for GnuPG class"""
 
     def __init__(self, methodName=None):
         BasicTest.__init__(self, methodName)
 
-        self.gnupg.passphrase = u"Three blind mice"
+        self.gnupg.passphrase = "Three blind mice"
         self.gnupg.options.armor = 1
         self.gnupg.options.meta_interactive = 0
-        self.gnupg.options.extra_args.append(u'--no-secmem-warning')
+        self.gnupg.options.extra_args.append('--no-secmem-warning')
 
     def do_create_fh_operation(self, args, input, passphrase=None):  # pylint: disable=redefined-builtin
-        creations = [u'stdin', u'stdout']
+        creations = ['stdin', 'stdout']
 
         # Make sure we're getting the passphrase to GnuPG
         # somehow!
         assert passphrase is not None or self.gnupg.passphrase is not None, \
-            u"No way to send the passphrase to GnuPG!"
+            "No way to send the passphrase to GnuPG!"
 
         # We'll handle the passphrase manually
         if passphrase is not None:
-            creations.append(u'passphrase')
+            creations.append('passphrase')
 
         proc = self.gnupg.run(args, create_fhs=creations)
 
         if passphrase is not None:
-            proc.handles[u'passphrase'].write(passphrase)
-            proc.handles[u'passphrase'].close()
+            proc.handles['passphrase'].write(passphrase)
+            proc.handles['passphrase'].close()
 
-        proc.handles[u'stdin'].write(input)
-        proc.handles[u'stdin'].close()
+        proc.handles['stdin'].write(input)
+        proc.handles['stdin'].close()
 
-        ciphertext = proc.handles[u'stdout'].read()
-        proc.handles[u'stdout'].close()
+        ciphertext = proc.handles['stdout'].read()
+        proc.handles['stdout'].close()
 
         # Checking to make sure GnuPG exited successfully
         proc.wait()
 
         return ciphertext
 
     def do_attach_fh_operation(self, args, stdin, stdout,
                                passphrase=None):
 
         # Make sure we're getting the passphrase to GnuPG
         # somehow!
         assert passphrase is not None or self.gnupg.passphrase is not None, \
-            u"No way to send the passphrase to GnuPG!"
+            "No way to send the passphrase to GnuPG!"
 
         creations = []
-        attachments = {u'stdin': stdin, u'stdout': stdout}
+        attachments = {'stdin': stdin, 'stdout': stdout}
 
         proc = self.gnupg.run(args, create_fhs=creations,
                               attach_fhs=attachments)
 
         # We'll handle the passphrase manually
         if passphrase is not None:
-            proc.handles.append(u'passphrase')
+            proc.handles.append('passphrase')
 
         if passphrase is not None:
-            proc.handles[u'passphrase'].write(passphrase)
-            proc.handles[u'passphrase'].close()
+            proc.handles['passphrase'].write(passphrase)
+            proc.handles['passphrase'].close()
 
         # Checking to make sure GnuPG exited successfully
         proc.wait()
 
     def test_create_fhs_solely(self):
-        u"""Do GnuPG operations using solely the create_fhs feature"""
+        """Do GnuPG operations using solely the create_fhs feature"""
         plaintext = b"Three blind mice"
 
-        ciphertext = self.do_create_fh_operation([u'--symmetric'],
+        ciphertext = self.do_create_fh_operation(['--symmetric'],
                                                  plaintext)
 
-        decryption = self.do_create_fh_operation([u'--decrypt'],
+        decryption = self.do_create_fh_operation(['--decrypt'],
                                                  ciphertext,
                                                  self.gnupg.passphrase)
         assert decryption == plaintext, \
-            u"GnuPG decrypted output does not match original input"
+            "GnuPG decrypted output does not match original input"
 
     def test_attach_fhs(self):
-        u"""Do GnuPG operations using the attach_fhs feature"""
+        """Do GnuPG operations using the attach_fhs feature"""
         plaintext_source = __file__
 
-        plainfile = open(plaintext_source, u"rb")
+        plainfile = open(plaintext_source, "rb")
         temp1 = tempfile.TemporaryFile()
         temp2 = tempfile.TemporaryFile()
 
-        self.do_attach_fh_operation([u'--symmetric'],
+        self.do_attach_fh_operation(['--symmetric'],
                                     stdin=plainfile, stdout=temp1)
 
         temp1.seek(0)
 
-        self.do_attach_fh_operation([u'--decrypt'],
+        self.do_attach_fh_operation(['--decrypt'],
                                     stdin=temp1, stdout=temp2)
 
         plainfile.seek(0)
         temp2.seek(0)
 
         assert fh_cmp(plainfile, temp2), \
-            u"GnuPG decrypted output does not match original input"
+            "GnuPG decrypted output does not match original input"
 
 
 class OptionsTests(BasicTest):
-    u"""Tests for Options class"""
+    """Tests for Options class"""
 
     def __init__(self, methodName=None):
         BasicTest.__init__(self, methodName)
         self.reset_options()
 
     def reset_options(self):
         self.gnupg.options = gpginterface.Options()
 
     def option_to_arg(self, option):
-        return u'--' + option.replace(u'_', u'-')
+        return f"--{option.replace('_', '-')}"
 
     def test_boolean_args(self):
-        u"""test Options boolean options that they generate
+        """test Options boolean options that they generate
         proper arguments"""
 
-        booleans = [u'armor', u'no_greeting', u'no_verbose',
-                    u'batch', u'always_trust', u'rfc1991',
-                    u'quiet', u'openpgp', u'force_v3_sigs',
-                    u'no_options', u'textmode']
+        booleans = ['armor', 'no_greeting', 'no_verbose',
+                    'batch', 'always_trust', 'rfc1991',
+                    'quiet', 'openpgp', 'force_v3_sigs',
+                    'no_options', 'textmode']
 
         for option in booleans:
             self.reset_options()
             setattr(self.gnupg.options, option, 1)
             arg = self.option_to_arg(option)
 
             should_be = [arg]
             result = self.gnupg.options.get_args()
 
             assert should_be == result, \
-                u"failure to set option '%s'; should be %s, but result is %s" \
-                % (option, should_be, result)
+                f"failure to set option '{option}'; should be {should_be}, but result is {result}"
 
     def test_string_args(self):
-        u"""test Options string-taking options that they generate
+        """test Options string-taking options that they generate
         proper arguments"""
 
-        strings = [u'homedir', u'default_key', u'comment', u'compress_algo',
-                   u'options']
+        strings = ['homedir', 'default_key', 'comment', 'compress_algo',
+                   'options']
 
-        string_value = u'test-argument'
+        string_value = 'test-argument'
 
         for option in strings:
             self.reset_options()
             setattr(self.gnupg.options, option, string_value)
             arg = self.option_to_arg(option)
 
             should_be = [arg, string_value]
             result = self.gnupg.options.get_args()
 
             assert should_be == result, \
-                u"failure to set option '%s'; should be %s, but result is %s" \
-                % (option, should_be, result)
+                f"failure to set option '{option}'; should be {should_be}, but result is {result}"
 
     def test_list_args(self):
-        u"""test Options string-taking options that they generate
+        """test Options string-taking options that they generate
         proper arguments"""
 
-        lists = [u'recipients', u'encrypt_to']
-        list_value = [u'test1', u'test2']
+        lists = ['recipients', 'encrypt_to']
+        list_value = ['test1', 'test2']
 
         for option in lists:
             self.reset_options()
             setattr(self.gnupg.options, option, list_value)
 
             # special case for recipients, since their
             # respective argument is 'recipient', not 'recipients'
-            if option == u'recipients':
-                arg = u'--recipient'
+            if option == 'recipients':
+                arg = '--recipient'
             else:
                 arg = self.option_to_arg(option)
 
             should_be = []
             for v in list_value:
                 should_be.extend([arg, v])
 
             result = self.gnupg.options.get_args()
 
             assert should_be == result, \
-                u"failure to set option '%s'; should be %s, but result is %s" \
-                % (option, should_be, result)
+                f"failure to set option '{option}'; should be {should_be}, but result is {result}"
 
 
 class PipesTests(unittest.TestCase):
-    u"""Tests for Pipes class"""
+    """Tests for Pipes class"""
 
     def test_constructor(self):
         self.pipe = gpginterface.Pipe(1, 2, 0)
         assert self.pipe.parent == 1
         assert self.pipe.child == 2
         assert not self.pipe.direct
 
 ########################################################################
 
 
 def fh_cmp(f1, f2, bufsize=8192):
-    while 1:
+    while True:
         b1 = f1.read(bufsize)
         b2 = f2.read(bufsize)
         if b1 != b2:
             return 0
         if not b1:
             return 1
 
 ########################################################################
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_patchdir.py` & `duplicity-2.0.0rc0/testing/unit/test_patchdir.py`

 * *Files 9% similar despite different names*

```diff
@@ -15,145 +15,135 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import map
-from builtins import object
-from builtins import range
 
 import io
-import os
 import platform
 import unittest
 
 from duplicity import diffdir
 from duplicity import patchdir
 from duplicity import selection
-from duplicity import tarfile
-from duplicity import librsync
-from duplicity.lazy import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 from duplicity.path import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 from testing import _runtest_dir
 from . import UnitTestCase
 
 
 class PatchingTest(UnitTestCase):
-    u"""Test patching"""
+    """Test patching"""
     def setUp(self):
-        super(PatchingTest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
 
     def copyfileobj(self, infp, outfp):
-        u"""Copy in fileobj to out, closing afterwards"""
+        """Copy in fileobj to out, closing afterwards"""
         blocksize = 32 * 1024
-        while 1:
+        while True:
             buf = infp.read(blocksize)
             if not buf:
                 break
             outfp.write(buf)
         assert not infp.close()
         assert not outfp.close()
 
     def test_total(self):
-        u"""Test cycle on dirx"""
-        self.total_sequence([u'{0}/testfiles/dir1'.format(_runtest_dir),
-                             u'{0}/testfiles/dir2'.format(_runtest_dir),
-                             u'{0}/testfiles/dir3'.format(_runtest_dir)])
+        """Test cycle on dirx"""
+        self.total_sequence([f'{_runtest_dir}/testfiles/dir1',
+                             f'{_runtest_dir}/testfiles/dir2',
+                             f'{_runtest_dir}/testfiles/dir3'])
 
     def get_sel(self, path):
-        u"""Get selection iter over the given directory"""
+        """Get selection iter over the given directory"""
         return selection.Select(path).set_iter()
 
     def total_sequence(self, filelist):
-        u"""Test signatures, diffing, and patching on directory list"""
+        """Test signatures, diffing, and patching on directory list"""
         assert len(filelist) >= 2
-        sig = Path(u"{0}/testfiles/output/sig.tar".format(_runtest_dir))
-        diff = Path(u"{0}/testfiles/output/diff.tar".format(_runtest_dir))
-        seq_path = Path(u"{0}/testfiles/output/sequence".format(_runtest_dir))
+        sig = Path(f"{_runtest_dir}/testfiles/output/sig.tar")
+        diff = Path(f"{_runtest_dir}/testfiles/output/diff.tar")
+        seq_path = Path(f"{_runtest_dir}/testfiles/output/sequence")
         new_path, old_path = None, None  # set below in for loop
 
         # Write initial full backup to diff.tar
         for dirname in filelist:
             old_path, new_path = new_path, Path(dirname)
             if old_path:
                 sigblock = diffdir.DirSig(self.get_sel(seq_path))
                 diffdir.write_block_iter(sigblock, sig)
                 deltablock = diffdir.DirDelta(self.get_sel(new_path),
-                                              sig.open(u"rb"))
+                                              sig.open("rb"))
             else:
                 deltablock = diffdir.DirFull(self.get_sel(new_path))
             diffdir.write_block_iter(deltablock, diff)
 
-            patchdir.Patch(seq_path, diff.open(u"rb"))
+            patchdir.Patch(seq_path, diff.open("rb"))
             # print "#########", seq_path, new_path
             assert seq_path.compare_recursive(new_path, 1)
 
     def test_block_tar(self):
-        u"""Test building block tar from a number of files"""
+        """Test building block tar from a number of files"""
         def get_fileobjs():
-            u"""Return iterator yielding open fileobjs of tar files"""
+            """Return iterator yielding open fileobjs of tar files"""
             for i in range(1, 4):
-                p = Path(u"{0}/testfiles/blocktartest/test{1}.tar".format(_runtest_dir, i))
-                fp = p.open(u"rb")
+                p = Path(f"{_runtest_dir}/testfiles/blocktartest/test{i}.tar")
+                fp = p.open("rb")
                 yield fp
                 fp.close()
 
         tf = patchdir.TarFile_FromFileobjs(get_fileobjs())
         namelist = []
         for tarinfo in tf:
             namelist.append(tarinfo.name)
         for i in range(1, 6):
-            assert (u"tmp/%d" % i) in namelist, namelist
+            assert (f"tmp/{int(i)}") in namelist, namelist
 
     def test_doubledot_hole(self):
-        u"""Test for the .. bug that lets tar overwrite parent dir"""
+        """Test for the .. bug that lets tar overwrite parent dir"""
 
         def make_bad_tar(filename):
-            u"""Write attack tarfile to filename"""
-            tf = tarfile.TarFile(name=filename, mode=u"w")
+            """Write attack tarfile to filename"""
+            tf = tarfile.TarFile(name=filename, mode="w")
 
             # file object will be empty, and tarinfo will have path
             # "snapshot/../warning-security-error"
-            assert not os.system(u"cat /dev/null > {0}/testfiles/output/file".format(_runtest_dir))
-            path = Path(u"{0}/testfiles/output/file".format(_runtest_dir))
+            assert not os.system(f"cat /dev/null > {_runtest_dir}/testfiles/output/file")
+            path = Path(f"{_runtest_dir}/testfiles/output/file")
             path.index = (b"diff", b"..", b"warning-security-error")
             ti = path.get_tarinfo()
-            fp = io.StringIO(u"")
+            fp = io.StringIO("")
             tf.addfile(ti, fp)
 
             tf.close()
 
-        make_bad_tar(u"{0}/testfiles/output/bad.tar".format(_runtest_dir))
-        os.mkdir(u"{0}/testfiles/output/temp".format(_runtest_dir))
+        make_bad_tar(f"{_runtest_dir}/testfiles/output/bad.tar")
+        os.mkdir(f"{_runtest_dir}/testfiles/output/temp")
 
         self.assertRaises(patchdir.PatchDirException, patchdir.Patch,
-                          Path(u"{0}/testfiles/output/temp".format(_runtest_dir)),
-                          open(u"{0}/testfiles/output/bad.tar".format(_runtest_dir), u"rb"))
-        assert not Path(u"{0}/testfiles/output/warning-security-error".format(_runtest_dir)).exists()
+                          Path(f"{_runtest_dir}/testfiles/output/temp"),
+                          open(f"{_runtest_dir}/testfiles/output/bad.tar", "rb"))
+        assert not Path(f"{_runtest_dir}/testfiles/output/warning-security-error").exists()
 
 
 class index(object):
-    u"""Used below to test the iter collation"""
+    """Used below to test the iter collation"""
     def __init__(self, index):
         self.index = index
 
 
 class CollateItersTest(UnitTestCase):
     def setUp(self):
-        super(CollateItersTest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
 
     def test_collate(self):
-        u"""Test collate_iters function"""
+        """Test collate_iters function"""
         indicies = [index(i) for i in [0, 1, 2, 3]]
         helper = lambda i: indicies[i]
 
         makeiter1 = lambda: iter(indicies)
         makeiter2 = lambda: map(helper, [0, 1, 3])
         makeiter3 = lambda: map(helper, [1, 2])
 
@@ -169,102 +159,102 @@
                                                  makeiter3()]),
                           iter([(indicies[0], indicies[0], None),
                                 (indicies[1], indicies[1], indicies[1]),
                                 (indicies[2], None, indicies[2]),
                                 (indicies[3], indicies[3], None)]), 1)
 
         assert Iter.equal(patchdir.collate_iters([makeiter1(), iter([])]),
-                          map(lambda i: (i, None), indicies))
-        assert Iter.equal(map(lambda i: (i, None), indicies),
+                          iter([(i, None) for i in indicies]))
+        assert Iter.equal([(i, None) for i in indicies],
                           patchdir.collate_iters([makeiter1(), iter([])]))
 
     def test_tuple(self):
-        u"""Test indexed tuple"""
-        i = patchdir.IndexedTuple((1, 2, 3), (u"a", u"b"))
-        i2 = patchdir.IndexedTuple((), (u"hello", u"there", u"how are you"))
-
-        assert i[0] == u"a"
-        assert i[1] == u"b"
-        assert i2[1] == u"there"
+        """Test indexed tuple"""
+        i = patchdir.IndexedTuple((1, 2, 3), ("a", "b"))
+        i2 = patchdir.IndexedTuple((), ("hello", "there", "how are you"))
+
+        assert i[0] == "a"
+        assert i[1] == "b"
+        assert i2[1] == "there"
         assert len(i) == 2 and len(i2) == 3
         assert i2 < i, i2 < i
 
     def test_tuple_assignment(self):
         a, b, c = patchdir.IndexedTuple((), (1, 2, 3))
         assert a == 1
         assert b == 2
         assert c == 3
 
 
 class TestInnerFuncs(UnitTestCase):
-    u"""Test some other functions involved in patching"""
+    """Test some other functions involved in patching"""
     def setUp(self):
-        super(TestInnerFuncs, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
         self.check_output()
 
     def check_output(self):
-        u"""Make {0}/testfiles/output exists"""
-        out = Path(u"{0}/testfiles/output".format(_runtest_dir))
+        """Make {0}/testfiles/output exists"""
+        out = Path(f"{_runtest_dir}/testfiles/output")
         if not (out.exists() and out.isdir()):
             out.mkdir()
         self.out = out
 
     def snapshot(self):
-        u"""Make a snapshot ROPath, permissions 0o600"""
-        ss = self.out.append(u"snapshot")
-        fout = ss.open(u"wb")
+        """Make a snapshot ROPath, permissions 0o600"""
+        ss = self.out.append("snapshot")
+        fout = ss.open("wb")
         fout.write(b"hello, world!")
         assert not fout.close()
         ss.chmod(0o600)
-        ss.difftype = u"snapshot"
+        ss.difftype = "snapshot"
         return ss
 
     def get_delta(self, old_buf, new_buf):
-        u"""Return delta buffer from old to new"""
+        """Return delta buffer from old to new"""
         sigfile = librsync.SigFile(io.BytesIO(old_buf))
         sig = sigfile.read()
         assert not sigfile.close()
 
         deltafile = librsync.DeltaFile(sig, io.BytesIO(new_buf))
         deltabuf = deltafile.read()
         assert not deltafile.close()
         return deltabuf
 
     def delta1(self):
-        u"""Make a delta ROPath, permissions 0o640"""
-        delta1 = self.out.append(u"delta1")
-        fout = delta1.open(u"wb")
+        """Make a delta ROPath, permissions 0o640"""
+        delta1 = self.out.append("delta1")
+        fout = delta1.open("wb")
         fout.write(self.get_delta(b"hello, world!",
                                   b"aonseuth aosetnuhaonsuhtansoetuhaoe"))
         assert not fout.close()
         delta1.chmod(0o640)
-        delta1.difftype = u"diff"
+        delta1.difftype = "diff"
         return delta1
 
     def delta2(self):
-        u"""Make another delta ROPath, permissions 0o644"""
-        delta2 = self.out.append(u"delta1")
-        fout = delta2.open(u"wb")
+        """Make another delta ROPath, permissions 0o644"""
+        delta2 = self.out.append("delta1")
+        fout = delta2.open("wb")
         fout.write(self.get_delta(b"aonseuth aosetnuhaonsuhtansoetuhaoe",
                                   b"3499 34957839485792357 458348573"))
         assert not fout.close()
         delta2.chmod(0o644)
-        delta2.difftype = u"diff"
+        delta2.difftype = "diff"
         return delta2
 
     def deleted(self):
-        u"""Make a deleted ROPath"""
-        deleted = self.out.append(u"deleted")
+        """Make a deleted ROPath"""
+        deleted = self.out.append("deleted")
         assert not deleted.exists()
-        deleted.difftype = u"deleted"
+        deleted.difftype = "deleted"
         return deleted
 
     def test_normalize(self):
-        u"""Test normalizing a sequence of diffs"""
+        """Test normalizing a sequence of diffs"""
         ss = self.snapshot()
         d1 = self.delta1()
         d2 = self.delta2()
         de = self.deleted()
 
         seq1 = [ss, d1, d2]
         seq2 = [ss, d1, d2, de]
@@ -288,29 +278,29 @@
     #     def testseq(seq, perms, buf):
     #         result = patchdir.patch_seq2ropath(seq)
     # >       assert result.getperms() == perms, (result.getperms(), perms)
     # E       AssertionError: ('501:0 600', '501:20 600')
     # E       assert '501:0 600' == '501:20 600'
     # E         - 501:0 600
     # E         + 501:20 600
-    @unittest.skipUnless(platform.platform().startswith(u"Linux"), u"Skip on non-Linux systems")
+    @unittest.skipUnless(platform.platform().startswith("Linux"), "Skip on non-Linux systems")
     def test_patch_seq2ropath(self):
-        u"""Test patching sequence"""
+        """Test patching sequence"""
         def testseq(seq, perms, buf):
             result = patchdir.patch_seq2ropath(seq)
             assert result.getperms() == perms, (result.getperms(), perms)
-            fout = result.open(u"rb")
+            fout = result.open("rb")
             contents = fout.read()
             assert not fout.close()
             assert contents == buf, (contents, buf)
 
-        ids = u"%d:%d" % (os.getuid(), os.getgid())
+        ids = f"{int(os.getuid())}:{int(os.getgid())}"
 
-        testseq([self.snapshot()], (u"%s 600" % ids), b"hello, world!")
-        testseq([self.snapshot(), self.delta1()], (u"%s 640" % ids),
+        testseq([self.snapshot()], (f"{ids} 600"), b"hello, world!")
+        testseq([self.snapshot(), self.delta1()], (f"{ids} 640"),
                 b"aonseuth aosetnuhaonsuhtansoetuhaoe")
-        testseq([self.snapshot(), self.delta1(), self.delta2()], (u"%s 644" % ids),
+        testseq([self.snapshot(), self.delta1(), self.delta2()], (f"{ids} 644"),
                 b"3499 34957839485792357 458348573")
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_lazy.py` & `duplicity-2.0.0rc0/testing/unit/test_lazy.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,53 +17,47 @@
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 # pylint: disable=no-value-for-parameter
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import next
-from builtins import range
 
-import unittest
 import pickle
-import sys
+import unittest
 from functools import reduce
 
 from duplicity.lazy import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 from . import UnitTestCase
 
 
 class Iterators(UnitTestCase):
     one_to_100 = lambda s: iter(list(range(1, 101)))
     evens = lambda s: iter(list(range(2, 101, 2)))
     odds = lambda s: iter(list(range(1, 100, 2)))
     empty = lambda s: iter([])
 
     def __init__(self, *args):
-        super(Iterators, self).__init__(*args)
+        super().__init__(*args)
         self.falseerror = self.falseerror_maker()
         self.trueerror = self.trueerror_maker()
         self.emptygen = self.emptygen_maker()
         self.typeerror = self.typeerror_maker()
         self.nameerror = self.nameerror_maker()
 
     def falseerror_maker(self):
         yield None
         yield 0
         yield []
         raise Exception
 
     def trueerror_maker(self):
         yield 1
-        yield u"hello"
-        yield (2, 3)
+        yield "hello"
+        yield 2, 3
         raise Exception
 
     def nameerror_maker(self):
         if 0:
             yield 1
         raise NameError
 
@@ -77,197 +71,188 @@
 
     def emptygen_maker(self):
         if 0:
             yield 1
 
 
 class IterEqualTestCase(Iterators):
-    u"""Tests for iter_equal function"""
+    """Tests for iter_equal function"""
     def testEmpty(self):
-        u"""Empty iterators should be equal"""
+        """Empty iterators should be equal"""
         assert Iter.equal(self.empty(), iter([]))
 
     def testNormal(self):
-        u"""See if normal iterators are equal"""
+        """See if normal iterators are equal"""
         assert Iter.equal(iter((1, 2, 3)), iter((1, 2, 3)))
         assert Iter.equal(self.odds(), iter(list(range(1, 100, 2))))
         assert Iter.equal(iter((1, 2, 3)), iter(list(range(1, 4))))
 
     def testNormalInequality(self):
-        u"""See if normal unequals work"""
+        """See if normal unequals work"""
         assert not Iter.equal(iter((1, 2, 3)), iter((1, 2, 4)))
-        assert not Iter.equal(self.odds(), iter([u"hello", u"there"]))
+        assert not Iter.equal(self.odds(), iter(["hello", "there"]))
 
     def testGenerators(self):
-        u"""equals works for generators"""
+        """equals works for generators"""
         def f():
             yield 1
-            yield u"hello"
+            yield "hello"
 
         def g():
             yield 1
-            yield u"hello"
+            yield "hello"
 
         assert Iter.equal(f(), g())
 
     def testLength(self):
-        u"""Differently sized iterators"""
+        """Differently sized iterators"""
         assert not Iter.equal(iter((1, 2, 3)), iter((1, 2)))
         assert not Iter.equal(iter((1, 2)), iter((1, 2, 3)))
 
 
 class FilterTestCase(Iterators):
-    u"""Tests for lazy_filter function"""
+    """Tests for lazy_filter function"""
     def testEmpty(self):
-        u"""empty iterators -> empty iterators"""
+        """empty iterators -> empty iterators"""
         assert Iter.empty(Iter.filter(self.alwayserror,
                                       self.empty())), \
-            u"Filtering an empty iterator should result in empty iterator"
+            "Filtering an empty iterator should result in empty iterator"
 
     def testNum1(self):
-        u"""Test numbers 1 - 100 #1"""
+        """Test numbers 1 - 100 #1"""
         assert Iter.equal(Iter.filter(lambda x: x % 2 == 0,
                                       self.one_to_100()),
                           self.evens())
         assert Iter.equal(Iter.filter(lambda x: x % 2,
                                       self.one_to_100()),
                           self.odds())
 
     def testError(self):
-        u"""Should raise appropriate error"""
+        """Should raise appropriate error"""
         i = Iter.filter(lambda x: x, self.falseerror_maker())
-        if sys.version_info.major >= 3:
-            self.assertRaises(Exception, i.__next__)
-        else:
-            self.assertRaises(Exception, i.next)
+        self.assertRaises(Exception, i.__next__)
 
 
 class MapTestCase(Iterators):
-    u"""Test mapping of iterators"""
+    """Test mapping of iterators"""
     def testNumbers(self):
-        u"""1 to 100 * 2 = 2 to 200"""
+        """1 to 100 * 2 = 2 to 200"""
         assert Iter.equal(Iter.map(lambda x: 2 * x, self.one_to_100()),
                           iter(list(range(2, 201, 2))))
 
     def testShortcut(self):
-        u"""Map should go in order"""
+        """Map should go in order"""
         def f(x):
-            if x == u"hello":
+            if x == "hello":
                 raise NameError
         i = Iter.map(f, self.trueerror_maker())
         next(i)
-        if sys.version_info.major >= 3:
-            self.assertRaises(NameError, i.__next__)
-        else:
-            self.assertRaises(NameError, i.next)
+        self.assertRaises(NameError, i.__next__)
 
     def testEmpty(self):
-        u"""Map of an empty iterator is empty"""
+        """Map of an empty iterator is empty"""
         assert Iter.empty(Iter.map(lambda x: x, iter([])))
 
 
 class CatTestCase(Iterators):
-    u"""Test concatenation of iterators"""
+    """Test concatenation of iterators"""
     def testEmpty(self):
-        u"""Empty + empty = empty"""
+        """Empty + empty = empty"""
         assert Iter.empty(Iter.cat(iter([]), iter([])))
 
     def testNumbers(self):
-        u"""1 to 50 + 51 to 100 = 1 to 100"""
+        """1 to 50 + 51 to 100 = 1 to 100"""
         assert Iter.equal(Iter.cat(iter(list(range(1, 51))), iter(list(range(51, 101)))),
                           self.one_to_100())
 
     def testShortcut(self):
-        u"""Process iterators in order"""
+        """Process iterators in order"""
         i = Iter.cat(self.typeerror_maker(), self.nameerror_maker())
         next(i)
         next(i)
-        if sys.version_info.major >= 3:
-            self.assertRaises(TypeError, i.__next__)
-        else:
-            self.assertRaises(TypeError, i.next)
+        self.assertRaises(TypeError, i.__next__)
 
 
 class AndOrTestCase(Iterators):
-    u"""Test And and Or"""
+    """Test And and Or"""
     def testEmpty(self):
-        u"""And() -> true, Or() -> false"""
+        """And() -> true, Or() -> false"""
         assert Iter.And(self.empty())
         assert not Iter.Or(self.empty())
 
     def testAndShortcut(self):
-        u"""And should return if any false"""
+        """And should return if any false"""
         assert Iter.And(self.falseerror_maker()) is None
 
     def testOrShortcut(self):
-        u"""Or should return if any true"""
+        """Or should return if any true"""
         assert Iter.Or(self.trueerror_maker()) == 1
 
     def testNormalAnd(self):
-        u"""And should go through true iterators, picking last"""
+        """And should go through true iterators, picking last"""
         assert Iter.And(iter([1, 2, 3, 4])) == 4
         self.assertRaises(Exception, Iter.And, self.trueerror_maker())
 
     def testNormalOr(self):
-        u"""Or goes through false iterators, picking last"""
+        """Or goes through false iterators, picking last"""
         assert Iter.Or(iter([0, None, []])) == []
         self.assertRaises(Exception, Iter.Or, self.falseerror_maker())
 
 
 class FoldingTest(Iterators):
-    u"""Test folding operations"""
+    """Test folding operations"""
     def f(self, x, y):
         return x + y
 
     def testEmpty(self):
-        u"""Folds of empty iterators should produce defaults"""
+        """Folds of empty iterators should produce defaults"""
         assert Iter.foldl(self.f, 23, self.empty()) == 23
         assert Iter.foldr(self.f, 32, self.empty()) == 32
 
     def testAddition(self):
-        u"""Use folds to sum lists"""
+        """Use folds to sum lists"""
         assert Iter.foldl(self.f, 0, self.one_to_100()) == 5050
         assert Iter.foldr(self.f, 0, self.one_to_100()) == 5050
 
     def testLargeAddition(self):
-        u"""Folds on 10000 element iterators"""
+        """Folds on 10000 element iterators"""
         assert Iter.foldl(self.f, 0, iter(list(range(1, 10001)))) == 50005000
         self.assertRaises(RuntimeError,
                           Iter.foldr, self.f, 0, iter(list(range(1, 10001))))
 
     def testLen(self):
-        u"""Use folds to calculate length of lists"""
+        """Use folds to calculate length of lists"""
         assert Iter.foldl(lambda x, y: x + 1, 0, self.evens()) == 50
         assert Iter.foldr(lambda x, y: y + 1, 0, self.odds()) == 50
 
 
 class MultiplexTest(Iterators):
     def testSingle(self):
-        u"""Test multiplex single stream"""
+        """Test multiplex single stream"""
         i_orig = self.one_to_100()
         i2_orig = self.one_to_100()
         i = Iter.multiplex(i_orig, 1)[0]
         assert Iter.equal(i, i2_orig)
 
     def testTrible(self):
-        u"""Test splitting iterator into three"""
+        """Test splitting iterator into three"""
         counter = [0]
 
         def ff(x):  # pylint: disable=unused-argument
             counter[0] += 1
 
         i_orig = self.one_to_100()
         i2_orig = self.one_to_100()
         i1, i2, i3 = Iter.multiplex(i_orig, 3, ff)
         assert Iter.equal(i1, i2)
         assert Iter.equal(i3, i2_orig)
         assert counter[0] == 100, counter
 
     def testDouble(self):
-        u"""Test splitting into two..."""
+        """Test splitting into two..."""
         i1, i2 = Iter.multiplex(self.one_to_100(), 2)
         assert Iter.equal(i1, self.one_to_100())
         assert Iter.equal(i2, self.one_to_100())
 
 
 class ITRBadder(ITRBranch):
     def start_process(self, index):  # pylint: disable=unused-argument
@@ -304,27 +289,27 @@
     def branch_process(self, subinstance):
         # print "Adding branch ", subinstance.total
         self.total += subinstance.total
 
 
 class TreeReducerTest(UnitTestCase):
     def setUp(self):
-        super(TreeReducerTest, self).setUp()
+        super().setUp()
 
         self.i1 = [(), (1,), (2,), (3,)]
         self.i2 = [(0,), (0, 1), (0, 1, 0), (0, 1, 1), (0, 2), (0, 2, 1), (0, 3)]
 
         self.i1a = [(), (1,)]
         self.i1b = [(2,), (3,)]
         self.i2a = [(0,), (0, 1), (0, 1, 0)]
         self.i2b = [(0, 1, 1), (0, 2)]
         self.i2c = [(0, 2, 1), (0, 3)]
 
     def testTreeReducer(self):
-        u"""testing IterTreeReducer"""
+        """testing IterTreeReducer"""
         itm = IterTreeReducer(ITRBadder, [])
         for index in self.i1:
             val = itm(index)
             assert val, (val, index)
         itm.Finish()
         assert itm.root_branch.total == 6, itm.root_branch.total
 
@@ -335,15 +320,15 @@
                 assert not val
             else:
                 assert val
         itm2.Finish()
         assert itm2.root_branch.total == 12, itm2.root_branch.total
 
     def testTreeReducerState(self):
-        u"""Test saving and recreation of an IterTreeReducer"""
+        """Test saving and recreation of an IterTreeReducer"""
         itm1a = IterTreeReducer(ITRBadder, [])
         for index in self.i1a:
             val = itm1a(index)
             assert val, index
         itm1b = pickle.loads(pickle.dumps(itm1a))
         for index in self.i1b:
             val = itm1b(index)
@@ -372,9 +357,9 @@
                 assert not val
             else:
                 assert val
         itm2c.Finish()
         assert itm2c.root_branch.total == 12, itm2c.root_branch.total
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_statistics.py` & `duplicity-2.0.0rc0/testing/unit/test_statistics.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,34 +15,31 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import unittest
 
-from . import UnitTestCase
 from duplicity import path
 from duplicity.statistics import *  # pylint: disable=redefined-builtin, unused-wildcard-import
 from testing import _runtest_dir
+from . import UnitTestCase
 
 
 class StatsObjTest(UnitTestCase):
-    u"""Test StatsObj class"""
+    """Test StatsObj class"""
     def setUp(self):
-        super(StatsObjTest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
 
     def set_obj(self, s):
-        u"""Set values of s's statistics"""
+        """Set values of s's statistics"""
         s.SourceFiles = 1
         s.SourceFileSize = 2
         s.NewFiles = 3
         s.NewFileSize = 4
         s.DeletedFiles = 5
         s.ChangedFiles = 7
         s.ChangedFileSize = 8
@@ -50,109 +47,109 @@
         s.DeltaEntries = 10
         s.RawDeltaSize = 11
         s.TotalDestinationSizeChange = 12
         s.StartTime = 13
         s.EndTime = 14
 
     def test_get_stats(self):
-        u"""Test reading and writing stat objects"""
+        """Test reading and writing stat objects"""
         s = StatsObj()
-        assert s.get_stat(u'SourceFiles') is None
+        assert s.get_stat('SourceFiles') is None
         self.set_obj(s)
-        assert s.get_stat(u'SourceFiles') == 1
+        assert s.get_stat('SourceFiles') == 1
 
         s1 = StatsDeltaProcess()
-        assert s1.get_stat(u'SourceFiles') == 0
+        assert s1.get_stat('SourceFiles') == 0
 
     def test_get_stats_string(self):
-        u"""Test conversion of stat object into string"""
+        """Test conversion of stat object into string"""
         s = StatsObj()
         stats_string = s.get_stats_string()
-        assert stats_string == u"", stats_string
+        assert stats_string == "", stats_string
 
         self.set_obj(s)
         stats_string = s.get_stats_string()
-        assert stats_string == u"""\
-StartTime 13.00 (Wed Dec 31 18:00:13 1969)
-EndTime 14.00 (Wed Dec 31 18:00:14 1969)
+        assert stats_string == """\
+StartTime 13.00 (Thu Jan  1 00:00:13 1970)
+EndTime 14.00 (Thu Jan  1 00:00:14 1970)
 ElapsedTime 1.00 (1 second)
 SourceFiles 1
 SourceFileSize 2 (2 bytes)
 NewFiles 3
 NewFileSize 4 (4 bytes)
 DeletedFiles 5
 ChangedFiles 7
 ChangedFileSize 8 (8 bytes)
 ChangedDeltaSize 9 (9 bytes)
 DeltaEntries 10
 RawDeltaSize 11 (11 bytes)
 TotalDestinationSizeChange 12 (12 bytes)
-""", u"'%s'" % stats_string
+""", f"'{stats_string}'"
 
     def test_line_string(self):
-        u"""Test conversion to a single line"""
+        """Test conversion to a single line"""
         s = StatsObj()
         self.set_obj(s)
-        statline = s.get_stats_line((u"sample", u"index", u"w", u"new\nline"))
-        assert statline == u"sample/index/w/new\\nline 1 2 3 4 5 7 8 9 10 11", \
+        statline = s.get_stats_line(("sample", "index", "w", "new\nline"))
+        assert statline == "sample/index/w/new\\nline 1 2 3 4 5 7 8 9 10 11", \
             repr(statline)
 
         statline = s.get_stats_line(())
-        assert statline == u". 1 2 3 4 5 7 8 9 10 11"
+        assert statline == ". 1 2 3 4 5 7 8 9 10 11"
 
-        statline = s.get_stats_line((u"file name with spaces",))
-        assert statline == (u"file\\x20name\\x20with\\x20spaces "
-                            u"1 2 3 4 5 7 8 9 10 11"), repr(statline)
+        statline = s.get_stats_line(("file name with spaces",))
+        assert statline == ("file\\x20name\\x20with\\x20spaces "
+                            "1 2 3 4 5 7 8 9 10 11"), repr(statline)
 
     def test_byte_summary(self):
-        u"""Test conversion of bytes to strings like 7.23MB"""
+        """Test conversion of bytes to strings like 7.23MB"""
         s = StatsObj()
         f = s.get_byte_summary_string
-        assert f(1) == u"1 byte"
-        assert f(234.34) == u"234 bytes"
-        assert f(2048) == u"2.00 KB"
-        assert f(3502243) == u"3.34 MB"
-        assert f(314992230) == u"300 MB"
-        assert f(36874871216) == u"34.3 GB", f(36874871216)
-        assert f(3775986812573450) == u"3434 TB"
+        assert f(1) == "1 byte"
+        assert f(234.34) == "234 bytes"
+        assert f(2048) == "2.00 KB"
+        assert f(3502243) == "3.34 MB"
+        assert f(314992230) == "300 MB"
+        assert f(36874871216) == "34.3 GB", f(36874871216)
+        assert f(3775986812573450) == "3434 TB"
 
     def test_init_stats(self):
-        u"""Test setting stat object from string"""
+        """Test setting stat object from string"""
         s = StatsObj()
-        s.set_stats_from_string(u"NewFiles 3 hello there")
+        s.set_stats_from_string("NewFiles 3 hello there")
         for attr in s.stat_attrs:
-            if attr == u'NewFiles':
+            if attr == 'NewFiles':
                 assert s.get_stat(attr) == 3
             else:
                 assert s.get_stat(attr) is None, (attr, s.__dict__[attr])
 
         s1 = StatsObj()
         self.set_obj(s1)
         assert not s1.stats_equal(s)
 
         s2 = StatsObj()
         s2.set_stats_from_string(s1.get_stats_string())
         assert s1.stats_equal(s2)
 
     def test_write_path(self):
-        u"""Test reading and writing of statistics object"""
-        p = path.Path(u"{0}/testfiles/statstest".format(_runtest_dir))
+        """Test reading and writing of statistics object"""
+        p = path.Path(f"{_runtest_dir}/testfiles/statstest")
         if p.exists():
             p.delete()
         s = StatsObj()
         self.set_obj(s)
         s.write_stats_to_path(p)
 
         s2 = StatsObj()
         assert not s2.stats_equal(s)
         s2.read_stats_from_path(p)
         assert s2.stats_equal(s)
 
     def testAverage(self):
-        u"""Test making an average statsobj"""
+        """Test making an average statsobj"""
         s1 = StatsObj()
         s1.StartTime = 5
         s1.EndTime = 10
         s1.ElapsedTime = 5
         s1.ChangedFiles = 2
         s1.SourceFiles = 100
         s1.NewFileSize = 4
@@ -170,9 +167,9 @@
         assert s3.ElapsedTime == 7.5
         assert s3.DeletedFiles is s3.NewFileSize is None, (s3.DeletedFiles,
                                                            s3.NewFileSize)
         assert s3.ChangedFiles == 1.5
         assert s3.SourceFiles == 75
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_manifest.py` & `duplicity-2.0.0rc0/testing/unit/test_manifest.py`

 * *Files 10% similar despite different names*

```diff
@@ -15,86 +15,84 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import re
 import unittest
+
 try:
     from unittest.mock import patch
 except ImportError:
     from mock import patch
 
 from duplicity import config
 from duplicity import manifest
 from duplicity import path
 
 from . import UnitTestCase
 
 
 class VolumeInfoTest(UnitTestCase):
-    u"""Test VolumeInfo"""
+    """Test VolumeInfo"""
     def test_basic(self):
-        u"""Basic VolumeInfoTest"""
+        """Basic VolumeInfoTest"""
         vi = manifest.VolumeInfo()
         vi.set_info(3, (b"hello", b"there"), None, (), None)
-        vi.set_hash(u"MD5", u"aoseutaohe")
+        vi.set_hash("MD5", "aoseutaohe")
         s = vi.to_string()
-        assert isinstance(s, (b"".__class__, u"".__class__))
+        assert isinstance(s, (b"".__class__, "".__class__))
         # print "---------\n%s\n---------" % s
         vi2 = manifest.VolumeInfo()
         vi2.from_string(s)
         assert vi == vi2
 
     def test_special(self):
-        u"""Test VolumeInfo with special characters"""
+        """Test VolumeInfo with special characters"""
         vi = manifest.VolumeInfo()
         vi.set_info(3234,
                     (b"\n eu \x233", b"heuo", b'\xd8\xab\xb1Wb\xae\xc5]\x8a\xbb\x15v*\xf4\x0f!\xf9>\xe2Y\x86\xbb\xab\xdbp\xb0\x84\x13k\x1d\xc2\xf1\xf5e\xa5U\x82\x9aUV\xa0\xf4\xdf4\xba\xfdX\x03\x82\x07s\xce\x9e\x8b\xb34\x04\x9f\x17 \xf4\x8f\xa6\xfa\x97\xab\xd8\xac\xda\x85\xdcKvC\xfa#\x94\x92\x9e\xc9\xb7\xc3_\x0f\x84g\x9aB\x11<=^\xdbM\x13\x96c\x8b\xa7|*"\\\'^$@#!(){}?+ ~` '),  # noqa
                     None,
                     (b"\n",),
                     None)
         s = vi.to_string()
         assert isinstance(s, (str, bytes))
         # print "---------\n%s\n---------" % s
         vi2 = manifest.VolumeInfo()
         vi2.from_string(s)
         assert vi == vi2
 
     def test_contains(self):
-        u"""Test to see if contains() works"""
+        """Test to see if contains() works"""
         vi = manifest.VolumeInfo()
-        vi.set_info(1, (u"1", u"2"), None, (u"1", u"3"), None)
-        assert vi.contains((u"1",), recursive=1)
-        assert not vi.contains((u"1",), recursive=0)
+        vi.set_info(1, ("1", "2"), None, ("1", "3"), None)
+        assert vi.contains(("1",), recursive=1)
+        assert not vi.contains(("1",), recursive=0)
 
         vi2 = manifest.VolumeInfo()
-        vi2.set_info(1, (u"A",), None, (u"Z",), None)
-        assert vi2.contains((u"M",), recursive=1)
-        assert vi2.contains((u"M",), recursive=0)
+        vi2.set_info(1, ("A",), None, ("Z",), None)
+        assert vi2.contains(("M",), recursive=1)
+        assert vi2.contains(("M",), recursive=0)
 
         vi3 = manifest.VolumeInfo()
-        vi3.set_info(1, (u"A",), None, (u"Z",), None)
-        assert not vi3.contains((u"3",), recursive=1)
-        assert not vi3.contains((u"3",), recursive=0)
+        vi3.set_info(1, ("A",), None, ("Z",), None)
+        assert not vi3.contains(("3",), recursive=1)
+        assert not vi3.contains(("3",), recursive=0)
 
 
 class ManifestTest(UnitTestCase):
-    u"""Test Manifest class"""
+    """Test Manifest class"""
 
     def setUp(self):
         UnitTestCase.setUp(self)
         self.old_files_changed = config.file_changed
-        config.file_changed = u'testing'
+        config.file_changed = 'testing'
 
     def tearDown(self):
         config.file_changed = self.old_files_changed
 
     def test_basic(self):
         vi1 = manifest.VolumeInfo()
         vi1.set_info(3, (b"hello",), None, (), None)
@@ -102,15 +100,15 @@
         vi2.set_info(4, (b"goodbye", b"there"), None, (b"aoeusht",), None)
         vi3 = manifest.VolumeInfo()
         vi3.set_info(34, (), None, (), None)
         m = manifest.Manifest()
         for vi in [vi1, vi2, vi3]:
             m.add_volume_info(vi)
 
-        self.set_config(u'local_path', path.Path(u"Foobar"))
+        self.set_config('local_path', path.Path("Foobar"))
         m.set_dirinfo()
         m.set_files_changed_info([])
 
         s = m.to_string()
         assert s.lower().startswith(b"hostname")
         assert s.endswith(b"\n")
 
@@ -124,47 +122,47 @@
         vi2.set_info(4, (b"goodbye", b"there"), None, (b"aoeusht",), None)
         vi3 = manifest.VolumeInfo()
         vi3.set_info(34, (), None, (), None)
         m = manifest.Manifest()
         for vi in [vi1, vi2, vi3]:
             m.add_volume_info(vi)
 
-        self.set_config(u'local_path', path.Path(u"Foobar"))
+        self.set_config('local_path', path.Path("Foobar"))
         m.set_dirinfo()
         m.set_files_changed_info([
             (b'one', b'new'),
             (b'two', b'changed'),
             (b'three', b'new'),
         ])
 
         # build manifest string
         s = m.to_string()
 
         # make filecount higher than files in list
         s2 = re.sub(b'Filelist 3', b'Filelist 5', s)
         m2 = manifest.Manifest().from_string(s2)
-        assert hasattr(m2, u'corrupt_filelist')
+        assert hasattr(m2, 'corrupt_filelist')
 
     def test_hostname_checks(self):
-        self.set_config(u'hostname', u'hostname')
-        self.set_config(u'fqdn', u'fqdn')
+        self.set_config('hostname', 'hostname')
+        self.set_config('fqdn', 'fqdn')
         m = manifest.Manifest()
 
         # Matching hostname should work
-        m.hostname = u'hostname'
+        m.hostname = 'hostname'
         m.check_dirinfo()
 
         # Matching fqdn should also work for backwards compatibility
-        m.hostname = u'fqdn'
+        m.hostname = 'fqdn'
         m.check_dirinfo()
 
         # Bad match should throw a fatal error and quit
-        m.hostname = u'foobar'
+        m.hostname = 'foobar'
         self.assertRaises(SystemExit, m.check_dirinfo)
 
         # But not if we tell the system to ignore it
-        self.set_config(u'allow_source_mismatch', True)
+        self.set_config('allow_source_mismatch', True)
         m.check_dirinfo()
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/__init__.py` & `duplicity-2.0.0rc0/duplicity/backends/cfbackend.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
-# Copyright 2012 Canonical Ltd
+# Copyright 2013 Kenneth Loafman
 #
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
 # under the terms of the GNU General Public License as published by the
 # Free Software Foundation; either version 2 of the License, or (at your
 # option) any later version.
@@ -14,16 +14,17 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
+import duplicity.backend
+from duplicity import config
 
-from .. import DuplicityTestCase
+if (config.cf_backend and
+        config.cf_backend.lower().strip() == 'pyrax'):
+    from ._cf_pyrax import PyraxBackend as CFBackend
+else:
+    from ._cf_cloudfiles import CloudFilesBackend as CFBackend
 
-
-class UnitTestCase(DuplicityTestCase):
-    pass
+duplicity.backend.register_backend("cf+http", CFBackend)
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_collections.py` & `duplicity-2.0.0rc0/testing/unit/test_collections.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,30 +15,28 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
-import pytest
 import random
 import unittest
 
-from . import UnitTestCase
+import pytest
+
 from duplicity import backend
 from duplicity import config
 from duplicity import dup_collections
 from duplicity import dup_time
 from duplicity import gpg
 from duplicity import path
 from testing import _runtest_dir
+from . import UnitTestCase
 
 filename_list1 = [b"duplicity-full.2002-08-17T16:17:01-07:00.manifest.gpg",
                   b"duplicity-full.2002-08-17T16:17:01-07:00.vol1.difftar.gpg",
                   b"duplicity-full.2002-08-17T16:17:01-07:00.vol2.difftar.gpg",
                   b"duplicity-full.2002-08-17T16:17:01-07:00.vol3.difftar.gpg",
                   b"duplicity-full.2002-08-17T16:17:01-07:00.vol4.difftar.gpg",
                   b"duplicity-full.2002-08-17T16:17:01-07:00.vol5.difftar.gpg",
@@ -75,106 +73,103 @@
                   b"duplicity-full.2002-08-15T01:01:01-07:00.vol1.difftar.gpg",
                   b"duplicity-inc.2000-08-17T16:17:01-07:00.to.2000-08-18T00:04:30-07:00.manifest.gpg",
                   b"duplicity-inc.2000-08-17T16:17:01-07:00.to.2000-08-18T00:04:30-07:00.vol1.difftar.gpg",
                   b"Extra stuff to be ignored"]
 
 
 class CollectionTest(UnitTestCase):
-    u"""Test collections"""
+    """Test collections"""
     def setUp(self):
-        super(CollectionTest, self).setUp()
+        super().setUp()
 
         self.unpack_testfiles()
 
-        col_test_dir = path.Path(u"{0}/testfiles/collectionstest".format(_runtest_dir))
-        archive_dir_path = col_test_dir.append(u"archive_dir")
-        self.set_config(u'archive_dir_path', archive_dir_path)
-        self.archive_dir_backend = backend.get_backend(u"file://{0}/testfiles/collectionstest".format(_runtest_dir) +
-                                                       u"/archive_dir")
-
-        self.real_backend = backend.get_backend(u"file://%s/%s" %
-                                                (col_test_dir.uc_name, u"remote_dir"))
-        self.output_dir = path.Path(u"{0}/testfiles/output".format(_runtest_dir))  # used as a temp directory
-        self.output_dir_backend = backend.get_backend(u"file://{0}/testfiles/output".format(_runtest_dir))
+        col_test_dir = path.Path(f"{_runtest_dir}/testfiles/collectionstest")
+        archive_dir_path = col_test_dir.append("archive_dir")
+        self.set_config('archive_dir_path', archive_dir_path)
+        self.archive_dir_backend = backend.get_backend(f"file://{_runtest_dir}/testfiles/collectionstest/archive_dir")
+        self.real_backend = backend.get_backend(f"file://{col_test_dir.uc_name}/remote_dir")
+        self.output_dir = path.Path(f"{_runtest_dir}/testfiles/output")  # used as a temp directory
+        self.output_dir_backend = backend.get_backend(f"file://{_runtest_dir}/testfiles/output")
 
     def set_gpg_profile(self):
-        u"""Set gpg profile to standard "foobar" sym"""
-        self.set_config(u'gpg_profile', gpg.GPGProfile(passphrase=u"foobar"))
+        """Set gpg profile to standard "foobar" sym"""
+        self.set_config('gpg_profile', gpg.GPGProfile(passphrase="foobar"))
 
     def test_backup_chains(self):
-        u"""Test basic backup chain construction"""
+        """Test basic backup chain construction"""
         random.shuffle(filename_list1)
-        cs = dup_collections.CollectionsStatus(None, config.archive_dir_path, u"full")
+        cs = dup_collections.CollectionsStatus(None, config.archive_dir_path, "full")
         chains, orphaned, incomplete = cs.get_backup_chains(filename_list1)
         if len(chains) != 1 or len(orphaned) != 0:
             print(chains)
             print(orphaned)
             assert 0
 
         chain = chains[0]
         assert chain.end_time == 1029654270
         assert chain.fullset.time == 1029626221
 
     def test_collections_status(self):
-        u"""Test CollectionStatus object's set_values()"""
+        """Test CollectionStatus object's set_values()"""
         def check_cs(cs):
-            u"""Check values of collections status"""
+            """Check values of collections status"""
             assert cs.values_set
 
             assert cs.matched_chain_pair
             assert cs.matched_chain_pair[0].end_time == 1029826800
             assert len(cs.all_backup_chains) == 1, cs.all_backup_chains
 
-        cs = dup_collections.CollectionsStatus(self.real_backend, config.archive_dir_path, u"full").set_values()
+        cs = dup_collections.CollectionsStatus(self.real_backend, config.archive_dir_path, "full").set_values()
         check_cs(cs)
         assert cs.matched_chain_pair[0].islocal()
 
     def test_sig_chain(self):
-        u"""Test a single signature chain"""
+        """Test a single signature chain"""
         chain = dup_collections.SignatureChain(1, config.archive_dir_path)
         for filename in local_sigchain_filename_list:
             assert chain.add_filename(filename)
         assert not chain.add_filename(
             b"duplicity-new-signatures.2002-08-18T00:04:30-07:00.to.2002-08-20T00:00:00-07:00.sigtar.gpg")
 
     def test_sig_chains(self):
-        u"""Test making signature chains from filename list"""
-        cs = dup_collections.CollectionsStatus(None, config.archive_dir_path, u"full")
+        """Test making signature chains from filename list"""
+        cs = dup_collections.CollectionsStatus(None, config.archive_dir_path, "full")
         chains, orphaned_paths = cs.get_signature_chains(local=1)
         self.sig_chains_helper(chains, orphaned_paths)
 
     def test_sig_chains2(self):
-        u"""Test making signature chains from filename list on backend"""
-        cs = dup_collections.CollectionsStatus(self.archive_dir_backend, config.archive_dir_path, u"full")
+        """Test making signature chains from filename list on backend"""
+        cs = dup_collections.CollectionsStatus(self.archive_dir_backend, config.archive_dir_path, "full")
         chains, orphaned_paths = cs.get_signature_chains(local=None)
         self.sig_chains_helper(chains, orphaned_paths)
 
     def sig_chains_helper(self, chains, orphaned_paths):
-        u"""Test chains and orphaned_paths values for two above tests"""
+        """Test chains and orphaned_paths values for two above tests"""
         if orphaned_paths:
             for op in orphaned_paths:
                 print(op)
             assert 0
         assert len(chains) == 1, chains
         assert chains[0].end_time == 1029826800
 
     def sigchain_fileobj_get(self, local):
-        u"""Return chain, local if local is true with filenames added"""
+        """Return chain, local if local is true with filenames added"""
         if local:
             chain = dup_collections.SignatureChain(1, config.archive_dir_path)
             for filename in local_sigchain_filename_list:
                 assert chain.add_filename(filename)
         else:
             chain = dup_collections.SignatureChain(None, self.real_backend)
             for filename in remote_sigchain_filename_list:
                 assert chain.add_filename(filename)
         return chain
 
     def sigchain_fileobj_check_list(self, chain):
-        u"""Make sure the list of file objects in chain has right contents
+        """Make sure the list of file objects in chain has right contents
 
         The contents of the /tmp/testfiles/collectiontest/remote_dir have
         to be coordinated with this test.
 
         """
         fileobjlist = chain.get_fileobjs()
         assert len(fileobjlist) == 3
@@ -184,68 +179,68 @@
             fileobjlist[i].close()
             assert buf == s, (buf, s)
 
         test_fileobj(0, b"Hello, world!")
         test_fileobj(1, b"hello 1")
         test_fileobj(2, b"Hello 2")
 
-    @pytest.mark.usefixtures(u"redirect_stdin")
+    @pytest.mark.usefixtures("redirect_stdin")
     def test_sigchain_fileobj(self):
-        u"""Test getting signature chain fileobjs from archive_dir_path"""
+        """Test getting signature chain fileobjs from archive_dir_path"""
         self.set_gpg_profile()
         self.sigchain_fileobj_check_list(self.sigchain_fileobj_get(1))
         self.sigchain_fileobj_check_list(self.sigchain_fileobj_get(None))
 
     def get_filelist2_cs(self):
-        u"""Return set CollectionsStatus object from filelist 2"""
+        """Return set CollectionsStatus object from filelist 2"""
         # Set up /tmp/testfiles/output with files from filename_list2
         for filename in filename_list2:
             p = self.output_dir.append(filename)
             p.touch()
 
-        cs = dup_collections.CollectionsStatus(self.output_dir_backend, config.archive_dir_path, u"full")
+        cs = dup_collections.CollectionsStatus(self.output_dir_backend, config.archive_dir_path, "full")
         cs.set_values()
         return cs
 
     def test_get_extraneous(self):
-        u"""Test the listing of extraneous files"""
+        """Test the listing of extraneous files"""
         cs = self.get_filelist2_cs()
         assert len(cs.orphaned_backup_sets) == 1, cs.orphaned_backup_sets
         assert len(cs.local_orphaned_sig_names) == 0, cs.local_orphaned_sig_names
         assert len(cs.remote_orphaned_sig_names) == 1, cs.remote_orphaned_sig_names
         assert len(cs.incomplete_backup_sets) == 1, cs.incomplete_backup_sets
 
         right_list = [b"duplicity-new-signatures.2001-08-17T02:05:13-05:00.to.2002-08-17T05:05:14-05:00.sigtar.gpg",
                       b"duplicity-full.2002-08-15T01:01:01-07:00.vol1.difftar.gpg",
                       b"duplicity-inc.2000-08-17T16:17:01-07:00.to.2000-08-18T00:04:30-07:00.manifest.gpg",
                       b"duplicity-inc.2000-08-17T16:17:01-07:00.to.2000-08-18T00:04:30-07:00.vol1.difftar.gpg"]
         local_received_list, remote_received_list = cs.get_extraneous()
         errors = []
         for filename in remote_received_list:
             if filename not in right_list:
-                errors.append(u"### Got bad extraneous filename " + filename.decode())
+                errors.append("### Got bad extraneous filename " + filename.decode())
             else:
                 right_list.remove(filename)
         for filename in right_list:
-            errors.append(u"### Didn't receive extraneous filename " + filename)
-        assert not errors, u"\n" + u"\n".join(errors)
+            errors.append("### Didn't receive extraneous filename " + filename)
+        assert not errors, "\n" + "\n".join(errors)
 
     def test_get_olderthan(self):
-        u"""Test getting list of files older than a certain time"""
+        """Test getting list of files older than a certain time"""
         cs = self.get_filelist2_cs()
         oldsets = cs.get_older_than(
-            dup_time.genstrtotime(u"2002-05-01T16:17:01-07:00"))
+            dup_time.genstrtotime("2002-05-01T16:17:01-07:00"))
         oldset_times = [s.get_time() for s in oldsets]
-        right_times = [dup_time.genstrtotime(u'2001-01-01T16:17:01-07:00')]
+        right_times = [dup_time.genstrtotime('2001-01-01T16:17:01-07:00')]
         assert oldset_times == right_times, \
             [oldset_times, right_times]
 
         oldsets_required = cs.get_older_than_required(
-            dup_time.genstrtotime(u"2002-08-17T20:00:00-07:00"))
+            dup_time.genstrtotime("2002-08-17T20:00:00-07:00"))
         oldset_times = [s.get_time() for s in oldsets_required]
-        right_times_required = [dup_time.genstrtotime(u'2002-08-17T16:17:01-07:00')]
+        right_times_required = [dup_time.genstrtotime('2002-08-17T16:17:01-07:00')]
         assert oldset_times == right_times_required, \
             [oldset_times, right_times_required]
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_dup_temp.py` & `duplicity-2.0.0rc0/testing/unit/test_dup_temp.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,67 +15,64 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import gzip
 import unittest
 
 from duplicity import dup_temp
 from duplicity import file_naming
 from . import UnitTestCase
 
 
 class TempTest(UnitTestCase):
-    u"""Test various temp files methods"""
+    """Test various temp files methods"""
 
     def test_temppath(self):
-        u"""Allocate new temppath, try open_with_delete"""
+        """Allocate new temppath, try open_with_delete"""
         tp = dup_temp.new_temppath()
         assert not tp.exists()
-        fileobj = tp.open(u"wb")
+        fileobj = tp.open("wb")
         fileobj.write(b"hello, there")
         fileobj.close()
         tp.setdata()
         assert tp.isreg()
 
-        fin = tp.open_with_delete(u"rb")
+        fin = tp.open_with_delete("rb")
         buf = fin.read()
         assert buf == b"hello, there", buf
         fin.close()
         assert not tp.exists()
 
     def test_tempduppath(self):
-        u"""Allocate new tempduppath, then open_with_delete"""
+        """Allocate new tempduppath, then open_with_delete"""
         # pr indicates file is gzipped
-        pr = file_naming.ParseResults(u"inc", manifest=1,
+        pr = file_naming.ParseResults("inc", manifest=1,
                                       start_time=1, end_time=3,
                                       compressed=1)
 
         tdp = dup_temp.new_tempduppath(pr)
         assert not tdp.exists()
-        fout = tdp.filtered_open(u"wb")
+        fout = tdp.filtered_open("wb")
         fout.write(b"hello, there")
         fout.close()
         tdp.setdata()
         assert tdp.isreg()
 
-        fin1 = gzip.GzipFile(tdp.name, u"rb")
+        fin1 = gzip.GzipFile(tdp.name, "rb")
         buf = fin1.read()
         assert buf == b"hello, there", buf
         fin1.close()
 
-        fin2 = tdp.filtered_open_with_delete(u"rb")
+        fin2 = tdp.filtered_open_with_delete("rb")
         buf2 = fin2.read()
         assert buf2 == b"hello, there", buf
         fin2.close()
         assert not tdp.exists()
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_file_naming.py` & `duplicity-2.0.0rc0/testing/unit/test_file_naming.py`

 * *Files 11% similar despite different names*

```diff
@@ -15,146 +15,132 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from builtins import object
-from future import standard_library
-standard_library.install_aliases()
 
+import os
 import unittest
 
+from duplicity import config
 from duplicity import dup_time
 from duplicity import file_naming
 from duplicity import log
-from duplicity import config
-from duplicity import util
 from . import UnitTestCase
 
 
 class Test36(UnitTestCase):
     def test_base36(self):
-        u"""Test conversion to/from base 36"""
+        """Test conversion to/from base 36"""
         numlist = [0, 1, 10, 1313, 34233, 872338, 2342889,
                    134242234, 1204684368, 34972382455]
         for n in numlist:
             b = file_naming.to_base36(n)
             assert file_naming.from_base36(b) == n, (b, n)
 
 
 class FileNamingBase(object):
-    u"""Holds file naming test functions, for use in subclasses"""
+    """Holds file naming test functions, for use in subclasses"""
     def test_basic(self):
-        u"""Check get/parse cycle"""
+        """Check get/parse cycle"""
         dup_time.setprevtime(10)
         dup_time.setcurtime(20)
 
         file_naming.prepare_regex(force=True)
-        filename = file_naming.get(u"inc", volume_number=23)
-        log.Info(u"Inc filename: " + util.fsdecode(filename))
+        filename = file_naming.get("inc", volume_number=23)
+        log.Info(f"Inc filename: {os.fsdecode(filename)}")
         pr = file_naming.parse(filename)
-        assert pr and pr.type == u"inc", pr
+        assert pr and pr.type == "inc", pr
         assert pr.start_time == 10
         assert pr.end_time == 20
         assert pr.volume_number == 23
         assert not pr.partial
 
-        filename = file_naming.get(u"full-sig")
-        log.Info(u"Full sig filename: " + util.fsdecode(filename))
+        filename = file_naming.get("full-sig")
+        log.Info(f"Full sig filename: {os.fsdecode(filename)}")
         pr = file_naming.parse(filename)
-        assert pr.type == u"full-sig"
+        assert pr.type == "full-sig"
         assert pr.time == 20
         assert not pr.partial
 
-        filename = file_naming.get(u"new-sig")
+        filename = file_naming.get("new-sig")
         pr = file_naming.parse(filename)
-        assert pr.type == u"new-sig"
+        assert pr.type == "new-sig"
         assert pr.start_time == 10
         assert pr.end_time == 20
         assert not pr.partial
 
     def test_suffix(self):
-        u"""Test suffix (encrypt/compressed) encoding and generation"""
+        """Test suffix (encrypt/compressed) encoding and generation"""
         file_naming.prepare_regex(force=True)
-        filename = file_naming.get(u"inc", manifest=1, gzipped=1)
+        filename = file_naming.get("inc", manifest=1, gzipped=1)
         pr = file_naming.parse(filename)
         assert pr and pr.compressed == 1
         assert pr.manifest
 
-        filename2 = file_naming.get(u"full", volume_number=23, encrypted=1)
+        filename2 = file_naming.get("full", volume_number=23, encrypted=1)
         pr = file_naming.parse(filename2)
         assert pr and pr.encrypted == 1
         assert pr.volume_number == 23
 
     def test_more(self):
-        u"""More file_parsing tests"""
+        """More file_parsing tests"""
         file_naming.prepare_regex(force=True)
         pr = file_naming.parse(config.file_prefix + config.file_prefix_signature + b"dns.h112bi.h14rg0.st.g")
         assert pr, pr
-        assert pr.type == u"new-sig"
+        assert pr.type == "new-sig"
         assert pr.end_time == 1029826800
 
-        if not config.short_filenames:
-            pr = file_naming.parse(config.file_prefix +
-                                   config.file_prefix_signature +
-                                   b"duplicity-new-signatures.2002-08-18T00:04:30-07:00.to.2002-08-20T00:00:00-07:00.sigtar.gpg")  # noqa
-            assert pr, pr
-            assert pr.type == u"new-sig"
-            assert pr.end_time == 1029826800
+        pr = file_naming.parse(config.file_prefix +
+                               config.file_prefix_signature +
+                               b"duplicity-new-signatures.2002-08-18T00:04:30-07:00.to.2002-08-20T00:00:00-07:00.sigtar.gpg")  # noqa
+        assert pr, pr
+        assert pr.type == "new-sig"
+        assert pr.end_time == 1029826800
 
         pr = file_naming.parse(config.file_prefix + config.file_prefix_signature + b"dfs.h5dixs.st.g")
         assert pr, pr
-        assert pr.type == u"full-sig"
+        assert pr.type == "full-sig"
         assert pr.time == 1036954144, repr(pr.time)
 
     def test_partial(self):
-        u"""Test addition of partial flag"""
+        """Test addition of partial flag"""
         file_naming.prepare_regex(force=True)
         pr = file_naming.parse(config.file_prefix + config.file_prefix_signature + b"dns.h112bi.h14rg0.st.p.g")
         assert pr, pr
         assert pr.partial
-        assert pr.type == u"new-sig"
+        assert pr.type == "new-sig"
         assert pr.end_time == 1029826800
 
-        if not config.short_filenames:
-            pr = file_naming.parse(config.file_prefix + config.file_prefix_signature + b"duplicity-new-signatures.2002-08-18T00:04:30-07:00.to.2002-08-20T00:00:00-07:00.sigtar.part.gpg")  # noqa
-            assert pr, pr
-            assert pr.partial
-            assert pr.type == u"new-sig"
-            assert pr.end_time == 1029826800
+        pr = file_naming.parse(config.file_prefix + config.file_prefix_signature + b"duplicity-new-signatures.2002-08-18T00:04:30-07:00.to.2002-08-20T00:00:00-07:00.sigtar.part.gpg")  # noqa
+        assert pr, pr
+        assert pr.partial
+        assert pr.type == "new-sig"
+        assert pr.end_time == 1029826800
 
         pr = file_naming.parse(config.file_prefix + config.file_prefix_signature + b"dfs.h5dixs.st.p.g")
         assert pr, pr
         assert pr.partial
-        assert pr.type == u"full-sig"
+        assert pr.type == "full-sig"
         assert pr.time == 1036954144, repr(pr.time)
 
 
-class FileNamingLong(UnitTestCase, FileNamingBase):
-    u"""Test long filename parsing and generation"""
-    def setUp(self):
-        super(FileNamingLong, self).setUp()
-        self.set_config(u'short_filenames', 0)
-
-
-class FileNamingShort(UnitTestCase, FileNamingBase):
-    u"""Test short filename parsing and generation"""
+class FileNaming(UnitTestCase, FileNamingBase):
+    """Test long filename parsing and generation"""
     def setUp(self):
-        super(FileNamingShort, self).setUp()
-        self.set_config(u'short_filenames', 1)
+        super().setUp()
 
 
 class FileNamingPrefixes(UnitTestCase, FileNamingBase):
-    u"""Test filename parsing and generation with prefixes"""
+    """Test filename parsing and generation with prefixes"""
     def setUp(self):
-        super(FileNamingPrefixes, self).setUp()
-        self.set_config(u'file_prefix', b"global-")
-        self.set_config(u'file_prefix_manifest', b"mani-")
-        self.set_config(u'file_prefix_signature', b"sign-")
-        self.set_config(u'file_prefix_archive', b"arch-")
+        super().setUp()
+        self.set_config('file_prefix', b"global-")
+        self.set_config('file_prefix_manifest', b"mani-")
+        self.set_config('file_prefix_signature', b"sign-")
+        self.set_config('file_prefix_archive', b"arch-")
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_tarfile.py` & `duplicity-2.0.0rc0/testing/unit/test_tarfile.py`

 * *Files 10% similar despite different names*

```diff
@@ -14,25 +14,23 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import unittest
+
 from duplicity import cached_ops
 from duplicity import tarfile
 from . import UnitTestCase
 
 
 class TarfileTest(UnitTestCase):
     def test_cached_ops(self):
         self.assertTrue(tarfile.grp is cached_ops)
         self.assertTrue(tarfile.pwd is cached_ops)
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_tempdir.py` & `duplicity-2.0.0rc0/testing/unit/test_tempdir.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,17 +15,14 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import os
 import tempfile
 import unittest
 
 from duplicity import tempdir
 from . import UnitTestCase
@@ -53,30 +50,30 @@
         fo, fname = td.mkstemp_file()
         fo.close()  # don't forget, leave to cleanup()
 
         # cleanup
         td.cleanup()
 
     def test_dirname(self):
-        u"""
+        """
         test if we generated a dirname
         """
         td = tempdir.default()
         dirname = td.dir()
         self.assertTrue(dirname is not None)
 
-        u"""
+        """
         test if duplicity's temp files are created in our temp dir
         """
         f1d, f1_name = tempdir.default().mkstemp()
         f1_dirname = os.path.dirname(f1_name)
 
         self.assertTrue(dirname == f1_dirname)
 
-        u"""
+        """
         test if tempfile creates in our temp dir now as well by default
         """
         f2 = tempfile.NamedTemporaryFile()
         f2_dirname = os.path.dirname(f2.name)
 
         self.assertTrue(dirname == f2_dirname)
 
@@ -85,9 +82,9 @@
         os.unlink(f1_name)
         td.forget(f1_name)
         f2.close()
 
         td.cleanup()
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_backend_instance.py` & `duplicity-2.0.0rc0/testing/unit/test_backend_instance.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,54 +14,50 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
-import os
 import io
+import os
 import unittest
 
-from . import UnitTestCase
+import duplicity.backend
 from duplicity import log
 from duplicity import path
 from duplicity import util
 from duplicity.errors import BackendException
-import duplicity.backend
-
 from testing import _runtest_dir
+from . import UnitTestCase
 
 
 class BackendInstanceBase(UnitTestCase):
 
     def setUp(self):
         UnitTestCase.setUp(self)
-        assert not os.system(u"rm -rf {0}/testfiles".format(_runtest_dir))
-        os.makedirs(u'{0}/testfiles'.format(_runtest_dir))
+        assert not os.system(f"rm -rf {_runtest_dir}/testfiles")
+        os.makedirs(f'{_runtest_dir}/testfiles')
         self.backend = None
-        self.local = path.Path(u'{0}/testfiles/local'.format(_runtest_dir))
+        self.local = path.Path(f'{_runtest_dir}/testfiles/local')
         self.local.writefileobj(io.BytesIO(b"hello"))
 
     def tearDown(self):
-        assert not os.system(u"rm -rf {0}/testfiles".format(_runtest_dir))
+        assert not os.system(f"rm -rf {_runtest_dir}/testfiles")
         if self.backend is None:
             return
-        if hasattr(self.backend, u'_close'):
+        if hasattr(self.backend, '_close'):
             self.backend._close()
 
     def test_get(self):
         if self.backend is None:
             return
         self.backend._put(self.local, b'file-a')
-        getfile = path.Path(u'{0}/testfiles/getfile'.format(_runtest_dir))
+        getfile = path.Path(f'{_runtest_dir}/testfiles/getfile')
         self.backend._get(b'file-a', getfile)
         self.assertTrue(self.local.compare_data(getfile))
 
     def test_list(self):
         if self.backend is None:
             return
         self.backend._put(self.local, b'file-a')
@@ -70,189 +66,202 @@
         # the par2 backend does), so only check that at least a and b exist.
         self.assertTrue(b'file-a' in self.backend._list())
         self.assertTrue(b'file-b' in self.backend._list())
 
     def test_delete(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_delete'):
-            self.assertTrue(hasattr(self.backend, u'_delete_list'))
+        if not hasattr(self.backend, '_delete'):
+            self.assertTrue(hasattr(self.backend, '_delete_list'))
             return
         self.backend._put(self.local, b'file-a')
         self.backend._put(self.local, b'file-b')
         self.backend._delete(b'file-a')
         self.assertFalse(b'file-a' in self.backend._list())
         self.assertTrue(b'file-b' in self.backend._list())
 
     def test_delete_clean(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_delete'):
-            self.assertTrue(hasattr(self.backend, u'_delete_list'))
+        if not hasattr(self.backend, '_delete'):
+            self.assertTrue(hasattr(self.backend, '_delete_list'))
             return
         self.backend._put(self.local, b'file-a')
         self.backend._delete(b'file-a')
         self.assertFalse(b'file-a' in self.backend._list())
 
     def test_delete_missing(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_delete'):
-            self.assertTrue(hasattr(self.backend, u'_delete_list'))
+        if not hasattr(self.backend, '_delete'):
+            self.assertTrue(hasattr(self.backend, '_delete_list'))
             return
         # Backends can either silently ignore this, or throw an error
         # that gives log.ErrorCode.backend_not_found.
         try:
             self.backend._delete(b'file-a')
         except BackendException as e:
             pass  # Something went wrong, but it was an 'expected' something
         except Exception as e:
-            code = duplicity.backend._get_code_from_exception(self.backend, u'delete', e)
+            code = duplicity.backend._get_code_from_exception(self.backend, 'delete', e)
             self.assertEqual(code, log.ErrorCode.backend_not_found)
 
     def test_delete_list(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_delete_list'):
-            self.assertTrue(hasattr(self.backend, u'_delete'))
+        if not hasattr(self.backend, '_delete_list'):
+            self.assertTrue(hasattr(self.backend, '_delete'))
             return
         self.backend._put(self.local, b'file-a')
         self.backend._put(self.local, b'file-b')
         self.backend._put(self.local, b'file-c')
         self.backend._delete_list([b'file-a', b'd', b'file-c'])
         files = self.backend._list()
         self.assertFalse(b'file-a' in files, files)
         self.assertTrue(b'file-b' in files, files)
         self.assertFalse(b'file-c' in files, files)
 
     def test_move(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_move'):
+        if not hasattr(self.backend, '_move'):
             return
 
-        copy = path.Path(u'{0}/testfiles/copy'.format(_runtest_dir))
+        copy = path.Path(f'{_runtest_dir}/testfiles/copy')
         self.local.copy(copy)
 
         self.backend._move(self.local, b'file-a')
         self.assertTrue(b'file-a' in self.backend._list())
         self.assertFalse(self.local.exists())
 
-        getfile = path.Path(u'{0}/testfiles/getfile'.format(_runtest_dir))
+        getfile = path.Path(f'{_runtest_dir}/testfiles/getfile')
         self.backend._get(b'file-a', getfile)
         self.assertTrue(copy.compare_data(getfile))
 
     def test_query_exists(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_query'):
+        if not hasattr(self.backend, '_query'):
             return
         self.backend._put(self.local, b'file-a')
         info = self.backend._query(b'file-a')
-        self.assertEqual(info[u'size'], self.local.getsize())
+        self.assertEqual(info['size'], self.local.getsize())
 
     def test_query_missing(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_query'):
+        if not hasattr(self.backend, '_query'):
             return
         # Backends can either return -1 themselves, or throw an error
         # that gives log.ErrorCode.backend_not_found.
         try:
             info = self.backend._query(b'file-a')
         except BackendException as e:  # pylint:
             pass  # Something went wrong, but it was an 'expected' something
         except Exception as e:
-            code = duplicity.backend._get_code_from_exception(self.backend, u'query', e)
+            code = duplicity.backend._get_code_from_exception(self.backend, 'query', e)
             self.assertEqual(code, log.ErrorCode.backend_not_found)
         else:
-            self.assertEqual(info[u'size'], -1)
+            self.assertEqual(info['size'], -1)
 
     def test_query_list(self):
         if self.backend is None:
             return
-        if not hasattr(self.backend, u'_query_list'):
+        if not hasattr(self.backend, '_query_list'):
             return
         self.backend._put(self.local, b'file-a')
         self.backend._put(self.local, b'file-c')
         info = self.backend._query_list([b'file-a', b'file-b'])
-        self.assertEqual(info[b'file-a'][u'size'], self.local.getsize())
-        self.assertEqual(info[b'file-b'][u'size'], -1)
+        self.assertEqual(info[b'file-a']['size'], self.local.getsize())
+        self.assertEqual(info[b'file-b']['size'], -1)
         self.assertFalse(b'file-c' in info)
 
 
 class LocalBackendTest(BackendInstanceBase):
     def setUp(self):
-        super(LocalBackendTest, self).setUp()
-        url = u'file://{0}/testfiles/output'.format(_runtest_dir)
+        super().setUp()
+        url = f'file://{_runtest_dir}/testfiles/output'
         self.backend = duplicity.backend.get_backend_object(url)
-        self.assertEqual(self.backend.__class__.__name__, u'LocalBackend')
+        self.assertEqual(self.backend.__class__.__name__, 'LocalBackend')
 
 
 # TODO: Add par2-specific tests here, to confirm that we can recover
-@unittest.skipIf(not util.which(u'par2'), u"par2 not installed")
+@unittest.skipIf(not util.which('par2'), "par2 not installed")
 class Par2BackendTest(BackendInstanceBase):
     def setUp(self):
-        super(Par2BackendTest, self).setUp()
-        url = u'par2+file://{0}/testfiles/output'.format(_runtest_dir)
+        super().setUp()
+        url = f'par2+file://{_runtest_dir}/testfiles/output'
         self.backend = duplicity.backend.get_backend_object(url)
-        self.assertEqual(self.backend.__class__.__name__, u'Par2Backend')
+        self.assertEqual(self.backend.__class__.__name__, 'Par2Backend')
 
 
 # TODO: Fix so localhost is not required.  Fails on LP and GitLab
 # class RsyncBackendTest(BackendInstanceBase):
 #     def setUp(self):
-#         super(RsyncBackendTest, self).setUp()
-#         os.makedirs(u'{0}/testfiles/output')  # rsync needs it to exist first
-#         url = u'rsync://localhost:2222//%s/{0}/testfiles/output' % os.getcwd()
+#         super().setUp()
+#         os.makedirs('{0}/testfiles/output')  # rsync needs it to exist first
+#         url = 'rsync://localhost:2222//%s/{0}/testfiles/output' % os.getcwd()
 #         self.backend = duplicity.backend.get_backend_object(url)
-#         self.assertEqual(self.backend.__class__.__name__, u'RsyncBackend')
+#         self.assertEqual(self.backend.__class__.__name__, 'RsyncBackend')
 
 
 class TahoeBackendTest(BackendInstanceBase):
     def setUp(self):
-        super(TahoeBackendTest, self).setUp()
-        os.makedirs(u'{0}/testfiles/output'.format(_runtest_dir))
-        url = u'tahoe://{0}/testfiles/output'.format(_runtest_dir)
+        super().setUp()
+        os.makedirs(f'{_runtest_dir}/testfiles/output')
+        url = f'tahoe://{_runtest_dir}/testfiles/output'
         self.backend = duplicity.backend.get_backend_object(url)
-        self.assertEqual(self.backend.__class__.__name__, u'TAHOEBackend')
+        self.assertEqual(self.backend.__class__.__name__, 'TAHOEBackend')
 
 
 # TODO: Modernize hsi backend stub
 #  class HSIBackendTest(BackendInstanceBase):
 #      def setUp(self):
-#          super(HSIBackendTest, self).setUp()
-#          os.makedirs(u'{0}/testfiles/output')
+#          super().setUp()
+#          os.makedirs('{0}/testfiles/output')
 #          # hostname is ignored...  Seemingly on purpose
-#          url = u'hsi://hostname%s/{0}/testfiles/output' % os.getcwd()
+#          url = 'hsi://hostname%s/{0}/testfiles/output' % os.getcwd()
 #          self.backend = duplicity.backend.get_backend_object(url)
-#          self.assertEqual(self.backend.__class__.__name__, u'HSIBackend')
+#          self.assertEqual(self.backend.__class__.__name__, 'HSIBackend')
 
 
-@unittest.skipIf(not util.which(u'lftp'), u"lftp not installed")
+@unittest.skipIf(not util.which('lftp'), "lftp not installed")
 class FTPBackendTest(BackendInstanceBase):
     def setUp(self):
-        super(FTPBackendTest, self).setUp()
-        os.makedirs(u'{0}/testfiles/output'.format(_runtest_dir))
-        url = u'ftp://user:pass@hostname/{0}/testfiles/output'.format(_runtest_dir)
+        super().setUp()
+        os.makedirs(f'{_runtest_dir}/testfiles/output')
+        url = f'ftp://user:pass@hostname/{_runtest_dir}/testfiles/output'
         self.backend = duplicity.backend.get_backend_object(url)
-        self.assertEqual(self.backend.__class__.__name__, u'LFTPBackend')
+        self.assertEqual(self.backend.__class__.__name__, 'LFTPBackend')
 
 
-@unittest.skipIf(not util.which(u'lftp'), u"lftp not installed")
+@unittest.skipIf(not util.which('lftp'), "lftp not installed")
 class FTPSBackendTest(BackendInstanceBase):
     def setUp(self):
-        super(FTPSBackendTest, self).setUp()
-        os.makedirs(u'{0}/testfiles/output'.format(_runtest_dir))
-        url = u'ftps://user:pass@hostname/{0}/testfiles/output'.format(_runtest_dir)
+        super().setUp()
+        os.makedirs(f'{_runtest_dir}/testfiles/output')
+        url = f'ftps://user:pass@hostname/{_runtest_dir}/testfiles/output'
         self.backend = duplicity.backend.get_backend_object(url)
-        self.assertEqual(self.backend.__class__.__name__, u'LFTPBackend')
+        self.assertEqual(self.backend.__class__.__name__, 'LFTPBackend')
 
 
-@unittest.skipIf(not util.which(u'rclone'), u"rclone not installed")
+@unittest.skipIf(not util.which('rclone'), "rclone not installed")
 class RCloneBackendTest(BackendInstanceBase):
     def setUp(self):
-        super(RCloneBackendTest, self).setUp()
-        os.makedirs(u'{0}/testfiles/output'.format(_runtest_dir))
-        url = u'rclone://duptest:/%s/{0}/testfiles/output'.format(_runtest_dir)
+        super().setUp()
+        # make sure rclone config exists
+        assert not os.system("rclone config touch")
+        # add a duptest local config
+        try:
+            assert not os.system("rclone config create duptest local local=true --non-interactive")
+            self.delete_config = True
+        except Exception as e:
+            self.delete_config = False
+        os.makedirs(f'{_runtest_dir}/testfiles/output')
+        url = f'rclone://duptest:/%s/{_runtest_dir}/testfiles/output'
         self.backend = duplicity.backend.get_backend_object(url)
-        self.assertEqual(self.backend.__class__.__name__, u'RcloneBackend')
+        self.assertEqual(self.backend.__class__.__name__, 'RcloneBackend')
+
+    def tearDown(self):
+        super().tearDown()
+        if self.delete_config:
+            assert not os.system("rclone config delete duptest")
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_path.py` & `duplicity-2.0.0rc0/testing/unit/test_path.py`

 * *Files 20% similar despite different names*

```diff
@@ -15,88 +15,72 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
-import os
 import unittest
 
 from duplicity.path import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 from testing import _runtest_dir
 from . import UnitTestCase
 
 
 class PathTest(UnitTestCase):
-    u"""Test basic path functions"""
+    """Test basic path functions"""
     def setUp(self):
-        super(PathTest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
 
     def test_deltree(self):
-        u"""Test deleting a tree"""
-        assert not os.system(u"cp -pR {0}/testfiles/deltree {0}/testfiles/output".format(_runtest_dir).format(_runtest_dir))  # noqa
-        p = Path(u"{0}/testfiles/output".format(_runtest_dir))
+        """Test deleting a tree"""
+        assert not os.system(f"cp -pR {_runtest_dir}/testfiles/deltree {_runtest_dir}/testfiles/output")
+        p = Path(f"{_runtest_dir}/testfiles/output")
         assert p.isdir()
         p.deltree()
         assert not p.type, p.type
 
-    @unittest.skipIf(os.path.exists(u"/.dockenv") or                        # Docker
-                     os.environ.get(u"USER", None) == u"buildd" or          # Launchpad
-                     os.environ.get(u"NON_NATIVE", None) == u"true",        # GitLab
-                     u"Skip on non-native environs")
-    def test_compare(self):
-        u"""Test directory comparisons"""
-        assert not os.system(u"cp -pR {0}/testfiles/dir1/ {0}/testfiles/output".format(_runtest_dir))
-        assert Path(u"{0}/testfiles/dir1".format(_runtest_dir)).compare_recursive(
-            Path(u"{0}/testfiles/output".format(_runtest_dir)), 1)
-        assert not Path(u"{0}/testfiles/dir1".format(_runtest_dir)).compare_recursive(
-            Path(u"{0}/testfiles/dir2".format(_runtest_dir)), 1)
-
     def test_quote(self):
-        u"""Test path quoting"""
-        p = Path(u"hello")
-        assert p.quote() == u'"hello"'
-        assert p.quote(u"\\") == u'"\\\\"', p.quote(u"\\")
-        assert p.quote(u"$HELLO") == u'"\\$HELLO"'
+        """Test path quoting"""
+        p = Path("hello")
+        assert p.quote() == '"hello"'
+        assert p.quote("\\") == '"\\\\"', p.quote("\\")
+        assert p.quote("$HELLO") == '"\\$HELLO"'
 
     def test_unquote(self):
-        u"""Test path unquoting"""
-        p = Path(u"foo")  # just to provide unquote function
+        """Test path unquoting"""
+        p = Path("foo")  # just to provide unquote function
 
         def t(s):
-            u"""Run test on string s"""
+            """Run test on string s"""
             quoted_version = p.quote(s)
             unquoted = p.unquote(quoted_version)
             assert unquoted == s, (unquoted, s)
 
-        t(u"\\")
-        t(u"$HELLO")
-        t(u" aoe aoe \\ \n`")
+        t("\\")
+        t("$HELLO")
+        t(" aoe aoe \\ \n`")
 
     def test_canonical(self):
-        u"""Test getting canonical version of path"""
-        c = Path(u".").get_canonical()
+        """Test getting canonical version of path"""
+        c = Path(".").get_canonical()
         assert c == b".", c
 
-        c = Path(u"//foo/bar/./").get_canonical()
+        c = Path("//foo/bar/./").get_canonical()
         assert c == b"/foo/bar", c
 
     def test_compare_verbose(self):
-        u"""Run compare_verbose on a few files"""
-        vft = Path(u"{0}/testfiles/various_file_types".format(_runtest_dir))
+        """Run compare_verbose on a few files"""
+        vft = Path(f"{_runtest_dir}/testfiles/various_file_types")
         assert vft.compare_verbose(vft)
-        reg_file = vft.append(u"regular_file")
+        reg_file = vft.append("regular_file")
         assert not vft.compare_verbose(reg_file)
         assert reg_file.compare_verbose(reg_file)
-        file2 = vft.append(u"executable")
+        file2 = vft.append("executable")
         assert not file2.compare_verbose(reg_file)
         assert file2.compare_verbose(file2)
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_util.py` & `duplicity-2.0.0rc0/testing/functional/test_badupload.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,9 +1,13 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
+# Copyright 2002 Ben Escoto <ben@emerose.org>
+# Copyright 2007 Kenneth Loafman <kenneth@loafman.com>
+# Copyright 2011 Canonical Ltd
+#
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
 # under the terms of the GNU General Public License as published by the
 # Free Software Foundation; either version 2 of the License, or (at your
 # option) any later version.
 #
@@ -12,36 +16,36 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
+import pytest
 import unittest
-import duplicity
-
-
-class TestExc(unittest.TestCase):
-
-    def test_uexc(self):
-
-        e = Exception(u'test')
-        msg = duplicity.util.uexc(e)
-        self.assertEqual(msg, u'test')
-
-        # Test for Bug #1770929
-        # https://bugs.launchpad.net/duplicity/+bug/1770929
-        e = Exception(b'\xe3\x83\x86\xe3\x82\xb9\xe3\x83\x88')
-        msg = duplicity.util.uexc(e)
-        self.assertEqual(msg, u'\u30c6\u30b9\u30c8')
 
-        e = Exception(u'\u30c6\u30b9\u30c8')
-        msg = duplicity.util.uexc(e)
-        self.assertEqual(msg, u'\u30c6\u30b9\u30c8')
+from testing import _runtest_dir
+from . import CmdError
+from . import FunctionalTestCase
+
+
+class BadUploadTest(FunctionalTestCase):
+    """
+    Test missing volume upload using duplicity binary
+    """
+    @pytest.mark.slow
+    def test_missing_file(self):
+        """
+        Test basic lost file
+        """
+        try:
+            self.backup("full", f"{_runtest_dir}/testfiles/dir1", options=["--skip-volume=1"])
+            self.fail()
+        except CmdError as e:
+            self.assertEqual(e.exit_status, 44, str(e))
+        else:
+            self.fail('Expected CmdError not thrown')
 
 
-if __name__ == u'__main__':
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_gpg.py` & `duplicity-2.0.0rc0/testing/unit/test_gpg.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,183 +15,177 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from __future__ import division
-from future import standard_library
-standard_library.install_aliases()
-from builtins import range
-from builtins import object
-from past.utils import old_div
 
 import os
 import platform
-import pytest
 import random
 import unittest
 
+import pytest
+
 from duplicity import gpg
 from duplicity import path
 from testing import _runtest_dir
 from . import UnitTestCase
 
 
-@pytest.mark.usefixtures(u"redirect_stdin")
+@pytest.mark.usefixtures("redirect_stdin")
 class GPGTest(UnitTestCase):
-    u"""Test GPGFile"""
+    """Test GPGFile"""
     def setUp(self):
-        super(GPGTest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
-        self.default_profile = gpg.GPGProfile(passphrase=u"foobar")
+        self.default_profile = gpg.GPGProfile(passphrase="foobar")
 
     def gpg_cycle(self, s, profile=None):
-        u"""Test encryption/decryption cycle on string s"""
-        epath = path.Path(u"{0}/testfiles/output/encrypted_file".format(_runtest_dir))
+        """Test encryption/decryption cycle on string s"""
+        epath = path.Path(f"{_runtest_dir}/testfiles/output/encrypted_file")
         if not profile:
             profile = self.default_profile
         encrypted_file = gpg.GPGFile(1, epath, profile)
         encrypted_file.write(s)
         encrypted_file.close()
 
-        epath2 = path.Path(u"{0}/testfiles/output/encrypted_file".format(_runtest_dir))
+        epath2 = path.Path(f"{_runtest_dir}/testfiles/output/encrypted_file")
         decrypted_file = gpg.GPGFile(0, epath2, profile)
         dec_buf = decrypted_file.read()
         decrypted_file.close()
 
         assert s == dec_buf, (len(s), len(dec_buf))
 
     def test_gpg1(self):
-        u"""Test gpg short strings"""
+        """Test gpg short strings"""
         self.gpg_cycle(b"hello, world")
         self.gpg_cycle(b"ansoetuh aoetnuh aoenstuh aoetnuh asoetuh saoteuh ")
 
     def test_gpg2(self):
-        u"""Test gpg long strings easily compressed"""
+        """Test gpg long strings easily compressed"""
         self.gpg_cycle(b" " * 50000)
         self.gpg_cycle(b"aoeu" * 1000000)
 
     def test_gpg3(self):
-        u"""Test on random data - must have /dev/urandom device"""
-        infp = open(u"/dev/urandom", u"rb")
+        """Test on random data - must have /dev/urandom device"""
+        infp = open("/dev/urandom", "rb")
         rand_buf = infp.read(120000)
         infp.close()
         self.gpg_cycle(rand_buf)
 
     def test_gpg_asym(self):
-        u"""Test GPG asymmetric encryption"""
+        """Test GPG asymmetric encryption"""
         profile = gpg.GPGProfile(passphrase=self.sign_passphrase,
                                  recipients=[self.encrypt_key1,
                                              self.encrypt_key2])
         self.gpg_cycle(b"aoensutha aonetuh saoe", profile)
 
         profile2 = gpg.GPGProfile(passphrase=self.sign_passphrase,
                                   recipients=[self.encrypt_key1])
         self.gpg_cycle(b"aoeu" * 10000, profile2)
 
     def test_gpg_hidden_asym(self):
-        u"""Test GPG asymmetric encryption with hidden key id"""
+        """Test GPG asymmetric encryption with hidden key id"""
         profile = gpg.GPGProfile(passphrase=self.sign_passphrase,
                                  hidden_recipients=[self.encrypt_key1,
                                                     self.encrypt_key2])
         self.gpg_cycle(b"aoensutha aonetuh saoe", profile)
 
         profile2 = gpg.GPGProfile(passphrase=self.sign_passphrase,
                                   hidden_recipients=[self.encrypt_key1])
         self.gpg_cycle(b"aoeu" * 10000, profile2)
 
     def test_gpg_signing(self):
-        u"""Test to make sure GPG reports the proper signature key"""
+        """Test to make sure GPG reports the proper signature key"""
         plaintext = b"hello" * 50000
 
         signing_profile = gpg.GPGProfile(passphrase=self.sign_passphrase,
                                          sign_key=self.sign_key,
                                          recipients=[self.encrypt_key1])
 
-        epath = path.Path(u"{0}/testfiles/output/encrypted_file".format(_runtest_dir))
+        epath = path.Path(f"{_runtest_dir}/testfiles/output/encrypted_file")
         encrypted_signed_file = gpg.GPGFile(1, epath, signing_profile)
         encrypted_signed_file.write(plaintext)
         encrypted_signed_file.close()
 
         decrypted_file = gpg.GPGFile(0, epath, signing_profile)
         assert decrypted_file.read() == plaintext
         decrypted_file.close()
         sig = decrypted_file.get_signature()
         assert sig == self.sign_key, sig
 
     def test_gpg_signing_and_hidden_encryption(self):
-        u"""Test to make sure GPG reports the proper signature key even with hidden encryption key id"""
+        """Test to make sure GPG reports the proper signature key even with hidden encryption key id"""
         plaintext = b"hello" * 50000
 
         signing_profile = gpg.GPGProfile(passphrase=self.sign_passphrase,
                                          sign_key=self.sign_key,
                                          hidden_recipients=[self.encrypt_key1])
 
-        epath = path.Path(u"{0}/testfiles/output/encrypted_file".format(_runtest_dir))
+        epath = path.Path(f"{_runtest_dir}/testfiles/output/encrypted_file")
         encrypted_signed_file = gpg.GPGFile(1, epath, signing_profile)
         encrypted_signed_file.write(plaintext)
         encrypted_signed_file.close()
 
         decrypted_file = gpg.GPGFile(0, epath, signing_profile)
         assert decrypted_file.read() == plaintext
         decrypted_file.close()
         sig = decrypted_file.get_signature()
         assert sig == self.sign_key, sig
 
-    @unittest.skipIf(platform.machine() in [u"ppc64el", u"ppc64le"], u"Skip on ppc64el of ppc64el machines")
+    @unittest.skipIf(platform.machine() in ["ppc64el", "ppc64le"], "Skip on ppc64el of ppc64el machines")
     def test_GPGWriteFile(self):
-        u"""Test GPGWriteFile"""
+        """Test GPGWriteFile"""
         size = 400 * 1000
         gwfh = GPGWriteFile_Helper()
-        profile = gpg.GPGProfile(passphrase=u"foobar")
+        profile = gpg.GPGProfile(passphrase="foobar")
         for i in range(10):
-            gpg.GPGWriteFile(gwfh, u"{0}/testfiles/output/gpgwrite.gpg".format(_runtest_dir),
+            gpg.GPGWriteFile(gwfh, f"{_runtest_dir}/testfiles/output/gpgwrite.gpg",
                              profile, size=size)
             # print os.stat("/tmp/testfiles/output/gpgwrite.gpg").st_size-size
-            assert size - 64 * 1024 <= os.stat(u"{0}/testfiles/output/gpgwrite.gpg".format(_runtest_dir)).st_size <= size + 64 * 1024  # noqa
+            assert size - 64 * 1024 <= os.stat(f"{_runtest_dir}/testfiles/output/gpgwrite.gpg").st_size <= size + 64 * 1024  # noqa
         gwfh.set_at_end()
-        gpg.GPGWriteFile(gwfh, u"{0}/testfiles/output/gpgwrite.gpg".format(_runtest_dir),
+        gpg.GPGWriteFile(gwfh, f"{_runtest_dir}/testfiles/output/gpgwrite.gpg",
                          profile, size=size)
         # print os.stat("/tmp/testfiles/output/gpgwrite.gpg").st_size
 
     def test_GzipWriteFile(self):
-        u"""Test GzipWriteFile"""
+        """Test GzipWriteFile"""
         size = 400 * 1000
         gwfh = GPGWriteFile_Helper()
         for i in range(10):
-            gpg.GzipWriteFile(gwfh, u"{0}/testfiles/output/gzwrite.gz".format(_runtest_dir),
+            gpg.GzipWriteFile(gwfh, f"{_runtest_dir}/testfiles/output/gzwrite.gz",
                               size=size)
             # print os.stat("/tmp/testfiles/output/gzwrite.gz").st_size-size
-            assert size - 64 * 1024 <= os.stat(u"{0}/testfiles/output/gzwrite.gz".format(_runtest_dir)).st_size <= size + 64 * 1024  # noqa
+            assert size - 64 * 1024 <= os.stat(f"{_runtest_dir}/testfiles/output/gzwrite.gz").st_size <= size + 64 * 1024  # noqa
         gwfh.set_at_end()
-        gpg.GzipWriteFile(gwfh, u"{0}/testfiles/output/gzwrite.gz".format(_runtest_dir), size=size)
+        gpg.GzipWriteFile(gwfh, f"{_runtest_dir}/testfiles/output/gzwrite.gz", size=size)
         # print os.stat("/tmp/testfiles/output/gzwrite.gz").st_size
 
 
 class GPGWriteHelper2(object):
     def __init__(self, data):
         self.data = data
 
 
 class GPGWriteFile_Helper(object):
-    u"""Used in test_GPGWriteFile above"""
+    """Used in test_GPGWriteFile above"""
     def __init__(self):
-        self.from_random_fp = open(u"/dev/urandom", u"rb")
+        self.from_random_fp = open("/dev/urandom", "rb")
         self.at_end = False
 
     def set_at_end(self):
-        u"""Iterator stops when you call this"""
+        """Iterator stops when you call this"""
         self.at_end = True
 
     def get_buffer(self, size):
-        u"""Return buffer of size size, consisting of half random data"""
-        s1 = int(old_div(size, 2))
+        """Return buffer of size size, consisting of half random data"""
+        s1 = size // 2
         s2 = size - s1
         return b"a" * s1 + self.from_random_fp.read(s2)
 
     def __next__(self):
         if self.at_end:
             raise StopIteration
         block_data = self.get_buffer(self.get_read_size())
@@ -205,19 +199,19 @@
             return random.randrange(0, size)
 
     def get_footer(self):
         return b"e" * random.randrange(0, 15000)
 
 
 class SHATest(UnitTestCase):
-    u"""Test making sha signatures"""
+    """Test making sha signatures"""
     def setUp(self):
-        super(SHATest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
 
     def test_sha(self):
-        testhash = gpg.get_hash(u"SHA1", path.Path(u"{0}/testfiles/various_file_types/regular_file".format(_runtest_dir)))  # noqa
-        assert testhash == u"886d722999862724e1e62d0ac51c468ee336ef8e", testhash
+        testhash = gpg.get_hash("SHA1", path.Path(f"{_runtest_dir}/testfiles/various_file_types/regular_file"))  # noqa
+        assert testhash == "886d722999862724e1e62d0ac51c468ee336ef8e", testhash
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_backend.py` & `duplicity-2.0.0rc0/testing/unit/test_backend.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,225 +15,221 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import sys
+
 try:
     import unittest.mock as mock
 except ImportError:
     import mock
 import unittest
 
 import duplicity.backend
 import duplicity.backends
 from duplicity.errors import *  # pylint: disable=unused-wildcard-import
 from duplicity import config
 from . import UnitTestCase
 
 
-@unittest.skipIf(sys.version_info[:2] < (3, 6), u"Skip on bad urllib.parse handling")
+@unittest.skipIf(sys.version_info[:2] < (3, 6), "Skip on bad urllib.parse handling")
 class ParsedUrlTest(UnitTestCase):
-    u"""Test the ParsedUrl class"""
+    """Test the ParsedUrl class"""
     def test_basic(self):
-        u"""Test various url strings"""
-        pu = duplicity.backend.ParsedUrl(u"scp://ben@foo.bar:1234/a/b")
-        assert pu.scheme == u"scp", pu.scheme
-        assert pu.netloc == u"ben@foo.bar:1234", pu.netloc
-        assert pu.path == u"/a/b", pu.path
-        assert pu.username == u"ben", pu.username
+        """Test various url strings"""
+        pu = duplicity.backend.ParsedUrl("scp://ben@foo.bar:1234/a/b")
+        assert pu.scheme == "scp", pu.scheme
+        assert pu.netloc == "ben@foo.bar:1234", pu.netloc
+        assert pu.path == "/a/b", pu.path
+        assert pu.username == "ben", pu.username
         assert pu.port == 1234, pu.port
-        assert pu.hostname == u"foo.bar", pu.hostname
+        assert pu.hostname == "foo.bar", pu.hostname
 
-        pu = duplicity.backend.ParsedUrl(u"ftp://foo.bar:1234/")
-        assert pu.scheme == u"ftp", pu.scheme
-        assert pu.netloc == u"foo.bar:1234", pu.netloc
-        assert pu.path == u"/", pu.path
+        pu = duplicity.backend.ParsedUrl("ftp://foo.bar:1234/")
+        assert pu.scheme == "ftp", pu.scheme
+        assert pu.netloc == "foo.bar:1234", pu.netloc
+        assert pu.path == "/", pu.path
         assert pu.username is None, pu.username
         assert pu.port == 1234, pu.port
-        assert pu.hostname == u"foo.bar", pu.hostname
+        assert pu.hostname == "foo.bar", pu.hostname
 
-        pu = duplicity.backend.ParsedUrl(u"file:///home")
-        assert pu.scheme == u"file", pu.scheme
-        assert pu.netloc == u"", pu.netloc
-        assert pu.path == u"///home", pu.path
+        pu = duplicity.backend.ParsedUrl("file:///home")
+        assert pu.scheme == "file", pu.scheme
+        assert pu.netloc == "", pu.netloc
+        assert pu.path == "///home", pu.path
         assert pu.username is None, pu.username
         assert pu.port is None, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"file://home")
-        assert pu.scheme == u"file", pu.scheme
-        assert pu.netloc == u"", pu.netloc
-        assert pu.path == u"//home", pu.path
+        pu = duplicity.backend.ParsedUrl("file://home")
+        assert pu.scheme == "file", pu.scheme
+        assert pu.netloc == "", pu.netloc
+        assert pu.path == "//home", pu.path
         assert pu.username is None, pu.username
         assert pu.port is None, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"ftp://foo@bar:pass@example.com:123/home")
-        assert pu.scheme == u"ftp", pu.scheme
-        assert pu.netloc == u"foo@bar:pass@example.com:123", pu.netloc
-        assert pu.hostname == u"example.com", pu.hostname
-        assert pu.path == u"/home", pu.path
-        assert pu.username == u"foo@bar", pu.username
-        assert pu.password == u"pass", pu.password
+        pu = duplicity.backend.ParsedUrl("ftp://foo@bar:pass@example.com:123/home")
+        assert pu.scheme == "ftp", pu.scheme
+        assert pu.netloc == "foo@bar:pass@example.com:123", pu.netloc
+        assert pu.hostname == "example.com", pu.hostname
+        assert pu.path == "/home", pu.path
+        assert pu.username == "foo@bar", pu.username
+        assert pu.password == "pass", pu.password
         assert pu.port == 123, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"ftp://foo%40bar:pass@example.com:123/home")
-        assert pu.scheme == u"ftp", pu.scheme
-        assert pu.netloc == u"foo%40bar:pass@example.com:123", pu.netloc
-        assert pu.hostname == u"example.com", pu.hostname
-        assert pu.path == u"/home", pu.path
-        assert pu.username == u"foo@bar", pu.username
-        assert pu.password == u"pass", pu.password
+        pu = duplicity.backend.ParsedUrl("ftp://foo%40bar:pass@example.com:123/home")
+        assert pu.scheme == "ftp", pu.scheme
+        assert pu.netloc == "foo%40bar:pass@example.com:123", pu.netloc
+        assert pu.hostname == "example.com", pu.hostname
+        assert pu.path == "/home", pu.path
+        assert pu.username == "foo@bar", pu.username
+        assert pu.password == "pass", pu.password
         assert pu.port == 123, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"imap://foo@bar:pass@example.com:123/home")
-        assert pu.scheme == u"imap", pu.scheme
-        assert pu.netloc == u"foo@bar:pass@example.com:123", pu.netloc
-        assert pu.hostname == u"example.com", pu.hostname
-        assert pu.path == u"/home", pu.path
-        assert pu.username == u"foo@bar", pu.username
-        assert pu.password == u"pass", pu.password
+        pu = duplicity.backend.ParsedUrl("imap://foo@bar:pass@example.com:123/home")
+        assert pu.scheme == "imap", pu.scheme
+        assert pu.netloc == "foo@bar:pass@example.com:123", pu.netloc
+        assert pu.hostname == "example.com", pu.hostname
+        assert pu.path == "/home", pu.path
+        assert pu.username == "foo@bar", pu.username
+        assert pu.password == "pass", pu.password
         assert pu.port == 123, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"imap://foo@bar@example.com:123/home")
-        assert pu.scheme == u"imap", pu.scheme
-        assert pu.netloc == u"foo@bar@example.com:123", pu.netloc
-        assert pu.hostname == u"example.com", pu.hostname
-        assert pu.path == u"/home", pu.path
-        assert pu.username == u"foo@bar", pu.username
+        pu = duplicity.backend.ParsedUrl("imap://foo@bar@example.com:123/home")
+        assert pu.scheme == "imap", pu.scheme
+        assert pu.netloc == "foo@bar@example.com:123", pu.netloc
+        assert pu.hostname == "example.com", pu.hostname
+        assert pu.path == "/home", pu.path
+        assert pu.username == "foo@bar", pu.username
         assert pu.password is None, pu.password
         assert pu.port == 123, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"imap://foo@bar@example.com/home")
-        assert pu.scheme == u"imap", pu.scheme
-        assert pu.netloc == u"foo@bar@example.com", pu.netloc
-        assert pu.hostname == u"example.com", pu.hostname
-        assert pu.path == u"/home", pu.path
-        assert pu.username == u"foo@bar", pu.username
+        pu = duplicity.backend.ParsedUrl("imap://foo@bar@example.com/home")
+        assert pu.scheme == "imap", pu.scheme
+        assert pu.netloc == "foo@bar@example.com", pu.netloc
+        assert pu.hostname == "example.com", pu.hostname
+        assert pu.path == "/home", pu.path
+        assert pu.username == "foo@bar", pu.username
         assert pu.password is None, pu.password
         assert pu.port is None, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"imap://foo@bar.com@example.com/home")
-        assert pu.scheme == u"imap", pu.scheme
-        assert pu.netloc == u"foo@bar.com@example.com", pu.netloc
-        assert pu.hostname == u"example.com", pu.hostname
-        assert pu.path == u"/home", pu.path
-        assert pu.username == u"foo@bar.com", pu.username
+        pu = duplicity.backend.ParsedUrl("imap://foo@bar.com@example.com/home")
+        assert pu.scheme == "imap", pu.scheme
+        assert pu.netloc == "foo@bar.com@example.com", pu.netloc
+        assert pu.hostname == "example.com", pu.hostname
+        assert pu.path == "/home", pu.path
+        assert pu.username == "foo@bar.com", pu.username
         assert pu.password is None, pu.password
         assert pu.port is None, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"imap://foo%40bar.com@example.com/home")
-        assert pu.scheme == u"imap", pu.scheme
-        assert pu.netloc == u"foo%40bar.com@example.com", pu.netloc
-        assert pu.hostname == u"example.com", pu.hostname
-        assert pu.path == u"/home", pu.path
-        assert pu.username == u"foo@bar.com", pu.username
+        pu = duplicity.backend.ParsedUrl("imap://foo%40bar.com@example.com/home")
+        assert pu.scheme == "imap", pu.scheme
+        assert pu.netloc == "foo%40bar.com@example.com", pu.netloc
+        assert pu.hostname == "example.com", pu.hostname
+        assert pu.path == "/home", pu.path
+        assert pu.username == "foo@bar.com", pu.username
         assert pu.password is None, pu.password
         assert pu.port is None, pu.port
 
-        pu = duplicity.backend.ParsedUrl(u"scheme://username:passwor@127.0.0.1:22/path/path")
-        assert pu.strip_auth() == u"scheme://127.0.0.1:22/path/path"
+        pu = duplicity.backend.ParsedUrl("scheme://username:passwor@127.0.0.1:22/path/path")
+        assert pu.strip_auth() == "scheme://127.0.0.1:22/path/path"
 
-        pu = duplicity.backend.ParsedUrl(u"xorriso:///dev/sr0")
-        assert pu.scheme == u"xorriso", pu.scheme
-        assert pu.path == u"///dev/sr0", pu.path
-
-        pu = duplicity.backend.ParsedUrl(u"xorriso:///dev/sr0:/path/on/iso")
-        assert pu.scheme == u"xorriso", pu.scheme
-        assert pu.path == u"///dev/sr0:/path/on/iso", pu.path
+        pu = duplicity.backend.ParsedUrl("xorriso:///dev/sr0")
+        assert pu.scheme == "xorriso", pu.scheme
+        assert pu.path == "///dev/sr0", pu.path
+
+        pu = duplicity.backend.ParsedUrl("xorriso:///dev/sr0:/path/on/iso")
+        assert pu.scheme == "xorriso", pu.scheme
+        assert pu.path == "///dev/sr0:/path/on/iso", pu.path
 
     def test_errors(self):
-        u"""Test various url errors"""
+        """Test various url errors"""
         self.assertRaises(InvalidBackendURL, duplicity.backend.ParsedUrl,
-                          u"file:path")  # no relative paths for non-netloc schemes
+                          "file:path")  # no relative paths for non-netloc schemes
         self.assertRaises(UnsupportedBackendScheme, duplicity.backend.get_backend,
-                          u"ssh://foo@bar:pass@example.com/home")
+                          "ssh://foo@bar:pass@example.com/home")
 
 
 class BackendWrapperTest(UnitTestCase):
 
     def setUp(self):
-        super(BackendWrapperTest, self).setUp()
+        super().setUp()
         self.mock = mock.MagicMock()
         self.backend = duplicity.backend.BackendWrapper(self.mock)
         self.local = mock.MagicMock()
-        self.remote = u'remote'
+        self.remote = 'remote'
 
-    @mock.patch(u'sys.exit')
+    @mock.patch('sys.exit')
     def test_default_error_exit(self, exit_mock):
-        self.set_config(u'num_retries', 1)
+        self.set_config('num_retries', 1)
         try:
             del self.mock._error_code
-        except:
-            # Old versions of mock don't let you mark non-present attributes
-            # like this.
-            return  # can't use self.skip() since that needs py27
+        except Exception as e:
+            return
         self.mock._put.side_effect = Exception
         self.backend.put(self.local, self.remote)
         exit_mock.assert_called_once_with(50)
 
-    @mock.patch(u'sys.exit')
+    @mock.patch('sys.exit')
     def test_translates_code(self, exit_mock):
-        self.set_config(u'num_retries', 1)
+        self.set_config('num_retries', 1)
         self.mock._error_code.return_value = 12345
         self.mock._put.side_effect = Exception
         self.backend.put(self.local, self.remote)
         exit_mock.assert_called_once_with(12345)
 
-    @mock.patch(u'sys.exit')
+    @mock.patch('sys.exit')
     def test_uses_exception_code(self, exit_mock):
-        self.set_config(u'num_retries', 1)
+        self.set_config('num_retries', 1)
         self.mock._error_code.return_value = 12345
-        self.mock._put.side_effect = BackendException(u'error', code=54321)
+        self.mock._put.side_effect = BackendException('error', code=54321)
         self.backend.put(self.local, self.remote)
         exit_mock.assert_called_once_with(54321)
 
-    @mock.patch(u'sys.exit')
-    @mock.patch(u'time.sleep')  # so no waiting
+    @mock.patch('sys.exit')
+    @mock.patch('time.sleep')  # so no waiting
     def test_cleans_up(self, exit_mock, time_mock):  # pylint: disable=unused-argument
-        self.set_config(u'num_retries', 2)
+        self.set_config('num_retries', 2)
         self.mock._retry_cleanup.return_value = None
         self.mock._put.side_effect = Exception
         self.backend.put(self.local, self.remote)
         self.mock._retry_cleanup.assert_called_once_with()
 
     def test_prefer_lists(self):
         self.mock._delete.return_value = None
         self.mock._delete_list.return_value = None
         self.backend.delete([self.remote])
         self.assertEqual(self.mock._delete.call_count, 0)
         self.assertEqual(self.mock._delete_list.call_count, 1)
         try:
             del self.mock._delete_list
-        except:
+        except Exception as e:
             return
         self.backend.delete([self.remote])
         self.assertEqual(self.mock._delete.call_count, 1)
 
         self.mock._query.return_value = None
         self.mock._query_list.return_value = None
         self.backend.query_info([self.remote])
         self.assertEqual(self.mock._query.call_count, 0)
         self.assertEqual(self.mock._query_list.call_count, 1)
         try:
             del self.mock._query_list
-        except:
+        except Exception as e:
             return
         self.backend.query_info([self.remote])
         self.assertEqual(self.mock._query.call_count, 1)
 
-    @mock.patch(u'sys.exit')
-    @mock.patch(u'time.sleep')  # so no waiting
+    @mock.patch('sys.exit')
+    @mock.patch('time.sleep')  # so no waiting
     def test_retries(self, exit_mock, time_mock):  # pylint: disable=unused-argument
-        self.set_config(u'num_retries', 2)
+        self.set_config('num_retries', 2)
 
         self.mock._get.side_effect = Exception
         self.backend.get(self.remote, self.local)
         self.assertEqual(self.mock._get.call_count, config.num_retries)
 
         self.mock._put.side_effect = Exception
         self.backend.put(self.local, self.remote)
@@ -249,23 +245,23 @@
 
         self.mock._query_list.side_effect = Exception
         self.backend.query_info([self.remote])
         self.assertEqual(self.mock._query_list.call_count, config.num_retries)
 
         try:
             del self.mock._delete_list
-        except:
+        except Exception as e:
             return
         self.mock._delete.side_effect = Exception
         self.backend.delete([self.remote])
         self.assertEqual(self.mock._delete.call_count, config.num_retries)
 
         try:
             del self.mock._query_list
-        except:
+        except Exception as e:
             return
         self.mock._query.side_effect = Exception
         self.backend.query_info([self.remote])
         self.assertEqual(self.mock._query.call_count, config.num_retries)
 
         self.mock._move.side_effect = Exception
         self.backend.move(self.local, self.remote)
@@ -283,21 +279,21 @@
         self.mock._move.assert_called_once_with(self.local, self.remote)
         self.mock._put.assert_called_once_with(self.local, self.remote)
         self.local.delete.assert_called_once_with()
 
     def test_move_fallback_undefined(self):
         try:
             del self.mock._move
-        except:
+        except Exception as e:
             return
         self.backend.move(self.local, self.remote)
         self.mock._put.assert_called_once_with(self.local, self.remote)
         self.local.delete.assert_called_once_with()
 
     def test_close(self):
         self.mock._close.return_value = None
         self.backend.close()
         self.mock._close.assert_called_once_with()
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/unit/test_selection.py` & `duplicity-2.0.0rc0/testing/unit/test_selection.py`

 * *Files 19% similar despite different names*

```diff
@@ -16,1215 +16,1217 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import io
 import platform
 import unittest
 
-from duplicity.selection import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 from duplicity.lazy import *  # pylint: disable=unused-wildcard-import,redefined-builtin
+from duplicity.selection import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 from . import UnitTestCase
+
 try:
     from unittest.mock import patch
 except ImportError:
     from mock import patch
 
 
 class MatchingTest(UnitTestCase):
-    u"""Test matching of file names against various selection functions"""
+    """Test matching of file names against various selection functions"""
+
     def setUp(self):
-        super(MatchingTest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
-        self.root = Path(u"testfiles/select")
+        self.root = Path("testfiles/select")
         self.Select = Select(self.root)
 
     def makeext(self, path):
         return self.root.new_index(tuple(path.encode().split(b"/")))
 
     def testRegexp(self):
-        u"""Test regular expression selection func"""
-        sf1 = self.Select.regexp_get_sf(u".*\\.py", 1)
-        assert sf1(self.makeext(u"1.py")) == 1
-        assert sf1(self.makeext(u"usr/foo.py")) == 1
-        assert sf1(self.root.append(u"1.doc")) is None
-
-        sf2 = self.Select.regexp_get_sf(u"hello", 0)
-        assert sf2(Path(u"hello")) == 0
-        assert sf2(Path(u"foohello_there")) == 0
-        assert sf2(Path(u"foo")) is None
+        """Test regular expression selection func"""
+        sf1 = self.Select.regexp_get_sf(".*\\.py", 1)
+        assert sf1(self.makeext("1.py")) == 1
+        assert sf1(self.makeext("usr/foo.py")) == 1
+        assert sf1(self.root.append("1.doc")) is None
+
+        sf2 = self.Select.regexp_get_sf("hello", 0)
+        assert sf2(Path("hello")) == 0
+        assert sf2(Path("foohello_there")) == 0
+        assert sf2(Path("foo")) is None
 
     def test_tuple_include(self):
-        u"""Test include selection function made from a regular filename"""
+        """Test include selection function made from a regular filename"""
         self.assertRaises(FilePrefixError, self.Select.glob_get_sf,
-                          u"foo", 1)
+                          "foo", 1)
 
-        sf2 = self.Select.general_get_sf(u"testfiles/select/usr/local/bin/", 1)
+        sf2 = self.Select.general_get_sf("testfiles/select/usr/local/bin/", 1)
 
-        with patch(u"duplicity.path.ROPath.isdir") as mock_isdir:
+        with patch("duplicity.path.ROPath.isdir") as mock_isdir:
             mock_isdir.return_value = True
             # Can't pass the return_value as an argument to patch, i.e.:
             # with patch("duplicity.path.ROPath.isdir", return_value=True):
             # as build system's mock is too old to support it.
 
-            self.assertEqual(sf2(self.makeext(u"usr")), 2)
-            self.assertEqual(sf2(self.makeext(u"usr/local")), 2)
-            self.assertEqual(sf2(self.makeext(u"usr/local/bin")), 1)
-            self.assertEqual(sf2(self.makeext(u"usr/local/doc")), None)
-            self.assertEqual(sf2(self.makeext(u"usr/local/bin/gzip")), 1)
-            self.assertEqual(sf2(self.makeext(u"usr/local/bingzip")), None)
+            self.assertEqual(sf2(self.makeext("usr")), 2)
+            self.assertEqual(sf2(self.makeext("usr/local")), 2)
+            self.assertEqual(sf2(self.makeext("usr/local/bin")), 1)
+            self.assertEqual(sf2(self.makeext("usr/local/doc")), None)
+            self.assertEqual(sf2(self.makeext("usr/local/bin/gzip")), 1)
+            self.assertEqual(sf2(self.makeext("usr/local/bingzip")), None)
 
     def test_tuple_exclude(self):
-        u"""Test exclude selection function made from a regular filename"""
+        """Test exclude selection function made from a regular filename"""
         self.assertRaises(FilePrefixError, self.Select.glob_get_sf,
-                          u"foo", 0)
+                          "foo", 0)
 
-        sf2 = self.Select.general_get_sf(u"testfiles/select/usr/local/bin/", 0)
+        sf2 = self.Select.general_get_sf("testfiles/select/usr/local/bin/", 0)
 
-        with patch(u"duplicity.path.ROPath.isdir") as mock_isdir:
+        with patch("duplicity.path.ROPath.isdir") as mock_isdir:
             mock_isdir.return_value = True
 
-            assert sf2(self.makeext(u"usr")) is None
-            assert sf2(self.makeext(u"usr/local")) is None
-            assert sf2(self.makeext(u"usr/local/bin")) == 0
-            assert sf2(self.makeext(u"usr/local/doc")) is None
-            assert sf2(self.makeext(u"usr/local/bin/gzip")) == 0
-            assert sf2(self.makeext(u"usr/local/bingzip")) is None
+            assert sf2(self.makeext("usr")) is None
+            assert sf2(self.makeext("usr/local")) is None
+            assert sf2(self.makeext("usr/local/bin")) == 0
+            assert sf2(self.makeext("usr/local/doc")) is None
+            assert sf2(self.makeext("usr/local/bin/gzip")) == 0
+            assert sf2(self.makeext("usr/local/bingzip")) is None
 
     def test_glob_star_include(self):
-        u"""Test a few globbing patterns, including **"""
-        sf1 = self.Select.general_get_sf(u"**", 1)
-        assert sf1(self.makeext(u"foo")) == 1
-        assert sf1(self.makeext(u"")) == 1
-
-        sf2 = self.Select.general_get_sf(u"**.py", 1)
-        assert sf2(self.makeext(u"foo")) == 2
-        assert sf2(self.makeext(u"usr/local/bin")) == 2
-        assert sf2(self.makeext(u"what/ever.py")) == 1
-        assert sf2(self.makeext(u"what/ever.py/foo")) == 1
+        """Test a few globbing patterns, including **"""
+        sf1 = self.Select.general_get_sf("**", 1)
+        assert sf1(self.makeext("foo")) == 1
+        assert sf1(self.makeext("")) == 1
+
+        sf2 = self.Select.general_get_sf("**.py", 1)
+        assert sf2(self.makeext("foo")) == 2
+        assert sf2(self.makeext("usr/local/bin")) == 2
+        assert sf2(self.makeext("what/ever.py")) == 1
+        assert sf2(self.makeext("what/ever.py/foo")) == 1
 
     def test_glob_star_exclude(self):
-        u"""Test a few glob excludes, including **"""
-        sf1 = self.Select.general_get_sf(u"**", 0)
-        assert sf1(self.makeext(u"/usr/local/bin")) == 0
-
-        sf2 = self.Select.general_get_sf(u"**.py", 0)
-        assert sf2(self.makeext(u"foo")) is None
-        assert sf2(self.makeext(u"usr/local/bin")) is None
-        assert sf2(self.makeext(u"what/ever.py")) == 0
-        assert sf2(self.makeext(u"what/ever.py/foo")) == 0
+        """Test a few glob excludes, including **"""
+        sf1 = self.Select.general_get_sf("**", 0)
+        assert sf1(self.makeext("/usr/local/bin")) == 0
+
+        sf2 = self.Select.general_get_sf("**.py", 0)
+        assert sf2(self.makeext("foo")) is None
+        assert sf2(self.makeext("usr/local/bin")) is None
+        assert sf2(self.makeext("what/ever.py")) == 0
+        assert sf2(self.makeext("what/ever.py/foo")) == 0
 
     def test_simple_glob_double_asterisk(self):
-        u"""test_simple_glob_double_asterisk - primarily to check that the defaults used by the error tests work"""
-        assert self.Select.glob_get_sf(u"**", 1)
+        """test_simple_glob_double_asterisk - primarily to check that the defaults used by the error tests work"""
+        assert self.Select.glob_get_sf("**", 1)
 
     def test_glob_sf_exception(self):
-        u"""test_glob_sf_exception - see if globbing errors returned"""
+        """test_glob_sf_exception - see if globbing errors returned"""
         self.assertRaises(GlobbingError, self.Select.glob_get_sf,
-                          u"testfiles/select/hello//there", 1)
+                          "testfiles/select/hello//there", 1)
 
     def test_file_prefix_sf_exception(self):
-        u"""test_file_prefix_sf_exception - see if FilePrefix error is returned"""
+        """test_file_prefix_sf_exception - see if FilePrefix error is returned"""
         # These should raise a FilePrefixError because the root directory for the selection is "testfiles/select"
         self.assertRaises(FilePrefixError,
-                          self.Select.general_get_sf, u"testfiles/whatever", 1)
+                          self.Select.general_get_sf, "testfiles/whatever", 1)
         self.assertRaises(FilePrefixError,
-                          self.Select.general_get_sf, u"testfiles/?hello", 0)
+                          self.Select.general_get_sf, "testfiles/?hello", 0)
 
     def test_scan(self):
-        u"""Tests what is returned for selection tests regarding directory scanning"""
-        select = Select(Path(u"/"))
+        """Tests what is returned for selection tests regarding directory scanning"""
+        select = Select(Path("/"))
 
-        assert select.general_get_sf(u"**.py", 1)(Path(u"/")) == 2
-        assert select.general_get_sf(u"**.py", 1)(Path(u"foo")) == 2
-        assert select.general_get_sf(u"**.py", 1)(Path(u"usr/local/bin")) == 2
-        assert select.general_get_sf(u"/testfiles/select/**.py", 1)(Path(u"/testfiles/select")) == 2
-        assert select.general_get_sf(u"/testfiles/select/test.py", 1)(Path(u"/testfiles/select")) == 2
-        assert select.glob_get_sf(u"/testfiles/se?ect/test.py", 1)(Path(u"/testfiles/select")) == 2
-        assert select.general_get_sf(u"/testfiles/select/test.py", 0)(Path(u"/testfiles/select")) is None
-        assert select.glob_get_sf(u"/testfiles/select/test.py", 0)(Path(u"/testfiles/select")) is None
+        assert select.general_get_sf("**.py", 1)(Path("/")) == 2
+        assert select.general_get_sf("**.py", 1)(Path("foo")) == 2
+        assert select.general_get_sf("**.py", 1)(Path("usr/local/bin")) == 2
+        assert select.general_get_sf("/testfiles/select/**.py", 1)(Path("/testfiles/select")) == 2
+        assert select.general_get_sf("/testfiles/select/test.py", 1)(Path("/testfiles/select")) == 2
+        assert select.glob_get_sf("/testfiles/se?ect/test.py", 1)(Path("/testfiles/select")) == 2
+        assert select.general_get_sf("/testfiles/select/test.py", 0)(Path("/testfiles/select")) is None
+        assert select.glob_get_sf("/testfiles/select/test.py", 0)(Path("/testfiles/select")) is None
 
     def test_ignore_case(self):
-        u"""test_ignore_case - try a few expressions with ignorecase:"""
+        """test_ignore_case - try a few expressions with ignorecase:"""
 
-        sf = self.Select.general_get_sf(u"ignorecase:testfiles/SeLect/foo/bar", 1)
-        assert sf(self.makeext(u"FOO/BAR")) == 1
-        assert sf(self.makeext(u"foo/bar")) == 1
-        assert sf(self.makeext(u"fOo/BaR")) == 1
+        sf = self.Select.general_get_sf("ignorecase:testfiles/SeLect/foo/bar", 1)
+        assert sf(self.makeext("FOO/BAR")) == 1
+        assert sf(self.makeext("foo/bar")) == 1
+        assert sf(self.makeext("fOo/BaR")) == 1
         self.assertRaises(FilePrefixError,
-                          self.Select.general_get_sf, u"ignorecase:tesfiles/sect/foo/bar", 1)
+                          self.Select.general_get_sf, "ignorecase:tesfiles/sect/foo/bar", 1)
 
     def test_ignore_case_prefix_override(self):
-        u"""test_ignore_case - confirm that ignorecase: overrides default. might
+        """test_ignore_case - confirm that ignorecase: overrides default. might
         seem a bit odd as ignore_case=False is the default, but --filter-strictcase is
         implemented by explicitly setting this parameter. this test should also
         cause a stop-and-think if someone changes said default arg value for
         general_get_sf() in future.
         """
 
-        sf = self.Select.general_get_sf(u"ignorecase:testfiles/SeLect/foo/bar", 1, ignore_case=False)
-        assert sf(self.makeext(u"FOO/BAR")) == 1
-        assert sf(self.makeext(u"foo/bar")) == 1
-        assert sf(self.makeext(u"fOo/BaR")) == 1
-        self.assertRaises(FilePrefixError, self.Select.general_get_sf, u"ignorecase:tesfiles/sect/foo/bar",
+        sf = self.Select.general_get_sf("ignorecase:testfiles/SeLect/foo/bar", 1, ignore_case=False)
+        assert sf(self.makeext("FOO/BAR")) == 1
+        assert sf(self.makeext("foo/bar")) == 1
+        assert sf(self.makeext("fOo/BaR")) == 1
+        self.assertRaises(FilePrefixError, self.Select.general_get_sf, "ignorecase:tesfiles/sect/foo/bar",
                           1, ignore_case=False)
 
     def test_root(self):
-        u"""test_root - / may be a counterexample to several of these.."""
-        root = Path(u"/")
+        """test_root - / may be a counterexample to several of these.."""
+        root = Path("/")
         select = Select(root)
 
-        self.assertEqual(select.general_get_sf(u"/", 1)(root), 1)
-        self.assertEqual(select.general_get_sf(u"/foo", 1)(root), 2)
-        self.assertEqual(select.general_get_sf(u"/foo/bar", 1)(root), 2)
-        self.assertEqual(select.general_get_sf(u"/", 0)(root), 0)
-        self.assertEqual(select.general_get_sf(u"/foo", 0)(root), None)
-
-        assert select.general_get_sf(u"**.py", 1)(root) == 2
-        assert select.general_get_sf(u"**", 1)(root) == 1
-        assert select.general_get_sf(u"ignorecase:/", 1)(root) == 1
-        assert select.general_get_sf(u"**.py", 0)(root) is None
-        assert select.general_get_sf(u"**", 0)(root) == 0
-        assert select.general_get_sf(u"/foo/*", 0)(root) is None
+        self.assertEqual(select.general_get_sf("/", 1)(root), 1)
+        self.assertEqual(select.general_get_sf("/foo", 1)(root), 2)
+        self.assertEqual(select.general_get_sf("/foo/bar", 1)(root), 2)
+        self.assertEqual(select.general_get_sf("/", 0)(root), 0)
+        self.assertEqual(select.general_get_sf("/foo", 0)(root), None)
+
+        assert select.general_get_sf("**.py", 1)(root) == 2
+        assert select.general_get_sf("**", 1)(root) == 1
+        assert select.general_get_sf("ignorecase:/", 1)(root) == 1
+        assert select.general_get_sf("**.py", 0)(root) is None
+        assert select.general_get_sf("**", 0)(root) == 0
+        assert select.general_get_sf("/foo/*", 0)(root) is None
 
     def test_other_filesystems(self):
-        u"""Test to see if --exclude-other-filesystems works correctly"""
-        root = Path(u"/")
+        """Test to see if --exclude-other-filesystems works correctly"""
+        root = Path("/")
         select = Select(root)
         sf = select.other_filesystems_get_sf(0)
         assert sf(root) is None
-        if os.path.ismount(u"/usr/bin"):
+        if os.path.ismount("/usr/bin"):
             sfval = 0
         else:
             sfval = None
-        assert sf(Path(u"/usr/bin")) == sfval, \
-            u"Assumption: /usr/bin is on the same filesystem as /"
-        if os.path.ismount(u"/dev"):
+        assert sf(Path("/usr/bin")) == sfval, \
+            "Assumption: /usr/bin is on the same filesystem as /"
+        if os.path.ismount("/dev"):
             sfval = 0
         else:
             sfval = None
-        assert sf(Path(u"/dev")) == sfval, \
-            u"Assumption: /dev is on a different filesystem"
-        if os.path.ismount(u"/proc"):
+        assert sf(Path("/dev")) == sfval, \
+            "Assumption: /dev is on a different filesystem"
+        if os.path.ismount("/proc"):
             sfval = 0
         else:
             sfval = None
-        assert sf(Path(u"/proc")) == sfval, \
-            u"Assumption: /proc is on a different filesystem"
+        assert sf(Path("/proc")) == sfval, \
+            "Assumption: /proc is on a different filesystem"
 
     def test_literal_special_chars(self):
-        u"""Test literal match with globbing and regex special characters"""
-        select = Select(Path(u"/foo"))
-        assert select.literal_get_sf(u"/foo/b*r", 1)(Path(u"/foo/bar")) is None
-        assert select.literal_get_sf(u"/foo/b*r", 1)(Path(u"/foo/b*r")) == 1
-        assert select.literal_get_sf(u"/foo/b[a-b]r", 1)(Path(u"/foo/bar")) is None
-        assert select.literal_get_sf(u"/foo/b[a-b]r", 1)(Path(u"/foo/b[a-b]r")) == 1
-        assert select.literal_get_sf(u"/foo/b\ar", 0)(Path(u"/foo/bar")) is None
-        assert select.literal_get_sf(u"/foo/b\ar", 0)(Path(u"/foo/b\ar")) == 0
-        assert select.literal_get_sf(u"/foo/b?r", 0)(Path(u"/foo/bar")) is None
-        assert select.literal_get_sf(u"/foo/b?r", 0)(Path(u"/foo/b?r")) == 0
+        """Test literal match with globbing and regex special characters"""
+        select = Select(Path("/foo"))
+        assert select.literal_get_sf("/foo/b*r", 1)(Path("/foo/bar")) is None
+        assert select.literal_get_sf("/foo/b*r", 1)(Path("/foo/b*r")) == 1
+        assert select.literal_get_sf("/foo/b[a-b]r", 1)(Path("/foo/bar")) is None
+        assert select.literal_get_sf("/foo/b[a-b]r", 1)(Path("/foo/b[a-b]r")) == 1
+        assert select.literal_get_sf("/foo/b\ar", 0)(Path("/foo/bar")) is None
+        assert select.literal_get_sf("/foo/b\ar", 0)(Path("/foo/b\ar")) == 0
+        assert select.literal_get_sf("/foo/b?r", 0)(Path("/foo/bar")) is None
+        assert select.literal_get_sf("/foo/b?r", 0)(Path("/foo/b?r")) == 0
 
 
 class ParseArgsTest(UnitTestCase):
-    u"""Test argument parsing"""
+    """Test argument parsing"""
+
     def setUp(self):
-        super(ParseArgsTest, self).setUp()
+        super().setUp()
         self.unpack_testfiles()
         self.root = None
-        self.expected_restored_tree = [(), (u"1",), (u"1", u"1sub1"), (u"1", u"1sub1", u"1sub1sub1"),
-                                       (u"1", u"1sub1", u"1sub1sub1", u"1sub1sub1_file.txt"),
-                                       (u"1", u"1sub1", u"1sub1sub3"), (u"1", u"1sub2"), (u"1", u"1sub2", u"1sub2sub1"),
-                                       (u"1", u"1sub3"), (u"1", u"1sub3", u"1sub3sub3"), (u"1.py",), (u"2",),
-                                       (u"2", u"2sub1"), (u"2", u"2sub1", u"2sub1sub1"),
-                                       (u"2", u"2sub1", u"2sub1sub1", u"2sub1sub1_file.txt"),
-                                       (u"3",), (u"3", u"3sub2"), (u"3", u"3sub2", u"3sub2sub1"),
-                                       (u"3", u"3sub2", u"3sub2sub2"), (u"3", u"3sub2", u"3sub2sub3"), (u"3", u"3sub3"),
-                                       (u"3", u"3sub3", u"3sub3sub1"), (u"3", u"3sub3", u"3sub3sub2"),
-                                       (u"3", u"3sub3", u"3sub3sub2", u"3sub3sub2_file.txt"),
-                                       (u"3", u"3sub3", u"3sub3sub3")]
+        self.expected_restored_tree = [(), ("1",), ("1", "1sub1"), ("1", "1sub1", "1sub1sub1"),
+                                       ("1", "1sub1", "1sub1sub1", "1sub1sub1_file.txt"),
+                                       ("1", "1sub1", "1sub1sub3"), ("1", "1sub2"), ("1", "1sub2", "1sub2sub1"),
+                                       ("1", "1sub3"), ("1", "1sub3", "1sub3sub3"), ("1.py",), ("2",),
+                                       ("2", "2sub1"), ("2", "2sub1", "2sub1sub1"),
+                                       ("2", "2sub1", "2sub1sub1", "2sub1sub1_file.txt"),
+                                       ("3",), ("3", "3sub2"), ("3", "3sub2", "3sub2sub1"),
+                                       ("3", "3sub2", "3sub2sub2"), ("3", "3sub2", "3sub2sub3"), ("3", "3sub3"),
+                                       ("3", "3sub3", "3sub3sub1"), ("3", "3sub3", "3sub3sub2"),
+                                       ("3", "3sub3", "3sub3sub2", "3sub3sub2_file.txt"),
+                                       ("3", "3sub3", "3sub3sub3")]
 
     def uc_index_from_path(self, path):
-        u"""Takes a path type and returns path.index, with each element converted into unicode"""
-        uindex = tuple([element.decode(sys.getfilesystemencoding(), u"strict") for element in path.index])
+        """Takes a path type and returns path.index, with each element converted into unicode"""
+        uindex = tuple([element.decode(sys.getfilesystemencoding(), "strict") for element in path.index])
         return uindex
 
-    def ParseTest(self, tuplelist, indicies, filelists=[]):
-        u"""No error if running select on tuple goes over indicies"""
+    def ParseTest(self, tuplelist, indicies, filelists=None):
+        """No error if running select on tuple goes over indicies"""
+        if filelists is None:
+            filelists = []
         if not self.root:
-            self.root = Path(u"testfiles/select")
+            self.root = Path("testfiles/select")
         self.Select = Select(self.root)
         self.Select.ParseArgs(tuplelist, self.remake_filelists(filelists))
         self.Select.set_iter()
 
         # Create a list of the paths returned by the select function, converted
         # into path.index styled tuples
         results_as_list = list(Iter.map(self.uc_index_from_path, self.Select))
         self.assertEqual(indicies, results_as_list)
 
     def remake_filelists(self, filelist):
-        u"""Turn strings in filelist into fileobjs"""
+        """Turn strings in filelist into fileobjs"""
         new_filelists = []
         for f in filelist:
-            if isinstance(f, u"".__class__):
+            if isinstance(f, "".__class__):
                 new_filelists.append(io.StringIO(f))
             else:
                 new_filelists.append(f)
         return new_filelists
 
     def test_parse(self):
-        u"""Test just one include, all exclude"""
-        self.ParseTest([(u"--include", u"testfiles/select/1/1"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"1"),
-                        (u"1", u"1", u"2"), (u"1", u"1", u"3")])
+        """Test just one include, all exclude"""
+        self.ParseTest([("--include", "testfiles/select/1/1"),
+                        ("--exclude", "**")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "1"),
+                        ("1", "1", "2"), ("1", "1", "3")])
 
     def test_parse2(self):
-        u"""Test three level include/exclude"""
-        self.ParseTest([(u"--exclude", u"testfiles/select/1/1/1"),
-                        (u"--include", u"testfiles/select/1/1"),
-                        (u"--exclude", u"testfiles/select/1"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")])
+        """Test three level include/exclude"""
+        self.ParseTest([("--exclude", "testfiles/select/1/1/1"),
+                        ("--include", "testfiles/select/1/1"),
+                        ("--exclude", "testfiles/select/1"),
+                        ("--exclude", "**")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")])
 
     def test_filelist(self):
-        u"""Filelist glob test similar to above testParse2"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to above testParse2"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_files_from_no_selections(self):
-        u"""Confirm that --files-from works in isolation"""
-        self.ParseTest([(u"--files-from", u"file")],
-                       [(), (u"1.doc",), (u"1.py",),
-                        (u"efools",), (u"efools", u"ping"),
-                        (u"foobar",), (u"foobar", u"pong")],
-                       [u"1.doc\n"
-                        u"1.py\n"
-                        u"efools/ping\n"
-                        u"foobar/pong"])
+        """Confirm that --files-from works in isolation"""
+        self.ParseTest([("--files-from", "file")],
+                       [(), ("1.doc",), ("1.py",),
+                        ("efools",), ("efools", "ping"),
+                        ("foobar",), ("foobar", "pong")],
+                       ["1.doc\n"
+                        "1.py\n"
+                        "efools/ping\n"
+                        "foobar/pong"])
 
     def test_files_from_implicit_parents(self):
-        u"""Confirm that --files-from includes parent directories implicitly"""
-        self.ParseTest([(u"--files-from", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"1"), (u"2",)],
-                       [u"1/1/1\n"
-                        u"2"])
+        """Confirm that --files-from includes parent directories implicitly"""
+        self.ParseTest([("--files-from", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "1"), ("2",)],
+                       ["1/1/1\n"
+                        "2"])
 
     def test_files_from_with_exclusions(self):
-        u"""Confirm that --files-from still respects the usual file selection rules"""
-        self.ParseTest([(u"--files-from", u"file"),
-                        (u"--exclude", u"testfiles/select/*.py"),
-                        (u"--exclude", u"testfiles/select/3/3/3")],
+        """Confirm that --files-from still respects the usual file selection rules"""
+        self.ParseTest([("--files-from", "file"),
+                        ("--exclude", "testfiles/select/*.py"),
+                        ("--exclude", "testfiles/select/3/3/3")],
                        [(),
-                        (u"1",), (u"1", u"1"), (u"1", u"1", u"1"),
-                        (u"1.doc",),
-                        (u"2",), (u"2", u"2"), (u"2", u"2", u"2"),
-                        (u"3",), (u"3", u"3")],
-                       [u"1.doc\n"
-                        u"1.py\n"
-                        u"1/1/1\n"
-                        u"2/2/2\n"
-                        u"3/3/3"])
+                        ("1",), ("1", "1"), ("1", "1", "1"),
+                        ("1.doc",),
+                        ("2",), ("2", "2"), ("2", "2", "2"),
+                        ("3",), ("3", "3")],
+                       ["1.doc\n"
+                        "1.py\n"
+                        "1/1/1\n"
+                        "2/2/2\n"
+                        "3/3/3"])
 
     def test_files_from_with_inclusions(self):
-        u"""Confirm that --files-from still respects the usual file selection rules"""
-        self.ParseTest([(u"--files-from", u"file"),
-                        (u"--include", u"testfiles/select/1.*"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1.doc",), (u"1.py",)],
-                       [u"1.doc\n"
-                        u"1.py\n"
-                        u"1\n"
-                        u"2\n"
-                        u"3"])
+        """Confirm that --files-from still respects the usual file selection rules"""
+        self.ParseTest([("--files-from", "file"),
+                        ("--include", "testfiles/select/1.*"),
+                        ("--exclude", "**")],
+                       [(), ("1.doc",), ("1.py",)],
+                       ["1.doc\n"
+                        "1.py\n"
+                        "1\n"
+                        "2\n"
+                        "3"])
 
     def test_files_from_multiple_filelists(self):
-        u"""Check that --files-from can co-exist with other options using file lists"""
-        self.ParseTest([(u"--files-from", u"file"),
-                        (u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"2"), (u"1", u"2", u"3"),
-                        (u"1.doc",)],
-                       [u"1.doc\n"                      # --files-from
-                        u"1.py\n"
-                        u"1/1/1\n"
-                        u"1/1/2\n"
-                        u"1/1/3\n"
-                        u"1/2/1\n"
-                        u"1/2/2\n"
-                        u"1/2/3\n"
-                        u"1/3/1\n"
-                        u"1/3/2\n"
-                        u"1/3/3\n"
-                        u"2",
-                        u"+ testfiles/select/*.doc\n"   # --include-filelist
-                        u"+ testfiles/select/1/2/3\n"
-                        u"- **"])
+        """Check that --files-from can co-exist with other options using file lists"""
+        self.ParseTest([("--files-from", "file"),
+                        ("--include-filelist", "file")],
+                       [(), ("1",), ("1", "2"), ("1", "2", "3"),
+                        ("1.doc",)],
+                       ["1.doc\n"  # --files-from
+                        "1.py\n"
+                        "1/1/1\n"
+                        "1/1/2\n"
+                        "1/1/3\n"
+                        "1/2/1\n"
+                        "1/2/2\n"
+                        "1/2/3\n"
+                        "1/3/1\n"
+                        "1/3/2\n"
+                        "1/3/3\n"
+                        "2",
+                        "+ testfiles/select/*.doc\n"  # --include-filelist
+                        "+ testfiles/select/1/2/3\n"
+                        "- **"])
 
     def test_files_from_null_separator(self):
-        u"""Check that --files-from works with null separators when requested"""
-        self.set_config(u"null_separator", 1)
-        self.ParseTest([(u"--files-from", u"file"),
-                        (u"--include", u"testfiles/select/*.doc"),
-                        (u"--include", u"testfiles/select/1/2/3"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1",), (u"1", u"2"), (u"1", u"2", u"3"),
-                        (u"1.doc",)],
-                       [u"1.doc\0"
-                        u"1.py\0"
-                        u"1/1/1\0"
-                        u"1/1/2\0"
-                        u"1/1/3\0"
-                        u"1/2/1\0"
-                        u"1/2/2\0"
-                        u"1/2/3\0"
-                        u"1/3/1\0"
-                        u"1/3/2\0"
-                        u"1/3/3\0"
-                        u"2"])
+        """Check that --files-from works with null separators when requested"""
+        self.set_config("null_separator", 1)
+        self.ParseTest([("--files-from", "file"),
+                        ("--include", "testfiles/select/*.doc"),
+                        ("--include", "testfiles/select/1/2/3"),
+                        ("--exclude", "**")],
+                       [(), ("1",), ("1", "2"), ("1", "2", "3"),
+                        ("1.doc",)],
+                       ["1.doc\0"
+                        "1.py\0"
+                        "1/1/1\0"
+                        "1/1/2\0"
+                        "1/1/3\0"
+                        "1/2/1\0"
+                        "1/2/2\0"
+                        "1/2/3\0"
+                        "1/3/1\0"
+                        "1/3/2\0"
+                        "1/3/3\0"
+                        "2"])
 
     def test_include_filelist_1_trailing_whitespace(self):
-        u"""Filelist glob test similar to globbing filelist, but with 1 trailing whitespace on include"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"testfiles/select/1/1 \n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 1 trailing whitespace on include"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "testfiles/select/1/1 \n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_2_trailing_whitespaces(self):
-        u"""Filelist glob test similar to globbing filelist, but with 2 trailing whitespaces on include"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"testfiles/select/1/1  \n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 2 trailing whitespaces on include"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "testfiles/select/1/1  \n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_1_leading_whitespace(self):
-        u"""Filelist glob test similar to globbing filelist, but with 1 leading whitespace on include"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u" testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 1 leading whitespace on include"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        " testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_2_leading_whitespaces(self):
-        u"""Filelist glob test similar to globbing filelist, but with 2 leading whitespaces on include"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"  testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 2 leading whitespaces on include"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "  testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_1_trailing_whitespace_exclude(self):
-        u"""Filelist glob test similar to globbing filelist, but with 1 trailing whitespace on exclude"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1 \n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 1 trailing whitespace on exclude"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1 \n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_2_trailing_whitespace_exclude(self):
-        u"""Filelist glob test similar to globbing filelist, but with 2 trailing whitespaces on exclude"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1  \n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 2 trailing whitespaces on exclude"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1  \n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_1_leading_whitespace_exclude(self):
-        u"""Filelist glob test similar to globbing filelist, but with 1 leading whitespace on exclude"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u" - testfiles/select/1/1/1\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 1 leading whitespace on exclude"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       [" - testfiles/select/1/1/1\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_2_leading_whitespaces_exclude(self):
-        u"""Filelist glob test similar to globbing filelist, but with 2 leading whitespaces on exclude"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"  - testfiles/select/1/1/1\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with 2 leading whitespaces on exclude"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["  - testfiles/select/1/1/1\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_check_excluded_folder_included_for_contents(self):
-        u"""Filelist glob test to check excluded folder is included if contents are"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3"), (u"1", u"2"), (u"1", u"2", u"1"), (u"1", u"3"), (u"1", u"3", u"1"),
-                        (u"1", u"3", u"2"), (u"1", u"3", u"3")],
-                       [u"+ testfiles/select/1/2/1\n"
-                        u"- testfiles/select/1/2\n"
-                        u"testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test to check excluded folder is included if contents are"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3"), ("1", "2"), ("1", "2", "1"), ("1", "3"), ("1", "3", "1"),
+                        ("1", "3", "2"), ("1", "3", "3")],
+                       ["+ testfiles/select/1/2/1\n"
+                        "- testfiles/select/1/2\n"
+                        "testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_with_unnecessary_quotes(self):
-        u"""Filelist glob test similar to globbing filelist, but with quotes around one of the paths."""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- 'testfiles/select/1/1/1'\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with quotes around one of the paths."""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- 'testfiles/select/1/1/1'\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_with_unnecessary_double_quotes(self):
-        u"""Filelist glob test similar to globbing filelist, but with double quotes around one of the paths."""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u'- "testfiles/select/1/1/1"\n'
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with double quotes around one of the paths."""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ['- "testfiles/select/1/1/1"\n'
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_with_full_line_comment(self):
-        u"""Filelist glob test similar to globbing filelist, but with a full-line comment."""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"# This is a test\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with a full-line comment."""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "# This is a test\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_with_blank_line(self):
-        u"""Filelist glob test similar to globbing filelist, but with a blank line."""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with a blank line."""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_with_blank_line_and_whitespace(self):
-        u"""Filelist glob test similar to globbing filelist, but with a blank line and whitespace."""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"  \n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with a blank line and whitespace."""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "  \n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_asterisk(self):
-        u"""Filelist glob test with * instead of 'testfiles'"""
+        """Filelist glob test with * instead of 'testfiles'"""
         # Thank you to Elifarley Cruz for this test case
         # (https://bugs.launchpad.net/duplicity/+bug/884371).
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"1"),
-                        (u"1", u"1", u"2"), (u"1", u"1", u"3")],
-                       [u"*/select/1/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "1"),
+                        ("1", "1", "2"), ("1", "1", "3")],
+                       ["*/select/1/1\n"
+                        "- **"])
 
     def test_include_filelist_asterisk_2(self):
-        u"""Identical to test_filelist, but with the exclude "select" replaced with '*'"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/*/1/1/1\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Identical to test_filelist, but with the exclude "select" replaced with '*'"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/*/1/1/1\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_asterisk_3(self):
-        u"""Identical to test_filelist, but with the auto-include "select" replaced with '*'"""
+        """Identical to test_filelist, but with the auto-include "select" replaced with '*'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"testfiles/*/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "testfiles/*/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_asterisk_4(self):
-        u"""Identical to test_filelist, but with a specific include "select" replaced with '*'"""
+        """Identical to test_filelist, but with a specific include "select" replaced with '*'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"+ testfiles/*/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "+ testfiles/*/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_asterisk_5(self):
-        u"""Identical to test_filelist, but with all 'select's replaced with '*'"""
+        """Identical to test_filelist, but with all 'select's replaced with '*'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/*/1/1/1\n"
-                        u"+ testfiles/*/1/1\n"
-                        u"- testfiles/*/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/*/1/1/1\n"
+                        "+ testfiles/*/1/1\n"
+                        "- testfiles/*/1\n"
+                        "- **"])
 
     def test_include_filelist_asterisk_6(self):
-        u"""Identical to test_filelist, but with numerous excluded folders replaced with '*'"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- */*/1/1/1\n"
-                        u"+ testfiles/select/1/1\n"
-                        u"- */*/1\n"
-                        u"- **"])
+        """Identical to test_filelist, but with numerous excluded folders replaced with '*'"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- */*/1/1/1\n"
+                        "+ testfiles/select/1/1\n"
+                        "- */*/1\n"
+                        "- **"])
 
     def test_include_filelist_asterisk_7(self):
-        u"""Identical to test_filelist, but with numerous included/excluded folders replaced with '*'"""
+        """Identical to test_filelist, but with numerous included/excluded folders replaced with '*'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- */*/1/1/1\n"
-                        u"+ */*/1/1\n"
-                        u"- */*/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- */*/1/1/1\n"
+                        "+ */*/1/1\n"
+                        "- */*/1\n"
+                        "- **"])
 
     def test_include_filelist_double_asterisk_1(self):
-        u"""Identical to test_filelist, but with the exclude "select' replaced with '**'"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/**/1/1/1\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Identical to test_filelist, but with the exclude "select' replaced with '**'"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/**/1/1/1\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_double_asterisk_2(self):
-        u"""Identical to test_filelist, but with the include 'select' replaced with '**'"""
+        """Identical to test_filelist, but with the include 'select' replaced with '**'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"**ct/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "**ct/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_double_asterisk_3(self):
-        u"""Identical to test_filelist, but with the exclude 'testfiles/select' replaced with '**'"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- **/1/1/1\n"
-                        u"testfiles/select/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        """Identical to test_filelist, but with the exclude 'testfiles/select' replaced with '**'"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- **/1/1/1\n"
+                        "testfiles/select/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_double_asterisk_4(self):
-        u"""Identical to test_filelist, but with the include 'testfiles/select' replaced with '**'"""
+        """Identical to test_filelist, but with the include 'testfiles/select' replaced with '**'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1\n"
-                        u"**t/1/1\n"
-                        u"- testfiles/select/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1\n"
+                        "**t/1/1\n"
+                        "- testfiles/select/1\n"
+                        "- **"])
 
     def test_include_filelist_double_asterisk_5(self):
-        u"""Identical to test_filelist, but with all 'testfiles/select's replaced with '**'"""
+        """Identical to test_filelist, but with all 'testfiles/select's replaced with '**'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- **/1/1/1\n"
-                        u"**t/1/1\n"
-                        u"- **t/1\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- **/1/1/1\n"
+                        "**t/1/1\n"
+                        "- **t/1\n"
+                        "- **"])
 
     def test_include_filelist_trailing_slashes(self):
-        u"""Filelist glob test similar to globbing filelist, but with trailing slashes"""
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- testfiles/select/1/1/1/\n"
-                        u"testfiles/select/1/1/\n"
-                        u"- testfiles/select/1/\n"
-                        u"- **"])
+        """Filelist glob test similar to globbing filelist, but with trailing slashes"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- testfiles/select/1/1/1/\n"
+                        "testfiles/select/1/1/\n"
+                        "- testfiles/select/1/\n"
+                        "- **"])
 
     def test_include_filelist_trailing_slashes_and_single_asterisks(self):
-        u"""Filelist glob test similar to globbing filelist, but with trailing slashes and single asterisks"""
+        """Filelist glob test similar to globbing filelist, but with trailing slashes and single asterisks"""
         # Regression test for Bug #932482 (https://bugs.launchpad.net/duplicity/+bug/932482)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- */select/1/1/1/\n"
-                        u"testfiles/select/1/1/\n"
-                        u"- testfiles/*/1/\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- */select/1/1/1/\n"
+                        "testfiles/select/1/1/\n"
+                        "- testfiles/*/1/\n"
+                        "- **"])
 
     def test_include_filelist_trailing_slashes_and_double_asterisks(self):
-        u"""Filelist glob test similar to globbing filelist, but with trailing slashes and double asterisks"""
+        """Filelist glob test similar to globbing filelist, but with trailing slashes and double asterisks"""
         # Regression test for Bug #932482 (https://bugs.launchpad.net/duplicity/+bug/932482)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"- **/1/1/1/\n"
-                        u"testfiles/select/1/1/\n"
-                        u"- **t/1/\n"
-                        u"- **"])
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["- **/1/1/1/\n"
+                        "testfiles/select/1/1/\n"
+                        "- **t/1/\n"
+                        "- **"])
 
     def test_filelist_null_separator(self):
-        u"""test_filelist, but with null_separator set"""
-        self.set_config(u"null_separator", 1)
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"\0- testfiles/select/1/1/1\0testfiles/select/1/1\0- testfiles/select/1\0- **\0"])
+        """test_filelist, but with null_separator set"""
+        self.set_config("null_separator", 1)
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["\0- testfiles/select/1/1/1\0testfiles/select/1/1\0- testfiles/select/1\0- **\0"])
 
     def test_exclude_filelist(self):
-        u"""Exclude version of test_filelist"""
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"testfiles/select/1/1/1\n"
-                        u"+ testfiles/select/1/1\n"
-                        u"testfiles/select/1\n"
-                        u"- **"])
+        """Exclude version of test_filelist"""
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["testfiles/select/1/1/1\n"
+                        "+ testfiles/select/1/1\n"
+                        "testfiles/select/1\n"
+                        "- **"])
 
     def test_exclude_filelist_asterisk_1(self):
-        u"""Exclude version of test_include_filelist_asterisk"""
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"1"),
-                        (u"1", u"1", u"2"), (u"1", u"1", u"3")],
-                       [u"+ */select/1/1\n"
-                        u"- **"])
+        """Exclude version of test_include_filelist_asterisk"""
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "1"),
+                        ("1", "1", "2"), ("1", "1", "3")],
+                       ["+ */select/1/1\n"
+                        "- **"])
 
     def test_exclude_filelist_asterisk_2(self):
-        u"""Identical to test_exclude_filelist, but with the exclude "select" replaced with '*'"""
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"testfiles/*/1/1/1\n"
-                        u"+ testfiles/select/1/1\n"
-                        u"testfiles/select/1\n"
-                        u"- **"])
+        """Identical to test_exclude_filelist, but with the exclude "select" replaced with '*'"""
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["testfiles/*/1/1/1\n"
+                        "+ testfiles/select/1/1\n"
+                        "testfiles/select/1\n"
+                        "- **"])
 
     def test_exclude_filelist_asterisk_3(self):
-        u"""Identical to test_exclude_filelist, but with the include "select" replaced with '*'"""
+        """Identical to test_exclude_filelist, but with the include "select" replaced with '*'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"testfiles/select/1/1/1\n"
-                        u"+ testfiles/*/1/1\n"
-                        u"testfiles/select/1\n"
-                        u"- **"])
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["testfiles/select/1/1/1\n"
+                        "+ testfiles/*/1/1\n"
+                        "testfiles/select/1\n"
+                        "- **"])
 
     def test_exclude_filelist_asterisk_4(self):
-        u"""Identical to test_exclude_filelist, but with numerous excluded folders replaced with '*'"""
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"*/select/1/1/1\n"
-                        u"+ testfiles/select/1/1\n"
-                        u"*/*/1\n"
-                        u"- **"])
+        """Identical to test_exclude_filelist, but with numerous excluded folders replaced with '*'"""
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["*/select/1/1/1\n"
+                        "+ testfiles/select/1/1\n"
+                        "*/*/1\n"
+                        "- **"])
 
     def test_exclude_filelist_asterisk_5(self):
-        u"""Identical to test_exclude_filelist, but with numerous included/excluded folders replaced with '*'"""
+        """Identical to test_exclude_filelist, but with numerous included/excluded folders replaced with '*'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"*/select/1/1/1\n"
-                        u"+ */*/1/1\n"
-                        u"*/*/1\n"
-                        u"- **"])
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["*/select/1/1/1\n"
+                        "+ */*/1/1\n"
+                        "*/*/1\n"
+                        "- **"])
 
     def test_exclude_filelist_double_asterisk(self):
-        u"""Identical to test_exclude_filelist, but with all included/excluded folders replaced with '**'"""
+        """Identical to test_exclude_filelist, but with all included/excluded folders replaced with '**'"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"1", u"3")],
-                       [u"**/1/1/1\n"
-                        u"+ **t/1/1\n"
-                        u"**t/1\n"
-                        u"- **"])
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("1",), ("1", "1"), ("1", "1", "2"),
+                        ("1", "1", "3")],
+                       ["**/1/1/1\n"
+                        "+ **t/1/1\n"
+                        "**t/1\n"
+                        "- **"])
 
     def test_exclude_filelist_single_asterisk_at_beginning(self):
-        u"""Exclude filelist testing limited functionality of functional test"""
+        """Exclude filelist testing limited functionality of functional test"""
         # Regression test for Bug #884371 (https://bugs.launchpad.net/duplicity/+bug/884371)
-        self.root = Path(u"testfiles/select/1")
-        self.ParseTest([(u"--exclude-filelist", u"file")],
-                       [(), (u"2",), (u"2", u"1")],
-                       [u"+ */select/1/2/1\n"
-                        u"- testfiles/select/1/2\n"
-                        u"- testfiles/*/1/1\n"
-                        u"- testfiles/select/1/3"])
+        self.root = Path("testfiles/select/1")
+        self.ParseTest([("--exclude-filelist", "file")],
+                       [(), ("2",), ("2", "1")],
+                       ["+ */select/1/2/1\n"
+                        "- testfiles/select/1/2\n"
+                        "- testfiles/*/1/1\n"
+                        "- testfiles/select/1/3"])
 
     def test_commandline_asterisks_double_both(self):
-        u"""Unit test the functional test TestAsterisks.test_commandline_asterisks_double_both"""
-        self.root = Path(u"testfiles/select/1")
-        self.ParseTest([(u"--include", u"**/1/2/1"),
-                        (u"--exclude", u"**t/1/2"),
-                        (u"--exclude", u"**t/1/1"),
-                        (u"--exclude", u"**t/1/3")],
-                       [(), (u"2",), (u"2", u"1")])
+        """Unit test the functional test TestAsterisks.test_commandline_asterisks_double_both"""
+        self.root = Path("testfiles/select/1")
+        self.ParseTest([("--include", "**/1/2/1"),
+                        ("--exclude", "**t/1/2"),
+                        ("--exclude", "**t/1/1"),
+                        ("--exclude", "**t/1/3")],
+                       [(), ("2",), ("2", "1")])
 
     def test_includes_files(self):
-        u"""Unit test the functional test test_includes_files"""
+        """Unit test the functional test test_includes_files"""
         # Test for Bug 1624725
         # https://bugs.launchpad.net/duplicity/+bug/1624725
-        self.root = Path(u"testfiles/select2/1/1sub1")
-        self.ParseTest([(u"--include", u"testfiles/select2/1/1sub1/1sub1sub1"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1sub1sub1",), (u"1sub1sub1",
-                        u"1sub1sub1_file.txt")])
+        self.root = Path("testfiles/select2/1/1sub1")
+        self.ParseTest([("--include", "testfiles/select2/1/1sub1/1sub1sub1"),
+                        ("--exclude", "**")],
+                       [(), ("1sub1sub1",), ("1sub1sub1",
+                                             "1sub1sub1_file.txt")])
 
     def test_includes_files_trailing_slash(self):
-        u"""Unit test the functional test test_includes_files_trailing_slash"""
+        """Unit test the functional test test_includes_files_trailing_slash"""
         # Test for Bug 1624725
         # https://bugs.launchpad.net/duplicity/+bug/1624725
-        self.root = Path(u"testfiles/select2/1/1sub1")
-        self.ParseTest([(u"--include", u"testfiles/select2/1/1sub1/1sub1sub1/"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1sub1sub1",), (u"1sub1sub1",
-                                              u"1sub1sub1_file.txt")])
+        self.root = Path("testfiles/select2/1/1sub1")
+        self.ParseTest([("--include", "testfiles/select2/1/1sub1/1sub1sub1/"),
+                        ("--exclude", "**")],
+                       [(), ("1sub1sub1",), ("1sub1sub1",
+                                             "1sub1sub1_file.txt")])
 
     def test_includes_files_trailing_slash_globbing_chars(self):
-        u"""Unit test functional test_includes_files_trailing_slash_globbing_chars"""
+        """Unit test functional test_includes_files_trailing_slash_globbing_chars"""
         # Test for Bug 1624725
         # https://bugs.launchpad.net/duplicity/+bug/1624725
-        self.root = Path(u"testfiles/select2/1/1sub1")
-        self.ParseTest([(u"--include", u"testfiles/s?lect2/1/1sub1/1sub1sub1/"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1sub1sub1",), (u"1sub1sub1", u"1sub1sub1_file.txt")])
+        self.root = Path("testfiles/select2/1/1sub1")
+        self.ParseTest([("--include", "testfiles/s?lect2/1/1sub1/1sub1sub1/"),
+                        ("--exclude", "**")],
+                       [(), ("1sub1sub1",), ("1sub1sub1", "1sub1sub1_file.txt")])
 
     def test_glob(self):
-        u"""Test globbing expression"""
-        self.ParseTest([(u"--exclude", u"**[3-5]"),
-                        (u"--include", u"testfiles/select/1"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1",), (u"1", u"1"),
-                        (u"1", u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"2"), (u"1", u"2", u"1"), (u"1", u"2", u"2")])
-        self.ParseTest([(u"--include", u"testfiles/select**/2"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1",), (u"1", u"1"),
-                        (u"1", u"1", u"2"),
-                        (u"1", u"2"),
-                        (u"1", u"2", u"1"), (u"1", u"2", u"2"), (u"1", u"2", u"3"),
-                        (u"1", u"3"),
-                        (u"1", u"3", u"2"),
-                        (u"2",), (u"2", u"1"),
-                        (u"2", u"1", u"1"), (u"2", u"1", u"2"), (u"2", u"1", u"3"),
-                        (u"2", u"2"),
-                        (u"2", u"2", u"1"), (u"2", u"2", u"2"), (u"2", u"2", u"3"),
-                        (u"2", u"3"),
-                        (u"2", u"3", u"1"), (u"2", u"3", u"2"), (u"2", u"3", u"3"),
-                        (u"3",), (u"3", u"1"),
-                        (u"3", u"1", u"2"),
-                        (u"3", u"2"),
-                        (u"3", u"2", u"1"), (u"3", u"2", u"2"), (u"3", u"2", u"3"),
-                        (u"3", u"3"),
-                        (u"3", u"3", u"2")])
+        """Test globbing expression"""
+        self.ParseTest([("--exclude", "**[3-5]"),
+                        ("--include", "testfiles/select/1"),
+                        ("--exclude", "**")],
+                       [(), ("1",), ("1", "1"),
+                        ("1", "1", "1"), ("1", "1", "2"),
+                        ("1", "2"), ("1", "2", "1"), ("1", "2", "2")])
+        self.ParseTest([("--include", "testfiles/select**/2"),
+                        ("--exclude", "**")],
+                       [(), ("1",), ("1", "1"),
+                        ("1", "1", "2"),
+                        ("1", "2"),
+                        ("1", "2", "1"), ("1", "2", "2"), ("1", "2", "3"),
+                        ("1", "3"),
+                        ("1", "3", "2"),
+                        ("2",), ("2", "1"),
+                        ("2", "1", "1"), ("2", "1", "2"), ("2", "1", "3"),
+                        ("2", "2"),
+                        ("2", "2", "1"), ("2", "2", "2"), ("2", "2", "3"),
+                        ("2", "3"),
+                        ("2", "3", "1"), ("2", "3", "2"), ("2", "3", "3"),
+                        ("3",), ("3", "1"),
+                        ("3", "1", "2"),
+                        ("3", "2"),
+                        ("3", "2", "1"), ("3", "2", "2"), ("3", "2", "3"),
+                        ("3", "3"),
+                        ("3", "3", "2")])
 
     def test_filelist2(self):
-        u"""Filelist glob test similar to above testGlob"""
-        self.ParseTest([(u"--exclude-filelist", u"asoeuth")],
-                       [(), (u"1",), (u"1", u"1"),
-                        (u"1", u"1", u"1"), (u"1", u"1", u"2"),
-                        (u"1", u"2"), (u"1", u"2", u"1"), (u"1", u"2", u"2")],
-                       [u"""
+        """Filelist glob test similar to above testGlob"""
+        self.ParseTest([("--exclude-filelist", "asoeuth")],
+                       [(), ("1",), ("1", "1"),
+                        ("1", "1", "1"), ("1", "1", "2"),
+                        ("1", "2"), ("1", "2", "1"), ("1", "2", "2")],
+                       ["""
 **[3-5]
 + testfiles/select/1
 **
 """])
-        self.ParseTest([(u"--include-filelist", u"file")],
-                       [(), (u"1",), (u"1", u"1"),
-                        (u"1", u"1", u"2"),
-                        (u"1", u"2"),
-                        (u"1", u"2", u"1"), (u"1", u"2", u"2"), (u"1", u"2", u"3"),
-                        (u"1", u"3"),
-                        (u"1", u"3", u"2"),
-                        (u"2",), (u"2", u"1"),
-                        (u"2", u"1", u"1"), (u"2", u"1", u"2"), (u"2", u"1", u"3"),
-                        (u"2", u"2"),
-                        (u"2", u"2", u"1"), (u"2", u"2", u"2"), (u"2", u"2", u"3"),
-                        (u"2", u"3"),
-                        (u"2", u"3", u"1"), (u"2", u"3", u"2"), (u"2", u"3", u"3"),
-                        (u"3",), (u"3", u"1"),
-                        (u"3", u"1", u"2"),
-                        (u"3", u"2"),
-                        (u"3", u"2", u"1"), (u"3", u"2", u"2"), (u"3", u"2", u"3"),
-                        (u"3", u"3"),
-                        (u"3", u"3", u"2")],
-                       [u"""
+        self.ParseTest([("--include-filelist", "file")],
+                       [(), ("1",), ("1", "1"),
+                        ("1", "1", "2"),
+                        ("1", "2"),
+                        ("1", "2", "1"), ("1", "2", "2"), ("1", "2", "3"),
+                        ("1", "3"),
+                        ("1", "3", "2"),
+                        ("2",), ("2", "1"),
+                        ("2", "1", "1"), ("2", "1", "2"), ("2", "1", "3"),
+                        ("2", "2"),
+                        ("2", "2", "1"), ("2", "2", "2"), ("2", "2", "3"),
+                        ("2", "3"),
+                        ("2", "3", "1"), ("2", "3", "2"), ("2", "3", "3"),
+                        ("3",), ("3", "1"),
+                        ("3", "1", "2"),
+                        ("3", "2"),
+                        ("3", "2", "1"), ("3", "2", "2"), ("3", "2", "3"),
+                        ("3", "3"),
+                        ("3", "3", "2")],
+                       ["""
 testfiles/select**/2
 - **
 """])
 
     def test_glob2(self):
-        u"""Test more globbing functions"""
-        self.ParseTest([(u"--include", u"testfiles/select/*foo*/p*"),
-                        (u"--exclude", u"**")],
-                       [(), (u"efools",), (u"efools", u"ping"),
-                        (u"foobar",), (u"foobar", u"pong")])
-        self.ParseTest([(u"--exclude", u"testfiles/select/1/1/*"),
-                        (u"--exclude", u"testfiles/select/1/2/**"),
-                        (u"--exclude", u"testfiles/select/1/3**"),
-                        (u"--include", u"testfiles/select/1"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"2")])
+        """Test more globbing functions"""
+        self.ParseTest([("--include", "testfiles/select/*foo*/p*"),
+                        ("--exclude", "**")],
+                       [(), ("efools",), ("efools", "ping"),
+                        ("foobar",), ("foobar", "pong")])
+        self.ParseTest([("--exclude", "testfiles/select/1/1/*"),
+                        ("--exclude", "testfiles/select/1/2/**"),
+                        ("--exclude", "testfiles/select/1/3**"),
+                        ("--include", "testfiles/select/1"),
+                        ("--exclude", "**")],
+                       [(), ("1",), ("1", "1"), ("1", "2")])
 
     def test_glob3(self):
-        u""" regression test for bug 25230 """
-        self.ParseTest([(u"--include", u"testfiles/select/**1"),
-                        (u"--include", u"testfiles/select/**2"),
-                        (u"--exclude", u"**")],
-                       [(), (u"1",), (u"1", u"1"),
-                        (u"1", u"1", u"1"), (u"1", u"1", u"2"), (u"1", u"1", u"3"),
-                        (u"1", u"2"),
-                        (u"1", u"2", u"1"), (u"1", u"2", u"2"), (u"1", u"2", u"3"),
-                        (u"1", u"3"),
-                        (u"1", u"3", u"1"), (u"1", u"3", u"2"), (u"1", u"3", u"3"),
-                        (u"2",), (u"2", u"1"),
-                        (u"2", u"1", u"1"), (u"2", u"1", u"2"), (u"2", u"1", u"3"),
-                        (u"2", u"2"),
-                        (u"2", u"2", u"1"), (u"2", u"2", u"2"), (u"2", u"2", u"3"),
-                        (u"2", u"3"),
-                        (u"2", u"3", u"1"), (u"2", u"3", u"2"), (u"2", u"3", u"3"),
-                        (u"3",), (u"3", u"1"),
-                        (u"3", u"1", u"1"), (u"3", u"1", u"2"), (u"3", u"1", u"3"),
-                        (u"3", u"2"),
-                        (u"3", u"2", u"1"), (u"3", u"2", u"2"), (u"3", u"2", u"3"),
-                        (u"3", u"3"),
-                        (u"3", u"3", u"1"), (u"3", u"3", u"2")])
+        """ regression test for bug 25230 """
+        self.ParseTest([("--include", "testfiles/select/**1"),
+                        ("--include", "testfiles/select/**2"),
+                        ("--exclude", "**")],
+                       [(), ("1",), ("1", "1"),
+                        ("1", "1", "1"), ("1", "1", "2"), ("1", "1", "3"),
+                        ("1", "2"),
+                        ("1", "2", "1"), ("1", "2", "2"), ("1", "2", "3"),
+                        ("1", "3"),
+                        ("1", "3", "1"), ("1", "3", "2"), ("1", "3", "3"),
+                        ("2",), ("2", "1"),
+                        ("2", "1", "1"), ("2", "1", "2"), ("2", "1", "3"),
+                        ("2", "2"),
+                        ("2", "2", "1"), ("2", "2", "2"), ("2", "2", "3"),
+                        ("2", "3"),
+                        ("2", "3", "1"), ("2", "3", "2"), ("2", "3", "3"),
+                        ("3",), ("3", "1"),
+                        ("3", "1", "1"), ("3", "1", "2"), ("3", "1", "3"),
+                        ("3", "2"),
+                        ("3", "2", "1"), ("3", "2", "2"), ("3", "2", "3"),
+                        ("3", "3"),
+                        ("3", "3", "1"), ("3", "3", "2")])
 
     def test_alternate_root(self):
-        u"""Test select with different root"""
-        self.root = Path(u"testfiles/select/1")
-        self.ParseTest([(u"--exclude", u"testfiles/select/1/[23]")],
-                       [(), (u"1",), (u"1", u"1"), (u"1", u"2"), (u"1", u"3")])
-
-        self.root = Path(u"/")
-        self.ParseTest([(u"--exclude", u"/tmp/*"),
-                        (u"--include", u"/tmp"),
-                        (u"--exclude", u"/")],
-                       [(), (u"tmp",)])
+        """Test select with different root"""
+        self.root = Path("testfiles/select/1")
+        self.ParseTest([("--exclude", "testfiles/select/1/[23]")],
+                       [(), ("1",), ("1", "1"), ("1", "2"), ("1", "3")])
+
+        self.root = Path("/")
+        self.ParseTest([("--exclude", "/tmp/*"),
+                        ("--include", "/tmp"),
+                        ("--exclude", "/")],
+                       [(), ("tmp",)])
 
     def test_exclude_after_scan(self):
-        u"""Test select with an exclude after a pattern that would return a scan for that file"""
-        self.root = Path(u"testfiles/select2/3")
-        self.ParseTest([(u"--include", u"testfiles/select2/3/**file.txt"),
-                        (u"--exclude", u"testfiles/select2/3/3sub2"),
-                        (u"--include", u"testfiles/select2/3/3sub1"),
-                        (u"--exclude", u"**")],
-                       [(), (u"3sub1",), (u"3sub1", u"3sub1sub1"), (u"3sub1", u"3sub1sub2"), (u"3sub1", u"3sub1sub3"),
-                        (u"3sub3",), (u"3sub3", u"3sub3sub2"), (u"3sub3", u"3sub3sub2", u"3sub3sub2_file.txt")])
+        """Test select with an exclude after a pattern that would return a scan for that file"""
+        self.root = Path("testfiles/select2/3")
+        self.ParseTest([("--include", "testfiles/select2/3/**file.txt"),
+                        ("--exclude", "testfiles/select2/3/3sub2"),
+                        ("--include", "testfiles/select2/3/3sub1"),
+                        ("--exclude", "**")],
+                       [(), ("3sub1",), ("3sub1", "3sub1sub1"), ("3sub1", "3sub1sub2"), ("3sub1", "3sub1sub3"),
+                        ("3sub3",), ("3sub3", "3sub3sub2"), ("3sub3", "3sub3sub2", "3sub3sub2_file.txt")])
 
     def test_include_exclude_basic(self):
-        u"""Test functional test test_include_exclude_basic as a unittest"""
-        self.root = Path(u"testfiles/select2")
-        self.ParseTest([(u"--include", u"testfiles/select2/3/3sub3/3sub3sub2/3sub3sub2_file.txt"),
-                        (u"--exclude", u"testfiles/select2/3/3sub3/3sub3sub2"),
-                        (u"--include", u"testfiles/select2/3/3sub2/3sub2sub2"),
-                        (u"--include", u"testfiles/select2/3/3sub3"),
-                        (u"--exclude", u"testfiles/select2/3/3sub1"),
-                        (u"--exclude", u"testfiles/select2/2/2sub1/2sub1sub3"),
-                        (u"--exclude", u"testfiles/select2/2/2sub1/2sub1sub2"),
-                        (u"--include", u"testfiles/select2/2/2sub1"),
-                        (u"--exclude", u"testfiles/select2/1/1sub3/1sub3sub2"),
-                        (u"--exclude", u"testfiles/select2/1/1sub3/1sub3sub1"),
-                        (u"--exclude", u"testfiles/select2/1/1sub2/1sub2sub3"),
-                        (u"--include", u"testfiles/select2/1/1sub2/1sub2sub1"),
-                        (u"--exclude", u"testfiles/select2/1/1sub1/1sub1sub3/1sub1sub3_file.txt"),
-                        (u"--exclude", u"testfiles/select2/1/1sub1/1sub1sub2"),
-                        (u"--exclude", u"testfiles/select2/1/1sub2"),
-                        (u"--include", u"testfiles/select2/1.py"),
-                        (u"--include", u"testfiles/select2/3"),
-                        (u"--include", u"testfiles/select2/1"),
-                        (u"--exclude", u"testfiles/select2/**")],
+        """Test functional test test_include_exclude_basic as a unittest"""
+        self.root = Path("testfiles/select2")
+        self.ParseTest([("--include", "testfiles/select2/3/3sub3/3sub3sub2/3sub3sub2_file.txt"),
+                        ("--exclude", "testfiles/select2/3/3sub3/3sub3sub2"),
+                        ("--include", "testfiles/select2/3/3sub2/3sub2sub2"),
+                        ("--include", "testfiles/select2/3/3sub3"),
+                        ("--exclude", "testfiles/select2/3/3sub1"),
+                        ("--exclude", "testfiles/select2/2/2sub1/2sub1sub3"),
+                        ("--exclude", "testfiles/select2/2/2sub1/2sub1sub2"),
+                        ("--include", "testfiles/select2/2/2sub1"),
+                        ("--exclude", "testfiles/select2/1/1sub3/1sub3sub2"),
+                        ("--exclude", "testfiles/select2/1/1sub3/1sub3sub1"),
+                        ("--exclude", "testfiles/select2/1/1sub2/1sub2sub3"),
+                        ("--include", "testfiles/select2/1/1sub2/1sub2sub1"),
+                        ("--exclude", "testfiles/select2/1/1sub1/1sub1sub3/1sub1sub3_file.txt"),
+                        ("--exclude", "testfiles/select2/1/1sub1/1sub1sub2"),
+                        ("--exclude", "testfiles/select2/1/1sub2"),
+                        ("--include", "testfiles/select2/1.py"),
+                        ("--include", "testfiles/select2/3"),
+                        ("--include", "testfiles/select2/1"),
+                        ("--exclude", "testfiles/select2/**")],
                        self.expected_restored_tree)
 
     def test_globbing_replacement(self):
-        u"""Test functional test test_globbing_replacement as a unittest"""
-        self.root = Path(u"testfiles/select2")
-        self.ParseTest([(u"--include", u"testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt"),
-                        (u"--exclude", u"testfiles/select2/*/3s*1"),
-                        (u"--exclude", u"testfiles/select2/**/2sub1sub3"),
-                        (u"--exclude", u"ignorecase:testfiles/select2/2/2sub1/2Sub1Sub2"),
-                        (u"--include", u"ignorecase:testfiles/sel[w,u,e,q]ct2/2/2S?b1"),
-                        (u"--exclude", u"testfiles/select2/1/1sub3/1s[w,u,p,q]b3sub2"),
-                        (u"--exclude", u"testfiles/select2/1/1sub[1-4]/1sub3sub1"),
-                        (u"--include", u"testfiles/select2/1/1sub2/1sub2sub1"),
-                        (u"--exclude", u"testfiles/select2/1/1sub1/1sub1sub3/1su?1sub3_file.txt"),
-                        (u"--exclude", u"testfiles/select2/1/1*1/1sub1sub2"),
-                        (u"--exclude", u"testfiles/select2/1/1sub2"),
-                        (u"--include", u"testfiles/select[2-4]/*.py"),
-                        (u"--include", u"testfiles/*2/3"),
-                        (u"--include", u"**/select2/1"),
-                        (u"--exclude", u"testfiles/select2/**")],
+        """Test functional test test_globbing_replacement as a unittest"""
+        self.root = Path("testfiles/select2")
+        self.ParseTest([("--include", "testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt"),
+                        ("--exclude", "testfiles/select2/*/3s*1"),
+                        ("--exclude", "testfiles/select2/**/2sub1sub3"),
+                        ("--exclude", "ignorecase:testfiles/select2/2/2sub1/2Sub1Sub2"),
+                        ("--include", "ignorecase:testfiles/sel[w,u,e,q]ct2/2/2S?b1"),
+                        ("--exclude", "testfiles/select2/1/1sub3/1s[w,u,p,q]b3sub2"),
+                        ("--exclude", "testfiles/select2/1/1sub[1-4]/1sub3sub1"),
+                        ("--include", "testfiles/select2/1/1sub2/1sub2sub1"),
+                        ("--exclude", "testfiles/select2/1/1sub1/1sub1sub3/1su?1sub3_file.txt"),
+                        ("--exclude", "testfiles/select2/1/1*1/1sub1sub2"),
+                        ("--exclude", "testfiles/select2/1/1sub2"),
+                        ("--include", "testfiles/select[2-4]/*.py"),
+                        ("--include", "testfiles/*2/3"),
+                        ("--include", "**/select2/1"),
+                        ("--exclude", "testfiles/select2/**")],
                        self.expected_restored_tree)
 
     def test_globbing_replacement_filter_ignorecase(self):
-        u"""Test functional test test_globbing_replacement as a unittest - an
+        """Test functional test test_globbing_replacement as a unittest - an
         alternate implementation of the above test which uses --filter-*case
         instead of the ignorecase: prefix.
         """
-        self.root = Path(u"testfiles/select2")
-        self.ParseTest([(u"--include", u"testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt"),
-                        (u"--exclude", u"testfiles/select2/*/3s*1"),
-                        (u"--exclude", u"testfiles/select2/**/2sub1sub3"),
-                        (u"--filter-ignorecase", None),
-                        (u"--exclude", u"testfiles/select2/2/2sub1/2Sub1Sub2"),
-                        (u"--include", u"testfiles/sel[w,u,e,q]ct2/2/2S?b1"),
-                        (u"--filter-strictcase", None),
-                        (u"--exclude", u"testfiles/select2/1/1sub3/1s[w,u,p,q]b3sub2"),
-                        (u"--exclude", u"testfiles/select2/1/1sub[1-4]/1sub3sub1"),
-                        (u"--include", u"testfiles/select2/1/1sub2/1sub2sub1"),
-                        (u"--exclude", u"testfiles/select2/1/1sub1/1sub1sub3/1su?1sub3_file.txt"),
-                        (u"--exclude", u"testfiles/select2/1/1*1/1sub1sub2"),
-                        (u"--exclude", u"testfiles/select2/1/1sub2"),
-                        (u"--include", u"testfiles/select[2-4]/*.py"),
-                        (u"--include", u"testfiles/*2/3"),
-                        (u"--include", u"**/select2/1"),
-                        (u"--exclude", u"testfiles/select2/**")],
+        self.root = Path("testfiles/select2")
+        self.ParseTest([("--include", "testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt"),
+                        ("--exclude", "testfiles/select2/*/3s*1"),
+                        ("--exclude", "testfiles/select2/**/2sub1sub3"),
+                        ("--filter-ignorecase", None),
+                        ("--exclude", "testfiles/select2/2/2sub1/2Sub1Sub2"),
+                        ("--include", "testfiles/sel[w,u,e,q]ct2/2/2S?b1"),
+                        ("--filter-strictcase", None),
+                        ("--exclude", "testfiles/select2/1/1sub3/1s[w,u,p,q]b3sub2"),
+                        ("--exclude", "testfiles/select2/1/1sub[1-4]/1sub3sub1"),
+                        ("--include", "testfiles/select2/1/1sub2/1sub2sub1"),
+                        ("--exclude", "testfiles/select2/1/1sub1/1sub1sub3/1su?1sub3_file.txt"),
+                        ("--exclude", "testfiles/select2/1/1*1/1sub1sub2"),
+                        ("--exclude", "testfiles/select2/1/1sub2"),
+                        ("--include", "testfiles/select[2-4]/*.py"),
+                        ("--include", "testfiles/*2/3"),
+                        ("--include", "**/select2/1"),
+                        ("--exclude", "testfiles/select2/**")],
                        self.expected_restored_tree)
 
     def test_select_mode(self):
-        u"""Test seletion function mode switching with --filter-* options"""
-        self.Select = Select(Path(u"testfiles/select"))
-        self.Select.ParseArgs([(u"--include", u"testfiles/select/1"),
-                               (u"--filter-literal", None),
-                               (u"--include", u"testfiles/select/2"),
-                               (u"--filter-regexp", None),
-                               (u"--include", u"testfiles/select/3"),
-                               (u"--filter-globbing", None),
-                               (u"--filter-ignorecase", None),
-                               (u"--include", u"testfiles/select/1"),
-                               (u"--filter-literal", None),
-                               (u"--include", u"testfiles/select/2"),
-                               (u"--filter-regexp", None),
-                               (u"--include", u"testfiles/select/3"),
-                               (u"--filter-globbing", None),
-                               (u"--filter-strictcase", None),
-                               (u"--exclude", u"testfiles/select")], [])
-        assert self.Select.selection_functions[0].name.lower().startswith(u"shell glob include case")
-        assert self.Select.selection_functions[1].name.lower().startswith(u"literal string include case")
-        assert self.Select.selection_functions[2].name.lower().startswith(u"regular expression include case")
-        assert self.Select.selection_functions[3].name.lower().startswith(u"shell glob include no-case")
-        assert self.Select.selection_functions[4].name.lower().startswith(u"literal string include no-case")
-        assert self.Select.selection_functions[5].name.lower().startswith(u"regular expression include no-case")
-        assert self.Select.selection_functions[6].name.lower().startswith(u"shell glob exclude case")
+        """Test seletion function mode switching with --filter-* options"""
+        self.Select = Select(Path("testfiles/select"))
+        self.Select.ParseArgs([("--include", "testfiles/select/1"),
+                               ("--filter-literal", None),
+                               ("--include", "testfiles/select/2"),
+                               ("--filter-regexp", None),
+                               ("--include", "testfiles/select/3"),
+                               ("--filter-globbing", None),
+                               ("--filter-ignorecase", None),
+                               ("--include", "testfiles/select/1"),
+                               ("--filter-literal", None),
+                               ("--include", "testfiles/select/2"),
+                               ("--filter-regexp", None),
+                               ("--include", "testfiles/select/3"),
+                               ("--filter-globbing", None),
+                               ("--filter-strictcase", None),
+                               ("--exclude", "testfiles/select")], [])
+        assert self.Select.selection_functions[0].name.lower().startswith("shell glob include case")
+        assert self.Select.selection_functions[1].name.lower().startswith("literal string include case")
+        assert self.Select.selection_functions[2].name.lower().startswith("regular expression include case")
+        assert self.Select.selection_functions[3].name.lower().startswith("shell glob include no-case")
+        assert self.Select.selection_functions[4].name.lower().startswith("literal string include no-case")
+        assert self.Select.selection_functions[5].name.lower().startswith("regular expression include no-case")
+        assert self.Select.selection_functions[6].name.lower().startswith("shell glob exclude case")
 
-    @unittest.skipUnless(platform.platform().startswith(u"Linux"), u"Skip on non-Linux systems")
+    @unittest.skipUnless(platform.platform().startswith("Linux"), "Skip on non-Linux systems")
     def _paths_non_globbing(self):
-        u"""Test functional test _paths_non_globbing as a unittest"""
-        self.root = Path(u"testfiles/select-unicode")
-        self.ParseTest([(u"--exclude", u"testfiles/select-unicode/прыклад/пример/例/Παράδειγμα/उदाहरण.txt"),
-                        (u"--exclude", u"testfiles/select-unicode/прыклад/пример/例/Παράδειγμα/דוגמא.txt"),
-                        (u"--exclude", u"testfiles/select-unicode/прыклад/пример/例/მაგალითი/"),
-                        (u"--include", u"testfiles/select-unicode/прыклад/пример/例/"),
-                        (u"--exclude", u"testfiles/select-unicode/прыклад/пример/"),
-                        (u"--include", u"testfiles/select-unicode/прыклад/"),
-                        (u"--include", u"testfiles/select-unicode/օրինակ.txt"),
-                        (u"--exclude", u"testfiles/select-unicode/**")],
-                       [(), (u"прыклад",), (u"прыклад", u"пример"), (u"прыклад", u"пример", u"例"),
-                        (u"прыклад", u"пример", u"例", u"Παράδειγμα"),
-                        (u"прыклад", u"пример", u"例", u"Παράδειγμα", u"ઉદાહરણ.log"),
-                        (u"прыклад", u"উদাহরণ"), (u"օրինակ.txt",)])
+        """Test functional test _paths_non_globbing as a unittest"""
+        self.root = Path("testfiles/select-unicode")
+        self.ParseTest([("--exclude", "testfiles/select-unicode/прыклад/пример/例/Παράδειγμα/उदाहरण.txt"),
+                        ("--exclude", "testfiles/select-unicode/прыклад/пример/例/Παράδειγμα/דוגמא.txt"),
+                        ("--exclude", "testfiles/select-unicode/прыклад/пример/例/მაგალითი/"),
+                        ("--include", "testfiles/select-unicode/прыклад/пример/例/"),
+                        ("--exclude", "testfiles/select-unicode/прыклад/пример/"),
+                        ("--include", "testfiles/select-unicode/прыклад/"),
+                        ("--include", "testfiles/select-unicode/օրինակ.txt"),
+                        ("--exclude", "testfiles/select-unicode/**")],
+                       [(), ("прыклад",), ("прыклад", "пример"), ("прыклад", "пример", "例"),
+                        ("прыклад", "пример", "例", "Παράδειγμα"),
+                        ("прыклад", "пример", "例", "Παράδειγμα", "ઉદાહરણ.log"),
+                        ("прыклад", "উদাহরণ"), ("օրինակ.txt",)])
 
 
 class TestGlobGetSf(UnitTestCase):
-    u"""Test glob parsing of the test_glob_get_sf function. Indirectly test behaviour of glob_to_re."""
+    """Test glob parsing of the test_glob_get_sf function. Indirectly test behaviour of glob_to_re."""
 
     def glob_tester(self, path, glob_string, include_exclude, root_path, ignore_case):
-        u"""Takes a path, glob string and include_exclude value (1 = include, 0 = exclude) and returns the output
+        """Takes a path, glob string and include_exclude value (1 = include, 0 = exclude) and returns the output
         of the selection function.
         None - means the test has nothing to say about the related file
         0 - the file is excluded by the test
         1 - the file is included
         2 - the test says the file (must be directory) should be scanned"""
         self.unpack_testfiles()
         self.root = Path(root_path)
         self.select = Select(self.root)
         selection_function = self.select.glob_get_sf(glob_string, include_exclude, ignore_case)
         path = Path(path)
         return selection_function(path)
 
-    def include_glob_tester(self, path, glob_string, root_path=u"/", ignore_case=False):
+    def include_glob_tester(self, path, glob_string, root_path="/", ignore_case=False):
         return self.glob_tester(path, glob_string, 1, root_path, ignore_case)
 
-    def exclude_glob_tester(self, path, glob_string, root_path=u"/", ignore_case=False):
+    def exclude_glob_tester(self, path, glob_string, root_path="/", ignore_case=False):
         return self.glob_tester(path, glob_string, 0, root_path, ignore_case)
 
     def test_glob_get_sf_exclude(self):
-        u"""Test simple exclude."""
-        self.assertEqual(self.exclude_glob_tester(u"/testfiles/select2/3", u"/testfiles/select2"), 0)
-        self.assertEqual(self.exclude_glob_tester(u"/testfiles/.git", u"/testfiles"), 0)
+        """Test simple exclude."""
+        self.assertEqual(self.exclude_glob_tester("/testfiles/select2/3", "/testfiles/select2"), 0)
+        self.assertEqual(self.exclude_glob_tester("/testfiles/.git", "/testfiles"), 0)
 
     def test_glob_get_sf_exclude_root(self):
-        u"""Test simple exclude with / as the glob."""
-        self.assertEqual(self.exclude_glob_tester(u"/.git", u"/"), 0)
-        self.assertEqual(self.exclude_glob_tester(u"/testfile", u"/"), 0)
+        """Test simple exclude with / as the glob."""
+        self.assertEqual(self.exclude_glob_tester("/.git", "/"), 0)
+        self.assertEqual(self.exclude_glob_tester("/testfile", "/"), 0)
 
     def test_glob_get_sf_2(self):
-        u"""Test same behaviour as the functional test test_globbing_replacement."""
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/3/3sub3/3sub3sub2/3sub3sub2_file.txt",
-                                                  u"/testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt"), 1)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/3/3sub1", u"/testfiles/select2/*/3s*1"), 1)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/2/2sub1/2sub1sub3",
-                                                  u"/testfiles/select2/**/2sub1sub3"), 1)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/2/2sub1",
-                                                  u"/testfiles/sel[w,u,e,q]ct2/2/2s?b1"), 1)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/1/1sub3/1sub3sub2",
-                                                  u"/testfiles/select2/1/1sub3/1s[w,u,p,q]b3sub2"), 1)
-        self.assertEqual(self.exclude_glob_tester(u"/testfiles/select2/1/1sub3/1sub3sub1",
-                                                  u"/testfiles/select2/1/1sub[1-4]/1sub3sub1"), 0)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/1/1sub2/1sub2sub1",
-                                                  u"/testfiles/select2/*/1sub2/1s[w,u,p,q]b2sub1"), 1)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/1/1sub1/1sub1sub3/1sub1sub3_file.txt",
-                                                  u"/testfiles/select2/1/1sub1/1sub1sub3/1su?1sub3_file.txt"), 1)
-        self.assertEqual(self.exclude_glob_tester(u"/testfiles/select2/1/1sub1/1sub1sub2",
-                                                  u"/testfiles/select2/1/1*1/1sub1sub2"), 0)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/1/1sub2", u"/testfiles/select2/1/1sub2"), 1)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/1.py", u"/testfiles/select[2-4]/*.py"), 1)
-        self.assertEqual(self.exclude_glob_tester(u"/testfiles/select2/3", u"/testfiles/*2/3"), 0)
-        self.assertEqual(self.include_glob_tester(u"/testfiles/select2/1", u"**/select2/1"), 1)
+        """Test same behaviour as the functional test test_globbing_replacement."""
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/3/3sub3/3sub3sub2/3sub3sub2_file.txt",
+                                                  "/testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt"), 1)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/3/3sub1", "/testfiles/select2/*/3s*1"), 1)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/2/2sub1/2sub1sub3",
+                                                  "/testfiles/select2/**/2sub1sub3"), 1)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/2/2sub1",
+                                                  "/testfiles/sel[w,u,e,q]ct2/2/2s?b1"), 1)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/1/1sub3/1sub3sub2",
+                                                  "/testfiles/select2/1/1sub3/1s[w,u,p,q]b3sub2"), 1)
+        self.assertEqual(self.exclude_glob_tester("/testfiles/select2/1/1sub3/1sub3sub1",
+                                                  "/testfiles/select2/1/1sub[1-4]/1sub3sub1"), 0)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/1/1sub2/1sub2sub1",
+                                                  "/testfiles/select2/*/1sub2/1s[w,u,p,q]b2sub1"), 1)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/1/1sub1/1sub1sub3/1sub1sub3_file.txt",
+                                                  "/testfiles/select2/1/1sub1/1sub1sub3/1su?1sub3_file.txt"), 1)
+        self.assertEqual(self.exclude_glob_tester("/testfiles/select2/1/1sub1/1sub1sub2",
+                                                  "/testfiles/select2/1/1*1/1sub1sub2"), 0)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/1/1sub2", "/testfiles/select2/1/1sub2"), 1)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/1.py", "/testfiles/select[2-4]/*.py"), 1)
+        self.assertEqual(self.exclude_glob_tester("/testfiles/select2/3", "/testfiles/*2/3"), 0)
+        self.assertEqual(self.include_glob_tester("/testfiles/select2/1", "**/select2/1"), 1)
 
     def test_glob_get_sf_negative_square_brackets_specified(self):
-        u"""Test negative square bracket (specified) [!a,b,c] replacement in get_normal_sf."""
+        """Test negative square bracket (specified) [!a,b,c] replacement in get_normal_sf."""
         # As in a normal shell, [!...] expands to any single character but those specified
-        self.assertEqual(self.include_glob_tester(u"/test/hello1.txt", u"/test/hello[!2,3,4].txt"), 1)
-        self.assertEqual(self.include_glob_tester(u"/test/hello.txt", u"/t[!w,f,h]st/hello.txt"), 1)
-        self.assertEqual(self.exclude_glob_tester(u"/long/example/path/hello.txt",
-                                                  u"/lon[!w,e,f]/e[!p]ample/path/hello.txt"), 0)
-        self.assertEqual(self.include_glob_tester(u"/test/hello1.txt", u"/test/hello[!2,1,3,4].txt"), None)
-        self.assertEqual(self.include_glob_tester(u"/test/hello.txt", u"/t[!e,f,h]st/hello.txt"), None)
-        self.assertEqual(self.exclude_glob_tester(u"/long/example/path/hello.txt",
-                                                  u"/lon[!w,e,g,f]/e[!p,x]ample/path/hello.txt"), None)
+        self.assertEqual(self.include_glob_tester("/test/hello1.txt", "/test/hello[!2,3,4].txt"), 1)
+        self.assertEqual(self.include_glob_tester("/test/hello.txt", "/t[!w,f,h]st/hello.txt"), 1)
+        self.assertEqual(self.exclude_glob_tester("/long/example/path/hello.txt",
+                                                  "/lon[!w,e,f]/e[!p]ample/path/hello.txt"), 0)
+        self.assertEqual(self.include_glob_tester("/test/hello1.txt", "/test/hello[!2,1,3,4].txt"), None)
+        self.assertEqual(self.include_glob_tester("/test/hello.txt", "/t[!e,f,h]st/hello.txt"), None)
+        self.assertEqual(self.exclude_glob_tester("/long/example/path/hello.txt",
+                                                  "/lon[!w,e,g,f]/e[!p,x]ample/path/hello.txt"), None)
 
     def test_glob_get_sf_negative_square_brackets_range(self):
-        u"""Test negative square bracket (range) [!a,b,c] replacement in get_normal_sf."""
+        """Test negative square bracket (range) [!a,b,c] replacement in get_normal_sf."""
         # As in a normal shell, [!1-5] or [!a-f] expands to any single character not in the range specified
-        self.assertEqual(self.include_glob_tester(u"/test/hello1.txt", u"/test/hello[!2-4].txt"), 1)
-        self.assertEqual(self.include_glob_tester(u"/test/hello.txt", u"/t[!f-h]st/hello.txt"), 1)
-        self.assertEqual(self.exclude_glob_tester(u"/long/example/path/hello.txt",
-                                                  u"/lon[!w,e,f]/e[!p-s]ample/path/hello.txt"), 0)
-        self.assertEqual(self.include_glob_tester(u"/test/hello1.txt", u"/test/hello[!1-4].txt"), None)
-        self.assertEqual(self.include_glob_tester(u"/test/hello.txt", u"/t[!b-h]st/hello.txt"), None)
-        self.assertEqual(self.exclude_glob_tester(u"/long/example/path/hello.txt",
-                                                  u"/lon[!f-p]/e[!p]ample/path/hello.txt"), None)
+        self.assertEqual(self.include_glob_tester("/test/hello1.txt", "/test/hello[!2-4].txt"), 1)
+        self.assertEqual(self.include_glob_tester("/test/hello.txt", "/t[!f-h]st/hello.txt"), 1)
+        self.assertEqual(self.exclude_glob_tester("/long/example/path/hello.txt",
+                                                  "/lon[!w,e,f]/e[!p-s]ample/path/hello.txt"), 0)
+        self.assertEqual(self.include_glob_tester("/test/hello1.txt", "/test/hello[!1-4].txt"), None)
+        self.assertEqual(self.include_glob_tester("/test/hello.txt", "/t[!b-h]st/hello.txt"), None)
+        self.assertEqual(self.exclude_glob_tester("/long/example/path/hello.txt",
+                                                  "/lon[!f-p]/e[!p]ample/path/hello.txt"), None)
 
     def test_glob_get_sf_2_ignorecase(self):
-        u"""Test same behaviour as the functional test test_globbing_replacement, ignorecase tests."""
-        self.assertEqual(self.include_glob_tester(u"testfiles/select2/2/2sub1",
-                                                  u"testfiles/sel[w,u,e,q]ct2/2/2S?b1",
-                                                  u"testfiles/select2", ignore_case=True), 1)
-        self.assertEqual(self.include_glob_tester(u"testfiles/select2/2/2sub1/2sub1sub2",
-                                                  u"testfiles/select2/2/2sub1/2Sub1Sub2",
-                                                  u"testfiles/select2", ignore_case=True), 1)
+        """Test same behaviour as the functional test test_globbing_replacement, ignorecase tests."""
+        self.assertEqual(self.include_glob_tester("testfiles/select2/2/2sub1",
+                                                  "testfiles/sel[w,u,e,q]ct2/2/2S?b1",
+                                                  "testfiles/select2", ignore_case=True), 1)
+        self.assertEqual(self.include_glob_tester("testfiles/select2/2/2sub1/2sub1sub2",
+                                                  "testfiles/select2/2/2sub1/2Sub1Sub2",
+                                                  "testfiles/select2", ignore_case=True), 1)
 
     def test_glob_get_sf_3_double_asterisks_dirs_to_scan(self):
-        u"""Test double asterisk (**) replacement in glob_get_sf with directories that should be scanned"""
+        """Test double asterisk (**) replacement in glob_get_sf with directories that should be scanned"""
         # The new special pattern, **, expands to any string of characters whether or not it contains "/".
-        self.assertEqual(self.include_glob_tester(u"/long/example/path", u"/**/hello.txt"), 2)
+        self.assertEqual(self.include_glob_tester("/long/example/path", "/**/hello.txt"), 2)
 
     def test_glob_get_sf_3_ignorecase(self):
-        u"""Test ignorecase in glob_get_sf"""
+        """Test ignorecase in glob_get_sf"""
         # If glob_get_sf() is invoked with ignore_case=True then any character
         # in the string can be replaced with an upper- or lowercase version of
         # itself (parsing the ignorecase: prefix is tested elsewhere).
-        self.assertEqual(self.include_glob_tester(u"testfiles/select2/2", u"testfiles/select2/2",
-                                                  u"testfiles/select2", ignore_case=True), 1)
-        self.assertEqual(self.include_glob_tester(u"testfiles/select2/2", u"testFiles/Select2/2",
-                                                  u"testfiles/select2", ignore_case=True), 1)
-        self.assertEqual(self.include_glob_tester(u"tEstfiles/seLect2/2", u"testFiles/Select2/2",
-                                                  u"testfiles/select2", ignore_case=True), 1)
-        self.assertEqual(self.include_glob_tester(u"TEstfiles/SeLect2/2", u"t?stFiles/S*ect2/2",
-                                                  u"testfiles/select2", ignore_case=True), 1)
-        self.assertEqual(self.include_glob_tester(u"TEstfiles/SeLect2/2", u"t?stFil**ect2/2",
-                                                  u"testfiles/select2", ignore_case=True), 1)
-        self.assertEqual(self.exclude_glob_tester(u"TEstfiles/SeLect2/2", u"t?stFiles/S*ect2/2",
-                                                  u"testfiles/select2", ignore_case=True), 0)
-        self.assertEqual(self.exclude_glob_tester(u"TEstFiles/SeLect2/2", u"t?stFile**ect2/2",
-                                                  u"testfiles/select2", ignore_case=True), 0)
+        self.assertEqual(self.include_glob_tester("testfiles/select2/2", "testfiles/select2/2",
+                                                  "testfiles/select2", ignore_case=True), 1)
+        self.assertEqual(self.include_glob_tester("testfiles/select2/2", "testFiles/Select2/2",
+                                                  "testfiles/select2", ignore_case=True), 1)
+        self.assertEqual(self.include_glob_tester("tEstfiles/seLect2/2", "testFiles/Select2/2",
+                                                  "testfiles/select2", ignore_case=True), 1)
+        self.assertEqual(self.include_glob_tester("TEstfiles/SeLect2/2", "t?stFiles/S*ect2/2",
+                                                  "testfiles/select2", ignore_case=True), 1)
+        self.assertEqual(self.include_glob_tester("TEstfiles/SeLect2/2", "t?stFil**ect2/2",
+                                                  "testfiles/select2", ignore_case=True), 1)
+        self.assertEqual(self.exclude_glob_tester("TEstfiles/SeLect2/2", "t?stFiles/S*ect2/2",
+                                                  "testfiles/select2", ignore_case=True), 0)
+        self.assertEqual(self.exclude_glob_tester("TEstFiles/SeLect2/2", "t?stFile**ect2/2",
+                                                  "testfiles/select2", ignore_case=True), 0)
 
     def test_glob_dirs_to_scan(self):
-        u"""Test parent directories are marked as needing to be scanned"""
-        with patch(u"duplicity.path.Path.isdir") as mock_isdir:
+        """Test parent directories are marked as needing to be scanned"""
+        with patch("duplicity.path.Path.isdir") as mock_isdir:
             mock_isdir.return_value = True
             self.assertEqual(
-                self.glob_tester(u"parent", u"parent/hello.txt", 1, u"parent", False), 2)
+                self.glob_tester("parent", "parent/hello.txt", 1, "parent", False), 2)
 
     def test_glob_dirs_to_scan_glob(self):
-        u"""Test parent directories are marked as needing to be scanned - globs"""
-        with patch(u"duplicity.path.Path.isdir") as mock_isdir:
+        """Test parent directories are marked as needing to be scanned - globs"""
+        with patch("duplicity.path.Path.isdir") as mock_isdir:
             mock_isdir.return_value = True
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/1", u"*/select/1/1", 1,
-                                 u"testfiles/select", False), 2)
+                self.glob_tester("testfiles/select/1", "*/select/1/1", 1,
+                                 "testfiles/select", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/1/2",
-                                 u"*/select/1/2/1", 1, u"testfiles/select", False), 2)
+                self.glob_tester("testfiles/select/1/2",
+                                 "*/select/1/2/1", 1, "testfiles/select", False), 2)
             self.assertEqual(
-                self.glob_tester(u"parent", u"parent/hel?o.txt", 1, u"parent", False), 2)
+                self.glob_tester("parent", "parent/hel?o.txt", 1, "parent", False), 2)
             self.assertEqual(
-                self.glob_tester(u"test/parent/folder",
-                                 u"test/par*t/folder/hello.txt", 1, u"test", False), 2)
+                self.glob_tester("test/parent/folder",
+                                 "test/par*t/folder/hello.txt", 1, "test", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/1/1",
-                                 u"**/1/2/1", 1, u"testfiles", False), 2)
+                self.glob_tester("testfiles/select/1/1",
+                                 "**/1/2/1", 1, "testfiles", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select2/3/3sub2",
-                                 u"testfiles/select2/3/**file.txt", 1,
-                                 u"testfiles", False), 2)
+                self.glob_tester("testfiles/select2/3/3sub2",
+                                 "testfiles/select2/3/**file.txt", 1,
+                                 "testfiles", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/1/2",
-                                 u"*/select/1/2/1", 1, u"testfiles", False), 2)
+                self.glob_tester("testfiles/select/1/2",
+                                 "*/select/1/2/1", 1, "testfiles", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/1",
-                                 u"testfiles/select**/2", 1, u"testfiles", False), 2)
+                self.glob_tester("testfiles/select/1",
+                                 "testfiles/select**/2", 1, "testfiles", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/efools",
-                                 u"testfiles/select/*foo*/p*", 1,
-                                 u"testfiles", False), 2)
+                self.glob_tester("testfiles/select/efools",
+                                 "testfiles/select/*foo*/p*", 1,
+                                 "testfiles", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/3",
-                                 u"testfiles/select/**2", 1, u"testfiles", False), 2)
+                self.glob_tester("testfiles/select/3",
+                                 "testfiles/select/**2", 1, "testfiles", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select2/1/1sub1/1sub1sub2",
-                                 u"testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt",
-                                 1, u"testfiles", False), 2)
+                self.glob_tester("testfiles/select2/1/1sub1/1sub1sub2",
+                                 "testfiles/select2/**/3sub3sub2/3sub3su?2_file.txt",
+                                 1, "testfiles", False), 2)
             self.assertEqual(
-                self.glob_tester(u"testfiles/select/1",
-                                 u"*/select/1/1", 1, u"testfiles", False), 2)
+                self.glob_tester("testfiles/select/1",
+                                 "*/select/1/1", 1, "testfiles", False), 2)
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/overrides/bin/ncftpls` & `duplicity-2.0.0rc0/testing/overrides/bin/ncftpls`

 * *Files 15% similar despite different names*

```diff
@@ -1,18 +1,17 @@
 #!/usr/bin/env python3
 
 from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
-from duplicity.backend import ParsedUrl
 import os
 import subprocess
 import sys
 
+from duplicity.backend import ParsedUrl
+
 if sys.argv[1] == '-v':
     print('blah 3.2.1')
     sys.exit(8)  # really, the backend expects 8 as the return
 
 for arg in sys.argv:
     if arg.startswith('DELE '):
         pu = ParsedUrl(sys.argv[-1])
```

### Comparing `duplicity-1.2.3.dev43/testing/__init__.py` & `duplicity-2.0.0rc0/testing/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -14,129 +14,121 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import gettext
 import os
 import platform
 import subprocess
 import sys
 import time
 import unittest
 
 from duplicity import backend
 from duplicity import config
 from duplicity import log
 from duplicity import util
 
-# util.start_debugger()
+gettext.install('duplicity', names=['ngettext'])
 
-if sys.version_info.major >= 3:
-    gettext.install(u'duplicity', names=[u'ngettext'])
-else:
-    gettext.install(u'duplicity', names=[u'ngettext'], unicode=True)  # pylint: disable=unexpected-keyword-arg
+log.setup()
+util.start_debugger()
 
 _testing_dir = os.path.dirname(os.path.abspath(__file__))
 _top_dir = os.path.dirname(_testing_dir)
-_overrides_dir = os.path.join(_testing_dir, u'overrides')
-_bin_dir = os.path.join(_testing_dir, u'overrides', u'bin')
+_overrides_dir = os.path.join(_testing_dir, 'overrides')
+_bin_dir = os.path.join(_testing_dir, 'overrides', 'bin')
 
-if platform.system().startswith(u'Darwin'):
+if platform.system().startswith('Darwin'):
     # Use temp space TMPDIR or from getconf, never /tmp
-    _runtest_dir = (os.environ.get(u"TMPDIR", None) or
-                    subprocess.check_output([u'getconf', u'DARWIN_USER_TEMP_DIR']))
-    _runtest_dir = os.fsdecode(_runtest_dir).rstrip().rstrip(u'/')
+    _runtest_dir = (os.environ.get("TMPDIR", None) or
+                    subprocess.check_output(['getconf', 'DARWIN_USER_TEMP_DIR']))
+    _runtest_dir = os.fsdecode(_runtest_dir).rstrip().rstrip('/')
+    if not os.path.exists(_runtest_dir):
+        os.makedirs(_runtest_dir)
 else:
     # be a little more flexible
-    _runtest_dir = os.getenv(u'TMPDIR', False) or os.getenv(u'TEMP', False) or u'/tmp'
+    _runtest_dir = os.getenv('TMPDIR', False) or os.getenv('TEMP', False) or '/tmp'
 
 if not os.path.exists(_runtest_dir):
     os.makedirs(_runtest_dir)
 
 # Adjust python path for duplicity and override modules
 sys.path = [_overrides_dir, _top_dir, _bin_dir] + sys.path
 
 # Also set PYTHONPATH for any subprocesses
-os.environ[u'PYTHONPATH'] = _overrides_dir + u":" + _top_dir + u":" + os.environ.get(u'PYTHONPATH', u'')
+os.environ['PYTHONPATH'] = f"{_overrides_dir}:{_top_dir}:{os.environ.get('PYTHONPATH', '')}"
 
 # And PATH for any subprocesses
-os.environ[u'PATH'] = _bin_dir + u":" + os.environ.get(u'PATH', u'')
+os.environ['PATH'] = f"{_bin_dir}:{os.environ.get('PATH', '')}"
 
 # Now set some variables that help standardize test behavior
-os.environ[u'LANG'] = u''
-os.environ[u'GNUPGHOME'] = os.path.join(_testing_dir, u'gnupg')
+os.environ['LANG'] = ''
+os.environ['GNUPGHOME'] = os.path.join(_testing_dir, 'gnupg')
 
 # bzr does not honor perms so fix the perms and avoid annoying error
-os.system(u"chmod 700 %s" % os.path.join(_testing_dir, u'gnupg'))
+os.system(f"chmod 700 {os.path.join(_testing_dir, 'gnupg')}")
 
 # Standardize time
-os.environ[u'TZ'] = u'US/Central'
+os.environ['TZ'] = 'US/Central'
 time.tzset()
 
-# TODO: find place in setup.py to do this
-# fix shebangs in _bin_dir to be current python
-if sys.version_info.major == 2:
-    files = os.listdir(_bin_dir)
-    for file in files:
-        print(u"converting %s to python2" % file, file=sys.stderr)
-        with open(os.path.join(_bin_dir, file), u"r") as f:
-            p2 = f.read().replace(u"python3", u"python")
-        with open(os.path.join(_bin_dir, file), u"w") as f:
-            p2 = f.write(p2)
-
 
 class DuplicityTestCase(unittest.TestCase):
 
-    sign_key = u'839E6A2856538CCF'
-    sign_passphrase = u'test'
-    encrypt_key1 = u'839E6A2856538CCF'
-    encrypt_key2 = u'453005CE9B736B2A'
+    sign_key = '839E6A2856538CCF'
+    sign_passphrase = 'test'
+    encrypt_key1 = '839E6A2856538CCF'
+    encrypt_key2 = '453005CE9B736B2A'
 
     def setUp(self):
-        super(DuplicityTestCase, self).setUp()
+        super().setUp()
         self.savedEnviron = {}
         self.savedConfig = {}
 
         log.setup()
         log.setverbosity(log.WARNING)
-        self.set_config(u'print_statistics', 0)
+        self.set_config('print_statistics', 0)
         backend.import_backends()
 
         self.remove_testfiles()
         self.unpack_testfiles()
 
+        self.set_environ("TZ", "UTC")
+        time.tzset()
+        assert time.tzname[0] == "UTC", f"{time.tzname[0]} should be 'UTC'"
+
         # Have all file references in tests relative to our runtest dir
         os.chdir(_runtest_dir)
 
     def tearDown(self):
         for key in self.savedEnviron:
             self._update_env(key, self.savedEnviron[key])
 
         for key in self.savedConfig:
             setattr(config, key, self.savedConfig[key])
 
+        time.tzset()
+
         self.remove_testfiles()
 
         os.chdir(_testing_dir)
-        super(DuplicityTestCase, self).tearDown()
+        super().tearDown()
 
     def unpack_testfiles(self):
-        assert not os.system(u"rm -rf {0}/testfiles".format(_runtest_dir))
-        assert not os.system(u"tar xzf {0}/testfiles.tar.gz -C {1} > /dev/null 2>&1".format(_testing_dir, _runtest_dir))
-        assert not os.system(u"mkdir {0}/testfiles/output {0}/testfiles/cache".format(_runtest_dir))
+        assert not os.system(f"rm -rf {_runtest_dir}/testfiles")
+        assert not os.system(f"tar xzf {_testing_dir}/testfiles.tar.gz -C {_runtest_dir} > /dev/null 2>&1")
+        assert not os.system(f"mkdir {_runtest_dir}/testfiles/output {_runtest_dir}/testfiles/cache")
 
     def remove_testfiles(self):
-        assert not os.system(u"rm -rf {0}/testfiles".format(_runtest_dir))
+        assert not os.system(f"rm -rf {_runtest_dir}/testfiles")
 
     def _update_env(self, key, value):
         if value is not None:
             os.environ[key] = value
         elif key in os.environ:
             del os.environ[key]
```

### Comparing `duplicity-1.2.3.dev43/testing/run-tests` & `duplicity-2.0.0rc0/testing/run-tests`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/testing/functional/test_log.py` & `duplicity-2.0.0rc0/testing/functional/test_log.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,67 +14,62 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
-import unittest
 import os
+import unittest
 
-from . import FunctionalTestCase
-from testing import _top_dir
 from testing import _runtest_dir
+from testing import _top_dir
+from . import FunctionalTestCase
 
 
 class LogTest(FunctionalTestCase):
-    u"""Test machine-readable functions/classes in log.py"""
+    """Test machine-readable functions/classes in log.py"""
 
-    logfile = u"{0}/duplicity.log".format(_runtest_dir)
+    logfile = f"{_runtest_dir}/duplicity.log"
 
     def setUp(self):
-        super(LogTest, self).setUp()
-        assert not os.system(u"rm -f {0}".format(self.logfile))
+        super().setUp()
+        assert not os.system(f"rm -f {self.logfile}")
 
     def tearDown(self):
-        super(LogTest, self).tearDown()
-        assert not os.system(u"rm -f {0}".format(self.logfile))
+        super().tearDown()
+        assert not os.system(f"rm -f {self.logfile}")
 
     def test_command_line_error(self):
-        u"""Check notification of a simple error code"""
+        """Check notification of a simple error code"""
 
-        # Run actual duplicity command (will fail, because no arguments passed)
-        basepython = os.environ.get(u'TOXPYTHON', None)
+        # Run actual duplicity command (will fail because bad dirs passed)
+        cmd = f"{_top_dir}/bin/duplicity --log-file={self.logfile} full testing baddir >/dev/null 2>&1"
+        basepython = os.environ.get('TOXPYTHON', None)
         if basepython is not None:
-            os.system(u"{0} {1}/bin/duplicity --log-file={2} >/dev/null 2>&1".format
-                      (basepython, _top_dir, self.logfile))
-        else:
-            os.system(u"{0}/bin/duplicity --log-file={1} >/dev/null 2>&1".format(
-                _top_dir, self.logfile))
+            cmd = f"{basepython} {cmd}"
+        os.system(cmd)
 
         # The format of the file should be:
-        # """ERROR 2
+        # """ERROR 23 CommandLineError
         # . Blah blah blah.
         # . Blah blah blah.
         #
         # """
-        f = open(self.logfile, u'r')
+        f = open(self.logfile, 'r')
         linecount = 0
         lastline = False
         for line in f:
             assert (not lastline)
             linecount += 1
             if linecount == 1:
-                assert (line == u"ERROR 2\n")
-            elif line[0] != u"\n":
+                assert (line == "ERROR 23 CommandLineError\n")
+            elif line[0] != "\n":
                 assert (line.startswith(r". "))
             else:
                 lastline = True
         assert lastline
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/functional/test_final.py` & `duplicity-2.0.0rc0/testing/functional/test_final.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,188 +15,179 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from builtins import range
-from future import standard_library
-standard_library.install_aliases()
 
 import os
 import pytest
 import unittest
 
 from duplicity import path
 from testing import _runtest_dir
 from . import CmdError, FunctionalTestCase
 
 
 class FinalTest(FunctionalTestCase):
-    u"""
+    """
     Test backup/restore using duplicity binary
     """
     def runtest(self, dirlist, backup_options=None, restore_options=None):
-        u"""Run backup/restore test on directories in dirlist"""
-        if restore_options is None:
-            restore_options = []
+        """Run backup/restore test on directories in dirlist"""
         if backup_options is None:
             backup_options = []
+        if restore_options is None:
+            restore_options = []
+
         assert len(dirlist) >= 1
 
+        backup_options += ["--allow-source-mismatch"]
+
         # Back up directories to local backend
         current_time = 100000
-        self.backup(u"full", dirlist[0], current_time=current_time,
+        self.backup("full", dirlist[0], current_time=current_time,
                     options=backup_options)
         for new_dir in dirlist[1:]:
             current_time += 100000
-            self.backup(u"inc", new_dir, current_time=current_time,
+            self.backup("inc", new_dir, current_time=current_time,
                         options=backup_options)
 
         # Restore each and compare them
         for i in range(len(dirlist)):
             dirname = dirlist[i]
             current_time = 100000 * (i + 1)
             self.restore(time=current_time, options=restore_options)
-            self.check_same(dirname, u"{0}/testfiles/restore_out".format(_runtest_dir))
+            self.check_same(dirname, f"{_runtest_dir}/testfiles/restore_out")
             self.verify(dirname,
                         time=current_time, options=restore_options)
 
     def check_same(self, filename1, filename2):
-        u"""Verify two filenames are the same"""
+        """Verify two filenames are the same"""
         path1, path2 = path.Path(filename1), path.Path(filename2)
         assert path1.compare_recursive(path2, verbose=1)
 
     @pytest.mark.slow
     def test_basic_cycle(self, backup_options=None, restore_options=None):
-        u"""Run backup/restore test on basic directories"""
+        """Run backup/restore test on basic directories"""
         if backup_options is None:
-            backup_options = []
+            backup_options = ["--no-encrypt", "--no-compress"]
         if restore_options is None:
-            restore_options = []
-        self.runtest([u"{0}/testfiles/dir1".format(_runtest_dir),
-                      u"{0}/testfiles/dir2".format(_runtest_dir),
-                      u"{0}/testfiles/dir3".format(_runtest_dir)],
+            restore_options = ["--no-encrypt", "--no-compress"]
+        self.runtest([f"{_runtest_dir}/testfiles/dir1",
+                      f"{_runtest_dir}/testfiles/dir2",
+                      f"{_runtest_dir}/testfiles/dir3"],
                      backup_options=backup_options,
                      restore_options=restore_options)
 
         # Test restoring various sub files
-        for filename, time, tfdir in [(u'symbolic_link', 99999, u'dir1'),
-                                      (u'directory_to_file', 100100, u'dir1'),
-                                      (u'directory_to_file', 200100, u'dir2'),
-                                      (u'largefile', 300000, u'dir3')]:
+        for filename, time, tfdir in [('symbolic_link', 99999, 'dir1'),
+                                      ('directory_to_file', 100100, 'dir1'),
+                                      ('directory_to_file', 200100, 'dir2'),
+                                      ('largefile', 300000, 'dir3')]:
             self.restore(filename, time, options=restore_options)
-            self.check_same(u'{0}/testfiles/{1}/{2}'.format(_runtest_dir, tfdir, filename),
-                            u'{0}/testfiles/restore_out'.format(_runtest_dir))
-            self.verify(u'{0}/testfiles/{1}/{2}'.format(_runtest_dir, tfdir, filename),
+            self.check_same(f'{_runtest_dir}/testfiles/{tfdir}/{filename}',
+                            f'{_runtest_dir}/testfiles/restore_out')
+            self.verify(f'{_runtest_dir}/testfiles/{tfdir}/{filename}',
                         file_to_verify=filename, time=time,
                         options=restore_options)
 
     @pytest.mark.slow
     def test_asym_cycle(self):
-        u"""Like test_basic_cycle but use asymmetric encryption and signing"""
-        backup_options = [u"--encrypt-key", self.encrypt_key1,
-                          u"--sign-key", self.sign_key]
-        restore_options = [u"--encrypt-key", self.encrypt_key1,
-                           u"--sign-key", self.sign_key]
+        """Like test_basic_cycle but use asymmetric encryption and signing"""
+        backup_options = ["--encrypt-key", self.encrypt_key1,
+                          "--sign-key", self.sign_key]
+        restore_options = ["--encrypt-key", self.encrypt_key1,
+                           "--sign-key", self.sign_key]
         self.test_basic_cycle(backup_options=backup_options,
                               restore_options=restore_options)
 
     @pytest.mark.slow
     def test_asym_with_hidden_recipient_cycle(self):
-        u"""Like test_basic_cycle but use asymmetric encryption (hiding key id) and signing"""
-        backup_options = [u"--hidden-encrypt-key", self.encrypt_key1,
-                          u"--sign-key", self.sign_key]
-        restore_options = [u"--hidden-encrypt-key", self.encrypt_key1,
-                           u"--sign-key", self.sign_key]
+        """Like test_basic_cycle but use asymmetric encryption (hiding key id) and signing"""
+        backup_options = ["--hidden-encrypt-key", self.encrypt_key1,
+                          "--sign-key", self.sign_key]
+        restore_options = ["--hidden-encrypt-key", self.encrypt_key1,
+                           "--sign-key", self.sign_key]
         self.test_basic_cycle(backup_options=backup_options,
                               restore_options=restore_options)
 
     def test_single_regfile(self):
-        u"""Test backing and restoring up a single regular file"""
-        self.runtest([u"{0}/testfiles/various_file_types/regular_file".format(_runtest_dir)])
+        """Test backing and restoring up a single regular file"""
+        self.runtest([f"{_runtest_dir}/testfiles/various_file_types/regular_file"])
 
     def test_empty_backup(self):
-        u"""Make sure backup works when no files change"""
-        self.backup(u"full", u"{0}/testfiles/empty_dir".format(_runtest_dir))
-        self.backup(u"inc", u"{0}/testfiles/empty_dir".format(_runtest_dir))
+        """Make sure backup works when no files change"""
+        self.backup("full", f"{_runtest_dir}/testfiles/empty_dir")
+        self.backup("inc", f"{_runtest_dir}/testfiles/empty_dir")
 
     @pytest.mark.slow
     def test_long_filenames(self):
-        u"""Test backing up a directory with long filenames in it"""
+        """Test backing up a directory with long filenames in it"""
         # Note that some versions of ecryptfs (at least through Ubuntu 11.10)
         # have a bug where they treat the max path segment length as 143
         # instead of 255.  So make sure that these segments don't break that.
-        lf_dir = path.Path(u"{0}/testfiles/long_filenames".format(_runtest_dir))
+        lf_dir = path.Path(f"{_runtest_dir}/testfiles/long_filenames")
         if lf_dir.exists():
             lf_dir.deltree()
         lf_dir.mkdir()
-        lf1 = lf_dir.append(u"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA")  # noqa
+        lf1 = lf_dir.append("AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA")  # noqa
         lf1.mkdir()
-        lf2 = lf1.append(u"BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB")  # noqa
+        lf2 = lf1.append("BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB")  # noqa
         lf2.mkdir()
-        lf3 = lf2.append(u"CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC")  # noqa
+        lf3 = lf2.append("CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC")  # noqa
         lf3.mkdir()
-        lf4 = lf3.append(u"DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD")  # noqa
+        lf4 = lf3.append("DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD")  # noqa
         lf4.touch()
-        lf4_1 = lf3.append(u"SYMLINK--------------------------------------------------------------------------------------------")  # noqa
-        os.symlink(u"SYMLINK-DESTINATION-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------", lf4_1.name)  # noqa
+        lf4_1 = lf3.append("SYMLINK--------------------------------------------------------------------------------------------")  # noqa
+        os.symlink("SYMLINK-DESTINATION-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------", lf4_1.name)  # noqa
         lf4_1.setdata()
         assert lf4_1.issym()
-        lf4_2 = lf3.append(u"DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD")  # noqa
-        fp = lf4_2.open(u"wb")
+        lf4_2 = lf3.append("DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD")  # noqa
+        fp = lf4_2.open("wb")
         fp.write(b"hello" * 1000)
         assert not fp.close()
 
-        self.runtest([u"{0}/testfiles/empty_dir".format(_runtest_dir), lf_dir.uc_name,
-                      u"{0}/testfiles/empty_dir".format(_runtest_dir), lf_dir.uc_name])
+        self.runtest([f"{_runtest_dir}/testfiles/empty_dir", lf_dir.uc_name,
+                      f"{_runtest_dir}/testfiles/empty_dir", lf_dir.uc_name])
 
     def test_empty_restore(self):
-        u"""Make sure error raised when restore doesn't match anything"""
-        self.backup(u"full", u"{0}/testfiles/dir1".format(_runtest_dir))
-        self.assertRaises(CmdError, self.restore, u"this_file_does_not_exist")
-        self.backup(u"inc", u"{0}/testfiles/empty_dir".format(_runtest_dir))
-        self.assertRaises(CmdError, self.restore, u"this_file_does_not_exist")
+        """Make sure error raised when restore doesn't match anything"""
+        self.backup("full", f"{_runtest_dir}/testfiles/dir1",
+                    options=["--allow-source-mismatch"])
+        self.assertRaises(CmdError, self.restore, "this_file_does_not_exist")
+        self.backup("inc", f"{_runtest_dir}/testfiles/empty_dir",
+                    options=["--allow-source-mismatch"])
+        self.assertRaises(CmdError, self.restore, "this_file_does_not_exist")
 
     @pytest.mark.slow
     def test_remove_older_than(self):
-        u"""Test removing old backup chains"""
-        first_chain = self.backup(u"full", u"{0}/testfiles/dir1".format(_runtest_dir), current_time=10000)
-        first_chain |= self.backup(u"inc", u"{0}/testfiles/dir2".format(_runtest_dir), current_time=20000)
-        second_chain = self.backup(u"full", u"{0}/testfiles/dir1".format(_runtest_dir), current_time=30000)
-        second_chain |= self.backup(u"inc", u"{0}/testfiles/dir3".format(_runtest_dir), current_time=40000)
+        """Test removing old backup chains"""
+        first_chain = self.backup("full", f"{_runtest_dir}/testfiles/dir1", current_time=10000,
+                                  options=["--allow-source-mismatch"])
+        first_chain |= self.backup("inc", f"{_runtest_dir}/testfiles/dir2", current_time=20000,
+                                   options=["--allow-source-mismatch"])
+        second_chain = self.backup("full", f"{_runtest_dir}/testfiles/dir1", current_time=30000,
+                                   options=["--allow-source-mismatch"])
+        second_chain |= self.backup("inc", f"{_runtest_dir}/testfiles/dir3", current_time=40000,
+                                    options=["--allow-source-mismatch"])
 
         self.assertEqual(self.get_backend_files(), first_chain | second_chain)
 
-        self.run_duplicity(options=[u"remove-older-than", u"35000", u"--force", self.backend_url])
+        self.run_duplicity(options=["remove-older-than", "35000", "--force", self.backend_url])
         self.assertEqual(self.get_backend_files(), second_chain)
 
         # Now check to make sure we can't delete only chain
-        self.run_duplicity(options=[u"remove-older-than", u"50000", u"--force", self.backend_url])
+        self.run_duplicity(options=["remove-older-than", "50000", "--force", self.backend_url])
         self.assertEqual(self.get_backend_files(), second_chain)
 
     def test_piped_password(self):
-        u"""Make sure that prompting for a password works"""
-        self.set_environ(u"PASSPHRASE", None)
-        self.backup(u"full", u"{0}/testfiles/empty_dir".format(_runtest_dir),
+        """Make sure that prompting for a password works"""
+        self.set_environ("PASSPHRASE", None)
+        self.backup("full", f"{_runtest_dir}/testfiles/empty_dir",
                     passphrase_input=[self.sign_passphrase, self.sign_passphrase])
         self.restore(passphrase_input=[self.sign_passphrase])
 
 
-class OldFilenamesFinalTest(FinalTest):
-
-    def setUp(self):
-        super(OldFilenamesFinalTest, self).setUp()
-        self.class_args.extend([u"--old-filenames"])
-
-
-class ShortFilenamesFinalTest(FinalTest):
-
-    def setUp(self):
-        super(ShortFilenamesFinalTest, self).setUp()
-        self.class_args.extend([u"--short-filenames"])
-
-
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/functional/test_cleanup.py` & `duplicity-2.0.0rc0/testing/functional/test_cleanup.py`

 * *Files 23% similar despite different names*

```diff
@@ -15,68 +15,66 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
-import pytest
 import unittest
 
+import pytest
+
 from testing import _runtest_dir
 from . import FunctionalTestCase
 
 
 class CleanupTest(FunctionalTestCase):
-    u"""
+    """
     Test cleanup using duplicity binary
     """
     @pytest.mark.slow
     def test_cleanup_after_partial(self):
-        u"""
+        """
         Regression test for https://bugs.launchpad.net/bugs/409593
         where duplicity deletes all the signatures during a cleanup
         after a failed backup.
         """
         self.make_largefiles()
-        good_files = self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        good_files |= self.backup(u"inc", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        good_files |= self.backup(u"inc", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=1)
+        good_files = self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
+        good_files |= self.backup("inc", f"{_runtest_dir}/testfiles/largefiles")
+        good_files |= self.backup("inc", f"{_runtest_dir}/testfiles/largefiles")
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=1)
         bad_files = self.get_backend_files()
         bad_files -= good_files
         self.assertNotEqual(bad_files, set())
         # the cleanup should go OK
-        self.run_duplicity(options=[u"cleanup", self.backend_url, u"--force"])
+        self.run_duplicity(options=["cleanup", self.backend_url, "--force"])
         leftovers = self.get_backend_files()
         self.assertEqual(good_files, leftovers)
-        self.backup(u"inc", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("inc", f"{_runtest_dir}/testfiles/largefiles")
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
-    def test_remove_all_but_n(self):
-        u"""
+    def test_remove_all_but_n_full(self):
+        """
         Test that remove-all-but-n works in the simple case.
         """
-        full1_files = self.backup(u"full", u"{0}/testfiles/empty_dir".format(_runtest_dir))
-        full2_files = self.backup(u"full", u"{0}/testfiles/empty_dir".format(_runtest_dir))
-        self.run_duplicity(options=[u"remove-all-but-n", u"1", self.backend_url, u"--force"])
+        full1_files = self.backup("full", f"{_runtest_dir}/testfiles/empty_dir")
+        full2_files = self.backup("full", f"{_runtest_dir}/testfiles/empty_dir")
+        self.run_duplicity(options=["remove-all-but-n-full", "1", self.backend_url, "--force"])
         leftovers = self.get_backend_files()
         self.assertEqual(full2_files, leftovers)
 
-    def test_remove_all_inc_of_but_n(self):
-        u"""
+    def test_remove_all_inc_of_but_n_full(self):
+        """
         Test that remove-all-inc-of-but-n-full works in the simple case.
         """
-        full1_files = self.backup(u"full", u"{0}/testfiles/empty_dir".format(_runtest_dir))
-        inc1_files = self.backup(u"inc", u"{0}/testfiles/empty_dir".format(_runtest_dir))
-        full2_files = self.backup(u"full", u"{0}/testfiles/empty_dir".format(_runtest_dir))
-        self.run_duplicity(options=[u"remove-all-inc-of-but-n-full", u"1", self.backend_url, u"--force"])
+        full1_files = self.backup("full", f"{_runtest_dir}/testfiles/empty_dir")
+        inc1_files = self.backup("inc", f"{_runtest_dir}/testfiles/empty_dir")
+        full2_files = self.backup("full", f"{_runtest_dir}/testfiles/empty_dir")
+        self.run_duplicity(options=["remove-all-inc-of-but-n-full", "1", self.backend_url, "--force"])
         leftovers = self.get_backend_files()
         self.assertEqual(full1_files | full2_files, leftovers)
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/functional/__init__.py` & `duplicity-2.0.0rc0/testing/functional/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -14,173 +14,163 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from builtins import range
-from future import standard_library
-standard_library.install_aliases()
 
 import os
-import pexpect
 import platform
 import sys
 import time
 
+import pexpect
+
+from duplicity import config
 from duplicity import backend
-from duplicity import util
 from .. import DuplicityTestCase
-from .. import _top_dir
 from .. import _runtest_dir
-from pkg_resources import parse_version
+from .. import _top_dir
 
 
 class CmdError(Exception):
-    u"""Indicates an error running an external command"""
+    """Indicates an error running an external command"""
     def __init__(self, code):
         Exception.__init__(self, code)
         self.exit_status = code
 
 
 class FunctionalTestCase(DuplicityTestCase):
 
     _setsid_w = None
 
     @classmethod
     def _check_setsid(cls):
         if cls._setsid_w is not None:
             return
-        if platform.platform().startswith(u'Linux'):
+        if platform.platform().startswith('Linux'):
             # setsid behavior differs between distributions.
             # If setsid supports -w ("wait"), use it.
             import subprocess
             try:
-                with open(u"/dev/null", u"w") as sink:
-                    subprocess.check_call([u"setsid", u"-w", u"ls"], stdout=sink, stderr=sink)
+                with open("/dev/null", "w") as sink:
+                    subprocess.check_call(["setsid", "-w", "ls"], stdout=sink, stderr=sink)
             except subprocess.CalledProcessError:
                 cls._setsid_w = False
             else:
                 cls._setsid_w = True
 
     def setUp(self):
-        super(FunctionalTestCase, self).setUp()
+        super().setUp()
 
         self.unpack_testfiles()
 
         self.class_args = []
-        self.backend_url = u"file://{0}/testfiles/output".format(_runtest_dir)
+        self.backend_url = f"file://{_runtest_dir}/testfiles/output"
         self.last_backup = None
-        self.set_environ(u'PASSPHRASE', self.sign_passphrase)
-        self.set_environ(u"SIGN_PASSPHRASE", self.sign_passphrase)
+        self.set_environ('PASSPHRASE', self.sign_passphrase)
+        self.set_environ("SIGN_PASSPHRASE", self.sign_passphrase)
 
         backend_inst = backend.get_backend(self.backend_url)
         bl = backend_inst.list()
         if bl:
             backend_inst.delete(backend_inst.list())
         backend_inst.close()
         self._check_setsid()
 
-    def run_duplicity(self, options=[], current_time=None, fail=None,
-                      passphrase_input=[]):
-        u"""
+    def run_duplicity(self, options=None, current_time=None, fail=None,
+                      passphrase_input=None):
+        """
         Run duplicity binary with given arguments and options
         """
         # We run under setsid and take input from /dev/null (below) because
         # this way we force a failure if duplicity tries to read from the
         # console unexpectedly (like for gpg password or such).
 
         # Check all string inputs are unicode -- we will convert to system encoding before running the command
-        for item in options:
-            if sys.version_info.major == 2:
-                assert not isinstance(item, str), u"item " + unicode(item) + u" in options is not unicode"
+        if options is None:
+            options = []
+        if passphrase_input is None:
+            passphrase_input = []
 
         for item in passphrase_input:
-            assert isinstance(item, u"".__class__), u"item " + unicode(item) + u" in passphrase_input is not unicode"
+            assert isinstance(item, "".__class__), f"item {os.fsdecode(item)} in passphrase_input is not unicode"
 
-        if platform.platform().startswith(u'Linux'):
-            cmd_list = [u'setsid']
+        if platform.platform().startswith('Linux'):
+            cmd_list = ['setsid']
             if self._setsid_w:
-                cmd_list.extend([u"-w"])
+                cmd_list.extend(["-w"])
         else:
             cmd_list = []
-        basepython = os.environ.get(u'TOXPYTHON', None)
-        if basepython is not None:
-            cmd_list.extend([basepython])
-        run_coverage = os.environ.get(u'RUN_COVERAGE', None)
-        if run_coverage is not None:
-            cmd_list.extend([u"-m", u"coverage", u"run", u"--source=duplicity", u"-p"])
-        cmd_list.extend([u"{0}/bin/duplicity".format(_top_dir)])
+
+        if basepython := os.environ.get('TOXPYTHON', None):
+            cmd_list.extend([basepython, '-bb'])
+        else:
+            cmd_list.extend(["python3", '-bb'])
+
+        if run_coverage := os.environ.get('RUN_COVERAGE', None):
+            cmd_list.extend(["-m", "coverage", "run", "--source=duplicity", "-p"])
+
+        cmd_list.extend([f"{_top_dir}/bin/duplicity"])
         cmd_list.extend(options)
-        cmd_list.extend([u"-v0"])
-        cmd_list.extend([u"--no-print-statistics"])
-        cmd_list.extend([u"--allow-source-mismatch"])
-        cmd_list.extend([u"--archive-dir={0}/testfiles/cache".format(_runtest_dir)])
+
+        if run_debugger := os.environ.get("PYDEVD", None):
+            cmd_list.extend(["--pydevd"])
+
+        cmd_list.extend(["-v0"])
+        cmd_list.extend(["--no-print-statistics"])
+        cmd_list.extend([f"--archive-dir={_runtest_dir}/testfiles/cache"])
+
         if current_time:
-            cmd_list.extend([u"--current-time", current_time])
+            cmd_list.extend(["--current-time", current_time])
+
         cmd_list.extend(self.class_args)
+
         if fail:
-            cmd_list.extend([u"--fail", u"".__class__(fail)])
-        cmdline = u" ".join([u'"%s"' % x for x in cmd_list])
+            cmd_list.extend(["--fail", "".__class__(fail)])
+
+        cmdline = " ".join([f'"{x}"' for x in cmd_list])
 
         if not passphrase_input:
-            cmdline += u" < /dev/null"
+            cmdline += " < /dev/null"
 
-        # The immediately following block is the nicer way to execute pexpect with
-        # unicode strings, but we need to have the pre-4.0 version for some time yet,
-        # so for now this is commented out so tests execute the same way on all systems.
-
-        # if parse_version(pexpect.__version__) >= parse_version("4.0"):
-        #     # pexpect.spawn only supports unicode from version 4.0
-        #     # there was a separate pexpect.spawnu in 3.x, but it has an error on readline
-        #     child = pexpect.spawn(u'/bin/sh', [u'-c', cmdline], timeout=None, encoding=sys.getfilesystemencoding())
-        #
-        #     for passphrase in passphrase_input:
-        #         child.expect(u'passphrase.*:')
-        #         child.sendline(passphrase)
-        # else:
-
-        # Manually encode to filesystem encoding and send to spawn as bytes
-        # ToDo: Remove this once we no longer have to support systems with pexpect < 4.0
-        if sys.version_info.major > 2:
-            child = pexpect.spawn(u'/bin/sh', [u'-c', cmdline], timeout=None)
-        else:
-            child = pexpect.spawn(b'/bin/sh', [b'-c', cmdline.encode(sys.getfilesystemencoding(),
-                                                                     u'replace')], timeout=None)
+        # Set encoding to filesystem encoding and send to spawn
+        child = pexpect.spawn('/bin/sh', ['-c', cmdline], timeout=None, encoding=config.fsencoding)
 
         for passphrase in passphrase_input:
-            child.expect(b'passphrase.*:')
+            child.expect('passphrase.*:')
             child.sendline(passphrase)
 
         # if the command fails, we need to clear its output
         # so it will terminate cleanly.
         child.expect_exact(pexpect.EOF)
         lines = child.before.splitlines()
         child.wait()
         child.ptyproc.delayafterclose = 0.0
         return_val = child.exitstatus
 
         if fail:
             self.assertEqual(30, return_val)
         elif return_val:
-            print(u"\n...command:", cmdline, file=sys.stderr)
-            print(u"...cwd:", os.getcwd(), file=sys.stderr)
-            print(u"...output:", file=sys.stderr)
+            print("\n...command:", cmdline, file=sys.stderr)
+            print("...cwd:", os.getcwd(), file=sys.stderr)
+            print("...output:", file=sys.stderr)
             for line in lines:
                 line = line.rstrip()
                 if line:
-                    print(line, file=sys.stderr)
-            print(u"...return_val:", return_val, file=sys.stderr)
+                    print(os.fsdecode(line), file=sys.stderr)
+            print("...return_val:", return_val, file=sys.stderr)
             raise CmdError(return_val)
 
-    def backup(self, type, input_dir, options=[], **kwargs):  # pylint: disable=redefined-builtin
-        u"""Run duplicity backup to default directory"""
-        options = [type, input_dir, self.backend_url, u"--volsize", u"1"] + options
+    def backup(self, type, input_dir, options=None, **kwargs):  # pylint: disable=redefined-builtin
+        """Run duplicity backup to default directory"""
+        if options is None:
+            options = []
+        options = [type, input_dir, self.backend_url, "--volsize", "1"] + options
         before_files = self.get_backend_files()
 
         # If a chain ends with time X and the next full chain begins at time X,
         # we may trigger an assert in dup_collections.py.  If needed, sleep to
         # avoid such problems
         now = time.time()
         if self.last_backup == int(now):
@@ -188,48 +178,54 @@
 
         self.run_duplicity(options=options, **kwargs)
         self.last_backup = int(time.time())
 
         after_files = self.get_backend_files()
         return after_files - before_files
 
-    def restore(self, file_to_restore=None, time=None, options=[], **kwargs):
-        assert not os.system(u"rm -rf {0}/testfiles/restore_out".format(_runtest_dir))
-        options = [self.backend_url, u"{0}/testfiles/restore_out".format(_runtest_dir)] + options
+    def restore(self, file_to_restore=None, time=None, options=None, **kwargs):
+        if options is None:
+            options = []
+        assert not os.system(f"rm -rf {_runtest_dir}/testfiles/restore_out")
+        options = ["restore", self.backend_url, f"{_runtest_dir}/testfiles/restore_out"] + options
         if file_to_restore:
-            options.extend([u'--file-to-restore', file_to_restore])
+            options.extend(['--path-to-restore', file_to_restore])
         if time:
-            options.extend([u'--restore-time', u"".__class__(time)])
+            options.extend(['--restore-time', "".__class__(time)])
         self.run_duplicity(options=options, **kwargs)
 
-    def verify(self, dirname, file_to_verify=None, time=None, options=[],
+    def verify(self, dirname, file_to_verify=None, time=None, options=None,
                **kwargs):
-        options = [u"verify", self.backend_url, dirname] + options
+        if options is None:
+            options = []
+        options = ["verify", self.backend_url, dirname] + options
         if file_to_verify:
-            options.extend([u'--file-to-restore', file_to_verify])
+            options.extend(['--path-to-restore', file_to_verify])
         if time:
-            options.extend([u'--restore-time', u"".__class__(time)])
+            options.extend(['--restore-time', "".__class__(time)])
         self.run_duplicity(options=options, **kwargs)
 
-    def cleanup(self, options=[]):
-        u"""
+    def cleanup(self, options=None):
+        """
         Run duplicity cleanup to default directory
         """
-        options = [u"cleanup", self.backend_url, u"--force"] + options
+        if options is None:
+            options = []
+        options = ["cleanup", self.backend_url, "--force"] + options
         self.run_duplicity(options=options)
 
     def get_backend_files(self):
         backend_inst = backend.get_backend(self.backend_url)
         bl = backend_inst.list()
         backend_inst.close()
         return set(bl)
 
     def make_largefiles(self, count=3, size=2):
-        u"""
+        """
         Makes a number of large files in /tmp/testfiles/largefiles that each are
         the specified number of megabytes.
         """
-        assert not os.system(u"mkdir {0}/testfiles/largefiles".format(_runtest_dir))
+        assert not os.system(f"mkdir {_runtest_dir}/testfiles/largefiles")
         for n in range(count):
             assert not os.system(
-                u"dd if=/dev/urandom of={0}/testfiles/largefiles/file{1} bs=1024 count={2} > /dev/null 2>&1".format(
-                    _runtest_dir, n + 1, size * 1024))
+                f"dd if=/dev/urandom of={_runtest_dir}/testfiles/largefiles/file{n+1} "
+                f"bs=1024 count={size*1024} > /dev/null 2>&1")
```

### Comparing `duplicity-1.2.3.dev43/testing/functional/test_restart.py` & `duplicity-2.0.0rc0/testing/functional/test_restart.py`

 * *Files 24% similar despite different names*

```diff
@@ -15,381 +15,374 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
 
 import glob
 import os
 import platform
 import subprocess
-import sys
-import pytest
 import unittest
 
+import pytest
+
+from duplicity import config
 from testing import _runtest_dir
 from . import FunctionalTestCase
 
 
 class RestartTest(FunctionalTestCase):
-    u"""
+    """
     Test checkpoint/restart using duplicity binary
     """
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_basic_checkpoint_restart(self):
-        u"""
+        """
         Test basic Checkpoint/Restart
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=1)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=1)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
     @pytest.mark.slow
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_multiple_checkpoint_restart(self):
-        u"""
+        """
         Test multiple Checkpoint/Restart
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=1)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=2)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=3)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=1)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=2)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=3)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_first_volume_failure(self):
-        u"""
+        """
         Test restart when no volumes are available on the remote.
         Caused when duplicity fails before the first transfer.
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=1)
-        assert not os.system(u"rm {0}/testfiles/output/duplicity-full*difftar*".format(_runtest_dir))
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=1)
+        assert not os.system(f"rm {_runtest_dir}/testfiles/output/duplicity-full*difftar*")
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_multi_volume_failure(self):
-        u"""
+        """
         Test restart when fewer volumes are available on the remote
         than the local manifest has on record.  Caused when duplicity
         fails the last queued transfer(s).
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=3)
-        assert not os.system(u"rm {0}/testfiles/output/duplicity-full*vol[23].difftar*".format(_runtest_dir))
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=3)
+        assert not os.system(f"rm {_runtest_dir}/testfiles/output/duplicity-full*vol[23].difftar*")
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_restart_encrypt_without_password(self):
-        u"""
+        """
         Test that we can successfully restart a encrypt-key-only backup without
         providing a password for it. (Normally, we'd need to decrypt the first
         volume, but there is special code to skip that with an encrypt key.)
         """
-        self.set_environ(u'PASSPHRASE', None)
-        self.set_environ(u'SIGN_PASSPHRASE', None)
+        self.set_environ('PASSPHRASE', None)
+        self.set_environ('SIGN_PASSPHRASE', None)
         self.make_largefiles()
-        enc_opts = [u"--encrypt-key", self.encrypt_key1]
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), options=enc_opts, fail=2)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), options=enc_opts)
+        enc_opts = ["--encrypt-key", self.encrypt_key1]
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", options=enc_opts, fail=2)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", options=enc_opts)
 
-        self.set_environ(u'PASSPHRASE', self.sign_passphrase)
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.set_environ('PASSPHRASE', self.sign_passphrase)
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_restart_sign_and_encrypt(self):
-        u"""
+        """
         Test restarting a backup using same key for sign and encrypt
         https://bugs.launchpad.net/duplicity/+bug/946988
         """
         self.make_largefiles()
-        enc_opts = [u"--sign-key", self.sign_key, u"--encrypt-key", self.sign_key]
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), options=enc_opts, fail=2)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), options=enc_opts)
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        enc_opts = ["--sign-key", self.sign_key, "--encrypt-key", self.sign_key]
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", options=enc_opts, fail=2)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", options=enc_opts)
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_restart_sign_and_hidden_encrypt(self):
-        u"""
+        """
         Test restarting a backup using same key for sign and encrypt (hidden key id)
         https://bugs.launchpad.net/duplicity/+bug/946988
         """
         self.make_largefiles()
-        enc_opts = [u"--sign-key", self.sign_key, u"--hidden-encrypt-key", self.sign_key]
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), options=enc_opts, fail=2)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), options=enc_opts)
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        enc_opts = ["--sign-key", self.sign_key, "--hidden-encrypt-key", self.sign_key]
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", options=enc_opts, fail=2)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", options=enc_opts)
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
     def test_last_file_missing_in_middle(self):
-        u"""
+        """
         Test restart when the last file being backed up is missing on restart.
         Caused when the user deletes a file after a failure.  This test puts
         the file in the middle of the backup, with files following.
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=3)
-        assert not os.system(u"rm {0}/testfiles/largefiles/file2".format(_runtest_dir))
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=3)
+        assert not os.system(f"rm {_runtest_dir}/testfiles/largefiles/file2")
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
-    @unittest.skipIf(platform.machine() in [u"ppc64el", u"ppc64le"], u"Skip on ppc64el and ppc64le machines")
+    @unittest.skipIf(platform.machine() in ["ppc64el", "ppc64le"], "Skip on ppc64el and ppc64le machines")
     def test_last_file_missing_at_end(self):
-        u"""
+        """
         Test restart when the last file being backed up is missing on restart.
         Caused when the user deletes a file after a failure.  This test puts
         the file at the end of the backup, with no files following.
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=6)
-        assert not os.system(u"rm {0}/testfiles/largefiles/file3".format(_runtest_dir))
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=6)
+        assert not os.system(f"rm {_runtest_dir}/testfiles/largefiles/file3")
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
     @pytest.mark.slow
     def test_restart_incremental(self):
-        u"""
+        """
         Test restarting an incremental backup
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/dir1".format(_runtest_dir))
-        self.backup(u"inc", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=2)
-        self.backup(u"inc", u"{0}/testfiles/largefiles".format(_runtest_dir))
-        self.verify(u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/dir1",
+                    options=["--allow-source-mismatch"])
+        self.backup("inc", f"{_runtest_dir}/testfiles/largefiles", fail=2,
+                    options=["--allow-source-mismatch"])
+        self.backup("inc", f"{_runtest_dir}/testfiles/largefiles",
+                    options=["--allow-source-mismatch"])
+        self.verify(f"{_runtest_dir}/testfiles/largefiles")
 
     def make_fake_second_volume(self, name):
-        u"""
+        """
         Takes a successful backup and pretend that we interrupted a backup
         after two-volumes.  (This is because we want to be able to model
         restarting the second volume and duplicity deletes the last volume
         found because it may have not finished uploading.)
         """
         # First, confirm that we have signs of a successful backup
-        self.assertEqual(len(glob.glob(u"{0}/testfiles/output/*.manifest*".format(_runtest_dir))), 1)
-        self.assertEqual(len(glob.glob(u"{0}/testfiles/output/*.sigtar*".format(_runtest_dir))), 1)
-        self.assertEqual(len(glob.glob(u"{0}/testfiles/cache/{1}/*".format(_runtest_dir, name))), 2)
+        self.assertEqual(len(glob.glob(f"{_runtest_dir}/testfiles/output/*.manifest*")), 1)
+        self.assertEqual(len(glob.glob(f"{_runtest_dir}/testfiles/output/*.sigtar*")), 1)
+        self.assertEqual(len(glob.glob(f"{_runtest_dir}/testfiles/cache/{name}/*")), 2)
         self.assertEqual(len(glob.glob(
-            u"{0}/testfiles/cache/{1}/*.manifest*".format(_runtest_dir, name))), 1)
+            f"{_runtest_dir}/testfiles/cache/{name}/*.manifest*")), 1)
         self.assertEqual(len(glob.glob(
-            u"{0}/testfiles/cache/{1}/*.sigtar*".format(_runtest_dir, name))), 1)
+            f"{_runtest_dir}/testfiles/cache/{name}/*.sigtar*")), 1)
         # Alright, everything is in order; fake a second interrupted volume
-        assert not os.system(u"rm {0}/testfiles/output/*.manifest*".format(_runtest_dir))
-        assert not os.system(u"rm {0}/testfiles/output/*.sigtar*".format(_runtest_dir))
-        assert not os.system(u"rm -f {0}/testfiles/output/*.vol[23456789].*".format(_runtest_dir))
-        assert not os.system(u"rm -f {0}/testfiles/output/*.vol1[^.]+.*".format(_runtest_dir))
-        self.assertEqual(len(glob.glob(u"{0}/testfiles/output/*.difftar*".format(_runtest_dir))), 1)
-        assert not os.system(u"rm {0}/testfiles/cache/{1}/*.sigtar*".format(_runtest_dir, name))
-        assert not os.system(u"cp {0}/testfiles/output/*.difftar* ".format(_runtest_dir) +
-                             u"`ls {0}/testfiles/output/*.difftar* | ".format(_runtest_dir) +
-                             u" sed 's|vol1|vol2|'`")
-        assert not os.system(u"head -n6 {0}/testfiles/cache/{1}/*.manifest > ".format(_runtest_dir, name) +
-                             u"{0}/testfiles/cache/{1}/".format(_runtest_dir, name) +
-                             u"`basename {0}/testfiles/cache/{1}/*.manifest`".format(_runtest_dir, name) +
-                             u".part")
-        assert not os.system(u"rm {0}/testfiles/cache/{1}/*.manifest".format(_runtest_dir, name))
-        assert not os.system(u"""echo 'Volume 2:
+        assert not os.system(f"rm {_runtest_dir}/testfiles/output/*.manifest*")
+        assert not os.system(f"rm {_runtest_dir}/testfiles/output/*.sigtar*")
+        assert not os.system(f"rm -f {_runtest_dir}/testfiles/output/*.vol[23456789].*")
+        assert not os.system(f"rm -f {_runtest_dir}/testfiles/output/*.vol1[^.]+.*")
+        self.assertEqual(len(glob.glob(f"{_runtest_dir}/testfiles/output/*.difftar*")), 1)
+        assert not os.system(f"rm {_runtest_dir}/testfiles/cache/{name}/*.sigtar*")
+        assert not os.system(f"cp {_runtest_dir}/testfiles/output/*.difftar* " +
+                             f"`ls {_runtest_dir}/testfiles/output/*.difftar* | " +
+                             " sed 's|vol1|vol2|'`")
+        assert not os.system(f"head -n6 {_runtest_dir}/testfiles/cache/{name}/*.manifest > " +
+                             f"{_runtest_dir}/testfiles/cache/{name}/" +
+                             f"`basename {_runtest_dir}/testfiles/cache/{name}/*.manifest`" +
+                             ".part")
+        assert not os.system(f"rm {_runtest_dir}/testfiles/cache/{name}/*.manifest")
+        assert not os.system(f"""echo 'Volume 2:
     StartingPath   foo
     EndingPath     bar
-    Hash SHA1 sha1' >> {0}/testfiles/cache/{1}/*.manifest.part""".format(_runtest_dir, name))
+    Hash SHA1 sha1' >> {_runtest_dir}/testfiles/cache/{name}/*.manifest.part""")
 
     def test_split_after_small(self):
-        u"""
+        """
         If we restart right after a volume that ended with a small
         (one-block) file, make sure we restart in the right place.
         """
-        source = u'{0}/testfiles/largefiles'.format(_runtest_dir)
-        assert not os.system(u"mkdir -p %s" % source)
-        assert not os.system(u"echo hello > %s/file1" % source)
-        self.backup(u"full", source, options=[u"--name=backup1"])
+        source = f'{_runtest_dir}/testfiles/largefiles'
+        assert not os.system(f"mkdir -p {source}")
+        assert not os.system(f"echo hello > {source}/file1")
+        self.backup("full", source, options=["--name=backup1"])
         # Fake an interruption
-        self.make_fake_second_volume(u"backup1")
+        self.make_fake_second_volume("backup1")
         # Add new file
-        assert not os.system(u"cp %s/file1 %s/newfile" % (source, source))
+        assert not os.system(f"cp {source}/file1 {source}/newfile")
         # 'restart' the backup
-        self.backup(u"full", source, options=[u"--name=backup1"])
+        self.backup("full", source, options=["--name=backup1"])
         # Confirm we actually resumed the previous backup
-        self.assertEqual(len(os.listdir(u"{0}/testfiles/output".format(_runtest_dir))), 4)
+        self.assertEqual(len(os.listdir(f"{_runtest_dir}/testfiles/output")), 4)
         # Now make sure everything is byte-for-byte the same once restored
         self.restore()
-        assert not os.system(u"diff -r {1} {0}/testfiles/restore_out".format(_runtest_dir, source))
+        assert not os.system(f"diff -r {source} {_runtest_dir}/testfiles/restore_out")
 
     def test_split_after_large(self):
-        u"""
+        """
         If we restart right after a volume that ended with a large
         (multi-block) file, make sure we restart in the right place.
         """
-        source = u'{0}/testfiles/largefiles'.format(_runtest_dir)
+        source = f'{_runtest_dir}/testfiles/largefiles'
         self.make_largefiles(count=1, size=1)
-        self.backup(u"full", source, options=[u"--volsize=5", u"--name=backup1"])
+        self.backup("full", source, options=["--volsize=5", "--name=backup1"])
         # Fake an interruption
-        self.make_fake_second_volume(u"backup1")
+        self.make_fake_second_volume("backup1")
         # Add new file
-        assert not os.system(u"cp %s/file1 %s/newfile" % (source, source))
+        assert not os.system(f"cp {source}/file1 {source}/newfile")
         # 'restart' the backup
-        self.backup(u"full", source, options=[u"--volsize=5", u"--name=backup1"])
+        self.backup("full", source, options=["--volsize=5", "--name=backup1"])
         # Confirm we actually resumed the previous backup
-        self.assertEqual(len(os.listdir(u"{0}/testfiles/output".format(_runtest_dir))), 4)
+        self.assertEqual(len(os.listdir(f"{_runtest_dir}/testfiles/output")), 4)
         # Now make sure everything is byte-for-byte the same once restored
         self.restore()
-        assert not os.system(u"diff -r %s {0}/testfiles/restore_out".format(_runtest_dir) % source)
+        assert not os.system(f"diff -r %s {_runtest_dir}/testfiles/restore_out" % source)
 
     def test_split_inside_large(self):
-        u"""
+        """
         If we restart right after a volume that ended inside of a large
         (multi-block) file, make sure we restart in the right place.
         """
-        source = u'{0}/testfiles/largefiles'.format(_runtest_dir)
+        source = f'{_runtest_dir}/testfiles/largefiles'
         self.make_largefiles(count=1, size=3)
-        self.backup(u"full", source, options=[u"--name=backup1"])
+        self.backup("full", source, options=["--name=backup1"])
         # Fake an interruption
-        self.make_fake_second_volume(u"backup1")
+        self.make_fake_second_volume("backup1")
         # 'restart' the backup
-        self.backup(u"full", source, options=[u"--name=backup1"])
+        self.backup("full", source, options=["--name=backup1"])
         # Now make sure everything is byte-for-byte the same once restored
         self.restore()
-        assert not os.system(u"diff -r {0} {1}/testfiles/restore_out".format(source, _runtest_dir))
+        assert not os.system(f"diff -r {source} {_runtest_dir}/testfiles/restore_out")
 
     def test_new_file(self):
-        u"""
+        """
         If we restart right after a volume, but there are new files that would
         have been backed up earlier in the volume, make sure we don't wig out.
         (Expected result is to ignore new, ealier files, but pick up later
         ones.)
         """
-        source = u'{0}/testfiles/largefiles'.format(_runtest_dir)
+        source = f'{_runtest_dir}/testfiles/largefiles'
         self.make_largefiles(count=1, size=1)
-        self.backup(u"full", source, options=[u"--name=backup1"])
+        self.backup("full", source, options=["--name=backup1"])
         # Fake an interruption
-        self.make_fake_second_volume(u"backup1")
+        self.make_fake_second_volume("backup1")
         # Add new files, earlier and later in filename sort order
-        assert not os.system(u"echo hello > %s/a" % source)
-        assert not os.system(u"echo hello > %s/z" % source)
+        assert not os.system(f"echo hello > {source}/a")
+        assert not os.system(f"echo hello > {source}/z")
         # 'restart' the backup
-        self.backup(u"full", source, options=[u"--name=backup1"])
+        self.backup("full", source, options=["--name=backup1"])
         # Now make sure everything is the same once restored, except 'a'
         self.restore()
-        assert not os.system(u"test ! -e {0}/testfiles/restore_out/a".format(_runtest_dir))
-        assert not os.system(u"diff {0}/file1 {1}/testfiles/restore_out/file1".format(source, _runtest_dir))
-        assert not os.system(u"diff {0}/z {1}/testfiles/restore_out/z".format(source, _runtest_dir))
+        assert not os.system(f"test ! -e {_runtest_dir}/testfiles/restore_out/a")
+        assert not os.system(f"diff {source}/file1 {_runtest_dir}/testfiles/restore_out/file1")
+        assert not os.system(f"diff {source}/z {_runtest_dir}/testfiles/restore_out/z")
 
-    @unittest.skipIf(sys.version_info.major == 2, u"Skip on possible timing error")
     def test_changed_source_dangling_manifest_volume(self):
-        u"""
+        """
         If we restart but find remote volumes missing, we can easily end up
         with a manifest that lists "vol1, vol2, vol3, vol2", leaving a dangling
         vol3.  Make sure we can gracefully handle that.  This will only happen
         if the source data changes to be small enough to not create a vol3 on
         restart.
         """
-        source = u'{0}/testfiles/largefiles'.format(_runtest_dir)
+        source = f'{_runtest_dir}/testfiles/largefiles'
         self.make_largefiles(count=5, size=1)
-        self.backup(u"full", source, fail=3)
+        self.backup("full", source, fail=3)
         # now delete the last volume on remote end and some source files
-        assert not os.system(u"rm {0}/testfiles/output/duplicity-full*vol3.difftar*".format(_runtest_dir))
-        assert not os.system(u"rm %s/file[2345]" % source)
-        assert not os.system(u"echo hello > %s/z" % source)
+        assert not os.system(f"rm {_runtest_dir}/testfiles/output/duplicity-full*vol3.difftar*")
+        assert not os.system(f"rm {source}/file[2345]")
+        assert not os.system(f"echo hello > {source}/z")
         # finish backup
-        self.backup(u"full", source)
+        self.backup("full", source)
         # and verify we can restore
         self.restore()
 
     def test_changed_source_file_disappears(self):
-        u"""
+        """
         Make sure we correctly handle restarting a backup when a file
         disappears when we had been in the middle of backing it up.  It's
         possible that the first chunk of the next file will be skipped unless
         we're careful.
         """
-        source = u'{0}/testfiles/largefiles'.format(_runtest_dir)
+        source = f'{_runtest_dir}/testfiles/largefiles'
         self.make_largefiles(count=1)
-        self.backup(u"full", source, fail=2)
+        self.backup("full", source, fail=2)
         # now remove starting source data and make sure we add something after
-        assert not os.system(u"rm %s/*" % source)
-        assert not os.system(u"echo hello > %s/z" % source)
+        assert not os.system(f"rm {source}/*")
+        assert not os.system(f"echo hello > {source}/z")
         # finish backup
-        self.backup(u"full", source)
+        self.backup("full", source)
         # and verify we can restore
         self.restore()
-        assert not os.system(u"diff {0}/z {1}/testfiles/restore_out/z".format(source, _runtest_dir))
+        assert not os.system(f"diff {source}/z {_runtest_dir}/testfiles/restore_out/z")
 
 
 # Note that this class duplicates all the tests in RestartTest
 class RestartTestWithoutEncryption(RestartTest):
 
     def setUp(self):
-        super(RestartTestWithoutEncryption, self).setUp()
-        self.class_args.extend([u"--no-encryption"])
+        super().setUp()
+        self.class_args.extend(["--no-encryption"])
 
     def test_no_write_double_snapshot(self):
-        u"""
+        """
         Test that restarting a full backup does not write duplicate entries
         into the sigtar, causing problems reading it back in older
         versions.
         https://launchpad.net/bugs/929067
         """
         self.make_largefiles()
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir), fail=2)
-        self.backup(u"full", u"{0}/testfiles/largefiles".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles", fail=2)
+        self.backup("full", f"{_runtest_dir}/testfiles/largefiles")
         # Now check sigtar
-        sigtars = glob.glob(u"{0}/testfiles/output/duplicity-full*.sigtar.gz".format(_runtest_dir))
+        sigtars = glob.glob(f"{_runtest_dir}/testfiles/output/duplicity-full*.sigtar.gz")
         self.assertEqual(1, len(sigtars))
         sigtar = sigtars[0]
-        output = subprocess.Popen([u"tar", u"t", u"--file=%s" % sigtar], stdout=subprocess.PIPE).communicate()[0]
+        output = subprocess.Popen(["tar", "t", f"--file={sigtar}"], stdout=subprocess.PIPE).communicate()[0]
         self.assertEqual(1, output.split(b"\n").count(b"snapshot/"))
 
     def test_ignore_double_snapshot(self):
-        u"""
+        """
         Test that we gracefully ignore double snapshot entries in a signature
         file.  This winds its way through duplicity as a deleted base dir,
         which doesn't make sense and should be ignored.  An older version of
         duplicity accidentally created such files as a result of a restart.
         https://launchpad.net/bugs/929067
         """
 
-        if platform.system().startswith(u'Linux'):
-            tarcmd = u"tar"
-        elif platform.system().startswith(u'Darwin'):
-            tarcmd = u"gtar"
-        elif platform.system().endswith(u'BSD'):
-            tarcmd = u"gtar"
+        if platform.system().startswith('Linux'):
+            tarcmd = "tar"
+        elif platform.system().startswith('Darwin'):
+            tarcmd = "gtar"
+        elif platform.system().endswith('BSD'):
+            tarcmd = "gtar"
         else:
-            raise Exception(u"Platform %s not supported by tar/gtar." % platform.platform())
+            raise Exception(f"Platform {platform.platform()} not supported by tar/gtar.")
 
         # Intial normal backup
-        self.backup(u"full", u"{0}/testfiles/blocktartest".format(_runtest_dir))
+        self.backup("full", f"{_runtest_dir}/testfiles/blocktartest")
         # Create an exact clone of the snapshot folder in the sigtar already.
         # Permissions and mtime must match.
-        os.mkdir(u"{0}/testfiles/snapshot".format(_runtest_dir), 0o755)
-        os.utime(u"{0}/testfiles/snapshot".format(_runtest_dir), (1030384548, 1030384548))
+        os.mkdir(f"{_runtest_dir}/testfiles/snapshot", 0o755)
+        os.utime(f"{_runtest_dir}/testfiles/snapshot", (1030384548, 1030384548))
         # Adjust the sigtar.gz file to have a bogus second snapshot/ entry
         # at the beginning.
-        sigtars = glob.glob(u"{0}/testfiles/output/duplicity-full*.sigtar.gz".format(_runtest_dir))
+        sigtars = glob.glob(f"{_runtest_dir}/testfiles/output/duplicity-full*.sigtar.gz")
         self.assertEqual(1, len(sigtars))
         sigtar = sigtars[0]
-        self.assertEqual(0, os.system(u"{0} c --file={1}/testfiles/snapshot.sigtar -C {1}/testfiles snapshot".format(
-            tarcmd, _runtest_dir)))
-        self.assertEqual(0, os.system(u"gunzip -c {1} > {0}/testfiles/full.sigtar".format(_runtest_dir, sigtar)))
-        self.assertEqual(0, os.system(u"{0} A --file={1}/testfiles/snapshot.sigtar {1}/testfiles/full.sigtar".format(
-            tarcmd, _runtest_dir)))
-        self.assertEqual(0, os.system(u"gzip {0}/testfiles/snapshot.sigtar".format(_runtest_dir)))
+        self.assertEqual(0, os.system(f"{tarcmd} c --file={_runtest_dir}/testfiles/snapshot.sigtar "
+                                      f"-C {_runtest_dir}/testfiles snapshot"))
+        self.assertEqual(0, os.system(f"gunzip -c {sigtar} > {_runtest_dir}/testfiles/full.sigtar"))
+        self.assertEqual(0, os.system(f"{tarcmd} A --file={_runtest_dir}/testfiles/snapshot.sigtar "
+                                      f"{_runtest_dir}/testfiles/full.sigtar"))
+        self.assertEqual(0, os.system(f"gzip {_runtest_dir}/testfiles/snapshot.sigtar"))
         os.remove(sigtar)
-        os.rename(u"{0}/testfiles/snapshot.sigtar.gz".format(_runtest_dir), sigtar)
+        os.rename(f"{_runtest_dir}/testfiles/snapshot.sigtar.gz", sigtar)
         # Clear cache so our adjusted sigtar will be sync'd back into the cache
-        self.assertEqual(0, os.system(u"rm -r {0}/testfiles/cache".format(_runtest_dir)))
+        self.assertEqual(0, os.system(f"rm -r {_runtest_dir}/testfiles/cache"))
         # Try a follow on incremental (which in buggy versions, would create
         # a deleted entry for the base dir)
-        self.backup(u"inc", u"{0}/testfiles/blocktartest".format(_runtest_dir))
-        self.assertEqual(1, len(glob.glob(u"{0}/testfiles/output/duplicity-new*.sigtar.gz".format(_runtest_dir))))
+        self.backup("inc", f"{_runtest_dir}/testfiles/blocktartest")
+        self.assertEqual(1, len(glob.glob(f"{_runtest_dir}/testfiles/output/duplicity-new*.sigtar.gz")))
         # Confirm we can restore it (which in buggy versions, would fail)
         self.restore()
 
 
-if __name__ == u"__main__":
+if __name__ == "__main__":
     unittest.main()
```

### Comparing `duplicity-1.2.3.dev43/testing/functional/test_selection.py` & `duplicity-2.0.0rc0/testing/functional/test_selection.py`

 * *Files 18% similar despite different names*

```diff
@@ -48,6914 +48,6005 @@
 000002f0: 3b20 6966 206e 6f74 2c20 7772 6974 6520  ; if not, write 
 00000300: 746f 2074 6865 2046 7265 6520 536f 6674  to the Free Soft
 00000310: 7761 7265 2046 6f75 6e64 6174 696f 6e2c  ware Foundation,
 00000320: 0a23 2049 6e63 2e2c 2035 3920 5465 6d70  .# Inc., 59 Temp
 00000330: 6c65 2050 6c61 6365 2c20 5375 6974 6520  le Place, Suite 
 00000340: 3333 302c 2042 6f73 746f 6e2c 204d 4120  330, Boston, MA 
 00000350: 3032 3131 312d 3133 3037 2055 5341 0a0a  02111-1307 USA..
-00000360: 6672 6f6d 205f 5f66 7574 7572 655f 5f20  from __future__ 
-00000370: 696d 706f 7274 2070 7269 6e74 5f66 756e  import print_fun
-00000380: 6374 696f 6e0a 6672 6f6d 2066 7574 7572  ction.from futur
-00000390: 6520 696d 706f 7274 2073 7461 6e64 6172  e import standar
-000003a0: 645f 6c69 6272 6172 790a 7374 616e 6461  d_library.standa
-000003b0: 7264 5f6c 6962 7261 7279 2e69 6e73 7461  rd_library.insta
-000003c0: 6c6c 5f61 6c69 6173 6573 2829 0a0a 0a69  ll_aliases()...i
-000003d0: 6d70 6f72 7420 6f73 0a69 6d70 6f72 7420  mport os.import 
-000003e0: 736f 636b 6574 0a69 6d70 6f72 7420 7374  socket.import st
-000003f0: 6174 0a69 6d70 6f72 7420 7379 730a 696d  at.import sys.im
-00000400: 706f 7274 2070 6c61 7466 6f72 6d0a 696d  port platform.im
-00000410: 706f 7274 2069 6f0a 0a69 6d70 6f72 7420  port io..import 
-00000420: 756e 6974 7465 7374 0a0a 6672 6f6d 202e  unittest..from .
-00000430: 2069 6d70 6f72 7420 4675 6e63 7469 6f6e   import Function
-00000440: 616c 5465 7374 4361 7365 2c20 436d 6445  alTestCase, CmdE
-00000450: 7272 6f72 0a66 726f 6d20 2e2e 2069 6d70  rror.from .. imp
-00000460: 6f72 7420 5f72 756e 7465 7374 5f64 6972  ort _runtest_dir
-00000470: 0a66 726f 6d20 6475 706c 6963 6974 7920  .from duplicity 
-00000480: 696d 706f 7274 206c 6f67 0a0a 0a63 6c61  import log...cla
-00000490: 7373 2049 6e63 6c75 6465 4578 636c 7564  ss IncludeExclud
-000004a0: 6546 756e 6374 696f 6e61 6c54 6573 7428  eFunctionalTest(
-000004b0: 4675 6e63 7469 6f6e 616c 5465 7374 4361  FunctionalTestCa
-000004c0: 7365 293a 0a20 2020 2075 2222 220a 2020  se):.    u""".  
-000004d0: 2020 5468 6973 2063 6f6e 7461 696e 7320    This contains 
-000004e0: 6d65 7468 6f64 7320 7573 6564 2069 6e20  methods used in 
-000004f0: 7468 6520 7465 7374 7320 6265 6c6f 7720  the tests below 
-00000500: 666f 7220 7465 7374 696e 6720 7468 6520  for testing the 
-00000510: 696e 636c 7564 652c 2065 7863 6c75 6465  include, exclude
-00000520: 2061 6e64 2076 6172 696f 7573 2066 696c   and various fil
-00000530: 656c 6973 7420 6665 6174 7572 6573 2e0a  elist features..
-00000540: 2020 2020 2222 220a 0a20 2020 2023 2054      """..    # T
-00000550: 6865 7365 2074 6573 7473 2061 7373 756d  hese tests assum
-00000560: 6520 7468 6520 666f 6c6c 6f77 696e 6720  e the following 
-00000570: 6669 6c65 7320 616e 6420 6c6f 6769 632c  files and logic,
-00000580: 2077 6974 683a 0a20 2020 2023 2022 6973   with:.    # "is
-00000590: 2220 6d65 616e 696e 6720 7468 6174 2074  " meaning that t
-000005a0: 6865 2066 696c 6520 6973 2069 6e63 6c75  he file is inclu
-000005b0: 6465 6420 7370 6563 6966 6963 616c 6c79  ded specifically
-000005c0: 0a20 2020 2023 2022 6961 2220 6d65 616e  .    # "ia" mean
-000005d0: 696e 6720 7468 6174 2074 6865 2066 696c  ing that the fil
-000005e0: 6520 7368 6f75 6c64 2062 6520 696e 636c  e should be incl
-000005f0: 7564 6564 2061 7574 6f6d 6174 6963 616c  uded automatical
-00000600: 6c79 2062 6563 6175 7365 2069 7473 2070  ly because its p
-00000610: 6172 656e 7420 6973 2069 6e63 6c75 6465  arent is include
-00000620: 640a 2020 2020 2320 2269 6322 206d 6561  d.    # "ic" mea
-00000630: 6e69 6e67 2074 6861 7420 7468 6520 666f  ning that the fo
-00000640: 6c64 6572 2069 7320 696e 636c 7564 6564  lder is included
-00000650: 2062 6563 6175 7365 2069 7473 2063 6f6e   because its con
-00000660: 7465 6e74 7320 6172 6520 696e 636c 7564  tents are includ
-00000670: 6564 0a20 2020 2023 2022 6573 2220 6d65  ed.    # "es" me
-00000680: 616e 696e 6720 7468 6174 2074 6865 2066  aning that the f
-00000690: 696c 6520 6973 2065 7863 6c75 6465 6420  ile is excluded 
-000006a0: 7370 6563 6966 6963 616c 6c79 0a20 2020  specifically.   
-000006b0: 2023 2022 6561 2220 6d65 616e 696e 6720   # "ea" meaning 
-000006c0: 7468 6174 2074 6865 2066 696c 6520 7368  that the file sh
-000006d0: 6f75 6c64 2062 6520 6578 636c 7564 6564  ould be excluded
-000006e0: 2061 7574 6f6d 6174 6963 616c 6c79 2062   automatically b
-000006f0: 6563 6175 7365 2069 7473 2070 6172 656e  ecause its paren
-00000700: 7420 6973 2065 7863 6c75 6465 640a 2020  t is excluded.  
-00000710: 2020 2320 7365 6c65 6374 3220 2865 7329    # select2 (es)
-00000720: 0a20 2020 2023 202d 2d2d 2031 2e64 6f63  .    # --- 1.doc
-00000730: 2028 6561 290a 2020 2020 2320 2d2d 2d20   (ea).    # --- 
-00000740: 312e 7079 2028 6973 290a 2020 2020 2320  1.py (is).    # 
-00000750: 2d2d 2d20 3120 2869 7329 0a20 2020 2023  --- 1 (is).    #
-00000760: 202d 2d2d 2d2d 2d20 3173 7562 3120 2869   ------ 1sub1 (i
-00000770: 6129 0a20 2020 2023 202d 2d2d 2d2d 2d2d  a).    # -------
-00000780: 2d2d 2031 7375 6231 7375 6231 2028 6961  -- 1sub1sub1 (ia
-00000790: 290a 2020 2020 2320 2d2d 2d2d 2d2d 2d2d  ).    # --------
-000007a0: 2d2d 2d2d 2031 7375 6231 7375 6231 5f66  ---- 1sub1sub1_f
-000007b0: 696c 652e 7478 7420 2869 6129 0a20 2020  ile.txt (ia).   
-000007c0: 2023 202d 2d2d 2d2d 2d2d 2d2d 2031 7375   # --------- 1su
-000007d0: 6231 7375 6232 2028 6573 290a 2020 2020  b1sub2 (es).    
-000007e0: 2320 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2031  # ------------ 1
-000007f0: 7375 6231 7375 6232 5f66 696c 652e 7478  sub1sub2_file.tx
-00000800: 7420 2865 6129 0a20 2020 2023 202d 2d2d  t (ea).    # ---
-00000810: 2d2d 2d2d 2d2d 2031 7375 6231 7375 6233  ------ 1sub1sub3
-00000820: 2028 6961 290a 2020 2020 2320 2d2d 2d2d   (ia).    # ----
-00000830: 2d2d 2d2d 2d2d 2d2d 2031 7375 6231 7375  -------- 1sub1su
-00000840: 6233 5f66 696c 652e 7478 7420 2865 7329  b3_file.txt (es)
-00000850: 0a20 2020 2023 202d 2d2d 2d2d 2d20 3173  .    # ------ 1s
-00000860: 7562 3220 2869 6329 0a20 2020 2023 202d  ub2 (ic).    # -
-00000870: 2d2d 2d2d 2d2d 2d2d 2031 7375 6232 7375  -------- 1sub2su
-00000880: 6231 2028 6973 290a 2020 2020 2320 2d2d  b1 (is).    # --
-00000890: 2d2d 2d2d 2d2d 2d20 3173 7562 3273 7562  ------- 1sub2sub
-000008a0: 3220 2865 6129 0a20 2020 2023 202d 2d2d  2 (ea).    # ---
-000008b0: 2d2d 2d2d 2d2d 2031 7375 6232 7375 6233  ------ 1sub2sub3
-000008c0: 2028 6573 2920 2023 204e 6f74 206e 6563   (es)  # Not nec
-000008d0: 6573 7361 7279 2061 7320 616c 736f 2065  essary as also e
-000008e0: 612c 2062 7574 2074 6f20 656e 7375 7265  a, but to ensure
-000008f0: 2074 6865 7265 2061 7265 206e 6f20 6973   there are no is
-00000900: 7375 6573 2064 6f69 6e67 2073 6f0a 2020  sues doing so.  
-00000910: 2020 2320 2d2d 2d2d 2d2d 2031 7375 6233    # ------ 1sub3
-00000920: 2028 6961 290a 2020 2020 2320 2d2d 2d2d   (ia).    # ----
-00000930: 2d2d 2d2d 2d20 3173 7562 3373 7562 3120  ----- 1sub3sub1 
-00000940: 2865 7329 0a20 2020 2023 202d 2d2d 2d2d  (es).    # -----
-00000950: 2d2d 2d2d 2031 7375 6233 7375 6232 2028  ---- 1sub3sub2 (
-00000960: 6573 290a 2020 2020 2320 2d2d 2d2d 2d2d  es).    # ------
-00000970: 2d2d 2d20 3173 7562 3373 7562 3320 2869  --- 1sub3sub3 (i
-00000980: 6129 0a20 2020 2023 202d 2d2d 2032 2028  a).    # --- 2 (
-00000990: 6963 290a 2020 2020 2320 2d2d 2d2d 2d2d  ic).    # ------
-000009a0: 2032 7375 6231 2028 6973 290a 2020 2020   2sub1 (is).    
-000009b0: 2320 2d2d 2d2d 2d2d 2d2d 2d20 3273 7562  # --------- 2sub
-000009c0: 3173 7562 3120 2869 6129 0a20 2020 2023  1sub1 (ia).    #
-000009d0: 202d 2d2d 2d2d 2d2d 2d2d 2d2d 2d20 3273   ------------ 2s
-000009e0: 7562 3173 7562 315f 6669 6c65 2e74 7874  ub1sub1_file.txt
-000009f0: 2028 6961 290a 2020 2020 2320 2d2d 2d2d   (ia).    # ----
-00000a00: 2d2d 2d2d 2d20 3273 7562 3173 7562 3220  ----- 2sub1sub2 
-00000a10: 2865 7329 0a20 2020 2023 202d 2d2d 2d2d  (es).    # -----
-00000a20: 2d2d 2d2d 2032 7375 6231 7375 6233 2028  ---- 2sub1sub3 (
-00000a30: 6573 290a 2020 2020 2320 2d2d 2d2d 2d2d  es).    # ------
-00000a40: 2032 7375 6232 2028 6561 290a 2020 2020   2sub2 (ea).    
-00000a50: 2320 2d2d 2d2d 2d2d 2d2d 2d20 3273 7562  # --------- 2sub
-00000a60: 3273 7562 3120 2865 6129 0a20 2020 2023  2sub1 (ea).    #
-00000a70: 202d 2d2d 2d2d 2d2d 2d2d 2032 7375 6232   --------- 2sub2
-00000a80: 7375 6232 2028 6561 290a 2020 2020 2320  sub2 (ea).    # 
-00000a90: 2d2d 2d2d 2d2d 2d2d 2d20 3273 7562 3273  --------- 2sub2s
-00000aa0: 7562 3320 2865 6129 0a20 2020 2023 202d  ub3 (ea).    # -
-00000ab0: 2d2d 2d2d 2d20 3273 7562 3320 2865 6129  ----- 2sub3 (ea)
-00000ac0: 0a20 2020 2023 202d 2d2d 2d2d 2d2d 2d2d  .    # ---------
-00000ad0: 2032 7375 6233 7375 6231 2028 6561 290a   2sub3sub1 (ea).
-00000ae0: 2020 2020 2320 2d2d 2d2d 2d2d 2d2d 2d20      # --------- 
-00000af0: 3273 7562 3373 7562 3320 2865 6129 0a20  2sub3sub3 (ea). 
-00000b00: 2020 2023 202d 2d2d 2d2d 2d2d 2d2d 2032     # --------- 2
-00000b10: 7375 6233 7375 6232 2028 6561 290a 2020  sub3sub2 (ea).  
-00000b20: 2020 2320 2d2d 2d20 3320 2869 7329 0a20    # --- 3 (is). 
-00000b30: 2020 2023 202d 2d2d 2d2d 2d20 3373 7562     # ------ 3sub
-00000b40: 3120 2865 7329 0a20 2020 2023 202d 2d2d  1 (es).    # ---
-00000b50: 2d2d 2d2d 2d2d 2033 7375 6231 7375 6231  ------ 3sub1sub1
-00000b60: 2028 6561 290a 2020 2020 2320 2d2d 2d2d   (ea).    # ----
-00000b70: 2d2d 2d2d 2d20 3373 7562 3173 7562 3220  ----- 3sub1sub2 
-00000b80: 2865 6129 0a20 2020 2023 202d 2d2d 2d2d  (ea).    # -----
-00000b90: 2d2d 2d2d 2033 7375 6231 7375 6233 2028  ---- 3sub1sub3 (
-00000ba0: 6561 290a 2020 2020 2320 2d2d 2d2d 2d2d  ea).    # ------
-00000bb0: 2033 7375 6232 2028 6961 290a 2020 2020   3sub2 (ia).    
-00000bc0: 2320 2d2d 2d2d 2d2d 2d2d 2d20 3373 7562  # --------- 3sub
-00000bd0: 3273 7562 3120 2869 6129 0a20 2020 2023  2sub1 (ia).    #
-00000be0: 202d 2d2d 2d2d 2d2d 2d2d 2033 7375 6232   --------- 3sub2
-00000bf0: 7375 6232 2028 6961 290a 2020 2020 2320  sub2 (ia).    # 
-00000c00: 2d2d 2d2d 2d2d 2d2d 2d20 3373 7562 3273  --------- 3sub2s
-00000c10: 7562 3320 2869 6129 0a20 2020 2023 202d  ub3 (ia).    # -
-00000c20: 2d2d 2d2d 2d20 3373 7562 3320 2869 7329  ----- 3sub3 (is)
-00000c30: 2020 2320 4e6f 7420 6e65 6365 7373 6172    # Not necessar
-00000c40: 7920 6173 2061 6c73 6f20 6961 2c20 6275  y as also ia, bu
-00000c50: 7420 746f 2065 6e73 7572 6520 7468 6572  t to ensure ther
-00000c60: 6520 6172 6520 6e6f 2069 7373 7565 7320  e are no issues 
-00000c70: 646f 696e 6720 736f 0a20 2020 2023 202d  doing so.    # -
-00000c80: 2d2d 2d2d 2d2d 2d2d 2033 7375 6233 7375  -------- 3sub3su
-00000c90: 6231 2028 6961 290a 2020 2020 2320 2d2d  b1 (ia).    # --
-00000ca0: 2d2d 2d2d 2d2d 2d20 3373 7562 3373 7562  ------- 3sub3sub
-00000cb0: 3220 2865 732c 2069 6329 0a20 2020 2023  2 (es, ic).    #
-00000cc0: 202d 2d2d 2d2d 2d2d 2d2d 2d2d 2d20 3373   ------------ 3s
-00000cd0: 7562 3373 7562 325f 6669 6c65 2e74 7874  ub3sub2_file.txt
-00000ce0: 2028 6973 290a 2020 2020 2320 2d2d 2d2d   (is).    # ----
-00000cf0: 2d2d 2d2d 2d20 3373 7562 3373 7562 3320  ----- 3sub3sub3 
-00000d00: 2869 6129 0a20 2020 2023 202d 2d2d 2074  (ia).    # --- t
-00000d10: 7261 696c 696e 675f 7370 6163 6520 2028  railing_space  (
-00000d20: 6561 2920 2023 204e 6f74 6520 7468 6973  ea)  # Note this
-00000d30: 2069 7320 2274 7261 696c 696e 675f 7370   is "trailing_sp
-00000d40: 6163 6520 222e 2045 7863 6c75 6465 6420  ace ". Excluded 
-00000d50: 756e 7469 6c20 7472 6169 6c69 6e67 5f73  until trailing_s
-00000d60: 7061 6365 2074 6573 742c 2077 6865 6e20  pace test, when 
-00000d70: 2869 7329 0a20 2020 2023 202d 2d2d 2d2d  (is).    # -----
-00000d80: 2d20 7472 6169 6c69 6e67 5f73 7061 6365  - trailing_space
-00000d90: 2073 7562 3120 2865 6129 2020 2320 4578   sub1 (ea)  # Ex
-00000da0: 636c 7564 6564 2075 6e74 696c 2074 7261  cluded until tra
-00000db0: 696c 696e 675f 7370 6163 6520 7465 7374  iling_space test
-00000dc0: 2c20 7768 656e 2028 6961 290a 2020 2020  , when (ia).    
-00000dd0: 2320 2d2d 2d2d 2d2d 2074 7261 696c 696e  # ------ trailin
-00000de0: 675f 7370 6163 6520 7375 6232 2028 6561  g_space sub2 (ea
-00000df0: 2920 2023 2045 7863 6c75 6465 6420 756e  )  # Excluded un
-00000e00: 7469 6c20 7472 6169 6c69 6e67 5f73 7061  til trailing_spa
-00000e10: 6365 2074 6573 742c 2077 6865 6e20 2865  ce test, when (e
-00000e20: 732c 2069 6329 0a20 2020 2023 202d 2d2d  s, ic).    # ---
-00000e30: 2d2d 2d2d 2d2d 2074 7261 696c 696e 675f  ------ trailing_
-00000e40: 7370 6163 6520 7375 6232 5f66 696c 652e  space sub2_file.
-00000e50: 7478 7420 2865 6129 2020 2320 4578 636c  txt (ea)  # Excl
-00000e60: 7564 6564 2075 6e74 696c 2074 7261 696c  uded until trail
-00000e70: 696e 675f 7370 6163 6520 7465 7374 2c20  ing_space test, 
-00000e80: 7768 656e 2028 6973 290a 0a20 2020 2063  when (is)..    c
-00000e90: 6f6d 706c 6574 655f 6469 7265 6374 6f72  omplete_director
-00000ea0: 795f 7472 6565 203d 205b 0a20 2020 2020  y_tree = [.     
-00000eb0: 2020 205b 7522 3122 2c20 7522 3222 2c20     [u"1", u"2", 
-00000ec0: 7522 3322 2c20 7522 7472 6169 6c69 6e67  u"3", u"trailing
-00000ed0: 5f73 7061 6365 2022 2c20 7522 312e 646f  _space ", u"1.do
-00000ee0: 6322 2c20 7522 312e 7079 225d 2c0a 2020  c", u"1.py"],.  
-00000ef0: 2020 2020 2020 5b75 2231 7375 6231 222c        [u"1sub1",
-00000f00: 2075 2231 7375 6232 222c 2075 2231 7375   u"1sub2", u"1su
-00000f10: 6233 225d 2c0a 2020 2020 2020 2020 5b75  b3"],.        [u
-00000f20: 2231 7375 6231 7375 6231 222c 2075 2231  "1sub1sub1", u"1
-00000f30: 7375 6231 7375 6232 222c 2075 2231 7375  sub1sub2", u"1su
-00000f40: 6231 7375 6233 225d 2c0a 2020 2020 2020  b1sub3"],.      
-00000f50: 2020 5b75 2231 7375 6231 7375 6231 5f66    [u"1sub1sub1_f
-00000f60: 696c 652e 7478 7422 5d2c 0a20 2020 2020  ile.txt"],.     
-00000f70: 2020 205b 7522 3173 7562 3173 7562 325f     [u"1sub1sub2_
-00000f80: 6669 6c65 2e74 7874 225d 2c0a 2020 2020  file.txt"],.    
-00000f90: 2020 2020 5b75 2231 7375 6231 7375 6233      [u"1sub1sub3
-00000fa0: 5f66 696c 652e 7478 7422 5d2c 0a20 2020  _file.txt"],.   
-00000fb0: 2020 2020 205b 7522 3173 7562 3273 7562       [u"1sub2sub
-00000fc0: 3122 2c20 7522 3173 7562 3273 7562 3222  1", u"1sub2sub2"
-00000fd0: 2c20 7522 3173 7562 3273 7562 3322 5d2c  , u"1sub2sub3"],
-00000fe0: 0a20 2020 2020 2020 205b 7522 3173 7562  .        [u"1sub
-00000ff0: 3373 7562 3122 2c20 7522 3173 7562 3373  3sub1", u"1sub3s
-00001000: 7562 3222 2c20 7522 3173 7562 3373 7562  ub2", u"1sub3sub
-00001010: 3322 5d2c 0a20 2020 2020 2020 205b 7522  3"],.        [u"
-00001020: 3273 7562 3122 2c20 7522 3273 7562 3222  2sub1", u"2sub2"
-00001030: 2c20 7522 3273 7562 3322 5d2c 0a20 2020  , u"2sub3"],.   
-00001040: 2020 2020 205b 7522 3273 7562 3173 7562       [u"2sub1sub
-00001050: 3122 2c20 7522 3273 7562 3173 7562 3222  1", u"2sub1sub2"
-00001060: 2c20 7522 3273 7562 3173 7562 3322 5d2c  , u"2sub1sub3"],
-00001070: 0a20 2020 2020 2020 205b 7522 3273 7562  .        [u"2sub
-00001080: 3173 7562 315f 6669 6c65 2e74 7874 225d  1sub1_file.txt"]
-00001090: 2c0a 2020 2020 2020 2020 5b75 2232 7375  ,.        [u"2su
-000010a0: 6232 7375 6231 222c 2075 2232 7375 6232  b2sub1", u"2sub2
-000010b0: 7375 6232 222c 2075 2232 7375 6232 7375  sub2", u"2sub2su
-000010c0: 6233 225d 2c0a 2020 2020 2020 2020 5b75  b3"],.        [u
-000010d0: 2232 7375 6233 7375 6231 222c 2075 2232  "2sub3sub1", u"2
-000010e0: 7375 6233 7375 6232 222c 2075 2232 7375  sub3sub2", u"2su
-000010f0: 6233 7375 6233 225d 2c0a 2020 2020 2020  b3sub3"],.      
-00001100: 2020 5b75 2233 7375 6231 222c 2075 2233    [u"3sub1", u"3
-00001110: 7375 6232 222c 2075 2233 7375 6233 225d  sub2", u"3sub3"]
-00001120: 2c0a 2020 2020 2020 2020 5b75 2233 7375  ,.        [u"3su
-00001130: 6231 7375 6231 222c 2075 2233 7375 6231  b1sub1", u"3sub1
-00001140: 7375 6232 222c 2075 2233 7375 6231 7375  sub2", u"3sub1su
-00001150: 6233 225d 2c0a 2020 2020 2020 2020 5b75  b3"],.        [u
-00001160: 2233 7375 6232 7375 6231 222c 2075 2233  "3sub2sub1", u"3
-00001170: 7375 6232 7375 6232 222c 2075 2233 7375  sub2sub2", u"3su
-00001180: 6232 7375 6233 225d 2c0a 2020 2020 2020  b2sub3"],.      
-00001190: 2020 5b75 2233 7375 6233 7375 6231 222c    [u"3sub3sub1",
-000011a0: 2075 2233 7375 6233 7375 6232 222c 2075   u"3sub3sub2", u
-000011b0: 2233 7375 6233 7375 6233 225d 2c0a 2020  "3sub3sub3"],.  
-000011c0: 2020 2020 2020 5b75 2233 7375 6233 7375        [u"3sub3su
-000011d0: 6232 5f66 696c 652e 7478 7422 5d2c 0a20  b2_file.txt"],. 
-000011e0: 2020 2020 2020 205b 7522 7472 6169 6c69         [u"traili
-000011f0: 6e67 5f73 7061 6365 2073 7562 3122 2c20  ng_space sub1", 
-00001200: 7522 7472 6169 6c69 6e67 5f73 7061 6365  u"trailing_space
-00001210: 2073 7562 3222 5d2c 0a20 2020 2020 2020   sub2"],.       
-00001220: 205b 7522 7472 6169 6c69 6e67 5f73 7061   [u"trailing_spa
-00001230: 6365 2073 7562 325f 6669 6c65 2e74 7874  ce sub2_file.txt
-00001240: 225d 0a20 2020 205d 0a0a 2020 2020 6578  "].    ]..    ex
-00001250: 7065 6374 6564 5f72 6573 746f 7265 645f  pected_restored_
-00001260: 7472 6565 203d 205b 5b75 2231 222c 2075  tree = [[u"1", u
-00001270: 2232 222c 2075 2233 222c 2075 2231 2e70  "2", u"3", u"1.p
-00001280: 7922 5d2c 0a20 2020 2020 2020 2020 2020  y"],.           
-00001290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000012a0: 2020 205b 7522 3173 7562 3122 2c20 7522     [u"1sub1", u"
-000012b0: 3173 7562 3222 2c20 7522 3173 7562 3322  1sub2", u"1sub3"
-000012c0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00000360: 0a69 6d70 6f72 7420 696f 0a69 6d70 6f72  .import io.impor
+00000370: 7420 6f73 0a69 6d70 6f72 7420 706c 6174  t os.import plat
+00000380: 666f 726d 0a69 6d70 6f72 7420 736f 636b  form.import sock
+00000390: 6574 0a69 6d70 6f72 7420 7374 6174 0a69  et.import stat.i
+000003a0: 6d70 6f72 7420 7379 730a 696d 706f 7274  mport sys.import
+000003b0: 2075 6e69 7474 6573 740a 0a66 726f 6d20   unittest..from 
+000003c0: 2e20 696d 706f 7274 2028 0a20 2020 2046  . import (.    F
+000003d0: 756e 6374 696f 6e61 6c54 6573 7443 6173  unctionalTestCas
+000003e0: 652c 0a20 2020 2043 6d64 4572 726f 722c  e,.    CmdError,
+000003f0: 0a29 0a66 726f 6d20 2e2e 2069 6d70 6f72  .).from .. impor
+00000400: 7420 5f72 756e 7465 7374 5f64 6972 0a66  t _runtest_dir.f
+00000410: 726f 6d20 6475 706c 6963 6974 7920 696d  rom duplicity im
+00000420: 706f 7274 206c 6f67 0a0a 0a63 6c61 7373  port log...class
+00000430: 2049 6e63 6c75 6465 4578 636c 7564 6546   IncludeExcludeF
+00000440: 756e 6374 696f 6e61 6c54 6573 7428 4675  unctionalTest(Fu
+00000450: 6e63 7469 6f6e 616c 5465 7374 4361 7365  nctionalTestCase
+00000460: 293a 0a20 2020 2022 2222 0a20 2020 2054  ):.    """.    T
+00000470: 6869 7320 636f 6e74 6169 6e73 206d 6574  his contains met
+00000480: 686f 6473 2075 7365 6420 696e 2074 6865  hods used in the
+00000490: 2074 6573 7473 2062 656c 6f77 2066 6f72   tests below for
+000004a0: 2074 6573 7469 6e67 2074 6865 2069 6e63   testing the inc
+000004b0: 6c75 6465 2c20 6578 636c 7564 6520 616e  lude, exclude an
+000004c0: 6420 7661 7269 6f75 7320 6669 6c65 6c69  d various fileli
+000004d0: 7374 2066 6561 7475 7265 732e 0a20 2020  st features..   
+000004e0: 2022 2222 0a0a 2020 2020 2320 5468 6573   """..    # Thes
+000004f0: 6520 7465 7374 7320 6173 7375 6d65 2074  e tests assume t
+00000500: 6865 2066 6f6c 6c6f 7769 6e67 2066 696c  he following fil
+00000510: 6573 2061 6e64 206c 6f67 6963 2c20 7769  es and logic, wi
+00000520: 7468 3a0a 2020 2020 2320 2269 7322 206d  th:.    # "is" m
+00000530: 6561 6e69 6e67 2074 6861 7420 7468 6520  eaning that the 
+00000540: 6669 6c65 2069 7320 696e 636c 7564 6564  file is included
+00000550: 2073 7065 6369 6669 6361 6c6c 790a 2020   specifically.  
+00000560: 2020 2320 2269 6122 206d 6561 6e69 6e67    # "ia" meaning
+00000570: 2074 6861 7420 7468 6520 6669 6c65 2073   that the file s
+00000580: 686f 756c 6420 6265 2069 6e63 6c75 6465  hould be include
+00000590: 6420 6175 746f 6d61 7469 6361 6c6c 7920  d automatically 
+000005a0: 6265 6361 7573 6520 6974 7320 7061 7265  because its pare
+000005b0: 6e74 2069 7320 696e 636c 7564 6564 0a20  nt is included. 
+000005c0: 2020 2023 2022 6963 2220 6d65 616e 696e     # "ic" meanin
+000005d0: 6720 7468 6174 2074 6865 2066 6f6c 6465  g that the folde
+000005e0: 7220 6973 2069 6e63 6c75 6465 6420 6265  r is included be
+000005f0: 6361 7573 6520 6974 7320 636f 6e74 656e  cause its conten
+00000600: 7473 2061 7265 2069 6e63 6c75 6465 640a  ts are included.
+00000610: 2020 2020 2320 2265 7322 206d 6561 6e69      # "es" meani
+00000620: 6e67 2074 6861 7420 7468 6520 6669 6c65  ng that the file
+00000630: 2069 7320 6578 636c 7564 6564 2073 7065   is excluded spe
+00000640: 6369 6669 6361 6c6c 790a 2020 2020 2320  cifically.    # 
+00000650: 2265 6122 206d 6561 6e69 6e67 2074 6861  "ea" meaning tha
+00000660: 7420 7468 6520 6669 6c65 2073 686f 756c  t the file shoul
+00000670: 6420 6265 2065 7863 6c75 6465 6420 6175  d be excluded au
+00000680: 746f 6d61 7469 6361 6c6c 7920 6265 6361  tomatically beca
+00000690: 7573 6520 6974 7320 7061 7265 6e74 2069  use its parent i
+000006a0: 7320 6578 636c 7564 6564 0a20 2020 2023  s excluded.    #
+000006b0: 2073 656c 6563 7432 2028 6573 290a 2020   select2 (es).  
+000006c0: 2020 2320 2d2d 2d20 312e 646f 6320 2865    # --- 1.doc (e
+000006d0: 6129 0a20 2020 2023 202d 2d2d 2031 2e70  a).    # --- 1.p
+000006e0: 7920 2869 7329 0a20 2020 2023 202d 2d2d  y (is).    # ---
+000006f0: 2031 2028 6973 290a 2020 2020 2320 2d2d   1 (is).    # --
+00000700: 2d2d 2d2d 2031 7375 6231 2028 6961 290a  ---- 1sub1 (ia).
+00000710: 2020 2020 2320 2d2d 2d2d 2d2d 2d2d 2d20      # --------- 
+00000720: 3173 7562 3173 7562 3120 2869 6129 0a20  1sub1sub1 (ia). 
+00000730: 2020 2023 202d 2d2d 2d2d 2d2d 2d2d 2d2d     # -----------
+00000740: 2d20 3173 7562 3173 7562 315f 6669 6c65  - 1sub1sub1_file
+00000750: 2e74 7874 2028 6961 290a 2020 2020 2320  .txt (ia).    # 
+00000760: 2d2d 2d2d 2d2d 2d2d 2d20 3173 7562 3173  --------- 1sub1s
+00000770: 7562 3220 2865 7329 0a20 2020 2023 202d  ub2 (es).    # -
+00000780: 2d2d 2d2d 2d2d 2d2d 2d2d 2d20 3173 7562  ----------- 1sub
+00000790: 3173 7562 325f 6669 6c65 2e74 7874 2028  1sub2_file.txt (
+000007a0: 6561 290a 2020 2020 2320 2d2d 2d2d 2d2d  ea).    # ------
+000007b0: 2d2d 2d20 3173 7562 3173 7562 3320 2869  --- 1sub1sub3 (i
+000007c0: 6129 0a20 2020 2023 202d 2d2d 2d2d 2d2d  a).    # -------
+000007d0: 2d2d 2d2d 2d20 3173 7562 3173 7562 335f  ----- 1sub1sub3_
+000007e0: 6669 6c65 2e74 7874 2028 6573 290a 2020  file.txt (es).  
+000007f0: 2020 2320 2d2d 2d2d 2d2d 2031 7375 6232    # ------ 1sub2
+00000800: 2028 6963 290a 2020 2020 2320 2d2d 2d2d   (ic).    # ----
+00000810: 2d2d 2d2d 2d20 3173 7562 3273 7562 3120  ----- 1sub2sub1 
+00000820: 2869 7329 0a20 2020 2023 202d 2d2d 2d2d  (is).    # -----
+00000830: 2d2d 2d2d 2031 7375 6232 7375 6232 2028  ---- 1sub2sub2 (
+00000840: 6561 290a 2020 2020 2320 2d2d 2d2d 2d2d  ea).    # ------
+00000850: 2d2d 2d20 3173 7562 3273 7562 3320 2865  --- 1sub2sub3 (e
+00000860: 7329 2020 2320 4e6f 7420 6e65 6365 7373  s)  # Not necess
+00000870: 6172 7920 6173 2061 6c73 6f20 6561 2c20  ary as also ea, 
+00000880: 6275 7420 746f 2065 6e73 7572 6520 7468  but to ensure th
+00000890: 6572 6520 6172 6520 6e6f 2069 7373 7565  ere are no issue
+000008a0: 7320 646f 696e 6720 736f 0a20 2020 2023  s doing so.    #
+000008b0: 202d 2d2d 2d2d 2d20 3173 7562 3320 2869   ------ 1sub3 (i
+000008c0: 6129 0a20 2020 2023 202d 2d2d 2d2d 2d2d  a).    # -------
+000008d0: 2d2d 2031 7375 6233 7375 6231 2028 6573  -- 1sub3sub1 (es
+000008e0: 290a 2020 2020 2320 2d2d 2d2d 2d2d 2d2d  ).    # --------
+000008f0: 2d20 3173 7562 3373 7562 3220 2865 7329  - 1sub3sub2 (es)
+00000900: 0a20 2020 2023 202d 2d2d 2d2d 2d2d 2d2d  .    # ---------
+00000910: 2031 7375 6233 7375 6233 2028 6961 290a   1sub3sub3 (ia).
+00000920: 2020 2020 2320 2d2d 2d20 3220 2869 6329      # --- 2 (ic)
+00000930: 0a20 2020 2023 202d 2d2d 2d2d 2d20 3273  .    # ------ 2s
+00000940: 7562 3120 2869 7329 0a20 2020 2023 202d  ub1 (is).    # -
+00000950: 2d2d 2d2d 2d2d 2d2d 2032 7375 6231 7375  -------- 2sub1su
+00000960: 6231 2028 6961 290a 2020 2020 2320 2d2d  b1 (ia).    # --
+00000970: 2d2d 2d2d 2d2d 2d2d 2d2d 2032 7375 6231  ---------- 2sub1
+00000980: 7375 6231 5f66 696c 652e 7478 7420 2869  sub1_file.txt (i
+00000990: 6129 0a20 2020 2023 202d 2d2d 2d2d 2d2d  a).    # -------
+000009a0: 2d2d 2032 7375 6231 7375 6232 2028 6573  -- 2sub1sub2 (es
+000009b0: 290a 2020 2020 2320 2d2d 2d2d 2d2d 2d2d  ).    # --------
+000009c0: 2d20 3273 7562 3173 7562 3320 2865 7329  - 2sub1sub3 (es)
+000009d0: 0a20 2020 2023 202d 2d2d 2d2d 2d20 3273  .    # ------ 2s
+000009e0: 7562 3220 2865 6129 0a20 2020 2023 202d  ub2 (ea).    # -
+000009f0: 2d2d 2d2d 2d2d 2d2d 2032 7375 6232 7375  -------- 2sub2su
+00000a00: 6231 2028 6561 290a 2020 2020 2320 2d2d  b1 (ea).    # --
+00000a10: 2d2d 2d2d 2d2d 2d20 3273 7562 3273 7562  ------- 2sub2sub
+00000a20: 3220 2865 6129 0a20 2020 2023 202d 2d2d  2 (ea).    # ---
+00000a30: 2d2d 2d2d 2d2d 2032 7375 6232 7375 6233  ------ 2sub2sub3
+00000a40: 2028 6561 290a 2020 2020 2320 2d2d 2d2d   (ea).    # ----
+00000a50: 2d2d 2032 7375 6233 2028 6561 290a 2020  -- 2sub3 (ea).  
+00000a60: 2020 2320 2d2d 2d2d 2d2d 2d2d 2d20 3273    # --------- 2s
+00000a70: 7562 3373 7562 3120 2865 6129 0a20 2020  ub3sub1 (ea).   
+00000a80: 2023 202d 2d2d 2d2d 2d2d 2d2d 2032 7375   # --------- 2su
+00000a90: 6233 7375 6233 2028 6561 290a 2020 2020  b3sub3 (ea).    
+00000aa0: 2320 2d2d 2d2d 2d2d 2d2d 2d20 3273 7562  # --------- 2sub
+00000ab0: 3373 7562 3220 2865 6129 0a20 2020 2023  3sub2 (ea).    #
+00000ac0: 202d 2d2d 2033 2028 6973 290a 2020 2020   --- 3 (is).    
+00000ad0: 2320 2d2d 2d2d 2d2d 2033 7375 6231 2028  # ------ 3sub1 (
+00000ae0: 6573 290a 2020 2020 2320 2d2d 2d2d 2d2d  es).    # ------
+00000af0: 2d2d 2d20 3373 7562 3173 7562 3120 2865  --- 3sub1sub1 (e
+00000b00: 6129 0a20 2020 2023 202d 2d2d 2d2d 2d2d  a).    # -------
+00000b10: 2d2d 2033 7375 6231 7375 6232 2028 6561  -- 3sub1sub2 (ea
+00000b20: 290a 2020 2020 2320 2d2d 2d2d 2d2d 2d2d  ).    # --------
+00000b30: 2d20 3373 7562 3173 7562 3320 2865 6129  - 3sub1sub3 (ea)
+00000b40: 0a20 2020 2023 202d 2d2d 2d2d 2d20 3373  .    # ------ 3s
+00000b50: 7562 3220 2869 6129 0a20 2020 2023 202d  ub2 (ia).    # -
+00000b60: 2d2d 2d2d 2d2d 2d2d 2033 7375 6232 7375  -------- 3sub2su
+00000b70: 6231 2028 6961 290a 2020 2020 2320 2d2d  b1 (ia).    # --
+00000b80: 2d2d 2d2d 2d2d 2d20 3373 7562 3273 7562  ------- 3sub2sub
+00000b90: 3220 2869 6129 0a20 2020 2023 202d 2d2d  2 (ia).    # ---
+00000ba0: 2d2d 2d2d 2d2d 2033 7375 6232 7375 6233  ------ 3sub2sub3
+00000bb0: 2028 6961 290a 2020 2020 2320 2d2d 2d2d   (ia).    # ----
+00000bc0: 2d2d 2033 7375 6233 2028 6973 2920 2023  -- 3sub3 (is)  #
+00000bd0: 204e 6f74 206e 6563 6573 7361 7279 2061   Not necessary a
+00000be0: 7320 616c 736f 2069 612c 2062 7574 2074  s also ia, but t
+00000bf0: 6f20 656e 7375 7265 2074 6865 7265 2061  o ensure there a
+00000c00: 7265 206e 6f20 6973 7375 6573 2064 6f69  re no issues doi
+00000c10: 6e67 2073 6f0a 2020 2020 2320 2d2d 2d2d  ng so.    # ----
+00000c20: 2d2d 2d2d 2d20 3373 7562 3373 7562 3120  ----- 3sub3sub1 
+00000c30: 2869 6129 0a20 2020 2023 202d 2d2d 2d2d  (ia).    # -----
+00000c40: 2d2d 2d2d 2033 7375 6233 7375 6232 2028  ---- 3sub3sub2 (
+00000c50: 6573 2c20 6963 290a 2020 2020 2320 2d2d  es, ic).    # --
+00000c60: 2d2d 2d2d 2d2d 2d2d 2d2d 2033 7375 6233  ---------- 3sub3
+00000c70: 7375 6232 5f66 696c 652e 7478 7420 2869  sub2_file.txt (i
+00000c80: 7329 0a20 2020 2023 202d 2d2d 2d2d 2d2d  s).    # -------
+00000c90: 2d2d 2033 7375 6233 7375 6233 2028 6961  -- 3sub3sub3 (ia
+00000ca0: 290a 2020 2020 2320 2d2d 2d20 7472 6169  ).    # --- trai
+00000cb0: 6c69 6e67 5f73 7061 6365 2020 2865 6129  ling_space  (ea)
+00000cc0: 2020 2320 4e6f 7465 2074 6869 7320 6973    # Note this is
+00000cd0: 2022 7472 6169 6c69 6e67 5f73 7061 6365   "trailing_space
+00000ce0: 2022 2e20 4578 636c 7564 6564 2075 6e74   ". Excluded unt
+00000cf0: 696c 2074 7261 696c 696e 675f 7370 6163  il trailing_spac
+00000d00: 6520 7465 7374 2c20 7768 656e 2028 6973  e test, when (is
+00000d10: 290a 2020 2020 2320 2d2d 2d2d 2d2d 2074  ).    # ------ t
+00000d20: 7261 696c 696e 675f 7370 6163 6520 7375  railing_space su
+00000d30: 6231 2028 6561 2920 2023 2045 7863 6c75  b1 (ea)  # Exclu
+00000d40: 6465 6420 756e 7469 6c20 7472 6169 6c69  ded until traili
+00000d50: 6e67 5f73 7061 6365 2074 6573 742c 2077  ng_space test, w
+00000d60: 6865 6e20 2869 6129 0a20 2020 2023 202d  hen (ia).    # -
+00000d70: 2d2d 2d2d 2d20 7472 6169 6c69 6e67 5f73  ----- trailing_s
+00000d80: 7061 6365 2073 7562 3220 2865 6129 2020  pace sub2 (ea)  
+00000d90: 2320 4578 636c 7564 6564 2075 6e74 696c  # Excluded until
+00000da0: 2074 7261 696c 696e 675f 7370 6163 6520   trailing_space 
+00000db0: 7465 7374 2c20 7768 656e 2028 6573 2c20  test, when (es, 
+00000dc0: 6963 290a 2020 2020 2320 2d2d 2d2d 2d2d  ic).    # ------
+00000dd0: 2d2d 2d20 7472 6169 6c69 6e67 5f73 7061  --- trailing_spa
+00000de0: 6365 2073 7562 325f 6669 6c65 2e74 7874  ce sub2_file.txt
+00000df0: 2028 6561 2920 2023 2045 7863 6c75 6465   (ea)  # Exclude
+00000e00: 6420 756e 7469 6c20 7472 6169 6c69 6e67  d until trailing
+00000e10: 5f73 7061 6365 2074 6573 742c 2077 6865  _space test, whe
+00000e20: 6e20 2869 7329 0a0a 2020 2020 636f 6d70  n (is)..    comp
+00000e30: 6c65 7465 5f64 6972 6563 746f 7279 5f74  lete_directory_t
+00000e40: 7265 6520 3d20 5b0a 2020 2020 2020 2020  ree = [.        
+00000e50: 5b22 3122 2c20 2232 222c 2022 3322 2c20  ["1", "2", "3", 
+00000e60: 2274 7261 696c 696e 675f 7370 6163 6520  "trailing_space 
+00000e70: 222c 2022 312e 646f 6322 2c20 2231 2e70  ", "1.doc", "1.p
+00000e80: 7922 5d2c 0a20 2020 2020 2020 205b 2231  y"],.        ["1
+00000e90: 7375 6231 222c 2022 3173 7562 3222 2c20  sub1", "1sub2", 
+00000ea0: 2231 7375 6233 225d 2c0a 2020 2020 2020  "1sub3"],.      
+00000eb0: 2020 5b22 3173 7562 3173 7562 3122 2c20    ["1sub1sub1", 
+00000ec0: 2231 7375 6231 7375 6232 222c 2022 3173  "1sub1sub2", "1s
+00000ed0: 7562 3173 7562 3322 5d2c 0a20 2020 2020  ub1sub3"],.     
+00000ee0: 2020 205b 2231 7375 6231 7375 6231 5f66     ["1sub1sub1_f
+00000ef0: 696c 652e 7478 7422 5d2c 0a20 2020 2020  ile.txt"],.     
+00000f00: 2020 205b 2231 7375 6231 7375 6232 5f66     ["1sub1sub2_f
+00000f10: 696c 652e 7478 7422 5d2c 0a20 2020 2020  ile.txt"],.     
+00000f20: 2020 205b 2231 7375 6231 7375 6233 5f66     ["1sub1sub3_f
+00000f30: 696c 652e 7478 7422 5d2c 0a20 2020 2020  ile.txt"],.     
+00000f40: 2020 205b 2231 7375 6232 7375 6231 222c     ["1sub2sub1",
+00000f50: 2022 3173 7562 3273 7562 3222 2c20 2231   "1sub2sub2", "1
+00000f60: 7375 6232 7375 6233 225d 2c0a 2020 2020  sub2sub3"],.    
+00000f70: 2020 2020 5b22 3173 7562 3373 7562 3122      ["1sub3sub1"
+00000f80: 2c20 2231 7375 6233 7375 6232 222c 2022  , "1sub3sub2", "
+00000f90: 3173 7562 3373 7562 3322 5d2c 0a20 2020  1sub3sub3"],.   
+00000fa0: 2020 2020 205b 2232 7375 6231 222c 2022       ["2sub1", "
+00000fb0: 3273 7562 3222 2c20 2232 7375 6233 225d  2sub2", "2sub3"]
+00000fc0: 2c0a 2020 2020 2020 2020 5b22 3273 7562  ,.        ["2sub
+00000fd0: 3173 7562 3122 2c20 2232 7375 6231 7375  1sub1", "2sub1su
+00000fe0: 6232 222c 2022 3273 7562 3173 7562 3322  b2", "2sub1sub3"
+00000ff0: 5d2c 0a20 2020 2020 2020 205b 2232 7375  ],.        ["2su
+00001000: 6231 7375 6231 5f66 696c 652e 7478 7422  b1sub1_file.txt"
+00001010: 5d2c 0a20 2020 2020 2020 205b 2232 7375  ],.        ["2su
+00001020: 6232 7375 6231 222c 2022 3273 7562 3273  b2sub1", "2sub2s
+00001030: 7562 3222 2c20 2232 7375 6232 7375 6233  ub2", "2sub2sub3
+00001040: 225d 2c0a 2020 2020 2020 2020 5b22 3273  "],.        ["2s
+00001050: 7562 3373 7562 3122 2c20 2232 7375 6233  ub3sub1", "2sub3
+00001060: 7375 6232 222c 2022 3273 7562 3373 7562  sub2", "2sub3sub
+00001070: 3322 5d2c 0a20 2020 2020 2020 205b 2233  3"],.        ["3
+00001080: 7375 6231 222c 2022 3373 7562 3222 2c20  sub1", "3sub2", 
+00001090: 2233 7375 6233 225d 2c0a 2020 2020 2020  "3sub3"],.      
+000010a0: 2020 5b22 3373 7562 3173 7562 3122 2c20    ["3sub1sub1", 
+000010b0: 2233 7375 6231 7375 6232 222c 2022 3373  "3sub1sub2", "3s
+000010c0: 7562 3173 7562 3322 5d2c 0a20 2020 2020  ub1sub3"],.     
+000010d0: 2020 205b 2233 7375 6232 7375 6231 222c     ["3sub2sub1",
+000010e0: 2022 3373 7562 3273 7562 3222 2c20 2233   "3sub2sub2", "3
+000010f0: 7375 6232 7375 6233 225d 2c0a 2020 2020  sub2sub3"],.    
+00001100: 2020 2020 5b22 3373 7562 3373 7562 3122      ["3sub3sub1"
+00001110: 2c20 2233 7375 6233 7375 6232 222c 2022  , "3sub3sub2", "
+00001120: 3373 7562 3373 7562 3322 5d2c 0a20 2020  3sub3sub3"],.   
+00001130: 2020 2020 205b 2233 7375 6233 7375 6232       ["3sub3sub2
+00001140: 5f66 696c 652e 7478 7422 5d2c 0a20 2020  _file.txt"],.   
+00001150: 2020 2020 205b 2274 7261 696c 696e 675f       ["trailing_
+00001160: 7370 6163 6520 7375 6231 222c 2022 7472  space sub1", "tr
+00001170: 6169 6c69 6e67 5f73 7061 6365 2073 7562  ailing_space sub
+00001180: 3222 5d2c 0a20 2020 2020 2020 205b 2274  2"],.        ["t
+00001190: 7261 696c 696e 675f 7370 6163 6520 7375  railing_space su
+000011a0: 6232 5f66 696c 652e 7478 7422 5d0a 2020  b2_file.txt"].  
+000011b0: 2020 5d0a 0a20 2020 2065 7870 6563 7465    ]..    expecte
+000011c0: 645f 7265 7374 6f72 6564 5f74 7265 6520  d_restored_tree 
+000011d0: 3d20 5b5b 2231 222c 2022 3222 2c20 2233  = [["1", "2", "3
+000011e0: 222c 2022 312e 7079 225d 2c0a 2020 2020  ", "1.py"],.    
+000011f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001200: 2020 2020 2020 2020 2020 5b22 3173 7562            ["1sub
+00001210: 3122 2c20 2231 7375 6232 222c 2022 3173  1", "1sub2", "1s
+00001220: 7562 3322 5d2c 0a20 2020 2020 2020 2020  ub3"],.         
+00001230: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001240: 2020 2020 205b 2231 7375 6231 7375 6231       ["1sub1sub1
+00001250: 222c 2022 3173 7562 3173 7562 3322 5d2c  ", "1sub1sub3"],
+00001260: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001270: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+00001280: 2231 7375 6231 7375 6231 5f66 696c 652e  "1sub1sub1_file.
+00001290: 7478 7422 5d2c 0a20 2020 2020 2020 2020  txt"],.         
+000012a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000012b0: 2020 2020 205b 2231 7375 6232 7375 6231       ["1sub2sub1
+000012c0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
 000012d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000012e0: 205b 7522 3173 7562 3173 7562 3122 2c20   [u"1sub1sub1", 
-000012f0: 7522 3173 7562 3173 7562 3322 5d2c 0a20  u"1sub1sub3"],. 
-00001300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001310: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-00001320: 3173 7562 3173 7562 315f 6669 6c65 2e74  1sub1sub1_file.t
-00001330: 7874 225d 2c0a 2020 2020 2020 2020 2020  xt"],.          
-00001340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001350: 2020 2020 5b75 2231 7375 6232 7375 6231      [u"1sub2sub1
-00001360: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
-00001370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001380: 2020 5b75 2231 7375 6233 7375 6233 225d    [u"1sub3sub3"]
-00001390: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000013a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000013b0: 5b75 2232 7375 6231 225d 2c0a 2020 2020  [u"2sub1"],.    
-000013c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000013d0: 2020 2020 2020 2020 2020 5b75 2232 7375            [u"2su
-000013e0: 6231 7375 6231 225d 2c0a 2020 2020 2020  b1sub1"],.      
-000013f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001400: 2020 2020 2020 2020 5b75 2232 7375 6231          [u"2sub1
-00001410: 7375 6231 5f66 696c 652e 7478 7422 5d2c  sub1_file.txt"],
-00001420: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001430: 2020 2020 2020 2020 2020 2020 2020 205b                 [
-00001440: 7522 3373 7562 3222 2c20 7522 3373 7562  u"3sub2", u"3sub
-00001450: 3322 5d2c 0a20 2020 2020 2020 2020 2020  3"],.           
-00001460: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001470: 2020 205b 7522 3373 7562 3273 7562 3122     [u"3sub2sub1"
-00001480: 2c20 7522 3373 7562 3273 7562 3222 2c20  , u"3sub2sub2", 
-00001490: 7522 3373 7562 3273 7562 3322 5d2c 0a20  u"3sub2sub3"],. 
-000014a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000014b0: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-000014c0: 3373 7562 3373 7562 3122 2c20 7522 3373  3sub3sub1", u"3s
-000014d0: 7562 3373 7562 3222 2c20 7522 3373 7562  ub3sub2", u"3sub
-000014e0: 3373 7562 3322 5d2c 0a20 2020 2020 2020  3sub3"],.       
+000012e0: 2020 5b22 3173 7562 3373 7562 3322 5d2c    ["1sub3sub3"],
+000012f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001300: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+00001310: 2232 7375 6231 225d 2c0a 2020 2020 2020  "2sub1"],.      
+00001320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001330: 2020 2020 2020 2020 5b22 3273 7562 3173          ["2sub1s
+00001340: 7562 3122 5d2c 0a20 2020 2020 2020 2020  ub1"],.         
+00001350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001360: 2020 2020 205b 2232 7375 6231 7375 6231       ["2sub1sub1
+00001370: 5f66 696c 652e 7478 7422 5d2c 0a20 2020  _file.txt"],.   
+00001380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001390: 2020 2020 2020 2020 2020 205b 2233 7375             ["3su
+000013a0: 6232 222c 2022 3373 7562 3322 5d2c 0a20  b2", "3sub3"],. 
+000013b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000013c0: 2020 2020 2020 2020 2020 2020 205b 2233               ["3
+000013d0: 7375 6232 7375 6231 222c 2022 3373 7562  sub2sub1", "3sub
+000013e0: 3273 7562 3222 2c20 2233 7375 6232 7375  2sub2", "3sub2su
+000013f0: 6233 225d 2c0a 2020 2020 2020 2020 2020  b3"],.          
+00001400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001410: 2020 2020 5b22 3373 7562 3373 7562 3122      ["3sub3sub1"
+00001420: 2c20 2233 7375 6233 7375 6232 222c 2022  , "3sub3sub2", "
+00001430: 3373 7562 3373 7562 3322 5d2c 0a20 2020  3sub3sub3"],.   
+00001440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001450: 2020 2020 2020 2020 2020 205b 2233 7375             ["3su
+00001460: 6233 7375 6232 5f66 696c 652e 7478 7422  b3sub2_file.txt"
+00001470: 5d5d 0a0a 2020 2020 6578 7065 6374 6564  ]]..    expected
+00001480: 5f72 6573 746f 7265 645f 7472 6565 5f77  _restored_tree_w
+00001490: 6974 685f 7472 6169 6c69 6e67 5f73 7061  ith_trailing_spa
+000014a0: 6365 203d 205b 5b22 3122 2c20 2232 222c  ce = [["1", "2",
+000014b0: 2022 3322 2c20 2274 7261 696c 696e 675f   "3", "trailing_
+000014c0: 7370 6163 6520 222c 2022 312e 7079 225d  space ", "1.py"]
+000014d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000014e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000014f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001500: 2020 2020 2020 205b 7522 3373 7562 3373         [u"3sub3s
-00001510: 7562 325f 6669 6c65 2e74 7874 225d 5d0a  ub2_file.txt"]].
-00001520: 0a20 2020 2065 7870 6563 7465 645f 7265  .    expected_re
-00001530: 7374 6f72 6564 5f74 7265 655f 7769 7468  stored_tree_with
-00001540: 5f74 7261 696c 696e 675f 7370 6163 6520  _trailing_space 
-00001550: 3d20 5b5b 7522 3122 2c20 7522 3222 2c20  = [[u"1", u"2", 
-00001560: 7522 3322 2c20 7522 7472 6169 6c69 6e67  u"3", u"trailing
-00001570: 5f73 7061 6365 2022 2c20 7522 312e 7079  _space ", u"1.py
-00001580: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00001500: 2020 2020 5b22 3173 7562 3122 2c20 2231      ["1sub1", "1
+00001510: 7375 6232 222c 2022 3173 7562 3322 5d2c  sub2", "1sub3"],
+00001520: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001550: 2020 205b 2231 7375 6231 7375 6231 222c     ["1sub1sub1",
+00001560: 2022 3173 7562 3173 7562 3322 5d2c 0a20   "1sub1sub3"],. 
+00001570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001580: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00001590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000015a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000015b0: 2020 2020 2020 5b75 2231 7375 6231 222c        [u"1sub1",
-000015c0: 2075 2231 7375 6232 222c 2075 2231 7375   u"1sub2", u"1su
-000015d0: 6233 225d 2c0a 2020 2020 2020 2020 2020  b3"],.          
-000015e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000015f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001600: 2020 2020 2020 2020 5b75 2231 7375 6231          [u"1sub1
-00001610: 7375 6231 222c 2075 2231 7375 6231 7375  sub1", u"1sub1su
-00001620: 6233 225d 2c0a 2020 2020 2020 2020 2020  b3"],.          
-00001630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000015a0: 205b 2231 7375 6231 7375 6231 5f66 696c   ["1sub1sub1_fil
+000015b0: 652e 7478 7422 5d2c 0a20 2020 2020 2020  e.txt"],.       
+000015c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000015d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000015e0: 2020 2020 2020 2020 2020 205b 2231 7375             ["1su
+000015f0: 6232 7375 6231 225d 2c0a 2020 2020 2020  b2sub1"],.      
+00001600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001620: 2020 2020 2020 2020 2020 2020 5b22 3173              ["1s
+00001630: 7562 3373 7562 3322 5d2c 0a20 2020 2020  ub3sub3"],.     
 00001640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001650: 2020 2020 2020 2020 5b75 2231 7375 6231          [u"1sub1
-00001660: 7375 6231 5f66 696c 652e 7478 7422 5d2c  sub1_file.txt"],
-00001670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00001650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001660: 2020 2020 2020 2020 2020 2020 205b 2232               ["2
+00001670: 7375 6231 225d 2c0a 2020 2020 2020 2020  sub1"],.        
 00001680: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00001690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000016a0: 2020 205b 7522 3173 7562 3273 7562 3122     [u"1sub2sub1"
-000016b0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+000016a0: 2020 2020 2020 2020 2020 5b22 3273 7562            ["2sub
+000016b0: 3173 7562 3122 5d2c 0a20 2020 2020 2020  1sub1"],.       
 000016c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000016d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000016e0: 2020 2020 205b 7522 3173 7562 3373 7562       [u"1sub3sub
-000016f0: 3322 5d2c 0a20 2020 2020 2020 2020 2020  3"],.           
-00001700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000016e0: 2020 2020 2020 2020 2020 205b 2232 7375             ["2su
+000016f0: 6231 7375 6231 5f66 696c 652e 7478 7422  b1sub1_file.txt"
+00001700: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
 00001710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001720: 2020 2020 2020 205b 7522 3273 7562 3122         [u"2sub1"
-00001730: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00001740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001730: 2020 2020 205b 2233 7375 6232 222c 2022       ["3sub2", "
+00001740: 3373 7562 3322 5d2c 0a20 2020 2020 2020  3sub3"],.       
 00001750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001760: 2020 2020 205b 7522 3273 7562 3173 7562       [u"2sub1sub
-00001770: 3122 5d2c 0a20 2020 2020 2020 2020 2020  1"],.           
-00001780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000017a0: 2020 2020 2020 205b 7522 3273 7562 3173         [u"2sub1s
-000017b0: 7562 315f 6669 6c65 2e74 7874 225d 2c0a  ub1_file.txt"],.
+00001760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001770: 2020 2020 2020 2020 2020 205b 2233 7375             ["3su
+00001780: 6232 7375 6231 222c 2022 3373 7562 3273  b2sub1", "3sub2s
+00001790: 7562 3222 2c20 2233 7375 6232 7375 6233  ub2", "3sub2sub3
+000017a0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+000017b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000017c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000017d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000017e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000017f0: 2020 5b75 2233 7375 6232 222c 2075 2233    [u"3sub2", u"3
-00001800: 7375 6233 225d 2c0a 2020 2020 2020 2020  sub3"],.        
+000017d0: 2020 2020 2020 5b22 3373 7562 3373 7562        ["3sub3sub
+000017e0: 3122 2c20 2233 7375 6233 7375 6232 222c  1", "3sub3sub2",
+000017f0: 2022 3373 7562 3373 7562 3322 5d2c 0a20   "3sub3sub3"],. 
+00001800: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00001810: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00001820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001830: 2020 2020 2020 2020 2020 5b75 2233 7375            [u"3su
-00001840: 6232 7375 6231 222c 2075 2233 7375 6232  b2sub1", u"3sub2
-00001850: 7375 6232 222c 2075 2233 7375 6232 7375  sub2", u"3sub2su
-00001860: 6233 225d 2c0a 2020 2020 2020 2020 2020  b3"],.          
-00001870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001890: 2020 2020 2020 2020 5b75 2233 7375 6233          [u"3sub3
-000018a0: 7375 6231 222c 2075 2233 7375 6233 7375  sub1", u"3sub3su
-000018b0: 6232 222c 2075 2233 7375 6233 7375 6233  b2", u"3sub3sub3
-000018c0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
-000018d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000018e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000018f0: 2020 2020 2020 5b75 2233 7375 6233 7375        [u"3sub3su
-00001900: 6232 5f66 696c 652e 7478 7422 5d2c 0a20  b2_file.txt"],. 
-00001910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001940: 205b 7522 7472 6169 6c69 6e67 5f73 7061   [u"trailing_spa
-00001950: 6365 2073 7562 3122 2c20 7522 7472 6169  ce sub1", u"trai
-00001960: 6c69 6e67 5f73 7061 6365 2073 7562 3222  ling_space sub2"
-00001970: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00001980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000019a0: 2020 2020 205b 7522 7472 6169 6c69 6e67       [u"trailing
-000019b0: 5f73 7061 6365 2073 7562 325f 6669 6c65  _space sub2_file
-000019c0: 2e74 7874 225d 5d0a 0a20 2020 2064 6566  .txt"]]..    def
-000019d0: 2064 6972 6563 746f 7279 5f74 7265 655f   directory_tree_
-000019e0: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-000019f0: 2873 656c 662c 2070 6172 656e 745f 6469  (self, parent_di
-00001a00: 7265 6374 6f72 7929 3a0a 2020 2020 2020  rectory):.      
-00001a10: 2020 7522 2222 0a20 2020 2020 2020 2054    u""".        T
-00001a20: 6869 7320 7461 6b65 7320 6120 666f 6c64  his takes a fold
-00001a30: 6572 2061 7320 616e 2069 6e70 7574 2061  er as an input a
-00001a40: 6e64 2072 6574 7572 6e73 2061 206c 6973  nd returns a lis
-00001a50: 7420 7769 7468 2069 7473 2063 6f6e 7465  t with its conte
-00001a60: 6e74 732e 2049 6620 7468 6520 6469 7265  nts. If the dire
-00001a70: 6374 6f72 7920 6861 7320 7375 6264 6972  ctory has subdir
-00001a80: 6563 746f 7269 6573 2c20 6974 0a20 2020  ectories, it.   
-00001a90: 2020 2020 2072 6574 7572 6e73 2061 206c       returns a l
-00001aa0: 6973 7420 6f66 206c 6973 7473 2077 6974  ist of lists wit
-00001ab0: 6820 7468 6520 636f 6e74 656e 7473 206f  h the contents o
-00001ac0: 6620 7468 6f73 6520 7375 6264 6972 6563  f those subdirec
-00001ad0: 746f 7269 6573 2e0a 2020 2020 2020 2020  tories..        
-00001ae0: 2222 220a 2020 2020 2020 2020 6469 7265  """.        dire
-00001af0: 6374 6f72 795f 6c69 7374 203d 205b 5d0a  ctory_list = [].
-00001b00: 2020 2020 2020 2020 666f 7220 726f 6f74          for root
-00001b10: 2c20 6469 7273 2c20 6669 6c65 7320 696e  , dirs, files in
-00001b20: 206f 732e 7761 6c6b 2870 6172 656e 745f   os.walk(parent_
-00001b30: 6469 7265 6374 6f72 7929 3a0a 2020 2020  directory):.    
-00001b40: 2020 2020 2020 2020 746f 5f61 6464 203d          to_add =
-00001b50: 205b 5d0a 2020 2020 2020 2020 2020 2020   [].            
-00001b60: 6966 2064 6972 733a 0a20 2020 2020 2020  if dirs:.       
-00001b70: 2020 2020 2020 2020 2064 6972 732e 736f           dirs.so
-00001b80: 7274 2829 2020 2320 536f 2074 6861 7420  rt()  # So that 
-00001b90: 7765 2063 616e 2065 6173 696c 7920 636f  we can easily co
-00001ba0: 6d70 6172 6520 746f 2077 6861 7420 7765  mpare to what we
-00001bb0: 2065 7870 6563 740a 2020 2020 2020 2020   expect.        
-00001bc0: 2020 2020 2020 2020 746f 5f61 6464 203d          to_add =
-00001bd0: 2064 6972 730a 2020 2020 2020 2020 2020   dirs.          
-00001be0: 2020 6966 2066 696c 6573 3a0a 2020 2020    if files:.    
-00001bf0: 2020 2020 2020 2020 2020 2020 6669 6c65              file
-00001c00: 732e 736f 7274 2829 2020 2320 536f 2074  s.sort()  # So t
-00001c10: 6861 7420 7765 2063 616e 2065 6173 696c  hat we can easil
-00001c20: 7920 636f 6d70 6172 6520 746f 2077 6861  y compare to wha
-00001c30: 7420 7765 2065 7870 6563 740a 2020 2020  t we expect.    
-00001c40: 2020 2020 2020 2020 2020 2020 746f 5f61              to_a
-00001c50: 6464 202b 3d20 6669 6c65 730a 2020 2020  dd += files.    
-00001c60: 2020 2020 2020 2020 6966 2074 6f5f 6164          if to_ad
-00001c70: 643a 0a20 2020 2020 2020 2020 2020 2020  d:.             
-00001c80: 2020 2064 6972 6563 746f 7279 5f6c 6973     directory_lis
-00001c90: 742e 6170 7065 6e64 2874 6f5f 6164 6429  t.append(to_add)
-00001ca0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00001cb0: 6469 7265 6374 6f72 795f 6c69 7374 0a0a  directory_list..
-00001cc0: 0a63 6c61 7373 2054 6573 7453 6b69 7053  .class TestSkipS
-00001cd0: 6f63 6b65 7428 496e 636c 7564 6545 7863  ocket(IncludeExc
-00001ce0: 6c75 6465 4675 6e63 7469 6f6e 616c 5465  ludeFunctionalTe
-00001cf0: 7374 293a 0a20 2020 2075 2222 2220 5465  st):.    u""" Te
-00001d00: 7374 7320 636f 7272 6563 7420 6861 6e64  sts correct hand
-00001d10: 6c69 6e67 206f 6620 756e 6978 2064 6f6d  ling of unix dom
-00001d20: 6169 6e20 736f 636b 6574 7320 696e 2062  ain sockets in b
-00001d30: 6163 6b75 7970 2073 6f75 7263 6520 2222  ackuyp source ""
-00001d40: 220a 2020 2020 736f 636b 5f70 6174 6820  ".    sock_path 
-00001d50: 3d20 6f73 2e70 6174 682e 6a6f 696e 285f  = os.path.join(_
-00001d60: 7275 6e74 6573 745f 6469 722c 2075 2274  runtest_dir, u"t
-00001d70: 6573 7466 696c 6573 2f76 6172 696f 7573  estfiles/various
-00001d80: 5f66 696c 655f 7479 7065 732f 736f 636b  _file_types/sock
-00001d90: 6574 2229 0a0a 2020 2020 6465 6620 7365  et")..    def se
-00001da0: 7455 7028 7365 6c66 293a 0a20 2020 2020  tUp(self):.     
-00001db0: 2020 2075 2222 2220 6361 6e27 7420 7075     u""" can't pu
-00001dc0: 7420 6120 736f 636b 6574 2069 6e74 6f20  t a socket into 
-00001dd0: 7465 7374 6669 6c65 732e 7461 722e 677a  testfiles.tar.gz
-00001de0: 2022 2222 0a20 2020 2020 2020 2073 7570   """.        sup
-00001df0: 6572 2854 6573 7453 6b69 7053 6f63 6b65  er(TestSkipSocke
-00001e00: 742c 2073 656c 6629 2e73 6574 5570 2829  t, self).setUp()
-00001e10: 0a20 2020 2020 2020 2069 6620 6f73 2e70  .        if os.p
-00001e20: 6174 682e 6578 6973 7473 2873 656c 662e  ath.exists(self.
-00001e30: 736f 636b 5f70 6174 6829 3a0a 2020 2020  sock_path):.    
-00001e40: 2020 2020 2020 2020 6f73 2e75 6e6c 696e          os.unlin
-00001e50: 6b28 7365 6c66 2e73 6f63 6b5f 7061 7468  k(self.sock_path
-00001e60: 290a 2020 2020 2020 2020 736f 636b 203d  ).        sock =
-00001e70: 2073 6f63 6b65 742e 736f 636b 6574 2873   socket.socket(s
-00001e80: 6f63 6b65 742e 4146 5f55 4e49 5829 0a20  ocket.AF_UNIX). 
-00001e90: 2020 2020 2020 2073 6f63 6b2e 6269 6e64         sock.bind
-00001ea0: 2873 656c 662e 736f 636b 5f70 6174 6829  (self.sock_path)
-00001eb0: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
-00001ec0: 7365 7274 5472 7565 2873 7461 742e 535f  sertTrue(stat.S_
-00001ed0: 4953 534f 434b 286f 732e 7374 6174 2873  ISSOCK(os.stat(s
-00001ee0: 656c 662e 736f 636b 5f70 6174 6829 2e73  elf.sock_path).s
-00001ef0: 745f 6d6f 6465 2929 0a0a 2020 2020 7522  t_mode))..    u"
-00001f00: 2222 2043 6865 636b 2073 6f63 6b65 7473  "" Check sockets
-00001f10: 2061 7265 2073 6b69 7070 6564 2077 6865   are skipped whe
-00001f20: 6e20 7363 616e 6e65 6420 6f75 7420 6e6f  n scanned out no
-00001f30: 726d 616c 6c79 2022 2222 0a20 2020 2064  rmally """.    d
-00001f40: 6566 2074 6573 745f 736f 636b 6574 5f73  ef test_socket_s
-00001f50: 6b69 7070 6564 5f62 6163 6b75 705f 7061  kipped_backup_pa
-00001f60: 7468 2873 656c 6629 3a0a 2020 2020 2020  th(self):.      
-00001f70: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-00001f80: 6675 6c6c 222c 2075 2274 6573 7466 696c  full", u"testfil
-00001f90: 6573 2f76 6172 696f 7573 5f66 696c 655f  es/various_file_
-00001fa0: 7479 7065 732f 2229 0a20 2020 2020 2020  types/").       
-00001fb0: 2073 656c 662e 7265 7374 6f72 6528 290a   self.restore().
-00001fc0: 2020 2020 2020 2020 7265 7374 6f72 655f          restore_
-00001fd0: 6469 7220 3d20 7522 7465 7374 6669 6c65  dir = u"testfile
-00001fe0: 732f 7265 7374 6f72 655f 6f75 7422 0a20  s/restore_out". 
-00001ff0: 2020 2020 2020 2072 6573 746f 7265 6420         restored 
-00002000: 3d20 7365 6c66 2e64 6972 6563 746f 7279  = self.directory
-00002010: 5f74 7265 655f 746f 5f6c 6973 745f 6f66  _tree_to_list_of
-00002020: 5f6c 6973 7473 2872 6573 746f 7265 5f64  _lists(restore_d
-00002030: 6972 290a 2020 2020 2020 2020 7365 6c66  ir).        self
-00002040: 2e61 7373 6572 7454 7275 6528 7522 736f  .assertTrue(u"so
-00002050: 636b 6574 2220 6e6f 7420 696e 2072 6573  cket" not in res
-00002060: 746f 7265 645b 305d 290a 0a20 2020 2075  tored[0])..    u
-00002070: 2222 2220 4368 6563 6b20 736f 636b 6574  """ Check socket
-00002080: 7320 6172 6520 736b 6970 7065 6420 6966  s are skipped if
-00002090: 2066 6f75 6e64 2069 6e20 2d2d 6669 6c65   found in --file
-000020a0: 732d 6672 6f6d 206c 6973 7420 2222 220a  s-from list """.
-000020b0: 2020 2020 6465 6620 7465 7374 5f73 6f63      def test_soc
-000020c0: 6b65 745f 736b 6970 7065 645f 6669 6c65  ket_skipped_file
-000020d0: 735f 6672 6f6d 2873 656c 6629 3a0a 2020  s_from(self):.  
-000020e0: 2020 2020 2020 7769 7468 2069 6f2e 6f70        with io.op
-000020f0: 656e 2875 2274 6573 7466 696c 6573 2f66  en(u"testfiles/f
-00002100: 696c 6573 5f66 726f 6d2e 7478 7422 2c20  iles_from.txt", 
-00002110: 7522 7722 2920 6173 2066 3a0a 2020 2020  u"w") as f:.    
-00002120: 2020 2020 2020 2020 662e 7772 6974 6528          f.write(
-00002130: 7522 7661 7269 6f75 735f 6669 6c65 5f74  u"various_file_t
-00002140: 7970 6573 2f63 6861 6e67 6561 626c 655f  ypes/changeable_
-00002150: 7065 726d 6973 7369 6f6e 5c6e 220a 2020  permission\n".  
+00001830: 205b 2233 7375 6233 7375 6232 5f66 696c   ["3sub3sub2_fil
+00001840: 652e 7478 7422 5d2c 0a20 2020 2020 2020  e.txt"],.       
+00001850: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001870: 2020 2020 2020 2020 2020 205b 2274 7261             ["tra
+00001880: 696c 696e 675f 7370 6163 6520 7375 6231  iling_space sub1
+00001890: 222c 2022 7472 6169 6c69 6e67 5f73 7061  ", "trailing_spa
+000018a0: 6365 2073 7562 3222 5d2c 0a20 2020 2020  ce sub2"],.     
+000018b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000018c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000018d0: 2020 2020 2020 2020 2020 2020 205b 2274               ["t
+000018e0: 7261 696c 696e 675f 7370 6163 6520 7375  railing_space su
+000018f0: 6232 5f66 696c 652e 7478 7422 5d5d 0a0a  b2_file.txt"]]..
+00001900: 2020 2020 6465 6620 6469 7265 6374 6f72      def director
+00001910: 795f 7472 6565 5f74 6f5f 6c69 7374 5f6f  y_tree_to_list_o
+00001920: 665f 6c69 7374 7328 7365 6c66 2c20 7061  f_lists(self, pa
+00001930: 7265 6e74 5f64 6972 6563 746f 7279 293a  rent_directory):
+00001940: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00001950: 2020 2020 2054 6869 7320 7461 6b65 7320       This takes 
+00001960: 6120 666f 6c64 6572 2061 7320 616e 2069  a folder as an i
+00001970: 6e70 7574 2061 6e64 2072 6574 7572 6e73  nput and returns
+00001980: 2061 206c 6973 7420 7769 7468 2069 7473   a list with its
+00001990: 2063 6f6e 7465 6e74 732e 2049 6620 7468   contents. If th
+000019a0: 6520 6469 7265 6374 6f72 7920 6861 7320  e directory has 
+000019b0: 7375 6264 6972 6563 746f 7269 6573 2c20  subdirectories, 
+000019c0: 6974 0a20 2020 2020 2020 2072 6574 7572  it.        retur
+000019d0: 6e73 2061 206c 6973 7420 6f66 206c 6973  ns a list of lis
+000019e0: 7473 2077 6974 6820 7468 6520 636f 6e74  ts with the cont
+000019f0: 656e 7473 206f 6620 7468 6f73 6520 7375  ents of those su
+00001a00: 6264 6972 6563 746f 7269 6573 2e0a 2020  bdirectories..  
+00001a10: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
+00001a20: 2020 6469 7265 6374 6f72 795f 6c69 7374    directory_list
+00001a30: 203d 205b 5d0a 2020 2020 2020 2020 666f   = [].        fo
+00001a40: 7220 726f 6f74 2c20 6469 7273 2c20 6669  r root, dirs, fi
+00001a50: 6c65 7320 696e 206f 732e 7761 6c6b 2870  les in os.walk(p
+00001a60: 6172 656e 745f 6469 7265 6374 6f72 7929  arent_directory)
+00001a70: 3a0a 2020 2020 2020 2020 2020 2020 746f  :.            to
+00001a80: 5f61 6464 203d 205b 5d0a 2020 2020 2020  _add = [].      
+00001a90: 2020 2020 2020 6966 2064 6972 733a 0a20        if dirs:. 
+00001aa0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00001ab0: 6972 732e 736f 7274 2829 2020 2320 536f  irs.sort()  # So
+00001ac0: 2074 6861 7420 7765 2063 616e 2065 6173   that we can eas
+00001ad0: 696c 7920 636f 6d70 6172 6520 746f 2077  ily compare to w
+00001ae0: 6861 7420 7765 2065 7870 6563 740a 2020  hat we expect.  
+00001af0: 2020 2020 2020 2020 2020 2020 2020 746f                to
+00001b00: 5f61 6464 203d 2064 6972 730a 2020 2020  _add = dirs.    
+00001b10: 2020 2020 2020 2020 6966 2066 696c 6573          if files
+00001b20: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00001b30: 2020 6669 6c65 732e 736f 7274 2829 2020    files.sort()  
+00001b40: 2320 536f 2074 6861 7420 7765 2063 616e  # So that we can
+00001b50: 2065 6173 696c 7920 636f 6d70 6172 6520   easily compare 
+00001b60: 746f 2077 6861 7420 7765 2065 7870 6563  to what we expec
+00001b70: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
+00001b80: 2020 746f 5f61 6464 202b 3d20 6669 6c65    to_add += file
+00001b90: 730a 2020 2020 2020 2020 2020 2020 6966  s.            if
+00001ba0: 2074 6f5f 6164 643a 0a20 2020 2020 2020   to_add:.       
+00001bb0: 2020 2020 2020 2020 2064 6972 6563 746f           directo
+00001bc0: 7279 5f6c 6973 742e 6170 7065 6e64 2874  ry_list.append(t
+00001bd0: 6f5f 6164 6429 0a20 2020 2020 2020 2072  o_add).        r
+00001be0: 6574 7572 6e20 6469 7265 6374 6f72 795f  eturn directory_
+00001bf0: 6c69 7374 0a0a 0a63 6c61 7373 2054 6573  list...class Tes
+00001c00: 7453 6b69 7053 6f63 6b65 7428 496e 636c  tSkipSocket(Incl
+00001c10: 7564 6545 7863 6c75 6465 4675 6e63 7469  udeExcludeFuncti
+00001c20: 6f6e 616c 5465 7374 293a 0a20 2020 2022  onalTest):.    "
+00001c30: 2222 2054 6573 7473 2063 6f72 7265 6374  "" Tests correct
+00001c40: 2068 616e 646c 696e 6720 6f66 2075 6e69   handling of uni
+00001c50: 7820 646f 6d61 696e 2073 6f63 6b65 7473  x domain sockets
+00001c60: 2069 6e20 6261 636b 7579 7020 736f 7572   in backuyp sour
+00001c70: 6365 2022 2222 0a20 2020 2073 6f63 6b5f  ce """.    sock_
+00001c80: 7061 7468 203d 206f 732e 7061 7468 2e6a  path = os.path.j
+00001c90: 6f69 6e28 5f72 756e 7465 7374 5f64 6972  oin(_runtest_dir
+00001ca0: 2c20 2274 6573 7466 696c 6573 2f76 6172  , "testfiles/var
+00001cb0: 696f 7573 5f66 696c 655f 7479 7065 732f  ious_file_types/
+00001cc0: 736f 636b 6574 2229 0a0a 2020 2020 6465  socket")..    de
+00001cd0: 6620 7365 7455 7028 7365 6c66 293a 0a20  f setUp(self):. 
+00001ce0: 2020 2020 2020 2022 2222 2063 616e 2774         """ can't
+00001cf0: 2070 7574 2061 2073 6f63 6b65 7420 696e   put a socket in
+00001d00: 746f 2074 6573 7466 696c 6573 2e74 6172  to testfiles.tar
+00001d10: 2e67 7a20 2222 220a 2020 2020 2020 2020  .gz """.        
+00001d20: 7375 7065 7228 5465 7374 536b 6970 536f  super(TestSkipSo
+00001d30: 636b 6574 2c20 7365 6c66 292e 7365 7455  cket, self).setU
+00001d40: 7028 290a 2020 2020 2020 2020 6966 206f  p().        if o
+00001d50: 732e 7061 7468 2e65 7869 7374 7328 7365  s.path.exists(se
+00001d60: 6c66 2e73 6f63 6b5f 7061 7468 293a 0a20  lf.sock_path):. 
+00001d70: 2020 2020 2020 2020 2020 206f 732e 756e             os.un
+00001d80: 6c69 6e6b 2873 656c 662e 736f 636b 5f70  link(self.sock_p
+00001d90: 6174 6829 0a20 2020 2020 2020 2073 6f63  ath).        soc
+00001da0: 6b20 3d20 736f 636b 6574 2e73 6f63 6b65  k = socket.socke
+00001db0: 7428 736f 636b 6574 2e41 465f 554e 4958  t(socket.AF_UNIX
+00001dc0: 290a 2020 2020 2020 2020 736f 636b 2e62  ).        sock.b
+00001dd0: 696e 6428 7365 6c66 2e73 6f63 6b5f 7061  ind(self.sock_pa
+00001de0: 7468 290a 2020 2020 2020 2020 7365 6c66  th).        self
+00001df0: 2e61 7373 6572 7454 7275 6528 7374 6174  .assertTrue(stat
+00001e00: 2e53 5f49 5353 4f43 4b28 6f73 2e73 7461  .S_ISSOCK(os.sta
+00001e10: 7428 7365 6c66 2e73 6f63 6b5f 7061 7468  t(self.sock_path
+00001e20: 292e 7374 5f6d 6f64 6529 290a 0a20 2020  ).st_mode))..   
+00001e30: 2022 2222 2043 6865 636b 2073 6f63 6b65   """ Check socke
+00001e40: 7473 2061 7265 2073 6b69 7070 6564 2077  ts are skipped w
+00001e50: 6865 6e20 7363 616e 6e65 6420 6f75 7420  hen scanned out 
+00001e60: 6e6f 726d 616c 6c79 2022 2222 0a0a 2020  normally """..  
+00001e70: 2020 6465 6620 7465 7374 5f73 6f63 6b65    def test_socke
+00001e80: 745f 736b 6970 7065 645f 6261 636b 7570  t_skipped_backup
+00001e90: 5f70 6174 6828 7365 6c66 293a 0a20 2020  _path(self):.   
+00001ea0: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
+00001eb0: 2822 6675 6c6c 222c 2022 7465 7374 6669  ("full", "testfi
+00001ec0: 6c65 732f 7661 7269 6f75 735f 6669 6c65  les/various_file
+00001ed0: 5f74 7970 6573 2f22 290a 2020 2020 2020  _types/").      
+00001ee0: 2020 7365 6c66 2e72 6573 746f 7265 2829    self.restore()
+00001ef0: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+00001f00: 5f64 6972 203d 2022 7465 7374 6669 6c65  _dir = "testfile
+00001f10: 732f 7265 7374 6f72 655f 6f75 7422 0a20  s/restore_out". 
+00001f20: 2020 2020 2020 2072 6573 746f 7265 6420         restored 
+00001f30: 3d20 7365 6c66 2e64 6972 6563 746f 7279  = self.directory
+00001f40: 5f74 7265 655f 746f 5f6c 6973 745f 6f66  _tree_to_list_of
+00001f50: 5f6c 6973 7473 2872 6573 746f 7265 5f64  _lists(restore_d
+00001f60: 6972 290a 2020 2020 2020 2020 7365 6c66  ir).        self
+00001f70: 2e61 7373 6572 7454 7275 6528 2273 6f63  .assertTrue("soc
+00001f80: 6b65 7422 206e 6f74 2069 6e20 7265 7374  ket" not in rest
+00001f90: 6f72 6564 5b30 5d29 0a0a 2020 2020 2222  ored[0])..    ""
+00001fa0: 2220 4368 6563 6b20 736f 636b 6574 7320  " Check sockets 
+00001fb0: 6172 6520 736b 6970 7065 6420 6966 2066  are skipped if f
+00001fc0: 6f75 6e64 2069 6e20 2d2d 6669 6c65 732d  ound in --files-
+00001fd0: 6672 6f6d 206c 6973 7420 2222 220a 0a20  from list """.. 
+00001fe0: 2020 2064 6566 2074 6573 745f 736f 636b     def test_sock
+00001ff0: 6574 5f73 6b69 7070 6564 5f66 696c 6573  et_skipped_files
+00002000: 5f66 726f 6d28 7365 6c66 293a 0a20 2020  _from(self):.   
+00002010: 2020 2020 2077 6974 6820 696f 2e6f 7065       with io.ope
+00002020: 6e28 2274 6573 7466 696c 6573 2f66 696c  n("testfiles/fil
+00002030: 6573 5f66 726f 6d2e 7478 7422 2c20 2277  es_from.txt", "w
+00002040: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
+00002050: 2020 2020 2066 2e77 7269 7465 2822 7661       f.write("va
+00002060: 7269 6f75 735f 6669 6c65 5f74 7970 6573  rious_file_types
+00002070: 2f63 6861 6e67 6561 626c 655f 7065 726d  /changeable_perm
+00002080: 6973 7369 6f6e 5c6e 220a 2020 2020 2020  ission\n".      
+00002090: 2020 2020 2020 2020 2020 2020 2020 2276                "v
+000020a0: 6172 696f 7573 5f66 696c 655f 7479 7065  arious_file_type
+000020b0: 732f 6578 6563 7574 6162 6c65 5c6e 220a  s/executable\n".
+000020c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000020d0: 2020 2020 2276 6172 696f 7573 5f66 696c      "various_fil
+000020e0: 655f 7479 7065 732f 6578 6563 7574 6162  e_types/executab
+000020f0: 6c65 325c 6e22 0a20 2020 2020 2020 2020  le2\n".         
+00002100: 2020 2020 2020 2020 2020 2022 7661 7269             "vari
+00002110: 6f75 735f 6669 6c65 5f74 7970 6573 2f66  ous_file_types/f
+00002120: 6966 6f5c 6e22 0a20 2020 2020 2020 2020  ifo\n".         
+00002130: 2020 2020 2020 2020 2020 2022 7661 7269             "vari
+00002140: 6f75 735f 6669 6c65 5f74 7970 6573 2f72  ous_file_types/r
+00002150: 6567 756c 6172 5f66 696c 655c 6e22 0a20  egular_file\n". 
 00002160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002170: 2020 7522 7661 7269 6f75 735f 6669 6c65    u"various_file
-00002180: 5f74 7970 6573 2f65 7865 6375 7461 626c  _types/executabl
-00002190: 655c 6e22 0a20 2020 2020 2020 2020 2020  e\n".           
-000021a0: 2020 2020 2020 2020 2075 2276 6172 696f           u"vario
-000021b0: 7573 5f66 696c 655f 7479 7065 732f 6578  us_file_types/ex
-000021c0: 6563 7574 6162 6c65 325c 6e22 0a20 2020  ecutable2\n".   
-000021d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000021e0: 2075 2276 6172 696f 7573 5f66 696c 655f   u"various_file_
-000021f0: 7479 7065 732f 6669 666f 5c6e 220a 2020  types/fifo\n".  
-00002200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002210: 2020 7522 7661 7269 6f75 735f 6669 6c65    u"various_file
-00002220: 5f74 7970 6573 2f72 6567 756c 6172 5f66  _types/regular_f
-00002230: 696c 655c 6e22 0a20 2020 2020 2020 2020  ile\n".         
-00002240: 2020 2020 2020 2020 2020 2075 2276 6172             u"var
-00002250: 696f 7573 5f66 696c 655f 7479 7065 732f  ious_file_types/
-00002260: 7265 6775 6c61 725f 6669 6c65 2e73 6967  regular_file.sig
-00002270: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-00002280: 2020 2020 2020 2020 7522 7661 7269 6f75          u"variou
-00002290: 735f 6669 6c65 5f74 7970 6573 2f73 796d  s_file_types/sym
-000022a0: 626f 6c69 635f 6c69 6e6b 5c6e 220a 2020  bolic_link\n".  
-000022b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000022c0: 2020 7522 7661 7269 6f75 735f 6669 6c65    u"various_file
-000022d0: 5f74 7970 6573 2f73 6f63 6b65 745c 6e22  _types/socket\n"
-000022e0: 2020 2023 204d 7573 7420 6d61 7463 6820     # Must match 
-000022f0: 7365 6c66 2e73 6f63 6b5f 7061 7468 2061  self.sock_path a
-00002300: 626f 7665 210a 2020 2020 2020 2020 2020  bove!.          
-00002310: 2020 2020 2020 2020 2020 7522 7661 7269            u"vari
-00002320: 6f75 735f 6669 6c65 5f74 7970 6573 2f74  ous_file_types/t
-00002330: 6573 745c 6e22 0a20 2020 2020 2020 2020  est\n".         
-00002340: 2020 2020 2020 2020 2020 2075 2276 6172             u"var
-00002350: 696f 7573 5f66 696c 655f 7479 7065 732f  ious_file_types/
-00002360: 7477 6f5f 6861 7264 6c69 6e6b 6564 5f66  two_hardlinked_f
-00002370: 696c 6573 315c 6e22 0a20 2020 2020 2020  iles1\n".       
-00002380: 2020 2020 2020 2020 2020 2020 2075 2276               u"v
-00002390: 6172 696f 7573 5f66 696c 655f 7479 7065  arious_file_type
-000023a0: 732f 7477 705f 6861 7264 6c69 6e6b 6564  s/twp_hardlinked
-000023b0: 5f66 696c 6573 3222 290a 2020 2020 2020  _files2").      
-000023c0: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-000023d0: 6675 6c6c 222c 2075 2274 6573 7466 696c  full", u"testfil
-000023e0: 6573 222c 0a20 2020 2020 2020 2020 2020  es",.           
-000023f0: 2020 2020 2020 2020 206f 7074 696f 6e73           options
-00002400: 3d5b 7522 2d2d 6669 6c65 732d 6672 6f6d  =[u"--files-from
-00002410: 222c 2075 2274 6573 7466 696c 6573 2f66  ", u"testfiles/f
-00002420: 696c 6573 5f66 726f 6d2e 7478 7422 5d29  iles_from.txt"])
-00002430: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-00002440: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
-00002450: 7265 7374 6f72 655f 6469 7220 3d20 7522  restore_dir = u"
-00002460: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
-00002470: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
-00002480: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
-00002490: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
-000024a0: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
-000024b0: 6573 746f 7265 5f64 6972 290a 2020 2020  estore_dir).    
-000024c0: 2020 2020 7365 6c66 2e61 7373 6572 7454      self.assertT
-000024d0: 7275 6528 7522 736f 636b 6574 2220 6e6f  rue(u"socket" no
-000024e0: 7420 696e 2072 6573 746f 7265 645b 305d  t in restored[0]
-000024f0: 290a 0a20 2020 2075 2222 2220 4368 6563  )..    u""" Chec
-00002500: 6b20 736f 636b 6574 7320 6172 6520 736b  k sockets are sk
-00002510: 6970 7065 6420 6966 2066 6f75 6e64 2069  ipped if found i
-00002520: 6e20 2d2d 696e 636c 7564 652d 6669 6c65  n --include-file
-00002530: 6c69 7374 206c 6973 7420 2222 220a 2020  list list """.  
-00002540: 2020 6465 6620 7465 7374 5f73 6f63 6b65    def test_socke
-00002550: 745f 736b 6970 7065 645f 696e 636c 7564  t_skipped_includ
-00002560: 655f 6669 6c65 6c69 7374 2873 656c 6629  e_filelist(self)
-00002570: 3a0a 2020 2020 2020 2020 7769 7468 2069  :.        with i
-00002580: 6f2e 6f70 656e 2875 2274 6573 7466 696c  o.open(u"testfil
-00002590: 6573 2f69 6e63 6c75 6465 2e74 7874 222c  es/include.txt",
-000025a0: 2075 2277 2229 2061 7320 663a 0a20 2020   u"w") as f:.   
-000025b0: 2020 2020 2020 2020 2066 2e77 7269 7465           f.write
-000025c0: 2875 2274 6573 7466 696c 6573 2f22 290a  (u"testfiles/").
-000025d0: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
-000025e0: 6b75 7028 7522 6675 6c6c 222c 2075 2274  kup(u"full", u"t
-000025f0: 6573 7466 696c 6573 2f76 6172 696f 7573  estfiles/various
-00002600: 5f66 696c 655f 7479 7065 732f 222c 0a20  _file_types/",. 
-00002610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002620: 2020 206f 7074 696f 6e73 3d5b 7522 2d2d     options=[u"--
-00002630: 696e 636c 7564 652d 6669 6c65 6c69 7374  include-filelist
-00002640: 222c 2075 2274 6573 7466 696c 6573 2f69  ", u"testfiles/i
-00002650: 6e63 6c75 6465 2e74 7874 222c 0a20 2020  nclude.txt",.   
-00002660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002670: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-00002680: 636c 7564 6522 2c20 7522 7465 7374 6669  clude", u"testfi
-00002690: 6c65 7322 5d29 0a20 2020 2020 2020 2073  les"]).        s
-000026a0: 656c 662e 7265 7374 6f72 6528 290a 2020  elf.restore().  
-000026b0: 2020 2020 2020 7265 7374 6f72 655f 6469        restore_di
-000026c0: 7220 3d20 7522 7465 7374 6669 6c65 732f  r = u"testfiles/
-000026d0: 7265 7374 6f72 655f 6f75 7422 0a20 2020  restore_out".   
-000026e0: 2020 2020 2072 6573 746f 7265 6420 3d20       restored = 
-000026f0: 7365 6c66 2e64 6972 6563 746f 7279 5f74  self.directory_t
-00002700: 7265 655f 746f 5f6c 6973 745f 6f66 5f6c  ree_to_list_of_l
-00002710: 6973 7473 2872 6573 746f 7265 5f64 6972  ists(restore_dir
-00002720: 290a 2020 2020 2020 2020 7365 6c66 2e61  ).        self.a
-00002730: 7373 6572 7454 7275 6528 7522 736f 636b  ssertTrue(u"sock
-00002740: 6574 2220 6e6f 7420 696e 2072 6573 746f  et" not in resto
-00002750: 7265 645b 305d 290a 0a0a 636c 6173 7320  red[0])...class 
-00002760: 5465 7374 4368 6563 6b54 6573 7446 696c  TestCheckTestFil
-00002770: 6573 2849 6e63 6c75 6465 4578 636c 7564  es(IncludeExclud
-00002780: 6546 756e 6374 696f 6e61 6c54 6573 7429  eFunctionalTest)
-00002790: 3a0a 2020 2020 7522 2222 2054 6573 7473  :.    u""" Tests
-000027a0: 2074 6865 2074 6573 7466 696c 6573 2072   the testfiles r
-000027b0: 6571 7569 7265 6420 6279 2074 6865 2065  equired by the e
-000027c0: 7863 6c75 6465 2f69 6e63 6c75 6465 2074  xclude/include t
-000027d0: 6573 7473 2061 7265 2061 7320 6578 7065  ests are as expe
-000027e0: 6374 6564 2e20 2222 220a 0a20 2020 2064  cted. """..    d
-000027f0: 6566 2074 6573 745f 6669 6c65 735f 6172  ef test_files_ar
-00002800: 655f 6173 5f65 7870 6563 7465 6428 7365  e_as_expected(se
-00002810: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00002820: 2254 6573 7420 7468 6174 2074 6865 2063  "Test that the c
-00002830: 6f6e 7465 6e74 7320 6f66 2074 6573 7466  ontents of testf
-00002840: 696c 6573 2f73 656c 6563 7420 6172 6520  iles/select are 
-00002850: 6173 2065 7870 6563 7465 642e 2222 220a  as expected.""".
-00002860: 2020 2020 2020 2020 7465 7374 6669 6c65          testfile
-00002870: 7320 3d20 7365 6c66 2e64 6972 6563 746f  s = self.directo
-00002880: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
-00002890: 6f66 5f6c 6973 7473 2875 2274 6573 7466  of_lists(u"testf
-000028a0: 696c 6573 2f73 656c 6563 7432 2229 0a20  iles/select2"). 
-000028b0: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
-000028c0: 7274 4571 7561 6c28 7465 7374 6669 6c65  rtEqual(testfile
-000028d0: 732c 2073 656c 662e 636f 6d70 6c65 7465  s, self.complete
-000028e0: 5f64 6972 6563 746f 7279 5f74 7265 6529  _directory_tree)
-000028f0: 0a0a 0a63 6c61 7373 2054 6573 7446 696c  ...class TestFil
-00002900: 6573 4672 6f6d 2849 6e63 6c75 6465 4578  esFrom(IncludeEx
-00002910: 636c 7564 6546 756e 6374 696f 6e61 6c54  cludeFunctionalT
-00002920: 6573 7429 3a0a 2020 2020 7522 2222 2054  est):.    u""" T
-00002930: 6573 7473 2062 6568 6176 696f 7572 7320  ests behaviours 
-00002940: 7768 656e 202d 2d66 696c 6573 2d66 726f  when --files-fro
-00002950: 6d20 6973 2075 7365 6420 2222 220a 0a20  m is used """.. 
-00002960: 2020 2023 2061 6c6c 2074 6865 2066 696c     # all the fil
-00002970: 6573 2069 6e20 7465 7374 6669 6c65 732f  es in testfiles/
-00002980: 7365 6c65 6374 3220 7768 6963 6820 6172  select2 which ar
-00002990: 6520 6e61 6d65 6420 7769 7468 206e 756d  e named with num
-000029a0: 6265 7273 0a20 2020 2074 6573 7466 696c  bers.    testfil
-000029b0: 6573 5f6e 756d 6265 7273 203d 205b 7522  es_numbers = [u"
-000029c0: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-000029d0: 2020 2020 2020 2020 2020 2020 2075 2232               u"2
-000029e0: 2f32 7375 6233 222c 0a20 2020 2020 2020  /2sub3",.       
-000029f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a00: 2020 7522 322f 3273 7562 332f 3273 7562    u"2/2sub3/2sub
-00002a10: 3373 7562 3222 2c0a 2020 2020 2020 2020  3sub2",.        
-00002a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a30: 2075 2232 2f32 7375 6233 2f32 7375 6233   u"2/2sub3/2sub3
-00002a40: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
-00002a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a60: 7522 322f 3273 7562 332f 3273 7562 3373  u"2/2sub3/2sub3s
-00002a70: 7562 3322 2c0a 2020 2020 2020 2020 2020  ub3",.          
-00002a80: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00002a90: 2232 2f32 7375 6231 222c 0a20 2020 2020  "2/2sub1",.     
-00002aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ab0: 2020 2020 7522 322f 3273 7562 312f 3273      u"2/2sub1/2s
-00002ac0: 7562 3173 7562 3322 2c0a 2020 2020 2020  ub1sub3",.      
-00002ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ae0: 2020 2075 2232 2f32 7375 6231 2f32 7375     u"2/2sub1/2su
-00002af0: 6231 7375 6232 222c 0a20 2020 2020 2020  b1sub2",.       
-00002b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b10: 2020 7522 322f 3273 7562 312f 3273 7562    u"2/2sub1/2sub
-00002b20: 3173 7562 3122 2c0a 2020 2020 2020 2020  1sub1",.        
-00002b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b40: 2075 2232 2f32 7375 6231 2f32 7375 6231   u"2/2sub1/2sub1
-00002b50: 7375 6231 2f32 7375 6231 7375 6231 5f66  sub1/2sub1sub1_f
-00002b60: 696c 652e 7478 7422 2c0a 2020 2020 2020  ile.txt",.      
-00002b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b80: 2020 2075 2232 2f32 7375 6232 222c 0a20     u"2/2sub2",. 
-00002b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ba0: 2020 2020 2020 2020 7522 322f 3273 7562          u"2/2sub
-00002bb0: 322f 3273 7562 3273 7562 3322 2c0a 2020  2/2sub2sub3",.  
-00002bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002bd0: 2020 2020 2020 2075 2232 2f32 7375 6232         u"2/2sub2
-00002be0: 2f32 7375 6232 7375 6231 222c 0a20 2020  /2sub2sub1",.   
-00002bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c00: 2020 2020 2020 7522 322f 3273 7562 322f        u"2/2sub2/
-00002c10: 3273 7562 3273 7562 3222 2c0a 2020 2020  2sub2sub2",.    
-00002c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c30: 2020 2020 2075 2231 2e64 6f63 222c 0a20       u"1.doc",. 
-00002c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c50: 2020 2020 2020 2020 7522 312e 7079 222c          u"1.py",
-00002c60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002c70: 2020 2020 2020 2020 2020 7522 3122 2c0a            u"1",.
+00002170: 2020 2022 7661 7269 6f75 735f 6669 6c65     "various_file
+00002180: 5f74 7970 6573 2f72 6567 756c 6172 5f66  _types/regular_f
+00002190: 696c 652e 7369 675c 6e22 0a20 2020 2020  ile.sig\n".     
+000021a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000021b0: 7661 7269 6f75 735f 6669 6c65 5f74 7970  various_file_typ
+000021c0: 6573 2f73 796d 626f 6c69 635f 6c69 6e6b  es/symbolic_link
+000021d0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+000021e0: 2020 2020 2020 2020 2276 6172 696f 7573          "various
+000021f0: 5f66 696c 655f 7479 7065 732f 736f 636b  _file_types/sock
+00002200: 6574 5c6e 2220 2023 204d 7573 7420 6d61  et\n"  # Must ma
+00002210: 7463 6820 7365 6c66 2e73 6f63 6b5f 7061  tch self.sock_pa
+00002220: 7468 2061 626f 7665 210a 2020 2020 2020  th above!.      
+00002230: 2020 2020 2020 2020 2020 2020 2020 2276                "v
+00002240: 6172 696f 7573 5f66 696c 655f 7479 7065  arious_file_type
+00002250: 732f 7465 7374 5c6e 220a 2020 2020 2020  s/test\n".      
+00002260: 2020 2020 2020 2020 2020 2020 2020 2276                "v
+00002270: 6172 696f 7573 5f66 696c 655f 7479 7065  arious_file_type
+00002280: 732f 7477 6f5f 6861 7264 6c69 6e6b 6564  s/two_hardlinked
+00002290: 5f66 696c 6573 315c 6e22 0a20 2020 2020  _files1\n".     
+000022a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000022b0: 7661 7269 6f75 735f 6669 6c65 5f74 7970  various_file_typ
+000022c0: 6573 2f74 7770 5f68 6172 646c 696e 6b65  es/twp_hardlinke
+000022d0: 645f 6669 6c65 7332 2229 0a20 2020 2020  d_files2").     
+000022e0: 2020 2073 656c 662e 6261 636b 7570 2822     self.backup("
+000022f0: 6675 6c6c 222c 2022 7465 7374 6669 6c65  full", "testfile
+00002300: 7322 2c0a 2020 2020 2020 2020 2020 2020  s",.            
+00002310: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
+00002320: 5b22 2d2d 6669 6c65 732d 6672 6f6d 222c  ["--files-from",
+00002330: 2022 7465 7374 6669 6c65 732f 6669 6c65   "testfiles/file
+00002340: 735f 6672 6f6d 2e74 7874 225d 290a 2020  s_from.txt"]).  
+00002350: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
+00002360: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
+00002370: 746f 7265 5f64 6972 203d 2022 7465 7374  tore_dir = "test
+00002380: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
+00002390: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
+000023a0: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
+000023b0: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
+000023c0: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
+000023d0: 7265 5f64 6972 290a 2020 2020 2020 2020  re_dir).        
+000023e0: 7365 6c66 2e61 7373 6572 7454 7275 6528  self.assertTrue(
+000023f0: 2273 6f63 6b65 7422 206e 6f74 2069 6e20  "socket" not in 
+00002400: 7265 7374 6f72 6564 5b30 5d29 0a0a 2020  restored[0])..  
+00002410: 2020 2222 2220 4368 6563 6b20 736f 636b    """ Check sock
+00002420: 6574 7320 6172 6520 736b 6970 7065 6420  ets are skipped 
+00002430: 6966 2066 6f75 6e64 2069 6e20 2d2d 696e  if found in --in
+00002440: 636c 7564 652d 6669 6c65 6c69 7374 206c  clude-filelist l
+00002450: 6973 7420 2222 220a 0a20 2020 2064 6566  ist """..    def
+00002460: 2074 6573 745f 736f 636b 6574 5f73 6b69   test_socket_ski
+00002470: 7070 6564 5f69 6e63 6c75 6465 5f66 696c  pped_include_fil
+00002480: 656c 6973 7428 7365 6c66 293a 0a20 2020  elist(self):.   
+00002490: 2020 2020 2077 6974 6820 696f 2e6f 7065       with io.ope
+000024a0: 6e28 2274 6573 7466 696c 6573 2f69 6e63  n("testfiles/inc
+000024b0: 6c75 6465 2e74 7874 222c 2022 7722 2920  lude.txt", "w") 
+000024c0: 6173 2066 3a0a 2020 2020 2020 2020 2020  as f:.          
+000024d0: 2020 662e 7772 6974 6528 2274 6573 7466    f.write("testf
+000024e0: 696c 6573 2f22 290a 2020 2020 2020 2020  iles/").        
+000024f0: 7365 6c66 2e62 6163 6b75 7028 2266 756c  self.backup("ful
+00002500: 6c22 2c20 2274 6573 7466 696c 6573 2f76  l", "testfiles/v
+00002510: 6172 696f 7573 5f66 696c 655f 7479 7065  arious_file_type
+00002520: 732f 222c 0a20 2020 2020 2020 2020 2020  s/",.           
+00002530: 2020 2020 2020 2020 206f 7074 696f 6e73           options
+00002540: 3d5b 222d 2d69 6e63 6c75 6465 2d66 696c  =["--include-fil
+00002550: 656c 6973 7422 2c20 2274 6573 7466 696c  elist", "testfil
+00002560: 6573 2f69 6e63 6c75 6465 2e74 7874 222c  es/include.txt",
+00002570: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002580: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00002590: 2d65 7863 6c75 6465 222c 2022 7465 7374  -exclude", "test
+000025a0: 6669 6c65 7322 5d29 0a20 2020 2020 2020  files"]).       
+000025b0: 2073 656c 662e 7265 7374 6f72 6528 290a   self.restore().
+000025c0: 2020 2020 2020 2020 7265 7374 6f72 655f          restore_
+000025d0: 6469 7220 3d20 2274 6573 7466 696c 6573  dir = "testfiles
+000025e0: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
+000025f0: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
+00002600: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
+00002610: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
+00002620: 6c69 7374 7328 7265 7374 6f72 655f 6469  lists(restore_di
+00002630: 7229 0a20 2020 2020 2020 2073 656c 662e  r).        self.
+00002640: 6173 7365 7274 5472 7565 2822 736f 636b  assertTrue("sock
+00002650: 6574 2220 6e6f 7420 696e 2072 6573 746f  et" not in resto
+00002660: 7265 645b 305d 290a 0a0a 636c 6173 7320  red[0])...class 
+00002670: 5465 7374 4368 6563 6b54 6573 7446 696c  TestCheckTestFil
+00002680: 6573 2849 6e63 6c75 6465 4578 636c 7564  es(IncludeExclud
+00002690: 6546 756e 6374 696f 6e61 6c54 6573 7429  eFunctionalTest)
+000026a0: 3a0a 2020 2020 2222 2220 5465 7374 7320  :.    """ Tests 
+000026b0: 7468 6520 7465 7374 6669 6c65 7320 7265  the testfiles re
+000026c0: 7175 6972 6564 2062 7920 7468 6520 6578  quired by the ex
+000026d0: 636c 7564 652f 696e 636c 7564 6520 7465  clude/include te
+000026e0: 7374 7320 6172 6520 6173 2065 7870 6563  sts are as expec
+000026f0: 7465 642e 2022 2222 0a0a 2020 2020 6465  ted. """..    de
+00002700: 6620 7465 7374 5f66 696c 6573 5f61 7265  f test_files_are
+00002710: 5f61 735f 6578 7065 6374 6564 2873 656c  _as_expected(sel
+00002720: 6629 3a0a 2020 2020 2020 2020 2222 2254  f):.        """T
+00002730: 6573 7420 7468 6174 2074 6865 2063 6f6e  est that the con
+00002740: 7465 6e74 7320 6f66 2074 6573 7466 696c  tents of testfil
+00002750: 6573 2f73 656c 6563 7420 6172 6520 6173  es/select are as
+00002760: 2065 7870 6563 7465 642e 2222 220a 2020   expected.""".  
+00002770: 2020 2020 2020 7465 7374 6669 6c65 7320        testfiles 
+00002780: 3d20 7365 6c66 2e64 6972 6563 746f 7279  = self.directory
+00002790: 5f74 7265 655f 746f 5f6c 6973 745f 6f66  _tree_to_list_of
+000027a0: 5f6c 6973 7473 2822 7465 7374 6669 6c65  _lists("testfile
+000027b0: 732f 7365 6c65 6374 3222 290a 2020 2020  s/select2").    
+000027c0: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
+000027d0: 7175 616c 2874 6573 7466 696c 6573 2c20  qual(testfiles, 
+000027e0: 7365 6c66 2e63 6f6d 706c 6574 655f 6469  self.complete_di
+000027f0: 7265 6374 6f72 795f 7472 6565 290a 0a0a  rectory_tree)...
+00002800: 636c 6173 7320 5465 7374 4669 6c65 7346  class TestFilesF
+00002810: 726f 6d28 496e 636c 7564 6545 7863 6c75  rom(IncludeExclu
+00002820: 6465 4675 6e63 7469 6f6e 616c 5465 7374  deFunctionalTest
+00002830: 293a 0a20 2020 2022 2222 2054 6573 7473  ):.    """ Tests
+00002840: 2062 6568 6176 696f 7572 7320 7768 656e   behaviours when
+00002850: 202d 2d66 696c 6573 2d66 726f 6d20 6973   --files-from is
+00002860: 2075 7365 6420 2222 220a 0a20 2020 2023   used """..    #
+00002870: 2061 6c6c 2074 6865 2066 696c 6573 2069   all the files i
+00002880: 6e20 7465 7374 6669 6c65 732f 7365 6c65  n testfiles/sele
+00002890: 6374 3220 7768 6963 6820 6172 6520 6e61  ct2 which are na
+000028a0: 6d65 6420 7769 7468 206e 756d 6265 7273  med with numbers
+000028b0: 0a20 2020 2074 6573 7466 696c 6573 5f6e  .    testfiles_n
+000028c0: 756d 6265 7273 203d 205b 2232 222c 0a20  umbers = ["2",. 
+000028d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000028e0: 2020 2020 2020 2020 2232 2f32 7375 6233          "2/2sub3
+000028f0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00002900: 2020 2020 2020 2020 2020 2020 2232 2f32              "2/2
+00002910: 7375 6233 2f32 7375 6233 7375 6232 222c  sub3/2sub3sub2",
+00002920: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002930: 2020 2020 2020 2020 2020 2232 2f32 7375            "2/2su
+00002940: 6233 2f32 7375 6233 7375 6231 222c 0a20  b3/2sub3sub1",. 
+00002950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002960: 2020 2020 2020 2020 2232 2f32 7375 6233          "2/2sub3
+00002970: 2f32 7375 6233 7375 6233 222c 0a20 2020  /2sub3sub3",.   
+00002980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002990: 2020 2020 2020 2232 2f32 7375 6231 222c        "2/2sub1",
+000029a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000029b0: 2020 2020 2020 2020 2020 2232 2f32 7375            "2/2su
+000029c0: 6231 2f32 7375 6231 7375 6233 222c 0a20  b1/2sub1sub3",. 
+000029d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029e0: 2020 2020 2020 2020 2232 2f32 7375 6231          "2/2sub1
+000029f0: 2f32 7375 6231 7375 6232 222c 0a20 2020  /2sub1sub2",.   
+00002a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002a10: 2020 2020 2020 2232 2f32 7375 6231 2f32        "2/2sub1/2
+00002a20: 7375 6231 7375 6231 222c 0a20 2020 2020  sub1sub1",.     
+00002a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002a40: 2020 2020 2232 2f32 7375 6231 2f32 7375      "2/2sub1/2su
+00002a50: 6231 7375 6231 2f32 7375 6231 7375 6231  b1sub1/2sub1sub1
+00002a60: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
+00002a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002a80: 2020 2020 2022 322f 3273 7562 3222 2c0a       "2/2sub2",.
+00002a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002aa0: 2020 2020 2020 2020 2022 322f 3273 7562           "2/2sub
+00002ab0: 322f 3273 7562 3273 7562 3322 2c0a 2020  2/2sub2sub3",.  
+00002ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ad0: 2020 2020 2020 2022 322f 3273 7562 322f         "2/2sub2/
+00002ae0: 3273 7562 3273 7562 3122 2c0a 2020 2020  2sub2sub1",.    
+00002af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b00: 2020 2020 2022 322f 3273 7562 322f 3273       "2/2sub2/2s
+00002b10: 7562 3273 7562 3222 2c0a 2020 2020 2020  ub2sub2",.      
+00002b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b30: 2020 2022 312e 646f 6322 2c0a 2020 2020     "1.doc",.    
+00002b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b50: 2020 2020 2022 312e 7079 222c 0a20 2020       "1.py",.   
+00002b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b70: 2020 2020 2020 2231 222c 0a20 2020 2020        "1",.     
+00002b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002b90: 2020 2020 2231 2f31 7375 6233 222c 0a20      "1/1sub3",. 
+00002ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002bb0: 2020 2020 2020 2020 2231 2f31 7375 6233          "1/1sub3
+00002bc0: 2f31 7375 6233 7375 6232 222c 0a20 2020  /1sub3sub2",.   
+00002bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002be0: 2020 2020 2020 2231 2f31 7375 6233 2f31        "1/1sub3/1
+00002bf0: 7375 6233 7375 6231 222c 0a20 2020 2020  sub3sub1",.     
+00002c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c10: 2020 2020 2231 2f31 7375 6233 2f31 7375      "1/1sub3/1su
+00002c20: 6233 7375 6233 222c 0a20 2020 2020 2020  b3sub3",.       
+00002c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c40: 2020 2231 2f31 7375 6231 222c 0a20 2020    "1/1sub1",.   
+00002c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c60: 2020 2020 2020 2231 2f31 7375 6231 2f31        "1/1sub1/1
+00002c70: 7375 6231 7375 6232 222c 0a20 2020 2020  sub1sub2",.     
 00002c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002c90: 2020 2020 2020 2020 2075 2231 2f31 7375           u"1/1su
-00002ca0: 6233 222c 0a20 2020 2020 2020 2020 2020  b3",.           
-00002cb0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00002cc0: 312f 3173 7562 332f 3173 7562 3373 7562  1/1sub3/1sub3sub
-00002cd0: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-00002ce0: 2020 2020 2020 2020 2020 2020 2075 2231               u"1
-00002cf0: 2f31 7375 6233 2f31 7375 6233 7375 6231  /1sub3/1sub3sub1
-00002d00: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00002d10: 2020 2020 2020 2020 2020 2020 7522 312f              u"1/
-00002d20: 3173 7562 332f 3173 7562 3373 7562 3322  1sub3/1sub3sub3"
-00002d30: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00002d40: 2020 2020 2020 2020 2020 2075 2231 2f31             u"1/1
-00002d50: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
+00002c90: 2020 2020 2231 2f31 7375 6231 2f31 7375      "1/1sub1/1su
+00002ca0: 6231 7375 6232 2f31 7375 6231 7375 6232  b1sub2/1sub1sub2
+00002cb0: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
+00002cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002cd0: 2020 2020 2022 312f 3173 7562 312f 3173       "1/1sub1/1s
+00002ce0: 7562 3173 7562 3322 2c0a 2020 2020 2020  ub1sub3",.      
+00002cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002d00: 2020 2022 312f 3173 7562 312f 3173 7562     "1/1sub1/1sub
+00002d10: 3173 7562 332f 3173 7562 3173 7562 335f  1sub3/1sub1sub3_
+00002d20: 6669 6c65 2e74 7874 222c 0a20 2020 2020  file.txt",.     
+00002d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002d40: 2020 2020 2231 2f31 7375 6231 2f31 7375      "1/1sub1/1su
+00002d50: 6231 7375 6231 222c 0a20 2020 2020 2020  b1sub1",.       
 00002d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d70: 7522 312f 3173 7562 312f 3173 7562 3173  u"1/1sub1/1sub1s
-00002d80: 7562 3222 2c0a 2020 2020 2020 2020 2020  ub2",.          
-00002d90: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00002da0: 2231 2f31 7375 6231 2f31 7375 6231 7375  "1/1sub1/1sub1su
-00002db0: 6232 2f31 7375 6231 7375 6232 5f66 696c  b2/1sub1sub2_fil
-00002dc0: 652e 7478 7422 2c0a 2020 2020 2020 2020  e.txt",.        
-00002dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002de0: 2075 2231 2f31 7375 6231 2f31 7375 6231   u"1/1sub1/1sub1
-00002df0: 7375 6233 222c 0a20 2020 2020 2020 2020  sub3",.         
-00002e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002e10: 7522 312f 3173 7562 312f 3173 7562 3173  u"1/1sub1/1sub1s
-00002e20: 7562 332f 3173 7562 3173 7562 335f 6669  ub3/1sub1sub3_fi
-00002e30: 6c65 2e74 7874 222c 0a20 2020 2020 2020  le.txt",.       
-00002e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002e50: 2020 7522 312f 3173 7562 312f 3173 7562    u"1/1sub1/1sub
-00002e60: 3173 7562 3122 2c0a 2020 2020 2020 2020  1sub1",.        
-00002e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002e80: 2075 2231 2f31 7375 6231 2f31 7375 6231   u"1/1sub1/1sub1
-00002e90: 7375 6231 2f31 7375 6231 7375 6231 5f66  sub1/1sub1sub1_f
-00002ea0: 696c 652e 7478 7422 2c0a 2020 2020 2020  ile.txt",.      
-00002eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ec0: 2020 2075 2231 2f31 7375 6232 222c 0a20     u"1/1sub2",. 
-00002ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002ee0: 2020 2020 2020 2020 7522 312f 3173 7562          u"1/1sub
-00002ef0: 322f 3173 7562 3273 7562 3322 2c0a 2020  2/1sub2sub3",.  
-00002f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f10: 2020 2020 2020 2075 2231 2f31 7375 6232         u"1/1sub2
-00002f20: 2f31 7375 6232 7375 6232 222c 0a20 2020  /1sub2sub2",.   
-00002f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f40: 2020 2020 2020 7522 312f 3173 7562 322f        u"1/1sub2/
-00002f50: 3173 7562 3273 7562 3122 2c0a 2020 2020  1sub2sub1",.    
-00002f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f70: 2020 2020 2075 2233 222c 0a20 2020 2020       u"3",.     
+00002d70: 2020 2231 2f31 7375 6231 2f31 7375 6231    "1/1sub1/1sub1
+00002d80: 7375 6231 2f31 7375 6231 7375 6231 5f66  sub1/1sub1sub1_f
+00002d90: 696c 652e 7478 7422 2c0a 2020 2020 2020  ile.txt",.      
+00002da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002db0: 2020 2022 312f 3173 7562 3222 2c0a 2020     "1/1sub2",.  
+00002dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002dd0: 2020 2020 2020 2022 312f 3173 7562 322f         "1/1sub2/
+00002de0: 3173 7562 3273 7562 3322 2c0a 2020 2020  1sub2sub3",.    
+00002df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e00: 2020 2020 2022 312f 3173 7562 322f 3173       "1/1sub2/1s
+00002e10: 7562 3273 7562 3222 2c0a 2020 2020 2020  ub2sub2",.      
+00002e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e30: 2020 2022 312f 3173 7562 322f 3173 7562     "1/1sub2/1sub
+00002e40: 3273 7562 3122 2c0a 2020 2020 2020 2020  2sub1",.        
+00002e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002e60: 2022 3322 2c0a 2020 2020 2020 2020 2020   "3",.          
+00002e70: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00002e80: 332f 3373 7562 3322 2c0a 2020 2020 2020  3/3sub3",.      
+00002e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ea0: 2020 2022 332f 3373 7562 332f 3373 7562     "3/3sub3/3sub
+00002eb0: 3373 7562 3322 2c0a 2020 2020 2020 2020  3sub3",.        
+00002ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002ed0: 2022 332f 3373 7562 332f 3373 7562 3373   "3/3sub3/3sub3s
+00002ee0: 7562 3122 2c0a 2020 2020 2020 2020 2020  ub1",.          
+00002ef0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00002f00: 332f 3373 7562 332f 3373 7562 3373 7562  3/3sub3/3sub3sub
+00002f10: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
+00002f20: 2020 2020 2020 2020 2020 2020 2022 332f               "3/
+00002f30: 3373 7562 332f 3373 7562 3373 7562 322f  3sub3/3sub3sub2/
+00002f40: 3373 7562 3373 7562 325f 6669 6c65 2e74  3sub3sub2_file.t
+00002f50: 7874 222c 0a20 2020 2020 2020 2020 2020  xt",.           
+00002f60: 2020 2020 2020 2020 2020 2020 2020 2233                "3
+00002f70: 2f33 7375 6232 222c 0a20 2020 2020 2020  /3sub2",.       
 00002f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002f90: 2020 2020 7522 332f 3373 7562 3322 2c0a      u"3/3sub3",.
-00002fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002fb0: 2020 2020 2020 2020 2075 2233 2f33 7375           u"3/3su
-00002fc0: 6233 2f33 7375 6233 7375 6233 222c 0a20  b3/3sub3sub3",. 
-00002fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002fe0: 2020 2020 2020 2020 7522 332f 3373 7562          u"3/3sub
-00002ff0: 332f 3373 7562 3373 7562 3122 2c0a 2020  3/3sub3sub1",.  
-00003000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003010: 2020 2020 2020 2075 2233 2f33 7375 6233         u"3/3sub3
-00003020: 2f33 7375 6233 7375 6232 222c 0a20 2020  /3sub3sub2",.   
+00002f90: 2020 2233 2f33 7375 6232 2f33 7375 6232    "3/3sub2/3sub2
+00002fa0: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
+00002fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002fc0: 2233 2f33 7375 6232 2f33 7375 6232 7375  "3/3sub2/3sub2su
+00002fd0: 6233 222c 0a20 2020 2020 2020 2020 2020  b3",.           
+00002fe0: 2020 2020 2020 2020 2020 2020 2020 2233                "3
+00002ff0: 2f33 7375 6232 2f33 7375 6232 7375 6232  /3sub2/3sub2sub2
+00003000: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00003010: 2020 2020 2020 2020 2020 2020 2233 2f33              "3/3
+00003020: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
 00003030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003040: 2020 2020 2020 7522 332f 3373 7562 332f        u"3/3sub3/
-00003050: 3373 7562 3373 7562 322f 3373 7562 3373  3sub3sub2/3sub3s
-00003060: 7562 325f 6669 6c65 2e74 7874 222c 0a20  ub2_file.txt",. 
-00003070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003080: 2020 2020 2020 2020 7522 332f 3373 7562          u"3/3sub
-00003090: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-000030a0: 2020 2020 2020 2020 2020 2020 2075 2233               u"3
-000030b0: 2f33 7375 6232 2f33 7375 6232 7375 6231  /3sub2/3sub2sub1
-000030c0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-000030d0: 2020 2020 2020 2020 2020 2020 7522 332f              u"3/
-000030e0: 3373 7562 322f 3373 7562 3273 7562 3322  3sub2/3sub2sub3"
-000030f0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00003100: 2020 2020 2020 2020 2020 2075 2233 2f33             u"3/3
-00003110: 7375 6232 2f33 7375 6232 7375 6232 222c  sub2/3sub2sub2",
-00003120: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003130: 2020 2020 2020 2020 2020 7522 332f 3373            u"3/3s
-00003140: 7562 3122 2c0a 2020 2020 2020 2020 2020  ub1",.          
-00003150: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00003160: 2233 2f33 7375 6231 2f33 7375 6231 7375  "3/3sub1/3sub1su
-00003170: 6233 222c 0a20 2020 2020 2020 2020 2020  b3",.           
-00003180: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00003190: 332f 3373 7562 312f 3373 7562 3173 7562  3/3sub1/3sub1sub
-000031a0: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
-000031b0: 2020 2020 2020 2020 2020 2020 2075 2233               u"3
-000031c0: 2f33 7375 6231 2f33 7375 6231 7375 6232  /3sub1/3sub1sub2
-000031d0: 225d 0a0a 2020 2020 6465 6620 7465 7374  "]..    def test
-000031e0: 5f65 7272 6f72 5f6f 6e5f 6669 6c65 735f  _error_on_files_
-000031f0: 6672 6f6d 5f61 6273 6f6c 7574 655f 7061  from_absolute_pa
-00003200: 7468 2873 656c 6629 3a0a 2020 2020 2020  th(self):.      
-00003210: 2020 7522 2222 2043 6865 636b 2065 7870    u""" Check exp
-00003220: 6563 7465 6420 6661 696c 7572 6520 6f6e  ected failure on
-00003230: 2061 6273 6f6c 7574 6520 7061 7468 7320   absolute paths 
-00003240: 2222 220a 2020 2020 2020 2020 7769 7468  """.        with
-00003250: 2069 6f2e 6f70 656e 2875 2274 6573 7466   io.open(u"testf
-00003260: 696c 6573 2f66 696c 6573 5f66 726f 6d2e  iles/files_from.
-00003270: 7478 7422 2c20 7522 7722 2920 6173 2066  txt", u"w") as f
-00003280: 3a0a 2020 2020 2020 2020 2020 2020 662e  :.            f.
-00003290: 7772 6974 6528 7522 2f74 6573 7466 696c  write(u"/testfil
-000032a0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-000032b0: 6231 2f31 7375 6231 7375 6231 2f31 7375  b1/1sub1sub1/1su
-000032c0: 6231 7375 6231 5f66 696c 652e 7478 745c  b1sub1_file.txt\
-000032d0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-000032e0: 2020 2020 2020 2075 222f 7465 7374 6669         u"/testfi
-000032f0: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-00003300: 7562 312f 3173 7562 3173 7562 322f 3173  ub1/1sub1sub2/1s
-00003310: 7562 3173 7562 325f 6669 6c65 2e74 7874  ub1sub2_file.txt
-00003320: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-00003330: 2020 2020 2020 2020 7522 2f74 6573 7466          u"/testf
-00003340: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00003350: 7375 6231 2f31 7375 6231 7375 6233 2f31  sub1/1sub1sub3/1
-00003360: 7375 6231 7375 6233 5f66 696c 652e 7478  sub1sub3_file.tx
-00003370: 745c 6e22 0a20 2020 2020 2020 2020 2020  t\n".           
-00003380: 2020 2020 2020 2020 2075 222f 7465 7374           u"/test
-00003390: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-000033a0: 3273 7562 312f 3273 7562 3173 7562 312f  2sub1/2sub1sub1/
-000033b0: 3273 7562 3173 7562 315f 6669 6c65 2e74  2sub1sub1_file.t
-000033c0: 7874 5c6e 220a 2020 2020 2020 2020 2020  xt\n".          
-000033d0: 2020 2020 2020 2020 2020 7522 2f74 6573            u"/tes
-000033e0: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
-000033f0: 2f33 7375 6233 2f33 7375 6233 7375 6232  /3sub3/3sub3sub2
-00003400: 2f33 7375 6233 7375 6232 5f66 696c 652e  /3sub3sub2_file.
-00003410: 7478 7422 290a 2020 2020 2020 2020 7769  txt").        wi
-00003420: 7468 2073 656c 662e 6173 7365 7274 5261  th self.assertRa
-00003430: 6973 6573 2843 6d64 4572 726f 7229 2061  ises(CmdError) a
-00003440: 7320 636f 6e74 6578 743a 0a20 2020 2020  s context:.     
-00003450: 2020 2020 2020 2073 656c 662e 6261 636b         self.back
-00003460: 7570 2875 2266 756c 6c22 2c20 7522 7465  up(u"full", u"te
-00003470: 7374 6669 6c65 732f 7365 6c65 6374 3222  stfiles/select2"
-00003480: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00003490: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
-000034a0: 733d 5b75 222d 2d66 696c 6573 2d66 726f  s=[u"--files-fro
-000034b0: 6d22 2c20 7522 7465 7374 6669 6c65 732f  m", u"testfiles/
-000034c0: 6669 6c65 735f 6672 6f6d 2e74 7874 225d  files_from.txt"]
-000034d0: 290a 2020 2020 2020 2020 7365 6c66 2e61  ).        self.a
-000034e0: 7373 6572 7445 7175 616c 2863 6f6e 7465  ssertEqual(conte
-000034f0: 7874 2e65 7863 6570 7469 6f6e 2e65 7869  xt.exception.exi
-00003500: 745f 7374 6174 7573 2c20 6c6f 672e 4572  t_status, log.Er
-00003510: 726f 7243 6f64 652e 6162 736f 6c75 7465  rorCode.absolute
-00003520: 5f66 696c 6573 5f66 726f 6d29 0a0a 2020  _files_from)..  
-00003530: 2020 6465 6620 7465 7374 5f65 7272 6f72    def test_error
-00003540: 5f6f 6e5f 6669 6c65 735f 6672 6f6d 5f65  _on_files_from_e
-00003550: 6d70 7479 2873 656c 6629 3a0a 2020 2020  mpty(self):.    
-00003560: 2020 2020 7522 2222 2043 6865 636b 2065      u""" Check e
-00003570: 7870 6563 7465 6420 6661 696c 7572 6520  xpected failure 
-00003580: 6966 2066 696c 6520 6c69 7374 2069 7320  if file list is 
-00003590: 656d 7074 7920 2222 220a 2020 2020 2020  empty """.      
-000035a0: 2020 7769 7468 2069 6f2e 6f70 656e 2875    with io.open(u
-000035b0: 2274 6573 7466 696c 6573 2f66 696c 6573  "testfiles/files
-000035c0: 5f66 726f 6d2e 7478 7422 2c20 7522 7722  _from.txt", u"w"
-000035d0: 2920 6173 2066 3a0a 2020 2020 2020 2020  ) as f:.        
-000035e0: 2020 2020 7061 7373 0a20 2020 2020 2020      pass.       
-000035f0: 2077 6974 6820 7365 6c66 2e61 7373 6572   with self.asser
-00003600: 7452 6169 7365 7328 436d 6445 7272 6f72  tRaises(CmdError
-00003610: 2920 6173 2063 6f6e 7465 7874 3a0a 2020  ) as context:.  
-00003620: 2020 2020 2020 2020 2020 7365 6c66 2e62            self.b
-00003630: 6163 6b75 7028 7522 6675 6c6c 222c 2075  ackup(u"full", u
-00003640: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00003650: 7432 222c 0a20 2020 2020 2020 2020 2020  t2",.           
-00003660: 2020 2020 2020 2020 2020 2020 206f 7074               opt
-00003670: 696f 6e73 3d5b 7522 2d2d 6669 6c65 732d  ions=[u"--files-
-00003680: 6672 6f6d 222c 2075 2274 6573 7466 696c  from", u"testfil
-00003690: 6573 2f66 696c 6573 5f66 726f 6d2e 7478  es/files_from.tx
-000036a0: 7422 5d29 0a20 2020 2020 2020 2073 656c  t"]).        sel
-000036b0: 662e 6173 7365 7274 4571 7561 6c28 636f  f.assertEqual(co
-000036c0: 6e74 6578 742e 6578 6365 7074 696f 6e2e  ntext.exception.
-000036d0: 6578 6974 5f73 7461 7475 732c 206c 6f67  exit_status, log
-000036e0: 2e45 7272 6f72 436f 6465 2e65 6d70 7479  .ErrorCode.empty
-000036f0: 5f66 696c 6573 5f66 726f 6d29 0a0a 2020  _files_from)..  
-00003700: 2020 6465 6620 7465 7374 5f66 696c 6573    def test_files
-00003710: 5f66 726f 6d5f 6e6f 5f73 656c 6563 7469  _from_no_selecti
-00003720: 6f6e 7328 7365 6c66 293a 0a20 2020 2020  ons(self):.     
-00003730: 2020 2075 2222 2220 5369 6d70 6c65 7374     u""" Simplest
-00003740: 2075 7365 2063 6173 652c 2077 6974 6820   use case, with 
-00003750: 6e6f 2061 6464 6974 696f 6e61 6c20 7365  no additional se
-00003760: 6c65 6374 696f 6e20 6675 6e63 7469 6f6e  lection function
-00003770: 7320 2222 220a 2020 2020 2020 2020 7769  s """.        wi
-00003780: 7468 2069 6f2e 6f70 656e 2875 2274 6573  th io.open(u"tes
-00003790: 7466 696c 6573 2f66 696c 6573 5f66 726f  tfiles/files_fro
-000037a0: 6d2e 7478 7422 2c20 7522 7722 2920 6173  m.txt", u"w") as
-000037b0: 2066 3a0a 2020 2020 2020 2020 2020 2020   f:.            
-000037c0: 662e 7772 6974 6528 7522 312e 646f 635c  f.write(u"1.doc\
-000037d0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-000037e0: 2020 2020 2020 2075 2231 2e70 7922 290a         u"1.py").
-000037f0: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
-00003800: 6b75 7028 7522 6675 6c6c 222c 2075 2274  kup(u"full", u"t
-00003810: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00003820: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00003830: 2020 2020 2020 206f 7074 696f 6e73 3d5b         options=[
-00003840: 7522 2d2d 6669 6c65 732d 6672 6f6d 222c  u"--files-from",
-00003850: 2075 2274 6573 7466 696c 6573 2f66 696c   u"testfiles/fil
-00003860: 6573 5f66 726f 6d2e 7478 7422 5d29 0a20  es_from.txt"]). 
-00003870: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
-00003880: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
-00003890: 7374 6f72 655f 6469 7220 3d20 7522 7465  store_dir = u"te
-000038a0: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
-000038b0: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
-000038c0: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
-000038d0: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
-000038e0: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
-000038f0: 746f 7265 5f64 6972 290a 2020 2020 2020  tore_dir).      
-00003900: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
-00003910: 616c 2872 6573 746f 7265 642c 205b 5b75  al(restored, [[u
-00003920: 2231 2e64 6f63 222c 2075 2231 2e70 7922  "1.doc", u"1.py"
-00003930: 5d5d 290a 0a20 2020 2064 6566 2074 6573  ]])..    def tes
-00003940: 745f 6669 6c65 735f 6672 6f6d 5f69 6d70  t_files_from_imp
-00003950: 6c69 6369 745f 7061 7265 6e74 7328 7365  licit_parents(se
-00003960: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00003970: 2220 436f 6e66 6972 6d20 7468 6174 2070  " Confirm that p
-00003980: 6172 656e 7420 6469 7265 6374 6f72 6965  arent directorie
-00003990: 7320 6765 7420 696e 636c 7564 6564 2069  s get included i
-000039a0: 6d70 6c69 6369 746c 7920 2222 220a 2020  mplicitly """.  
-000039b0: 2020 2020 2020 7769 7468 2069 6f2e 6f70        with io.op
-000039c0: 656e 2875 2274 6573 7466 696c 6573 2f66  en(u"testfiles/f
-000039d0: 696c 6573 5f66 726f 6d2e 7478 7422 2c20  iles_from.txt", 
-000039e0: 7522 7722 2920 6173 2066 3a0a 2020 2020  u"w") as f:.    
-000039f0: 2020 2020 2020 2020 662e 7772 6974 6528          f.write(
-00003a00: 7522 312f 3173 7562 312f 3173 7562 3173  u"1/1sub1/1sub1s
-00003a10: 7562 312f 3173 7562 3173 7562 315f 6669  ub1/1sub1sub1_fi
-00003a20: 6c65 2e74 7874 5c6e 220a 2020 2020 2020  le.txt\n".      
-00003a30: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00003a40: 312f 3173 7562 312f 3173 7562 3173 7562  1/1sub1/1sub1sub
-00003a50: 322f 3173 7562 3173 7562 325f 6669 6c65  2/1sub1sub2_file
-00003a60: 2e74 7874 5c6e 220a 2020 2020 2020 2020  .txt\n".        
-00003a70: 2020 2020 2020 2020 2020 2020 7522 312f              u"1/
-00003a80: 3173 7562 312f 3173 7562 3173 7562 332f  1sub1/1sub1sub3/
-00003a90: 3173 7562 3173 7562 335f 6669 6c65 2e74  1sub1sub3_file.t
-00003aa0: 7874 5c6e 220a 2020 2020 2020 2020 2020  xt\n".          
-00003ab0: 2020 2020 2020 2020 2020 7522 322f 3273            u"2/2s
-00003ac0: 7562 312f 3273 7562 3173 7562 312f 3273  ub1/2sub1sub1/2s
-00003ad0: 7562 3173 7562 315f 6669 6c65 2e74 7874  ub1sub1_file.txt
-00003ae0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-00003af0: 2020 2020 2020 2020 7522 332f 3373 7562          u"3/3sub
-00003b00: 332f 3373 7562 3373 7562 322f 3373 7562  3/3sub3sub2/3sub
-00003b10: 3373 7562 325f 6669 6c65 2e74 7874 2229  3sub2_file.txt")
-00003b20: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
-00003b30: 636b 7570 2875 2266 756c 6c22 2c20 7522  ckup(u"full", u"
-00003b40: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00003b50: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-00003b60: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-00003b70: 5b75 222d 2d66 696c 6573 2d66 726f 6d22  [u"--files-from"
-00003b80: 2c20 7522 7465 7374 6669 6c65 732f 6669  , u"testfiles/fi
-00003b90: 6c65 735f 6672 6f6d 2e74 7874 225d 290a  les_from.txt"]).
-00003ba0: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-00003bb0: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
-00003bc0: 6573 746f 7265 5f64 6972 203d 2075 2274  estore_dir = u"t
-00003bd0: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
-00003be0: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
-00003bf0: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
-00003c00: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
-00003c10: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
-00003c20: 7374 6f72 655f 6469 7229 0a20 2020 2020  store_dir).     
-00003c30: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
-00003c40: 7561 6c28 7265 7374 6f72 6564 2c20 5b5b  ual(restored, [[
-00003c50: 7522 3122 2c20 7522 3222 2c20 7522 3322  u"1", u"2", u"3"
-00003c60: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00003c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003c80: 2020 2020 2020 205b 7522 3173 7562 3122         [u"1sub1"
-00003c90: 5d2c 205b 7522 3173 7562 3173 7562 3122  ], [u"1sub1sub1"
-00003ca0: 2c20 7522 3173 7562 3173 7562 3222 2c20  , u"1sub1sub2", 
-00003cb0: 7522 3173 7562 3173 7562 3322 5d2c 0a20  u"1sub1sub3"],. 
-00003cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ce0: 2020 205b 7522 3173 7562 3173 7562 315f     [u"1sub1sub1_
-00003cf0: 6669 6c65 2e74 7874 225d 2c20 5b75 2231  file.txt"], [u"1
-00003d00: 7375 6231 7375 6232 5f66 696c 652e 7478  sub1sub2_file.tx
-00003d10: 7422 5d2c 205b 7522 3173 7562 3173 7562  t"], [u"1sub1sub
-00003d20: 335f 6669 6c65 2e74 7874 225d 2c0a 2020  3_file.txt"],.  
-00003d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d50: 2020 5b75 2232 7375 6231 225d 2c20 5b75    [u"2sub1"], [u
-00003d60: 2232 7375 6231 7375 6231 225d 2c20 5b75  "2sub1sub1"], [u
-00003d70: 2232 7375 6231 7375 6231 5f66 696c 652e  "2sub1sub1_file.
-00003d80: 7478 7422 5d2c 0a20 2020 2020 2020 2020  txt"],.         
-00003d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003da0: 2020 2020 2020 2020 2020 205b 7522 3373             [u"3s
-00003db0: 7562 3322 5d2c 205b 7522 3373 7562 3373  ub3"], [u"3sub3s
-00003dc0: 7562 3222 5d2c 205b 7522 3373 7562 3373  ub2"], [u"3sub3s
-00003dd0: 7562 325f 6669 6c65 2e74 7874 225d 5d29  ub2_file.txt"]])
-00003de0: 0a0a 2020 2020 6465 6620 7465 7374 5f66  ..    def test_f
-00003df0: 696c 6573 5f66 726f 6d5f 7472 6169 6c69  iles_from_traili
-00003e00: 6e67 5f73 7061 6365 2873 656c 6629 3a0a  ng_space(self):.
-00003e10: 2020 2020 2020 2020 7522 2222 2043 6865          u""" Che
-00003e20: 636b 2074 6861 7420 7472 6169 6c69 6e67  ck that trailing
-00003e30: 2073 7061 6365 2069 7320 7072 6573 6572   space is preser
-00003e40: 7665 6420 2222 220a 2020 2020 2020 2020  ved """.        
-00003e50: 7769 7468 2069 6f2e 6f70 656e 2875 2274  with io.open(u"t
-00003e60: 6573 7466 696c 6573 2f66 696c 6573 5f66  estfiles/files_f
-00003e70: 726f 6d2e 7478 7422 2c20 7522 7722 2920  rom.txt", u"w") 
-00003e80: 6173 2066 3a0a 2020 2020 2020 2020 2020  as f:.          
-00003e90: 2020 662e 7772 6974 6528 7522 7472 6169    f.write(u"trai
-00003ea0: 6c69 6e67 5f73 7061 6365 202f 7472 6169  ling_space /trai
-00003eb0: 6c69 6e67 5f73 7061 6365 2073 7562 315c  ling_space sub1\
-00003ec0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00003ed0: 2020 2020 2020 2075 2274 7261 696c 696e         u"trailin
-00003ee0: 675f 7370 6163 6520 2f74 7261 696c 696e  g_space /trailin
-00003ef0: 675f 7370 6163 6520 7375 6232 2f74 7261  g_space sub2/tra
-00003f00: 696c 696e 675f 7370 6163 6520 7375 6232  iling_space sub2
-00003f10: 5f66 696c 652e 7478 7422 290a 2020 2020  _file.txt").    
-00003f20: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
-00003f30: 7522 6675 6c6c 222c 2075 2274 6573 7466  u"full", u"testf
-00003f40: 696c 6573 2f73 656c 6563 7432 222c 0a20  iles/select2",. 
-00003f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f60: 2020 206f 7074 696f 6e73 3d5b 7522 2d2d     options=[u"--
-00003f70: 6669 6c65 732d 6672 6f6d 222c 2075 2274  files-from", u"t
-00003f80: 6573 7466 696c 6573 2f66 696c 6573 5f66  estfiles/files_f
-00003f90: 726f 6d2e 7478 7422 5d29 0a20 2020 2020  rom.txt"]).     
-00003fa0: 2020 2073 656c 662e 7265 7374 6f72 6528     self.restore(
-00003fb0: 290a 2020 2020 2020 2020 7265 7374 6f72  ).        restor
-00003fc0: 655f 6469 7220 3d20 7522 7465 7374 6669  e_dir = u"testfi
-00003fd0: 6c65 732f 7265 7374 6f72 655f 6f75 7422  les/restore_out"
-00003fe0: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
-00003ff0: 6420 3d20 7365 6c66 2e64 6972 6563 746f  d = self.directo
-00004000: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
-00004010: 6f66 5f6c 6973 7473 2872 6573 746f 7265  of_lists(restore
-00004020: 5f64 6972 290a 2020 2020 2020 2020 7365  _dir).        se
-00004030: 6c66 2e61 7373 6572 7445 7175 616c 2872  lf.assertEqual(r
-00004040: 6573 746f 7265 642c 205b 5b75 2274 7261  estored, [[u"tra
-00004050: 696c 696e 675f 7370 6163 6520 225d 2c0a  iling_space "],.
-00004060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004080: 2020 2020 5b75 2274 7261 696c 696e 675f      [u"trailing_
-00004090: 7370 6163 6520 7375 6231 222c 2075 2274  space sub1", u"t
-000040a0: 7261 696c 696e 675f 7370 6163 6520 7375  railing_space su
-000040b0: 6232 225d 2c0a 2020 2020 2020 2020 2020  b2"],.          
-000040c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000040d0: 2020 2020 2020 2020 2020 5b75 2274 7261            [u"tra
-000040e0: 696c 696e 675f 7370 6163 6520 7375 6232  iling_space sub2
-000040f0: 5f66 696c 652e 7478 7422 5d5d 290a 0a20  _file.txt"]]).. 
-00004100: 2020 2064 6566 2074 6573 745f 6669 6c65     def test_file
-00004110: 735f 6672 6f6d 5f74 7261 696c 696e 675f  s_from_trailing_
-00004120: 7370 6163 655f 666f 6c64 6572 2873 656c  space_folder(sel
-00004130: 6629 3a0a 2020 2020 2020 2020 7522 2222  f):.        u"""
-00004140: 2043 6865 636b 2074 6861 7420 7472 6169   Check that trai
-00004150: 6c69 6e67 2073 7061 6365 2069 7320 7072  ling space is pr
-00004160: 6573 6572 7665 6420 7768 6572 6520 6974  eserved where it
-00004170: 2069 736e 2774 2064 656c 696d 6974 6564   isn't delimited
-00004180: 0a20 2020 2020 2020 2062 7920 616e 6f74  .        by anot
-00004190: 6865 7220 7061 7468 2063 6f6d 706f 6e65  her path compone
-000041a0: 6e74 206f 7220 696d 706c 6965 6420 6279  nt or implied by
-000041b0: 2061 6e6f 7468 6572 2070 6174 6820 696e   another path in
-000041c0: 2074 6865 2073 616d 6520 6669 6c65 0a20   the same file. 
-000041d0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-000041e0: 2020 2077 6974 6820 696f 2e6f 7065 6e28     with io.open(
-000041f0: 7522 7465 7374 6669 6c65 732f 6669 6c65  u"testfiles/file
-00004200: 735f 6672 6f6d 2e74 7874 222c 2075 2277  s_from.txt", u"w
-00004210: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
-00004220: 2020 2020 2066 2e77 7269 7465 2875 2274       f.write(u"t
-00004230: 7261 696c 696e 675f 7370 6163 6520 2229  railing_space ")
-00004240: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
-00004250: 636b 7570 2875 2266 756c 6c22 2c20 7522  ckup(u"full", u"
-00004260: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00004270: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-00004280: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-00004290: 5b75 222d 2d66 696c 6573 2d66 726f 6d22  [u"--files-from"
-000042a0: 2c20 7522 7465 7374 6669 6c65 732f 6669  , u"testfiles/fi
-000042b0: 6c65 735f 6672 6f6d 2e74 7874 225d 290a  les_from.txt"]).
-000042c0: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-000042d0: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
-000042e0: 6573 746f 7265 5f64 6972 203d 2075 2274  estore_dir = u"t
-000042f0: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
-00004300: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
-00004310: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
-00004320: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
-00004330: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
-00004340: 7374 6f72 655f 6469 7229 0a20 2020 2020  store_dir).     
-00004350: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
-00004360: 7561 6c28 7265 7374 6f72 6564 2c20 5b5b  ual(restored, [[
-00004370: 7522 7472 6169 6c69 6e67 5f73 7061 6365  u"trailing_space
-00004380: 2022 5d5d 290a 0a20 2020 2064 6566 2074   "]])..    def t
-00004390: 6573 745f 6669 6c65 735f 6672 6f6d 5f77  est_files_from_w
-000043a0: 6974 685f 6578 636c 7573 696f 6e73 2873  ith_exclusions(s
-000043b0: 656c 6629 3a0a 2020 2020 2020 2020 7522  elf):.        u"
-000043c0: 2222 2041 7070 6c79 2073 6f6d 6520 2d2d  "" Apply some --
-000043d0: 6578 636c 7564 6520 7275 6c65 7320 746f  exclude rules to
-000043e0: 2061 2062 6163 6b75 7020 6669 6c65 7365   a backup filese
-000043f0: 7420 6465 6669 6e65 6420 6279 202d 2d66  t defined by --f
-00004400: 696c 6573 2d66 726f 6d22 2222 0a20 2020  iles-from""".   
-00004410: 2020 2020 2077 6974 6820 696f 2e6f 7065       with io.ope
-00004420: 6e28 7522 7465 7374 6669 6c65 732f 6669  n(u"testfiles/fi
-00004430: 6c65 735f 6672 6f6d 2e74 7874 222c 2075  les_from.txt", u
-00004440: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
-00004450: 2020 2020 2020 2066 2e77 7269 7465 2875         f.write(u
-00004460: 225c 6e22 2e6a 6f69 6e28 7365 6c66 2e74  "\n".join(self.t
-00004470: 6573 7466 696c 6573 5f6e 756d 6265 7273  estfiles_numbers
-00004480: 2929 0a20 2020 2020 2020 2073 656c 662e  )).        self.
-00004490: 6261 636b 7570 2875 2266 756c 6c22 2c20  backup(u"full", 
-000044a0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-000044b0: 6374 3222 2c0a 2020 2020 2020 2020 2020  ct2",.          
-000044c0: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
-000044d0: 733d 5b75 222d 2d66 696c 6573 2d66 726f  s=[u"--files-fro
-000044e0: 6d22 2c20 7522 7465 7374 6669 6c65 732f  m", u"testfiles/
-000044f0: 6669 6c65 735f 6672 6f6d 2e74 7874 222c  files_from.txt",
-00004500: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00004510: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00004520: 2d2d 6578 636c 7564 6522 2c20 7522 7465  --exclude", u"te
-00004530: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00004540: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
+00003040: 2233 2f33 7375 6231 2f33 7375 6231 7375  "3/3sub1/3sub1su
+00003050: 6233 222c 0a20 2020 2020 2020 2020 2020  b3",.           
+00003060: 2020 2020 2020 2020 2020 2020 2020 2233                "3
+00003070: 2f33 7375 6231 2f33 7375 6231 7375 6231  /3sub1/3sub1sub1
+00003080: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00003090: 2020 2020 2020 2020 2020 2020 2233 2f33              "3/3
+000030a0: 7375 6231 2f33 7375 6231 7375 6232 225d  sub1/3sub1sub2"]
+000030b0: 0a0a 2020 2020 6465 6620 7465 7374 5f65  ..    def test_e
+000030c0: 7272 6f72 5f6f 6e5f 6669 6c65 735f 6672  rror_on_files_fr
+000030d0: 6f6d 5f61 6273 6f6c 7574 655f 7061 7468  om_absolute_path
+000030e0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+000030f0: 2222 2220 4368 6563 6b20 6578 7065 6374  """ Check expect
+00003100: 6564 2066 6169 6c75 7265 206f 6e20 6162  ed failure on ab
+00003110: 736f 6c75 7465 2070 6174 6873 2022 2222  solute paths """
+00003120: 0a20 2020 2020 2020 2077 6974 6820 696f  .        with io
+00003130: 2e6f 7065 6e28 2274 6573 7466 696c 6573  .open("testfiles
+00003140: 2f66 696c 6573 5f66 726f 6d2e 7478 7422  /files_from.txt"
+00003150: 2c20 2277 2229 2061 7320 663a 0a20 2020  , "w") as f:.   
+00003160: 2020 2020 2020 2020 2066 2e77 7269 7465           f.write
+00003170: 2822 2f74 6573 7466 696c 6573 2f73 656c  ("/testfiles/sel
+00003180: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
+00003190: 6231 7375 6231 2f31 7375 6231 7375 6231  b1sub1/1sub1sub1
+000031a0: 5f66 696c 652e 7478 745c 6e22 0a20 2020  _file.txt\n".   
+000031b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000031c0: 2022 2f74 6573 7466 696c 6573 2f73 656c   "/testfiles/sel
+000031d0: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
+000031e0: 6231 7375 6232 2f31 7375 6231 7375 6232  b1sub2/1sub1sub2
+000031f0: 5f66 696c 652e 7478 745c 6e22 0a20 2020  _file.txt\n".   
+00003200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003210: 2022 2f74 6573 7466 696c 6573 2f73 656c   "/testfiles/sel
+00003220: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
+00003230: 6231 7375 6233 2f31 7375 6231 7375 6233  b1sub3/1sub1sub3
+00003240: 5f66 696c 652e 7478 745c 6e22 0a20 2020  _file.txt\n".   
+00003250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003260: 2022 2f74 6573 7466 696c 6573 2f73 656c   "/testfiles/sel
+00003270: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
+00003280: 6231 7375 6231 2f32 7375 6231 7375 6231  b1sub1/2sub1sub1
+00003290: 5f66 696c 652e 7478 745c 6e22 0a20 2020  _file.txt\n".   
+000032a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000032b0: 2022 2f74 6573 7466 696c 6573 2f73 656c   "/testfiles/sel
+000032c0: 6563 7432 2f33 2f33 7375 6233 2f33 7375  ect2/3/3sub3/3su
+000032d0: 6233 7375 6232 2f33 7375 6233 7375 6232  b3sub2/3sub3sub2
+000032e0: 5f66 696c 652e 7478 7422 290a 2020 2020  _file.txt").    
+000032f0: 2020 2020 7769 7468 2073 656c 662e 6173      with self.as
+00003300: 7365 7274 5261 6973 6573 2843 6d64 4572  sertRaises(CmdEr
+00003310: 726f 7229 2061 7320 636f 6e74 6578 743a  ror) as context:
+00003320: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00003330: 662e 6261 636b 7570 2822 6675 6c6c 222c  f.backup("full",
+00003340: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00003350: 6374 3222 2c0a 2020 2020 2020 2020 2020  ct2",.          
+00003360: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+00003370: 7469 6f6e 733d 5b22 2d2d 6669 6c65 732d  tions=["--files-
+00003380: 6672 6f6d 222c 2022 7465 7374 6669 6c65  from", "testfile
+00003390: 732f 6669 6c65 735f 6672 6f6d 2e74 7874  s/files_from.txt
+000033a0: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
+000033b0: 2e61 7373 6572 7445 7175 616c 2863 6f6e  .assertEqual(con
+000033c0: 7465 7874 2e65 7863 6570 7469 6f6e 2e65  text.exception.e
+000033d0: 7869 745f 7374 6174 7573 2c20 6c6f 672e  xit_status, log.
+000033e0: 4572 726f 7243 6f64 652e 6162 736f 6c75  ErrorCode.absolu
+000033f0: 7465 5f66 696c 6573 5f66 726f 6d29 0a0a  te_files_from)..
+00003400: 2020 2020 6465 6620 7465 7374 5f65 7272      def test_err
+00003410: 6f72 5f6f 6e5f 6669 6c65 735f 6672 6f6d  or_on_files_from
+00003420: 5f65 6d70 7479 2873 656c 6629 3a0a 2020  _empty(self):.  
+00003430: 2020 2020 2020 2222 2220 4368 6563 6b20        """ Check 
+00003440: 6578 7065 6374 6564 2066 6169 6c75 7265  expected failure
+00003450: 2069 6620 6669 6c65 206c 6973 7420 6973   if file list is
+00003460: 2065 6d70 7479 2022 2222 0a20 2020 2020   empty """.     
+00003470: 2020 2077 6974 6820 696f 2e6f 7065 6e28     with io.open(
+00003480: 2274 6573 7466 696c 6573 2f66 696c 6573  "testfiles/files
+00003490: 5f66 726f 6d2e 7478 7422 2c20 2277 2229  _from.txt", "w")
+000034a0: 2061 7320 663a 0a20 2020 2020 2020 2020   as f:.         
+000034b0: 2020 2070 6173 730a 2020 2020 2020 2020     pass.        
+000034c0: 7769 7468 2073 656c 662e 6173 7365 7274  with self.assert
+000034d0: 5261 6973 6573 2843 6d64 4572 726f 7229  Raises(CmdError)
+000034e0: 2061 7320 636f 6e74 6578 743a 0a20 2020   as context:.   
+000034f0: 2020 2020 2020 2020 2073 656c 662e 6261           self.ba
+00003500: 636b 7570 2822 6675 6c6c 222c 2022 7465  ckup("full", "te
+00003510: 7374 6669 6c65 732f 7365 6c65 6374 3222  stfiles/select2"
+00003520: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00003530: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
+00003540: 733d 5b22 2d2d 6669 6c65 732d 6672 6f6d  s=["--files-from
+00003550: 222c 2022 7465 7374 6669 6c65 732f 6669  ", "testfiles/fi
+00003560: 6c65 735f 6672 6f6d 2e74 7874 225d 290a  les_from.txt"]).
+00003570: 2020 2020 2020 2020 7365 6c66 2e61 7373          self.ass
+00003580: 6572 7445 7175 616c 2863 6f6e 7465 7874  ertEqual(context
+00003590: 2e65 7863 6570 7469 6f6e 2e65 7869 745f  .exception.exit_
+000035a0: 7374 6174 7573 2c20 6c6f 672e 4572 726f  status, log.Erro
+000035b0: 7243 6f64 652e 656d 7074 795f 6669 6c65  rCode.empty_file
+000035c0: 735f 6672 6f6d 290a 0a20 2020 2064 6566  s_from)..    def
+000035d0: 2074 6573 745f 6669 6c65 735f 6672 6f6d   test_files_from
+000035e0: 5f6e 6f5f 7365 6c65 6374 696f 6e73 2873  _no_selections(s
+000035f0: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+00003600: 2220 5369 6d70 6c65 7374 2075 7365 2063  " Simplest use c
+00003610: 6173 652c 2077 6974 6820 6e6f 2061 6464  ase, with no add
+00003620: 6974 696f 6e61 6c20 7365 6c65 6374 696f  itional selectio
+00003630: 6e20 6675 6e63 7469 6f6e 7320 2222 220a  n functions """.
+00003640: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
+00003650: 6f70 656e 2822 7465 7374 6669 6c65 732f  open("testfiles/
+00003660: 6669 6c65 735f 6672 6f6d 2e74 7874 222c  files_from.txt",
+00003670: 2022 7722 2920 6173 2066 3a0a 2020 2020   "w") as f:.    
+00003680: 2020 2020 2020 2020 662e 7772 6974 6528          f.write(
+00003690: 2231 2e64 6f63 5c6e 220a 2020 2020 2020  "1.doc\n".      
+000036a0: 2020 2020 2020 2020 2020 2020 2020 2231                "1
+000036b0: 2e70 7922 290a 2020 2020 2020 2020 7365  .py").        se
+000036c0: 6c66 2e62 6163 6b75 7028 2266 756c 6c22  lf.backup("full"
+000036d0: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+000036e0: 6563 7432 222c 0a20 2020 2020 2020 2020  ect2",.         
+000036f0: 2020 2020 2020 2020 2020 206f 7074 696f             optio
+00003700: 6e73 3d5b 222d 2d66 696c 6573 2d66 726f  ns=["--files-fro
+00003710: 6d22 2c20 2274 6573 7466 696c 6573 2f66  m", "testfiles/f
+00003720: 696c 6573 5f66 726f 6d2e 7478 7422 5d29  iles_from.txt"])
+00003730: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+00003740: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
+00003750: 7265 7374 6f72 655f 7061 7468 203d 2022  restore_path = "
+00003760: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
+00003770: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
+00003780: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
+00003790: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
+000037a0: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
+000037b0: 6573 746f 7265 5f70 6174 6829 0a20 2020  estore_path).   
+000037c0: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
+000037d0: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
+000037e0: 5b5b 2231 2e64 6f63 222c 2022 312e 7079  [["1.doc", "1.py
+000037f0: 225d 5d29 0a0a 2020 2020 6465 6620 7465  "]])..    def te
+00003800: 7374 5f66 696c 6573 5f66 726f 6d5f 696d  st_files_from_im
+00003810: 706c 6963 6974 5f70 6172 656e 7473 2873  plicit_parents(s
+00003820: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+00003830: 2220 436f 6e66 6972 6d20 7468 6174 2070  " Confirm that p
+00003840: 6172 656e 7420 6469 7265 6374 6f72 6965  arent directorie
+00003850: 7320 6765 7420 696e 636c 7564 6564 2069  s get included i
+00003860: 6d70 6c69 6369 746c 7920 2222 220a 2020  mplicitly """.  
+00003870: 2020 2020 2020 7769 7468 2069 6f2e 6f70        with io.op
+00003880: 656e 2822 7465 7374 6669 6c65 732f 6669  en("testfiles/fi
+00003890: 6c65 735f 6672 6f6d 2e74 7874 222c 2022  les_from.txt", "
+000038a0: 7722 2920 6173 2066 3a0a 2020 2020 2020  w") as f:.      
+000038b0: 2020 2020 2020 662e 7772 6974 6528 2231        f.write("1
+000038c0: 2f31 7375 6231 2f31 7375 6231 7375 6231  /1sub1/1sub1sub1
+000038d0: 2f31 7375 6231 7375 6231 5f66 696c 652e  /1sub1sub1_file.
+000038e0: 7478 745c 6e22 0a20 2020 2020 2020 2020  txt\n".         
+000038f0: 2020 2020 2020 2020 2020 2022 312f 3173             "1/1s
+00003900: 7562 312f 3173 7562 3173 7562 322f 3173  ub1/1sub1sub2/1s
+00003910: 7562 3173 7562 325f 6669 6c65 2e74 7874  ub1sub2_file.txt
+00003920: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+00003930: 2020 2020 2020 2020 2231 2f31 7375 6231          "1/1sub1
+00003940: 2f31 7375 6231 7375 6233 2f31 7375 6231  /1sub1sub3/1sub1
+00003950: 7375 6233 5f66 696c 652e 7478 745c 6e22  sub3_file.txt\n"
+00003960: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003970: 2020 2020 2022 322f 3273 7562 312f 3273       "2/2sub1/2s
+00003980: 7562 3173 7562 312f 3273 7562 3173 7562  ub1sub1/2sub1sub
+00003990: 315f 6669 6c65 2e74 7874 5c6e 220a 2020  1_file.txt\n".  
+000039a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000039b0: 2020 2233 2f33 7375 6233 2f33 7375 6233    "3/3sub3/3sub3
+000039c0: 7375 6232 2f33 7375 6233 7375 6232 5f66  sub2/3sub3sub2_f
+000039d0: 696c 652e 7478 7422 290a 2020 2020 2020  ile.txt").      
+000039e0: 2020 7365 6c66 2e62 6163 6b75 7028 2266    self.backup("f
+000039f0: 756c 6c22 2c20 2274 6573 7466 696c 6573  ull", "testfiles
+00003a00: 2f73 656c 6563 7432 222c 0a20 2020 2020  /select2",.     
+00003a10: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00003a20: 7074 696f 6e73 3d5b 222d 2d66 696c 6573  ptions=["--files
+00003a30: 2d66 726f 6d22 2c20 2274 6573 7466 696c  -from", "testfil
+00003a40: 6573 2f66 696c 6573 5f66 726f 6d2e 7478  es/files_from.tx
+00003a50: 7422 5d29 0a20 2020 2020 2020 2073 656c  t"]).        sel
+00003a60: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
+00003a70: 2020 2020 7265 7374 6f72 655f 7061 7468      restore_path
+00003a80: 203d 2022 7465 7374 6669 6c65 732f 7265   = "testfiles/re
+00003a90: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
+00003aa0: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
+00003ab0: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
+00003ac0: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
+00003ad0: 7473 2872 6573 746f 7265 5f70 6174 6829  ts(restore_path)
+00003ae0: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
+00003af0: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
+00003b00: 6564 2c20 5b5b 2231 222c 2022 3222 2c20  ed, [["1", "2", 
+00003b10: 2233 225d 2c0a 2020 2020 2020 2020 2020  "3"],.          
+00003b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003b30: 2020 2020 2020 2020 2020 5b22 3173 7562            ["1sub
+00003b40: 3122 5d2c 205b 2231 7375 6231 7375 6231  1"], ["1sub1sub1
+00003b50: 222c 2022 3173 7562 3173 7562 3222 2c20  ", "1sub1sub2", 
+00003b60: 2231 7375 6231 7375 6233 225d 2c0a 2020  "1sub1sub3"],.  
+00003b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003b90: 2020 5b22 3173 7562 3173 7562 315f 6669    ["1sub1sub1_fi
+00003ba0: 6c65 2e74 7874 225d 2c20 5b22 3173 7562  le.txt"], ["1sub
+00003bb0: 3173 7562 325f 6669 6c65 2e74 7874 225d  1sub2_file.txt"]
+00003bc0: 2c20 5b22 3173 7562 3173 7562 335f 6669  , ["1sub1sub3_fi
+00003bd0: 6c65 2e74 7874 225d 2c0a 2020 2020 2020  le.txt"],.      
+00003be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003bf0: 2020 2020 2020 2020 2020 2020 2020 5b22                ["
+00003c00: 3273 7562 3122 5d2c 205b 2232 7375 6231  2sub1"], ["2sub1
+00003c10: 7375 6231 225d 2c20 5b22 3273 7562 3173  sub1"], ["2sub1s
+00003c20: 7562 315f 6669 6c65 2e74 7874 225d 2c0a  ub1_file.txt"],.
+00003c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003c50: 2020 2020 5b22 3373 7562 3322 5d2c 205b      ["3sub3"], [
+00003c60: 2233 7375 6233 7375 6232 225d 2c20 5b22  "3sub3sub2"], ["
+00003c70: 3373 7562 3373 7562 325f 6669 6c65 2e74  3sub3sub2_file.t
+00003c80: 7874 225d 5d29 0a0a 2020 2020 6465 6620  xt"]])..    def 
+00003c90: 7465 7374 5f66 696c 6573 5f66 726f 6d5f  test_files_from_
+00003ca0: 7472 6169 6c69 6e67 5f73 7061 6365 2873  trailing_space(s
+00003cb0: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+00003cc0: 2220 4368 6563 6b20 7468 6174 2074 7261  " Check that tra
+00003cd0: 696c 696e 6720 7370 6163 6520 6973 2070  iling space is p
+00003ce0: 7265 7365 7276 6564 2022 2222 0a20 2020  reserved """.   
+00003cf0: 2020 2020 2077 6974 6820 696f 2e6f 7065       with io.ope
+00003d00: 6e28 2274 6573 7466 696c 6573 2f66 696c  n("testfiles/fil
+00003d10: 6573 5f66 726f 6d2e 7478 7422 2c20 2277  es_from.txt", "w
+00003d20: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
+00003d30: 2020 2020 2066 2e77 7269 7465 2822 7472       f.write("tr
+00003d40: 6169 6c69 6e67 5f73 7061 6365 202f 7472  ailing_space /tr
+00003d50: 6169 6c69 6e67 5f73 7061 6365 2073 7562  ailing_space sub
+00003d60: 315c 6e22 0a20 2020 2020 2020 2020 2020  1\n".           
+00003d70: 2020 2020 2020 2020 2022 7472 6169 6c69           "traili
+00003d80: 6e67 5f73 7061 6365 202f 7472 6169 6c69  ng_space /traili
+00003d90: 6e67 5f73 7061 6365 2073 7562 322f 7472  ng_space sub2/tr
+00003da0: 6169 6c69 6e67 5f73 7061 6365 2073 7562  ailing_space sub
+00003db0: 325f 6669 6c65 2e74 7874 2229 0a20 2020  2_file.txt").   
+00003dc0: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
+00003dd0: 2822 6675 6c6c 222c 2022 7465 7374 6669  ("full", "testfi
+00003de0: 6c65 732f 7365 6c65 6374 3222 2c0a 2020  les/select2",.  
+00003df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003e00: 2020 6f70 7469 6f6e 733d 5b22 2d2d 6669    options=["--fi
+00003e10: 6c65 732d 6672 6f6d 222c 2022 7465 7374  les-from", "test
+00003e20: 6669 6c65 732f 6669 6c65 735f 6672 6f6d  files/files_from
+00003e30: 2e74 7874 225d 290a 2020 2020 2020 2020  .txt"]).        
+00003e40: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
+00003e50: 2020 2020 2020 2072 6573 746f 7265 5f70         restore_p
+00003e60: 6174 6820 3d20 2274 6573 7466 696c 6573  ath = "testfiles
+00003e70: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
+00003e80: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
+00003e90: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
+00003ea0: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
+00003eb0: 6c69 7374 7328 7265 7374 6f72 655f 7061  lists(restore_pa
+00003ec0: 7468 290a 2020 2020 2020 2020 7365 6c66  th).        self
+00003ed0: 2e61 7373 6572 7445 7175 616c 2872 6573  .assertEqual(res
+00003ee0: 746f 7265 642c 205b 5b22 7472 6169 6c69  tored, [["traili
+00003ef0: 6e67 5f73 7061 6365 2022 5d2c 0a20 2020  ng_space "],.   
+00003f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f20: 205b 2274 7261 696c 696e 675f 7370 6163   ["trailing_spac
+00003f30: 6520 7375 6231 222c 2022 7472 6169 6c69  e sub1", "traili
+00003f40: 6e67 5f73 7061 6365 2073 7562 3222 5d2c  ng_space sub2"],
+00003f50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f70: 2020 2020 205b 2274 7261 696c 696e 675f       ["trailing_
+00003f80: 7370 6163 6520 7375 6232 5f66 696c 652e  space sub2_file.
+00003f90: 7478 7422 5d5d 290a 0a20 2020 2064 6566  txt"]])..    def
+00003fa0: 2074 6573 745f 6669 6c65 735f 6672 6f6d   test_files_from
+00003fb0: 5f74 7261 696c 696e 675f 7370 6163 655f  _trailing_space_
+00003fc0: 666f 6c64 6572 2873 656c 6629 3a0a 2020  folder(self):.  
+00003fd0: 2020 2020 2020 2222 2220 4368 6563 6b20        """ Check 
+00003fe0: 7468 6174 2074 7261 696c 696e 6720 7370  that trailing sp
+00003ff0: 6163 6520 6973 2070 7265 7365 7276 6564  ace is preserved
+00004000: 2077 6865 7265 2069 7420 6973 6e27 7420   where it isn't 
+00004010: 6465 6c69 6d69 7465 640a 2020 2020 2020  delimited.      
+00004020: 2020 6279 2061 6e6f 7468 6572 2070 6174    by another pat
+00004030: 6820 636f 6d70 6f6e 656e 7420 6f72 2069  h component or i
+00004040: 6d70 6c69 6564 2062 7920 616e 6f74 6865  mplied by anothe
+00004050: 7220 7061 7468 2069 6e20 7468 6520 7361  r path in the sa
+00004060: 6d65 2066 696c 650a 2020 2020 2020 2020  me file.        
+00004070: 2222 220a 2020 2020 2020 2020 7769 7468  """.        with
+00004080: 2069 6f2e 6f70 656e 2822 7465 7374 6669   io.open("testfi
+00004090: 6c65 732f 6669 6c65 735f 6672 6f6d 2e74  les/files_from.t
+000040a0: 7874 222c 2022 7722 2920 6173 2066 3a0a  xt", "w") as f:.
+000040b0: 2020 2020 2020 2020 2020 2020 662e 7772              f.wr
+000040c0: 6974 6528 2274 7261 696c 696e 675f 7370  ite("trailing_sp
+000040d0: 6163 6520 2229 0a20 2020 2020 2020 2073  ace ").        s
+000040e0: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+000040f0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00004100: 6c65 6374 3222 2c0a 2020 2020 2020 2020  lect2",.        
+00004110: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
+00004120: 6f6e 733d 5b22 2d2d 6669 6c65 732d 6672  ons=["--files-fr
+00004130: 6f6d 222c 2022 7465 7374 6669 6c65 732f  om", "testfiles/
+00004140: 6669 6c65 735f 6672 6f6d 2e74 7874 225d  files_from.txt"]
+00004150: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
+00004160: 6573 746f 7265 2829 0a20 2020 2020 2020  estore().       
+00004170: 2072 6573 746f 7265 5f70 6174 6820 3d20   restore_path = 
+00004180: 2274 6573 7466 696c 6573 2f72 6573 746f  "testfiles/resto
+00004190: 7265 5f6f 7574 220a 2020 2020 2020 2020  re_out".        
+000041a0: 7265 7374 6f72 6564 203d 2073 656c 662e  restored = self.
+000041b0: 6469 7265 6374 6f72 795f 7472 6565 5f74  directory_tree_t
+000041c0: 6f5f 6c69 7374 5f6f 665f 6c69 7374 7328  o_list_of_lists(
+000041d0: 7265 7374 6f72 655f 7061 7468 290a 2020  restore_path).  
+000041e0: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
+000041f0: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
+00004200: 205b 5b22 7472 6169 6c69 6e67 5f73 7061   [["trailing_spa
+00004210: 6365 2022 5d5d 290a 0a20 2020 2064 6566  ce "]])..    def
+00004220: 2074 6573 745f 6669 6c65 735f 6672 6f6d   test_files_from
+00004230: 5f77 6974 685f 6578 636c 7573 696f 6e73  _with_exclusions
+00004240: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00004250: 2222 2220 4170 706c 7920 736f 6d65 202d  """ Apply some -
+00004260: 2d65 7863 6c75 6465 2072 756c 6573 2074  -exclude rules t
+00004270: 6f20 6120 6261 636b 7570 2066 696c 6573  o a backup files
+00004280: 6574 2064 6566 696e 6564 2062 7920 2d2d  et defined by --
+00004290: 6669 6c65 732d 6672 6f6d 2222 220a 2020  files-from""".  
+000042a0: 2020 2020 2020 7769 7468 2069 6f2e 6f70        with io.op
+000042b0: 656e 2822 7465 7374 6669 6c65 732f 6669  en("testfiles/fi
+000042c0: 6c65 735f 6672 6f6d 2e74 7874 222c 2022  les_from.txt", "
+000042d0: 7722 2920 6173 2066 3a0a 2020 2020 2020  w") as f:.      
+000042e0: 2020 2020 2020 662e 7772 6974 6528 225c        f.write("\
+000042f0: 6e22 2e6a 6f69 6e28 7365 6c66 2e74 6573  n".join(self.tes
+00004300: 7466 696c 6573 5f6e 756d 6265 7273 2929  tfiles_numbers))
+00004310: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
+00004320: 636b 7570 2822 6675 6c6c 222c 2022 7465  ckup("full", "te
+00004330: 7374 6669 6c65 732f 7365 6c65 6374 3222  stfiles/select2"
+00004340: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00004350: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+00004360: 2d2d 6669 6c65 732d 6672 6f6d 222c 2022  --files-from", "
+00004370: 7465 7374 6669 6c65 732f 6669 6c65 735f  testfiles/files_
+00004380: 6672 6f6d 2e74 7874 222c 0a20 2020 2020  from.txt",.     
+00004390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000043a0: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+000043b0: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+000043c0: 7365 6c65 6374 322f 3222 2c0a 2020 2020  select2/2",.    
+000043d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000043e0: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+000043f0: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00004400: 2f73 656c 6563 7432 2f33 222c 0a20 2020  /select2/3",.   
+00004410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004420: 2020 2020 2020 2020 2020 222d 2d65 7863            "--exc
+00004430: 6c75 6465 222c 2022 2a2a 2e74 7874 225d  lude", "**.txt"]
+00004440: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
+00004450: 6573 746f 7265 2829 0a20 2020 2020 2020  estore().       
+00004460: 2072 6573 746f 7265 5f70 6174 6820 3d20   restore_path = 
+00004470: 2274 6573 7466 696c 6573 2f72 6573 746f  "testfiles/resto
+00004480: 7265 5f6f 7574 220a 2020 2020 2020 2020  re_out".        
+00004490: 7265 7374 6f72 6564 203d 2073 656c 662e  restored = self.
+000044a0: 6469 7265 6374 6f72 795f 7472 6565 5f74  directory_tree_t
+000044b0: 6f5f 6c69 7374 5f6f 665f 6c69 7374 7328  o_list_of_lists(
+000044c0: 7265 7374 6f72 655f 7061 7468 290a 2020  restore_path).  
+000044d0: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
+000044e0: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
+000044f0: 205b 5b22 3122 2c20 2231 2e64 6f63 222c   [["1", "1.doc",
+00004500: 2022 312e 7079 225d 2c0a 2020 2020 2020   "1.py"],.      
+00004510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004520: 2020 2020 2020 2020 2020 2020 2020 5b22                ["
+00004530: 3173 7562 3122 2c20 2231 7375 6232 222c  1sub1", "1sub2",
+00004540: 2022 3173 7562 3322 5d2c 0a20 2020 2020   "1sub3"],.     
 00004550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004560: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00004570: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00004580: 7432 2f33 222c 0a20 2020 2020 2020 2020  t2/3",.         
-00004590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000045a0: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-000045b0: 2c20 7522 2a2a 2e74 7874 225d 290a 2020  , u"**.txt"]).  
-000045c0: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
-000045d0: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
-000045e0: 746f 7265 5f64 6972 203d 2075 2274 6573  tore_dir = u"tes
-000045f0: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
-00004600: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
-00004610: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
-00004620: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
-00004630: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
-00004640: 6f72 655f 6469 7229 0a20 2020 2020 2020  ore_dir).       
-00004650: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
-00004660: 6c28 7265 7374 6f72 6564 2c20 5b5b 7522  l(restored, [[u"
-00004670: 3122 2c20 7522 312e 646f 6322 2c20 7522  1", u"1.doc", u"
-00004680: 312e 7079 225d 2c0a 2020 2020 2020 2020  1.py"],.        
-00004690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000046a0: 2020 2020 2020 2020 2020 2020 5b75 2231              [u"1
-000046b0: 7375 6231 222c 2075 2231 7375 6232 222c  sub1", u"1sub2",
-000046c0: 2075 2231 7375 6233 225d 2c0a 2020 2020   u"1sub3"],.    
-000046d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000046e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000046f0: 5b75 2231 7375 6231 7375 6231 222c 2075  [u"1sub1sub1", u
-00004700: 2231 7375 6231 7375 6232 222c 2075 2231  "1sub1sub2", u"1
-00004710: 7375 6231 7375 6233 225d 2c0a 2020 2020  sub1sub3"],.    
-00004720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004740: 5b75 2231 7375 6232 7375 6231 222c 2075  [u"1sub2sub1", u
-00004750: 2231 7375 6232 7375 6232 222c 2075 2231  "1sub2sub2", u"1
-00004760: 7375 6232 7375 6233 225d 2c0a 2020 2020  sub2sub3"],.    
-00004770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004790: 5b75 2231 7375 6233 7375 6231 222c 2075  [u"1sub3sub1", u
-000047a0: 2231 7375 6233 7375 6232 222c 2075 2231  "1sub3sub2", u"1
-000047b0: 7375 6233 7375 6233 225d 5d29 0a0a 2020  sub3sub3"]])..  
-000047c0: 2020 6465 6620 7465 7374 5f66 696c 6573    def test_files
-000047d0: 5f66 726f 6d5f 7769 7468 5f69 6e63 6c75  _from_with_inclu
-000047e0: 7369 6f6e 7328 7365 6c66 293a 0a20 2020  sions(self):.   
-000047f0: 2020 2020 2075 2222 2220 4170 706c 7920       u""" Apply 
-00004800: 736f 6d65 202d 2d65 7863 6c75 6465 2072  some --exclude r
-00004810: 756c 6573 2074 6f20 6120 6261 636b 7570  ules to a backup
-00004820: 2066 696c 6573 6574 2064 6566 696e 6564   fileset defined
-00004830: 2062 7920 2d2d 6669 6c65 732d 6672 6f6d   by --files-from
-00004840: 2222 220a 2020 2020 2020 2020 7769 7468  """.        with
-00004850: 2069 6f2e 6f70 656e 2875 2274 6573 7466   io.open(u"testf
-00004860: 696c 6573 2f66 696c 6573 5f66 726f 6d2e  iles/files_from.
-00004870: 7478 7422 2c20 7522 7722 2920 6173 2066  txt", u"w") as f
-00004880: 3a0a 2020 2020 2020 2020 2020 2020 662e  :.            f.
-00004890: 7772 6974 6528 7522 5c6e 222e 6a6f 696e  write(u"\n".join
-000048a0: 2873 656c 662e 7465 7374 6669 6c65 735f  (self.testfiles_
-000048b0: 6e75 6d62 6572 7329 290a 2020 2020 2020  numbers)).      
-000048c0: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-000048d0: 6675 6c6c 222c 2075 2274 6573 7466 696c  full", u"testfil
-000048e0: 6573 2f73 656c 6563 7432 222c 0a20 2020  es/select2",.   
-000048f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004900: 206f 7074 696f 6e73 3d5b 7522 2d2d 6669   options=[u"--fi
-00004910: 6c65 732d 6672 6f6d 222c 2075 2274 6573  les-from", u"tes
-00004920: 7466 696c 6573 2f66 696c 6573 5f66 726f  tfiles/files_fro
-00004930: 6d2e 7478 7422 2c0a 2020 2020 2020 2020  m.txt",.        
-00004940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004950: 2020 2020 2075 222d 2d69 6e63 6c75 6465       u"--include
-00004960: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00004970: 656c 6563 7432 2f31 2e2a 222c 0a20 2020  elect2/1.*",.   
+00004560: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+00004570: 2231 7375 6231 7375 6231 222c 2022 3173  "1sub1sub1", "1s
+00004580: 7562 3173 7562 3222 2c20 2231 7375 6231  ub1sub2", "1sub1
+00004590: 7375 6233 225d 2c0a 2020 2020 2020 2020  sub3"],.        
+000045a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000045b0: 2020 2020 2020 2020 2020 2020 5b22 3173              ["1s
+000045c0: 7562 3273 7562 3122 2c20 2231 7375 6232  ub2sub1", "1sub2
+000045d0: 7375 6232 222c 2022 3173 7562 3273 7562  sub2", "1sub2sub
+000045e0: 3322 5d2c 0a20 2020 2020 2020 2020 2020  3"],.           
+000045f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004600: 2020 2020 2020 2020 205b 2231 7375 6233           ["1sub3
+00004610: 7375 6231 222c 2022 3173 7562 3373 7562  sub1", "1sub3sub
+00004620: 3222 2c20 2231 7375 6233 7375 6233 225d  2", "1sub3sub3"]
+00004630: 5d29 0a0a 2020 2020 6465 6620 7465 7374  ])..    def test
+00004640: 5f66 696c 6573 5f66 726f 6d5f 7769 7468  _files_from_with
+00004650: 5f69 6e63 6c75 7369 6f6e 7328 7365 6c66  _inclusions(self
+00004660: 293a 0a20 2020 2020 2020 2022 2222 2041  ):.        """ A
+00004670: 7070 6c79 2073 6f6d 6520 2d2d 6578 636c  pply some --excl
+00004680: 7564 6520 7275 6c65 7320 746f 2061 2062  ude rules to a b
+00004690: 6163 6b75 7020 6669 6c65 7365 7420 6465  ackup fileset de
+000046a0: 6669 6e65 6420 6279 202d 2d66 696c 6573  fined by --files
+000046b0: 2d66 726f 6d22 2222 0a20 2020 2020 2020  -from""".       
+000046c0: 2077 6974 6820 696f 2e6f 7065 6e28 2274   with io.open("t
+000046d0: 6573 7466 696c 6573 2f66 696c 6573 5f66  estfiles/files_f
+000046e0: 726f 6d2e 7478 7422 2c20 2277 2229 2061  rom.txt", "w") a
+000046f0: 7320 663a 0a20 2020 2020 2020 2020 2020  s f:.           
+00004700: 2066 2e77 7269 7465 2822 5c6e 222e 6a6f   f.write("\n".jo
+00004710: 696e 2873 656c 662e 7465 7374 6669 6c65  in(self.testfile
+00004720: 735f 6e75 6d62 6572 7329 290a 2020 2020  s_numbers)).    
+00004730: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
+00004740: 2266 756c 6c22 2c20 2274 6573 7466 696c  "full", "testfil
+00004750: 6573 2f73 656c 6563 7432 222c 0a20 2020  es/select2",.   
+00004760: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004770: 206f 7074 696f 6e73 3d5b 222d 2d66 696c   options=["--fil
+00004780: 6573 2d66 726f 6d22 2c20 2274 6573 7466  es-from", "testf
+00004790: 696c 6573 2f66 696c 6573 5f66 726f 6d2e  iles/files_from.
+000047a0: 7478 7422 2c0a 2020 2020 2020 2020 2020  txt",.          
+000047b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000047c0: 2020 2022 2d2d 696e 636c 7564 6522 2c20     "--include", 
+000047d0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+000047e0: 7432 2f31 2e2a 222c 0a20 2020 2020 2020  t2/1.*",.       
+000047f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004800: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+00004810: 222c 2022 2a2a 2e74 7874 222c 0a20 2020  ", "**.txt",.   
+00004820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004830: 2020 2020 2020 2020 2020 222d 2d65 7863            "--exc
+00004840: 6c75 6465 222c 2022 2a2a 225d 290a 2020  lude", "**"]).  
+00004850: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
+00004860: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
+00004870: 746f 7265 5f70 6174 6820 3d20 2274 6573  tore_path = "tes
+00004880: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
+00004890: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
+000048a0: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
+000048b0: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
+000048c0: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
+000048d0: 6f72 655f 7061 7468 290a 2020 2020 2020  ore_path).      
+000048e0: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
+000048f0: 616c 2872 6573 746f 7265 642c 205b 5b22  al(restored, [["
+00004900: 3122 2c20 2232 222c 2022 3322 2c20 2231  1", "2", "3", "1
+00004910: 2e64 6f63 222c 2022 312e 7079 225d 2c0a  .doc", "1.py"],.
+00004920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004940: 2020 2020 5b22 3173 7562 3122 5d2c 205b      ["1sub1"], [
+00004950: 2231 7375 6231 7375 6231 222c 2022 3173  "1sub1sub1", "1s
+00004960: 7562 3173 7562 3222 2c20 2231 7375 6231  ub1sub2", "1sub1
+00004970: 7375 6233 225d 2c0a 2020 2020 2020 2020  sub3"],.        
 00004980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004990: 2020 2020 2020 2020 2020 7522 2d2d 696e            u"--in
-000049a0: 636c 7564 6522 2c20 7522 2a2a 2e74 7874  clude", u"**.txt
-000049b0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-000049c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000049d0: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-000049e0: 2a2a 225d 290a 2020 2020 2020 2020 7365  **"]).        se
-000049f0: 6c66 2e72 6573 746f 7265 2829 0a20 2020  lf.restore().   
-00004a00: 2020 2020 2072 6573 746f 7265 5f64 6972       restore_dir
-00004a10: 203d 2075 2274 6573 7466 696c 6573 2f72   = u"testfiles/r
-00004a20: 6573 746f 7265 5f6f 7574 220a 2020 2020  estore_out".    
-00004a30: 2020 2020 7265 7374 6f72 6564 203d 2073      restored = s
-00004a40: 656c 662e 6469 7265 6374 6f72 795f 7472  elf.directory_tr
-00004a50: 6565 5f74 6f5f 6c69 7374 5f6f 665f 6c69  ee_to_list_of_li
-00004a60: 7374 7328 7265 7374 6f72 655f 6469 7229  sts(restore_dir)
-00004a70: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
-00004a80: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
-00004a90: 6564 2c20 5b5b 7522 3122 2c20 7522 3222  ed, [[u"1", u"2"
-00004aa0: 2c20 7522 3322 2c20 7522 312e 646f 6322  , u"3", u"1.doc"
-00004ab0: 2c20 7522 312e 7079 225d 2c0a 2020 2020  , u"1.py"],.    
-00004ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004ae0: 5b75 2231 7375 6231 225d 2c20 5b75 2231  [u"1sub1"], [u"1
-00004af0: 7375 6231 7375 6231 222c 2075 2231 7375  sub1sub1", u"1su
-00004b00: 6231 7375 6232 222c 2075 2231 7375 6231  b1sub2", u"1sub1
-00004b10: 7375 6233 225d 2c0a 2020 2020 2020 2020  sub3"],.        
-00004b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004b30: 2020 2020 2020 2020 2020 2020 5b75 2231              [u"1
-00004b40: 7375 6231 7375 6231 5f66 696c 652e 7478  sub1sub1_file.tx
-00004b50: 7422 5d2c 205b 7522 3173 7562 3173 7562  t"], [u"1sub1sub
-00004b60: 325f 6669 6c65 2e74 7874 225d 2c20 5b75  2_file.txt"], [u
-00004b70: 2231 7375 6231 7375 6233 5f66 696c 652e  "1sub1sub3_file.
-00004b80: 7478 7422 5d2c 0a20 2020 2020 2020 2020  txt"],.         
-00004b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004ba0: 2020 2020 2020 2020 2020 205b 7522 3273             [u"2s
-00004bb0: 7562 3122 5d2c 205b 7522 3273 7562 3173  ub1"], [u"2sub1s
-00004bc0: 7562 3122 5d2c 205b 7522 3273 7562 3173  ub1"], [u"2sub1s
-00004bd0: 7562 315f 6669 6c65 2e74 7874 225d 2c0a  ub1_file.txt"],.
-00004be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004990: 2020 2020 2020 2020 2020 2020 5b22 3173              ["1s
+000049a0: 7562 3173 7562 315f 6669 6c65 2e74 7874  ub1sub1_file.txt
+000049b0: 225d 2c20 5b22 3173 7562 3173 7562 325f  "], ["1sub1sub2_
+000049c0: 6669 6c65 2e74 7874 225d 2c20 5b22 3173  file.txt"], ["1s
+000049d0: 7562 3173 7562 335f 6669 6c65 2e74 7874  ub1sub3_file.txt
+000049e0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+000049f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004a00: 2020 2020 2020 2020 5b22 3273 7562 3122          ["2sub1"
+00004a10: 5d2c 205b 2232 7375 6231 7375 6231 225d  ], ["2sub1sub1"]
+00004a20: 2c20 5b22 3273 7562 3173 7562 315f 6669  , ["2sub1sub1_fi
+00004a30: 6c65 2e74 7874 225d 2c0a 2020 2020 2020  le.txt"],.      
+00004a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004a50: 2020 2020 2020 2020 2020 2020 2020 5b22                ["
+00004a60: 3373 7562 3322 5d2c 205b 2233 7375 6233  3sub3"], ["3sub3
+00004a70: 7375 6232 225d 2c20 5b22 3373 7562 3373  sub2"], ["3sub3s
+00004a80: 7562 325f 6669 6c65 2e74 7874 225d 5d29  ub2_file.txt"]])
+00004a90: 0a0a 2020 2020 6465 6620 7465 7374 5f66  ..    def test_f
+00004aa0: 696c 6573 5f66 726f 6d5f 6d75 6c74 6970  iles_from_multip
+00004ab0: 6c65 5f66 696c 656c 6973 7473 2873 656c  le_filelists(sel
+00004ac0: 6629 3a0a 2020 2020 2020 2020 2222 2220  f):.        """ 
+00004ad0: 5573 6520 6669 6c65 6c69 7374 7320 666f  Use filelists fo
+00004ae0: 7220 626f 7468 202d 2d66 696c 6573 2d66  r both --files-f
+00004af0: 726f 6d20 616e 6420 2d2d 696e 636c 7564  rom and --includ
+00004b00: 652d 6669 6c65 6c69 7374 2022 2222 0a20  e-filelist """. 
+00004b10: 2020 2020 2020 2077 6974 6820 696f 2e6f         with io.o
+00004b20: 7065 6e28 2274 6573 7466 696c 6573 2f66  pen("testfiles/f
+00004b30: 696c 6573 5f66 726f 6d2e 7478 7422 2c20  iles_from.txt", 
+00004b40: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
+00004b50: 2020 2020 2020 2066 2e77 7269 7465 2822         f.write("
+00004b60: 5c6e 222e 6a6f 696e 2873 656c 662e 7465  \n".join(self.te
+00004b70: 7374 6669 6c65 735f 6e75 6d62 6572 7329  stfiles_numbers)
+00004b80: 290a 2020 2020 2020 2020 7769 7468 2069  ).        with i
+00004b90: 6f2e 6f70 656e 2822 7465 7374 6669 6c65  o.open("testfile
+00004ba0: 732f 696e 636c 7564 652e 7478 7422 2c20  s/include.txt", 
+00004bb0: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
+00004bc0: 2020 2020 2020 2066 2e77 7269 7465 2822         f.write("
+00004bd0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00004be0: 322f 312f 3173 7562 325c 6e22 0a20 2020  2/1/1sub2\n".   
 00004bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004c00: 2020 2020 5b75 2233 7375 6233 225d 2c20      [u"3sub3"], 
-00004c10: 5b75 2233 7375 6233 7375 6232 225d 2c20  [u"3sub3sub2"], 
-00004c20: 5b75 2233 7375 6233 7375 6232 5f66 696c  [u"3sub3sub2_fil
-00004c30: 652e 7478 7422 5d5d 290a 0a20 2020 2064  e.txt"]])..    d
-00004c40: 6566 2074 6573 745f 6669 6c65 735f 6672  ef test_files_fr
-00004c50: 6f6d 5f6d 756c 7469 706c 655f 6669 6c65  om_multiple_file
-00004c60: 6c69 7374 7328 7365 6c66 293a 0a20 2020  lists(self):.   
-00004c70: 2020 2020 2075 2222 2220 5573 6520 6669       u""" Use fi
-00004c80: 6c65 6c69 7374 7320 666f 7220 626f 7468  lelists for both
-00004c90: 202d 2d66 696c 6573 2d66 726f 6d20 616e   --files-from an
-00004ca0: 6420 2d2d 696e 636c 7564 652d 6669 6c65  d --include-file
-00004cb0: 6c69 7374 2022 2222 0a20 2020 2020 2020  list """.       
-00004cc0: 2077 6974 6820 696f 2e6f 7065 6e28 7522   with io.open(u"
-00004cd0: 7465 7374 6669 6c65 732f 6669 6c65 735f  testfiles/files_
-00004ce0: 6672 6f6d 2e74 7874 222c 2075 2277 2229  from.txt", u"w")
-00004cf0: 2061 7320 663a 0a20 2020 2020 2020 2020   as f:.         
-00004d00: 2020 2066 2e77 7269 7465 2875 225c 6e22     f.write(u"\n"
-00004d10: 2e6a 6f69 6e28 7365 6c66 2e74 6573 7466  .join(self.testf
-00004d20: 696c 6573 5f6e 756d 6265 7273 2929 0a20  iles_numbers)). 
-00004d30: 2020 2020 2020 2077 6974 6820 696f 2e6f         with io.o
-00004d40: 7065 6e28 7522 7465 7374 6669 6c65 732f  pen(u"testfiles/
-00004d50: 696e 636c 7564 652e 7478 7422 2c20 7522  include.txt", u"
-00004d60: 7722 2920 6173 2066 3a0a 2020 2020 2020  w") as f:.      
-00004d70: 2020 2020 2020 662e 7772 6974 6528 7522        f.write(u"
-00004d80: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00004d90: 322f 312f 3173 7562 325c 6e22 0a20 2020  2/1/1sub2\n".   
-00004da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004db0: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00004dc0: 6563 7432 2f31 2f31 7375 6233 5c6e 220a  ect2/1/1sub3\n".
+00004c00: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00004c10: 6374 322f 312f 3173 7562 335c 6e22 0a20  ct2/1/1sub3\n". 
+00004c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004c30: 2020 2022 7465 7374 6669 6c65 732f 7365     "testfiles/se
+00004c40: 6c65 6374 322f 322f 3273 7562 325c 6e22  lect2/2/2sub2\n"
+00004c50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004c60: 2020 2020 2022 7465 7374 6669 6c65 732f       "testfiles/
+00004c70: 7365 6c65 6374 322f 322f 3273 7562 335c  select2/2/2sub3\
+00004c80: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+00004c90: 2020 2020 2020 2022 7465 7374 6669 6c65         "testfile
+00004ca0: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
+00004cb0: 315c 6e22 0a20 2020 2020 2020 2020 2020  1\n".           
+00004cc0: 2020 2020 2020 2020 2022 7465 7374 6669           "testfi
+00004cd0: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
+00004ce0: 7562 325c 6e22 0a20 2020 2020 2020 2020  ub2\n".         
+00004cf0: 2020 2020 2020 2020 2020 2022 7465 7374             "test
+00004d00: 6669 6c65 732f 7365 6c65 6374 322f 7472  files/select2/tr
+00004d10: 6169 6c69 6e67 5f73 7061 6365 2a22 2920  ailing_space*") 
+00004d20: 2023 206c 6173 7420 696e 636c 7564 6520   # last include 
+00004d30: 646f 6573 206e 6f74 6869 6e67 2064 7565  does nothing due
+00004d40: 2074 6f20 2d2d 6669 6c65 732d 6672 6f6d   to --files-from
+00004d50: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
+00004d60: 636b 7570 2822 6675 6c6c 222c 2022 7465  ckup("full", "te
+00004d70: 7374 6669 6c65 732f 7365 6c65 6374 3222  stfiles/select2"
+00004d80: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00004d90: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+00004da0: 2d2d 6669 6c65 732d 6672 6f6d 222c 2022  --files-from", "
+00004db0: 7465 7374 6669 6c65 732f 6669 6c65 735f  testfiles/files_
+00004dc0: 6672 6f6d 2e74 7874 222c 0a20 2020 2020  from.txt",.     
 00004dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004de0: 2020 2020 7522 7465 7374 6669 6c65 732f      u"testfiles/
-00004df0: 7365 6c65 6374 322f 322f 3273 7562 325c  select2/2/2sub2\
-00004e00: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00004e10: 2020 2020 2020 2075 2274 6573 7466 696c         u"testfil
-00004e20: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
-00004e30: 6233 5c6e 220a 2020 2020 2020 2020 2020  b3\n".          
-00004e40: 2020 2020 2020 2020 2020 7522 7465 7374            u"test
-00004e50: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
-00004e60: 3373 7562 315c 6e22 0a20 2020 2020 2020  3sub1\n".       
-00004e70: 2020 2020 2020 2020 2020 2020 2075 2274               u"t
-00004e80: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00004e90: 2f33 2f33 7375 6232 5c6e 220a 2020 2020  /3/3sub2\n".    
-00004ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004eb0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00004ec0: 6374 322f 7472 6169 6c69 6e67 5f73 7061  ct2/trailing_spa
-00004ed0: 6365 2a22 2920 2023 206c 6173 7420 696e  ce*")  # last in
-00004ee0: 636c 7564 6520 646f 6573 206e 6f74 6869  clude does nothi
-00004ef0: 6e67 2064 7565 2074 6f20 2d2d 6669 6c65  ng due to --file
-00004f00: 732d 6672 6f6d 0a20 2020 2020 2020 2073  s-from.        s
-00004f10: 656c 662e 6261 636b 7570 2875 2266 756c  elf.backup(u"ful
-00004f20: 6c22 2c20 7522 7465 7374 6669 6c65 732f  l", u"testfiles/
-00004f30: 7365 6c65 6374 3222 2c0a 2020 2020 2020  select2",.      
-00004f40: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00004f50: 7469 6f6e 733d 5b75 222d 2d66 696c 6573  tions=[u"--files
-00004f60: 2d66 726f 6d22 2c20 7522 7465 7374 6669  -from", u"testfi
-00004f70: 6c65 732f 6669 6c65 735f 6672 6f6d 2e74  les/files_from.t
-00004f80: 7874 222c 0a20 2020 2020 2020 2020 2020  xt",.           
+00004de0: 2020 2020 2020 2020 222d 2d69 6e63 6c75          "--inclu
+00004df0: 6465 2d66 696c 656c 6973 7422 2c20 2274  de-filelist", "t
+00004e00: 6573 7466 696c 6573 2f69 6e63 6c75 6465  estfiles/include
+00004e10: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
+00004e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004e30: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00004e40: 2022 2a2a 225d 290a 2020 2020 2020 2020   "**"]).        
+00004e50: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
+00004e60: 2020 2020 2020 2072 6573 746f 7265 5f70         restore_p
+00004e70: 6174 6820 3d20 2274 6573 7466 696c 6573  ath = "testfiles
+00004e80: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
+00004e90: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
+00004ea0: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
+00004eb0: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
+00004ec0: 6c69 7374 7328 7265 7374 6f72 655f 7061  lists(restore_pa
+00004ed0: 7468 290a 2020 2020 2020 2020 7365 6c66  th).        self
+00004ee0: 2e61 7373 6572 7445 7175 616c 2872 6573  .assertEqual(res
+00004ef0: 746f 7265 642c 205b 5b22 3122 2c20 2232  tored, [["1", "2
+00004f00: 222c 2022 3322 5d2c 0a20 2020 2020 2020  ", "3"],.       
+00004f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004f20: 2020 2020 2020 2020 2020 2020 205b 2231               ["1
+00004f30: 7375 6232 222c 2022 3173 7562 3322 5d2c  sub2", "1sub3"],
+00004f40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004f60: 2020 2020 205b 2231 7375 6232 7375 6231       ["1sub2sub1
+00004f70: 222c 2022 3173 7562 3273 7562 3222 2c20  ", "1sub2sub2", 
+00004f80: 2231 7375 6232 7375 6233 225d 2c0a 2020  "1sub2sub3"],.  
 00004f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004fa0: 2020 7522 2d2d 696e 636c 7564 652d 6669    u"--include-fi
-00004fb0: 6c65 6c69 7374 222c 2075 2274 6573 7466  lelist", u"testf
-00004fc0: 696c 6573 2f69 6e63 6c75 6465 2e74 7874  iles/include.txt
-00004fd0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00004fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004fb0: 2020 5b22 3173 7562 3373 7562 3122 2c20    ["1sub3sub1", 
+00004fc0: 2231 7375 6233 7375 6232 222c 2022 3173  "1sub3sub2", "1s
+00004fd0: 7562 3373 7562 3322 5d2c 0a20 2020 2020  ub3sub3"],.     
 00004fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004ff0: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00005000: 2a2a 225d 290a 2020 2020 2020 2020 7365  **"]).        se
-00005010: 6c66 2e72 6573 746f 7265 2829 0a20 2020  lf.restore().   
-00005020: 2020 2020 2072 6573 746f 7265 5f64 6972       restore_dir
-00005030: 203d 2075 2274 6573 7466 696c 6573 2f72   = u"testfiles/r
-00005040: 6573 746f 7265 5f6f 7574 220a 2020 2020  estore_out".    
-00005050: 2020 2020 7265 7374 6f72 6564 203d 2073      restored = s
-00005060: 656c 662e 6469 7265 6374 6f72 795f 7472  elf.directory_tr
-00005070: 6565 5f74 6f5f 6c69 7374 5f6f 665f 6c69  ee_to_list_of_li
-00005080: 7374 7328 7265 7374 6f72 655f 6469 7229  sts(restore_dir)
-00005090: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
-000050a0: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
-000050b0: 6564 2c20 5b5b 7522 3122 2c20 7522 3222  ed, [[u"1", u"2"
-000050c0: 2c20 7522 3322 5d2c 0a20 2020 2020 2020  , u"3"],.       
-000050d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000050e0: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-000050f0: 3173 7562 3222 2c20 7522 3173 7562 3322  1sub2", u"1sub3"
-00005100: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00005110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005120: 2020 2020 2020 205b 7522 3173 7562 3273         [u"1sub2s
-00005130: 7562 3122 2c20 7522 3173 7562 3273 7562  ub1", u"1sub2sub
-00005140: 3222 2c20 7522 3173 7562 3273 7562 3322  2", u"1sub2sub3"
-00005150: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00005160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005170: 2020 2020 2020 205b 7522 3173 7562 3373         [u"1sub3s
-00005180: 7562 3122 2c20 7522 3173 7562 3373 7562  ub1", u"1sub3sub
-00005190: 3222 2c20 7522 3173 7562 3373 7562 3322  2", u"1sub3sub3"
-000051a0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-000051b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000051c0: 2020 2020 2020 205b 7522 3273 7562 3222         [u"2sub2"
-000051d0: 2c20 7522 3273 7562 3322 5d2c 0a20 2020  , u"2sub3"],.   
-000051e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000051f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005200: 205b 7522 3273 7562 3273 7562 3122 2c20   [u"2sub2sub1", 
-00005210: 7522 3273 7562 3273 7562 3222 2c20 7522  u"2sub2sub2", u"
-00005220: 3273 7562 3273 7562 3322 5d2c 0a20 2020  2sub2sub3"],.   
-00005230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005250: 205b 7522 3273 7562 3373 7562 3122 2c20   [u"2sub3sub1", 
-00005260: 7522 3273 7562 3373 7562 3222 2c20 7522  u"2sub3sub2", u"
-00005270: 3273 7562 3373 7562 3322 5d2c 0a20 2020  2sub3sub3"],.   
-00005280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000052a0: 205b 7522 3373 7562 3122 2c20 7522 3373   [u"3sub1", u"3s
-000052b0: 7562 3222 5d2c 0a20 2020 2020 2020 2020  ub2"],.         
+00004ff0: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+00005000: 2232 7375 6232 222c 2022 3273 7562 3322  "2sub2", "2sub3"
+00005010: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00005020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005030: 2020 2020 2020 205b 2232 7375 6232 7375         ["2sub2su
+00005040: 6231 222c 2022 3273 7562 3273 7562 3222  b1", "2sub2sub2"
+00005050: 2c20 2232 7375 6232 7375 6233 225d 2c0a  , "2sub2sub3"],.
+00005060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005080: 2020 2020 5b22 3273 7562 3373 7562 3122      ["2sub3sub1"
+00005090: 2c20 2232 7375 6233 7375 6232 222c 2022  , "2sub3sub2", "
+000050a0: 3273 7562 3373 7562 3322 5d2c 0a20 2020  2sub3sub3"],.   
+000050b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000050c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000050d0: 205b 2233 7375 6231 222c 2022 3373 7562   ["3sub1", "3sub
+000050e0: 3222 5d2c 0a20 2020 2020 2020 2020 2020  2"],.           
+000050f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005100: 2020 2020 2020 2020 205b 2233 7375 6231           ["3sub1
+00005110: 7375 6231 222c 2022 3373 7562 3173 7562  sub1", "3sub1sub
+00005120: 3222 2c20 2233 7375 6231 7375 6233 225d  2", "3sub1sub3"]
+00005130: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00005140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005150: 2020 2020 2020 5b22 3373 7562 3273 7562        ["3sub2sub
+00005160: 3122 2c20 2233 7375 6232 7375 6232 222c  1", "3sub2sub2",
+00005170: 2022 3373 7562 3273 7562 3322 5d5d 290a   "3sub2sub3"]]).
+00005180: 0a20 2020 2064 6566 2074 6573 745f 6669  .    def test_fi
+00005190: 6c65 735f 6672 6f6d 5f6e 756c 6c5f 7365  les_from_null_se
+000051a0: 7061 7261 746f 7228 7365 6c66 293a 0a20  parator(self):. 
+000051b0: 2020 2020 2020 2022 2222 2055 7369 6e67         """ Using
+000051c0: 206e 756c 6c73 2074 6f20 7365 7061 7261   nulls to separa
+000051d0: 7465 202d 2d66 696c 6573 2d66 726f 6d20  te --files-from 
+000051e0: 2222 220a 2020 2020 2020 2020 7769 7468  """.        with
+000051f0: 2069 6f2e 6f70 656e 2822 7465 7374 6669   io.open("testfi
+00005200: 6c65 732f 6669 6c65 735f 6672 6f6d 2e74  les/files_from.t
+00005210: 7874 222c 2022 7722 2920 6173 2066 3a0a  xt", "w") as f:.
+00005220: 2020 2020 2020 2020 2020 2020 662e 7772              f.wr
+00005230: 6974 6528 225c 3022 2e6a 6f69 6e28 7365  ite("\0".join(se
+00005240: 6c66 2e74 6573 7466 696c 6573 5f6e 756d  lf.testfiles_num
+00005250: 6265 7273 2929 0a20 2020 2020 2020 2073  bers)).        s
+00005260: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+00005270: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00005280: 6c65 6374 3222 2c0a 2020 2020 2020 2020  lect2",.        
+00005290: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
+000052a0: 6f6e 733d 5b22 2d2d 6e75 6c6c 2d73 6570  ons=["--null-sep
+000052b0: 6172 6174 6f72 222c 0a20 2020 2020 2020  arator",.       
 000052c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000052d0: 2020 2020 2020 2020 2020 205b 7522 3373             [u"3s
-000052e0: 7562 3173 7562 3122 2c20 7522 3373 7562  ub1sub1", u"3sub
-000052f0: 3173 7562 3222 2c20 7522 3373 7562 3173  1sub2", u"3sub1s
-00005300: 7562 3322 5d2c 0a20 2020 2020 2020 2020  ub3"],.         
-00005310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005320: 2020 2020 2020 2020 2020 205b 7522 3373             [u"3s
-00005330: 7562 3273 7562 3122 2c20 7522 3373 7562  ub2sub1", u"3sub
-00005340: 3273 7562 3222 2c20 7522 3373 7562 3273  2sub2", u"3sub2s
-00005350: 7562 3322 5d5d 290a 0a20 2020 2064 6566  ub3"]])..    def
-00005360: 2074 6573 745f 6669 6c65 735f 6672 6f6d   test_files_from
-00005370: 5f6e 756c 6c5f 7365 7061 7261 746f 7228  _null_separator(
-00005380: 7365 6c66 293a 0a20 2020 2020 2020 2075  self):.        u
-00005390: 2222 2220 5573 696e 6720 6e75 6c6c 7320  """ Using nulls 
-000053a0: 746f 2073 6570 6172 6174 6520 2d2d 6669  to separate --fi
-000053b0: 6c65 732d 6672 6f6d 2022 2222 0a20 2020  les-from """.   
-000053c0: 2020 2020 2077 6974 6820 696f 2e6f 7065       with io.ope
-000053d0: 6e28 7522 7465 7374 6669 6c65 732f 6669  n(u"testfiles/fi
-000053e0: 6c65 735f 6672 6f6d 2e74 7874 222c 2075  les_from.txt", u
-000053f0: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
-00005400: 2020 2020 2020 2066 2e77 7269 7465 2875         f.write(u
-00005410: 225c 3022 2e6a 6f69 6e28 7365 6c66 2e74  "\0".join(self.t
-00005420: 6573 7466 696c 6573 5f6e 756d 6265 7273  estfiles_numbers
-00005430: 2929 0a20 2020 2020 2020 2073 656c 662e  )).        self.
-00005440: 6261 636b 7570 2875 2266 756c 6c22 2c20  backup(u"full", 
-00005450: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00005460: 6374 3222 2c0a 2020 2020 2020 2020 2020  ct2",.          
-00005470: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
-00005480: 733d 5b75 222d 2d6e 756c 6c2d 7365 7061  s=[u"--null-sepa
-00005490: 7261 746f 7222 2c0a 2020 2020 2020 2020  rator",.        
-000054a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000054b0: 2020 2020 2075 222d 2d66 696c 6573 2d66       u"--files-f
-000054c0: 726f 6d22 2c20 7522 7465 7374 6669 6c65  rom", u"testfile
-000054d0: 732f 6669 6c65 735f 6672 6f6d 2e74 7874  s/files_from.txt
-000054e0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-000054f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005500: 7522 2d2d 696e 636c 7564 6522 2c20 7522  u"--include", u"
-00005510: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00005520: 322f 312f 3173 7562 3222 2c0a 2020 2020  2/1/1sub2",.    
-00005530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005540: 2020 2020 2020 2020 2075 222d 2d69 6e63           u"--inc
-00005550: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00005560: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-00005570: 6233 222c 0a20 2020 2020 2020 2020 2020  b3",.           
-00005580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005590: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-000055a0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-000055b0: 6374 322f 322f 3273 7562 3222 2c0a 2020  ct2/2/2sub2",.  
-000055c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000055d0: 2020 2020 2020 2020 2020 2075 222d 2d69             u"--i
-000055e0: 6e63 6c75 6465 222c 2075 2274 6573 7466  nclude", u"testf
-000055f0: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
-00005600: 7375 6233 222c 0a20 2020 2020 2020 2020  sub3",.         
-00005610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005620: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-00005630: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00005640: 6c65 6374 322f 332f 3373 7562 3122 2c0a  lect2/3/3sub1",.
-00005650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005660: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00005670: 2d69 6e63 6c75 6465 222c 2075 2274 6573  -include", u"tes
-00005680: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
-00005690: 2f33 7375 6232 222c 0a20 2020 2020 2020  /3sub2",.       
-000056a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000056b0: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-000056c0: 6522 2c20 7522 2a2a 225d 290a 2020 2020  e", u"**"]).    
-000056d0: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
-000056e0: 2829 0a20 2020 2020 2020 2072 6573 746f  ().        resto
-000056f0: 7265 5f64 6972 203d 2075 2274 6573 7466  re_dir = u"testf
-00005700: 696c 6573 2f72 6573 746f 7265 5f6f 7574  iles/restore_out
-00005710: 220a 2020 2020 2020 2020 7265 7374 6f72  ".        restor
-00005720: 6564 203d 2073 656c 662e 6469 7265 6374  ed = self.direct
-00005730: 6f72 795f 7472 6565 5f74 6f5f 6c69 7374  ory_tree_to_list
-00005740: 5f6f 665f 6c69 7374 7328 7265 7374 6f72  _of_lists(restor
-00005750: 655f 6469 7229 0a20 2020 2020 2020 2073  e_dir).        s
-00005760: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
-00005770: 7265 7374 6f72 6564 2c20 5b5b 7522 3122  restored, [[u"1"
-00005780: 2c20 7522 3222 2c20 7522 3322 5d2c 0a20  , u"2", u"3"],. 
-00005790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000057a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000057b0: 2020 205b 7522 3173 7562 3222 2c20 7522     [u"1sub2", u"
-000057c0: 3173 7562 3322 5d2c 0a20 2020 2020 2020  1sub3"],.       
+000052d0: 2020 2020 2020 222d 2d66 696c 6573 2d66        "--files-f
+000052e0: 726f 6d22 2c20 2274 6573 7466 696c 6573  rom", "testfiles
+000052f0: 2f66 696c 6573 5f66 726f 6d2e 7478 7422  /files_from.txt"
+00005300: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00005310: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00005320: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+00005330: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+00005340: 2f31 7375 6232 222c 0a20 2020 2020 2020  /1sub2",.       
+00005350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005360: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+00005370: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00005380: 6c65 6374 322f 312f 3173 7562 3322 2c0a  lect2/1/1sub3",.
+00005390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000053a0: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+000053b0: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+000053c0: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
+000053d0: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
+000053e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000053f0: 2020 2020 222d 2d69 6e63 6c75 6465 222c      "--include",
+00005400: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00005410: 6374 322f 322f 3273 7562 3322 2c0a 2020  ct2/2/2sub3",.  
+00005420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005430: 2020 2020 2020 2020 2020 2022 2d2d 696e             "--in
+00005440: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00005450: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
+00005460: 6231 222c 0a20 2020 2020 2020 2020 2020  b1",.           
+00005470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005480: 2020 222d 2d69 6e63 6c75 6465 222c 2022    "--include", "
+00005490: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+000054a0: 322f 332f 3373 7562 3222 2c0a 2020 2020  2/3/3sub2",.    
+000054b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000054c0: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+000054d0: 7564 6522 2c20 222a 2a22 5d29 0a20 2020  ude", "**"]).   
+000054e0: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
+000054f0: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
+00005500: 6f72 655f 7061 7468 203d 2022 7465 7374  ore_path = "test
+00005510: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
+00005520: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
+00005530: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
+00005540: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
+00005550: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
+00005560: 7265 5f70 6174 6829 0a20 2020 2020 2020  re_path).       
+00005570: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
+00005580: 6c28 7265 7374 6f72 6564 2c20 5b5b 2231  l(restored, [["1
+00005590: 222c 2022 3222 2c20 2233 225d 2c0a 2020  ", "2", "3"],.  
+000055a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000055b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000055c0: 2020 5b22 3173 7562 3222 2c20 2231 7375    ["1sub2", "1su
+000055d0: 6233 225d 2c0a 2020 2020 2020 2020 2020  b3"],.          
+000055e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000055f0: 2020 2020 2020 2020 2020 5b22 3173 7562            ["1sub
+00005600: 3273 7562 3122 2c20 2231 7375 6232 7375  2sub1", "1sub2su
+00005610: 6232 222c 2022 3173 7562 3273 7562 3322  b2", "1sub2sub3"
+00005620: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00005630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005640: 2020 2020 2020 205b 2231 7375 6233 7375         ["1sub3su
+00005650: 6231 222c 2022 3173 7562 3373 7562 3222  b1", "1sub3sub2"
+00005660: 2c20 2231 7375 6233 7375 6233 225d 2c0a  , "1sub3sub3"],.
+00005670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005690: 2020 2020 5b22 3273 7562 3222 2c20 2232      ["2sub2", "2
+000056a0: 7375 6233 225d 2c0a 2020 2020 2020 2020  sub3"],.        
+000056b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000056c0: 2020 2020 2020 2020 2020 2020 5b22 3273              ["2s
+000056d0: 7562 3273 7562 3122 2c20 2232 7375 6232  ub2sub1", "2sub2
+000056e0: 7375 6232 222c 2022 3273 7562 3273 7562  sub2", "2sub2sub
+000056f0: 3322 5d2c 0a20 2020 2020 2020 2020 2020  3"],.           
+00005700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005710: 2020 2020 2020 2020 205b 2232 7375 6233           ["2sub3
+00005720: 7375 6231 222c 2022 3273 7562 3373 7562  sub1", "2sub3sub
+00005730: 3222 2c20 2232 7375 6233 7375 6233 225d  2", "2sub3sub3"]
+00005740: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00005750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005760: 2020 2020 2020 5b22 3373 7562 3122 2c20        ["3sub1", 
+00005770: 2233 7375 6232 225d 2c0a 2020 2020 2020  "3sub2"],.      
+00005780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005790: 2020 2020 2020 2020 2020 2020 2020 5b22                ["
+000057a0: 3373 7562 3173 7562 3122 2c20 2233 7375  3sub1sub1", "3su
+000057b0: 6231 7375 6232 222c 2022 3373 7562 3173  b1sub2", "3sub1s
+000057c0: 7562 3322 5d2c 0a20 2020 2020 2020 2020  ub3"],.         
 000057d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000057e0: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-000057f0: 3173 7562 3273 7562 3122 2c20 7522 3173  1sub2sub1", u"1s
-00005800: 7562 3273 7562 3222 2c20 7522 3173 7562  ub2sub2", u"1sub
-00005810: 3273 7562 3322 5d2c 0a20 2020 2020 2020  2sub3"],.       
-00005820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005830: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-00005840: 3173 7562 3373 7562 3122 2c20 7522 3173  1sub3sub1", u"1s
-00005850: 7562 3373 7562 3222 2c20 7522 3173 7562  ub3sub2", u"1sub
-00005860: 3373 7562 3322 5d2c 0a20 2020 2020 2020  3sub3"],.       
-00005870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005880: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-00005890: 3273 7562 3222 2c20 7522 3273 7562 3322  2sub2", u"2sub3"
-000058a0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-000058b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000058c0: 2020 2020 2020 205b 7522 3273 7562 3273         [u"2sub2s
-000058d0: 7562 3122 2c20 7522 3273 7562 3273 7562  ub1", u"2sub2sub
-000058e0: 3222 2c20 7522 3273 7562 3273 7562 3322  2", u"2sub2sub3"
-000058f0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00005900: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005910: 2020 2020 2020 205b 7522 3273 7562 3373         [u"2sub3s
-00005920: 7562 3122 2c20 7522 3273 7562 3373 7562  ub1", u"2sub3sub
-00005930: 3222 2c20 7522 3273 7562 3373 7562 3322  2", u"2sub3sub3"
-00005940: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00005950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005960: 2020 2020 2020 205b 7522 3373 7562 3122         [u"3sub1"
-00005970: 2c20 7522 3373 7562 3222 5d2c 0a20 2020  , u"3sub2"],.   
-00005980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000059a0: 205b 7522 3373 7562 3173 7562 3122 2c20   [u"3sub1sub1", 
-000059b0: 7522 3373 7562 3173 7562 3222 2c20 7522  u"3sub1sub2", u"
-000059c0: 3373 7562 3173 7562 3322 5d2c 0a20 2020  3sub1sub3"],.   
+000057e0: 2020 2020 2020 2020 2020 205b 2233 7375             ["3su
+000057f0: 6232 7375 6231 222c 2022 3373 7562 3273  b2sub1", "3sub2s
+00005800: 7562 3222 2c20 2233 7375 6232 7375 6233  ub2", "3sub2sub3
+00005810: 225d 5d29 0a0a 0a63 6c61 7373 2054 6573  "]])...class Tes
+00005820: 7449 6e63 6c75 6465 4578 636c 7564 654f  tIncludeExcludeO
+00005830: 7074 696f 6e73 2849 6e63 6c75 6465 4578  ptions(IncludeEx
+00005840: 636c 7564 6546 756e 6374 696f 6e61 6c54  cludeFunctionalT
+00005850: 6573 7429 3a0a 2020 2020 2222 2220 5468  est):.    """ Th
+00005860: 6973 2074 6573 7473 2074 6865 2062 6568  is tests the beh
+00005870: 6176 696f 7572 206f 6620 7468 6520 6475  aviour of the du
+00005880: 706c 6963 6974 7920 6269 6e61 7279 2077  plicity binary w
+00005890: 6865 6e20 7468 6520 696e 636c 7564 652f  hen the include/
+000058a0: 6578 636c 7564 6520 6f70 7469 6f6e 7320  exclude options 
+000058b0: 6172 6520 7061 7373 6564 2064 6972 6563  are passed direc
+000058c0: 746c 7920 2222 220a 0a20 2020 2064 6566  tly """..    def
+000058d0: 2074 6573 745f 696e 636c 7564 655f 6578   test_include_ex
+000058e0: 636c 7564 655f 6261 7369 6328 7365 6c66  clude_basic(self
+000058f0: 293a 0a20 2020 2020 2020 2022 2222 2054  ):.        """ T
+00005900: 6573 7420 2d2d 696e 636c 7564 6520 616e  est --include an
+00005910: 6420 2d2d 6578 636c 7564 6520 776f 726b  d --exclude work
+00005920: 2069 6e20 7468 6520 6261 7369 6320 6361   in the basic ca
+00005930: 7365 2022 2222 0a20 2020 2020 2020 2073  se """.        s
+00005940: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+00005950: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00005960: 6c65 6374 3222 2c0a 2020 2020 2020 2020  lect2",.        
+00005970: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
+00005980: 6f6e 733d 5b22 2d2d 696e 636c 7564 6522  ons=["--include"
+00005990: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+000059a0: 6563 7432 2f33 2f33 7375 6233 2f33 7375  ect2/3/3sub3/3su
+000059b0: 6233 7375 6232 2f33 7375 6233 7375 6232  b3sub2/3sub3sub2
+000059c0: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
 000059d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000059e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000059f0: 205b 7522 3373 7562 3273 7562 3122 2c20   [u"3sub2sub1", 
-00005a00: 7522 3373 7562 3273 7562 3222 2c20 7522  u"3sub2sub2", u"
-00005a10: 3373 7562 3273 7562 3322 5d5d 290a 0a0a  3sub2sub3"]])...
-00005a20: 636c 6173 7320 5465 7374 496e 636c 7564  class TestInclud
-00005a30: 6545 7863 6c75 6465 4f70 7469 6f6e 7328  eExcludeOptions(
-00005a40: 496e 636c 7564 6545 7863 6c75 6465 4675  IncludeExcludeFu
-00005a50: 6e63 7469 6f6e 616c 5465 7374 293a 0a20  nctionalTest):. 
-00005a60: 2020 2075 2222 2220 5468 6973 2074 6573     u""" This tes
-00005a70: 7473 2074 6865 2062 6568 6176 696f 7572  ts the behaviour
-00005a80: 206f 6620 7468 6520 6475 706c 6963 6974   of the duplicit
-00005a90: 7920 6269 6e61 7279 2077 6865 6e20 7468  y binary when th
-00005aa0: 6520 696e 636c 7564 652f 6578 636c 7564  e include/exclud
-00005ab0: 6520 6f70 7469 6f6e 7320 6172 6520 7061  e options are pa
-00005ac0: 7373 6564 2064 6972 6563 746c 7920 2222  ssed directly ""
-00005ad0: 220a 0a20 2020 2064 6566 2074 6573 745f  "..    def test_
-00005ae0: 696e 636c 7564 655f 6578 636c 7564 655f  include_exclude_
-00005af0: 6261 7369 6328 7365 6c66 293a 0a20 2020  basic(self):.   
-00005b00: 2020 2020 2075 2222 2220 5465 7374 202d       u""" Test -
-00005b10: 2d69 6e63 6c75 6465 2061 6e64 202d 2d65  -include and --e
-00005b20: 7863 6c75 6465 2077 6f72 6b20 696e 2074  xclude work in t
-00005b30: 6865 2062 6173 6963 2063 6173 6520 2222  he basic case ""
-00005b40: 220a 2020 2020 2020 2020 7365 6c66 2e62  ".        self.b
-00005b50: 6163 6b75 7028 7522 6675 6c6c 222c 2075  ackup(u"full", u
-00005b60: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00005b70: 7432 222c 0a20 2020 2020 2020 2020 2020  t2",.           
-00005b80: 2020 2020 2020 2020 206f 7074 696f 6e73           options
-00005b90: 3d5b 7522 2d2d 696e 636c 7564 6522 2c20  =[u"--include", 
-00005ba0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00005bb0: 6374 322f 332f 3373 7562 332f 3373 7562  ct2/3/3sub3/3sub
-00005bc0: 3373 7562 322f 3373 7562 3373 7562 325f  3sub2/3sub3sub2_
-00005bd0: 6669 6c65 2e74 7874 222c 0a20 2020 2020  file.txt",.     
-00005be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005bf0: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-00005c00: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-00005c10: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-00005c20: 332f 3373 7562 3373 7562 3222 2c0a 2020  3/3sub3sub2",.  
-00005c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005c40: 2020 2020 2020 2020 2020 2075 222d 2d69             u"--i
-00005c50: 6e63 6c75 6465 222c 2075 2274 6573 7466  nclude", u"testf
-00005c60: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
-00005c70: 7375 6232 2f33 7375 6232 7375 6232 222c  sub2/3sub2sub2",
-00005c80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005c90: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00005ca0: 2d2d 696e 636c 7564 6522 2c20 7522 7465  --include", u"te
-00005cb0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00005cc0: 332f 3373 7562 3322 2c0a 2020 2020 2020  3/3sub3",.      
-00005cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005ce0: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-00005cf0: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00005d00: 2f73 656c 6563 7432 2f33 2f33 7375 6231  /select2/3/3sub1
-00005d10: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00005d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005d30: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00005d40: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00005d50: 322f 322f 3273 7562 312f 3273 7562 3173  2/2/2sub1/2sub1s
-00005d60: 7562 3322 2c0a 2020 2020 2020 2020 2020  ub3",.          
-00005d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005d80: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-00005d90: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00005da0: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
-00005db0: 6231 7375 6232 222c 0a20 2020 2020 2020  b1sub2",.       
-00005dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005dd0: 2020 2020 2020 7522 2d2d 696e 636c 7564        u"--includ
-00005de0: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-00005df0: 7365 6c65 6374 322f 322f 3273 7562 3122  select2/2/2sub1"
-00005e00: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00005e10: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00005e20: 222d 2d65 7863 6c75 6465 222c 2075 2274  "--exclude", u"t
-00005e30: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00005e40: 2f31 2f31 7375 6233 2f31 7375 6233 7375  /1/1sub3/1sub3su
-00005e50: 6232 222c 0a20 2020 2020 2020 2020 2020  b2",.           
-00005e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005e70: 2020 7522 2d2d 6578 636c 7564 6522 2c20    u"--exclude", 
-00005e80: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00005e90: 6374 322f 312f 3173 7562 332f 3173 7562  ct2/1/1sub3/1sub
-00005ea0: 3373 7562 3122 2c0a 2020 2020 2020 2020  3sub1",.        
+000059e0: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+000059f0: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00005a00: 2f73 656c 6563 7432 2f33 2f33 7375 6233  /select2/3/3sub3
+00005a10: 2f33 7375 6233 7375 6232 222c 0a20 2020  /3sub3sub2",.   
+00005a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005a30: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+00005a40: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00005a50: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
+00005a60: 322f 3373 7562 3273 7562 3222 2c0a 2020  2/3sub2sub2",.  
+00005a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005a80: 2020 2020 2020 2020 2020 2022 2d2d 696e             "--in
+00005a90: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00005aa0: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
+00005ab0: 6233 222c 0a20 2020 2020 2020 2020 2020  b3",.           
+00005ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005ad0: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+00005ae0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00005af0: 322f 332f 3373 7562 3122 2c0a 2020 2020  2/3/3sub1",.    
+00005b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b10: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00005b20: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00005b30: 2f73 656c 6563 7432 2f32 2f32 7375 6231  /select2/2/2sub1
+00005b40: 2f32 7375 6231 7375 6233 222c 0a20 2020  /2sub1sub3",.   
+00005b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005b60: 2020 2020 2020 2020 2020 222d 2d65 7863            "--exc
+00005b70: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00005b80: 732f 7365 6c65 6374 322f 322f 3273 7562  s/select2/2/2sub
+00005b90: 312f 3273 7562 3173 7562 3222 2c0a 2020  1/2sub1sub2",.  
+00005ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005bb0: 2020 2020 2020 2020 2020 2022 2d2d 696e             "--in
+00005bc0: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00005bd0: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
+00005be0: 6231 222c 0a20 2020 2020 2020 2020 2020  b1",.           
+00005bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005c00: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+00005c10: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00005c20: 322f 312f 3173 7562 332f 3173 7562 3373  2/1/1sub3/1sub3s
+00005c30: 7562 3222 2c0a 2020 2020 2020 2020 2020  ub2",.          
+00005c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005c50: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00005c60: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00005c70: 7432 2f31 2f31 7375 6233 2f31 7375 6233  t2/1/1sub3/1sub3
+00005c80: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
+00005c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005ca0: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00005cb0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00005cc0: 6374 322f 312f 3173 7562 322f 3173 7562  ct2/1/1sub2/1sub
+00005cd0: 3273 7562 3322 2c0a 2020 2020 2020 2020  2sub3",.        
+00005ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005cf0: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+00005d00: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00005d10: 6563 7432 2f31 2f31 7375 6232 2f31 7375  ect2/1/1sub2/1su
+00005d20: 6232 7375 6231 222c 0a20 2020 2020 2020  b2sub1",.       
+00005d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005d40: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+00005d50: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00005d60: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
+00005d70: 7562 3173 7562 332f 3173 7562 3173 7562  ub1sub3/1sub1sub
+00005d80: 335f 6669 6c65 2e74 7874 222c 0a20 2020  3_file.txt",.   
+00005d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005da0: 2020 2020 2020 2020 2020 222d 2d65 7863            "--exc
+00005db0: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00005dc0: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
+00005dd0: 312f 3173 7562 3173 7562 3222 2c0a 2020  1/1sub1sub2",.  
+00005de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005df0: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00005e00: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00005e10: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+00005e20: 6232 222c 0a20 2020 2020 2020 2020 2020  b2",.           
+00005e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005e40: 2020 222d 2d69 6e63 6c75 6465 222c 2022    "--include", "
+00005e50: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00005e60: 322f 312e 7079 222c 0a20 2020 2020 2020  2/1.py",.       
+00005e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005e80: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+00005e90: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00005ea0: 6c65 6374 322f 3322 2c0a 2020 2020 2020  lect2/3",.      
 00005eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005ec0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00005ed0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00005ee0: 656c 6563 7432 2f31 2f31 7375 6232 2f31  elect2/1/1sub2/1
-00005ef0: 7375 6232 7375 6233 222c 0a20 2020 2020  sub2sub3",.     
-00005f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005f10: 2020 2020 2020 2020 7522 2d2d 696e 636c          u"--incl
-00005f20: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-00005f30: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-00005f40: 322f 3173 7562 3273 7562 3122 2c0a 2020  2/1sub2sub1",.  
-00005f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005f60: 2020 2020 2020 2020 2020 2075 222d 2d65             u"--e
-00005f70: 7863 6c75 6465 222c 2075 2274 6573 7466  xclude", u"testf
-00005f80: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00005f90: 7375 6231 2f31 7375 6231 7375 6233 2f31  sub1/1sub1sub3/1
-00005fa0: 7375 6231 7375 6233 5f66 696c 652e 7478  sub1sub3_file.tx
-00005fb0: 7422 2c0a 2020 2020 2020 2020 2020 2020  t",.            
-00005fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005fd0: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00005fe0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00005ff0: 7432 2f31 2f31 7375 6231 2f31 7375 6231  t2/1/1sub1/1sub1
-00006000: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
-00006010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006020: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-00006030: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00006040: 6c65 6374 322f 312f 3173 7562 3222 2c0a  lect2/1/1sub2",.
-00006050: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006060: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00006070: 2d69 6e63 6c75 6465 222c 2075 2274 6573  -include", u"tes
-00006080: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-00006090: 2e70 7922 2c0a 2020 2020 2020 2020 2020  .py",.          
-000060a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000060b0: 2020 2075 222d 2d69 6e63 6c75 6465 222c     u"--include",
-000060c0: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-000060d0: 6563 7432 2f33 222c 0a20 2020 2020 2020  ect2/3",.       
-000060e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000060f0: 2020 2020 2020 7522 2d2d 696e 636c 7564        u"--includ
-00006100: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-00006110: 7365 6c65 6374 322f 3122 2c0a 2020 2020  select2/1",.    
-00006120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006130: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00006140: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00006150: 6573 2f73 656c 6563 7432 2f2a 2a22 5d29  es/select2/**"])
-00006160: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-00006170: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
-00006180: 7265 7374 6f72 655f 6469 7220 3d20 7522  restore_dir = u"
-00006190: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
-000061a0: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
-000061b0: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
-000061c0: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
-000061d0: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
-000061e0: 6573 746f 7265 5f64 6972 290a 2020 2020  estore_dir).    
-000061f0: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
-00006200: 7175 616c 2872 6573 746f 7265 642c 2073  qual(restored, s
-00006210: 656c 662e 6578 7065 6374 6564 5f72 6573  elf.expected_res
-00006220: 746f 7265 645f 7472 6565 290a 0a20 2020  tored_tree)..   
-00006230: 2064 6566 2074 6573 745f 696e 636c 7564   def test_includ
-00006240: 655f 6578 636c 7564 655f 7472 6169 6c69  e_exclude_traili
-00006250: 6e67 5f77 6869 7465 7370 6163 6528 7365  ng_whitespace(se
-00006260: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00006270: 2254 6573 7420 7468 6174 2066 6f6c 6465  "Test that folde
-00006280: 7273 2077 6974 6820 7472 6169 6c69 6e67  rs with trailing
-00006290: 2077 6869 7465 7370 6163 6520 696e 2074   whitespace in t
-000062a0: 6865 206e 616d 6573 2077 6f72 6b20 636f  he names work co
-000062b0: 7272 6563 746c 7920 7768 656e 2070 6173  rrectly when pas
-000062c0: 7369 6e67 2061 7320 696e 636c 7564 652f  sing as include/
-000062d0: 6578 636c 7564 6522 2222 0a20 2020 2020  exclude""".     
-000062e0: 2020 2023 204e 6f74 6520 7468 6174 2c20     # Note that, 
-000062f0: 6265 6361 7573 6520 7468 6973 206f 6e6c  because this onl
-00006300: 7920 7061 7373 6573 2069 7465 6d73 2069  y passes items i
-00006310: 6e20 6173 2061 206c 6973 7420 6f66 206f  n as a list of o
-00006320: 7074 696f 6e73 2c20 7468 6973 2074 6573  ptions, this tes
-00006330: 7420 646f 6573 206e 6f74 2074 6573 7420  t does not test 
-00006340: 7768 6574 6865 7220 6475 706c 6963 6974  whether duplicit
-00006350: 790a 2020 2020 2020 2020 2320 776f 756c  y.        # woul
-00006360: 6420 636f 7272 6563 746c 7920 696e 7465  d correctly inte
-00006370: 7270 7265 7420 636f 6d6d 616e 646c 696e  rpret commandlin
-00006380: 6520 6f70 7469 6f6e 7320 7769 7468 2073  e options with s
-00006390: 7061 6365 732e 2048 6f77 6576 6572 2c20  paces. However, 
-000063a0: 6269 6e2f 6475 706c 6963 6974 7920 7573  bin/duplicity us
-000063b0: 6573 2073 7973 2e61 7267 765b 313a 5d2c  es sys.argv[1:],
-000063c0: 2077 6869 6368 0a20 2020 2020 2020 2023   which.        #
-000063d0: 2073 686f 756c 6420 7265 7475 726e 2061   should return a
-000063e0: 206c 6973 7420 6f66 2073 7472 696e 6773   list of strings
-000063f0: 2061 6674 6572 2068 6176 696e 6720 636f   after having co
-00006400: 7272 6563 746c 7920 7072 6f63 6573 7365  rrectly processe
-00006410: 6420 7175 6f74 6573 2065 7463 2e0a 2020  d quotes etc..  
-00006420: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-00006430: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-00006440: 7466 696c 6573 2f73 656c 6563 7432 222c  tfiles/select2",
-00006450: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006460: 2020 2020 206f 7074 696f 6e73 3d5b 7522       options=[u"
-00006470: 2d2d 696e 636c 7564 6522 2c20 7522 7465  --include", u"te
-00006480: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00006490: 7472 6169 6c69 6e67 5f73 7061 6365 202f  trailing_space /
-000064a0: 7472 6169 6c69 6e67 5f73 7061 6365 2022  trailing_space "
-000064b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000064c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000064d0: 2020 2020 2020 2020 2020 2020 7522 7375              u"su
-000064e0: 6232 2f74 7261 696c 696e 675f 7370 6163  b2/trailing_spac
-000064f0: 6520 7375 6232 5f66 696c 652e 7478 7422  e sub2_file.txt"
-00006500: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00006510: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00006520: 222d 2d65 7863 6c75 6465 222c 2075 2274  "--exclude", u"t
-00006530: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00006540: 2f74 7261 696c 696e 675f 7370 6163 6520  /trailing_space 
-00006550: 2f74 7261 696c 696e 675f 7370 6163 6520  /trailing_space 
-00006560: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
-00006570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006580: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-00006590: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-000065a0: 6c65 6374 322f 7472 6169 6c69 6e67 5f73  lect2/trailing_s
-000065b0: 7061 6365 2022 2c0a 2020 2020 2020 2020  pace ",.        
-000065c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000065d0: 2020 2020 2075 222d 2d69 6e63 6c75 6465       u"--include
-000065e0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-000065f0: 656c 6563 7432 2f33 2f33 7375 6233 2f33  elect2/3/3sub3/3
-00006600: 7375 6233 7375 6232 2f33 7375 6233 7375  sub3sub2/3sub3su
-00006610: 6232 5f66 696c 652e 7478 7422 2c0a 2020  b2_file.txt",.  
-00006620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006630: 2020 2020 2020 2020 2020 2075 222d 2d65             u"--e
-00006640: 7863 6c75 6465 222c 2075 2274 6573 7466  xclude", u"testf
-00006650: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
-00006660: 7375 6233 2f33 7375 6233 7375 6232 222c  sub3/3sub3sub2",
-00006670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006680: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00006690: 2d2d 696e 636c 7564 6522 2c20 7522 7465  --include", u"te
-000066a0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-000066b0: 332f 3373 7562 322f 3373 7562 3273 7562  3/3sub2/3sub2sub
-000066c0: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-000066d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000066e0: 2075 222d 2d69 6e63 6c75 6465 222c 2075   u"--include", u
-000066f0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00006700: 7432 2f33 2f33 7375 6233 222c 0a20 2020  t2/3/3sub3",.   
-00006710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006720: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-00006730: 636c 7564 6522 2c20 7522 7465 7374 6669  clude", u"testfi
-00006740: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
-00006750: 7562 3122 2c0a 2020 2020 2020 2020 2020  ub1",.          
-00006760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006770: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-00006780: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00006790: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
-000067a0: 6231 7375 6233 222c 0a20 2020 2020 2020  b1sub3",.       
-000067b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000067c0: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-000067d0: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-000067e0: 7365 6c65 6374 322f 322f 3273 7562 312f  select2/2/2sub1/
-000067f0: 3273 7562 3173 7562 3222 2c0a 2020 2020  2sub1sub2",.    
-00006800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006810: 2020 2020 2020 2020 2075 222d 2d69 6e63           u"--inc
-00006820: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00006830: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
-00006840: 6231 222c 0a20 2020 2020 2020 2020 2020  b1",.           
-00006850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006860: 2020 7522 2d2d 6578 636c 7564 6522 2c20    u"--exclude", 
-00006870: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00006880: 6374 322f 312f 3173 7562 332f 3173 7562  ct2/1/1sub3/1sub
-00006890: 3373 7562 3222 2c0a 2020 2020 2020 2020  3sub2",.        
-000068a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000068b0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-000068c0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-000068d0: 656c 6563 7432 2f31 2f31 7375 6233 2f31  elect2/1/1sub3/1
-000068e0: 7375 6233 7375 6231 222c 0a20 2020 2020  sub3sub1",.     
-000068f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006900: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-00006910: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-00006920: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-00006930: 322f 3173 7562 3273 7562 3322 2c0a 2020  2/1sub2sub3",.  
-00006940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006950: 2020 2020 2020 2020 2020 2075 222d 2d69             u"--i
-00006960: 6e63 6c75 6465 222c 2075 2274 6573 7466  nclude", u"testf
-00006970: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00006980: 7375 6232 2f31 7375 6232 7375 6231 222c  sub2/1sub2sub1",
-00006990: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000069a0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-000069b0: 2d2d 6578 636c 7564 6522 2c20 7522 7465  --exclude", u"te
-000069c0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-000069d0: 312f 3173 7562 312f 3173 7562 3173 7562  1/1sub1/1sub1sub
-000069e0: 332f 3173 7562 3173 7562 335f 6669 6c65  3/1sub1sub3_file
-000069f0: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
-00006a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006a10: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-00006a20: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00006a30: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
-00006a40: 7562 3173 7562 3222 2c0a 2020 2020 2020  ub1sub2",.      
-00006a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006a60: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-00006a70: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00006a80: 2f73 656c 6563 7432 2f31 2f31 7375 6232  /select2/1/1sub2
-00006a90: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00006aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ab0: 7522 2d2d 696e 636c 7564 6522 2c20 7522  u"--include", u"
-00006ac0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00006ad0: 322f 312e 7079 222c 0a20 2020 2020 2020  2/1.py",.       
-00006ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006af0: 2020 2020 2020 7522 2d2d 696e 636c 7564        u"--includ
-00006b00: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-00006b10: 7365 6c65 6374 322f 3322 2c0a 2020 2020  select2/3",.    
-00006b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006b30: 2020 2020 2020 2020 2075 222d 2d69 6e63           u"--inc
-00006b40: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00006b50: 6573 2f73 656c 6563 7432 2f31 222c 0a20  es/select2/1",. 
-00006b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006b70: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00006b80: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-00006b90: 6669 6c65 732f 7365 6c65 6374 322f 2a2a  files/select2/**
-00006ba0: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
-00006bb0: 2e72 6573 746f 7265 2829 0a20 2020 2020  .restore().     
-00006bc0: 2020 2072 6573 746f 7265 5f64 6972 203d     restore_dir =
-00006bd0: 2075 2274 6573 7466 696c 6573 2f72 6573   u"testfiles/res
-00006be0: 746f 7265 5f6f 7574 220a 2020 2020 2020  tore_out".      
-00006bf0: 2020 7265 7374 6f72 6564 203d 2073 656c    restored = sel
-00006c00: 662e 6469 7265 6374 6f72 795f 7472 6565  f.directory_tree
-00006c10: 5f74 6f5f 6c69 7374 5f6f 665f 6c69 7374  _to_list_of_list
-00006c20: 7328 7265 7374 6f72 655f 6469 7229 0a20  s(restore_dir). 
-00006c30: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
-00006c40: 7274 4571 7561 6c28 7265 7374 6f72 6564  rtEqual(restored
-00006c50: 2c20 7365 6c66 2e65 7870 6563 7465 645f  , self.expected_
-00006c60: 7265 7374 6f72 6564 5f74 7265 655f 7769  restored_tree_wi
-00006c70: 7468 5f74 7261 696c 696e 675f 7370 6163  th_trailing_spac
-00006c80: 6529 0a0a 0a63 6c61 7373 2054 6573 7449  e)...class TestI
-00006c90: 6e63 6c75 6465 4578 636c 7564 6546 696c  ncludeExcludeFil
-00006ca0: 7465 724d 6f64 6573 2849 6e63 6c75 6465  terModes(Include
-00006cb0: 4578 636c 7564 6546 756e 6374 696f 6e61  ExcludeFunctiona
-00006cc0: 6c54 6573 7429 3a0a 2020 2020 7522 2222  lTest):.    u"""
-00006cd0: 0a20 2020 2044 6972 6563 7420 7573 6520  .    Direct use 
-00006ce0: 6f66 202d 2d69 6e63 6c75 6465 2f2d 2d65  of --include/--e
-00006cf0: 7863 6c75 6465 2077 6974 6820 2d2d 6669  xclude with --fi
-00006d00: 6c74 6572 2d2a 206d 6f64 6520 7377 6974  lter-* mode swit
-00006d10: 6368 6573 2075 7365 642e 0a20 2020 2022  ches used..    "
-00006d20: 2222 0a0a 2020 2020 6465 6620 7465 7374  ""..    def test
-00006d30: 5f65 7272 6f72 5f6f 6e5f 7265 6475 6e64  _error_on_redund
-00006d40: 616e 745f 6669 6c74 6572 5f6f 7074 696f  ant_filter_optio
-00006d50: 6e28 7365 6c66 293a 0a20 2020 2020 2020  n(self):.       
-00006d60: 2075 2222 2220 5465 7374 2066 6f72 2065   u""" Test for e
-00006d70: 7870 6c69 6369 7420 7370 6563 6966 6963  xplicit specific
-00006d80: 6174 696f 6e20 6f66 2064 6566 6175 6c74  ation of default
-00006d90: 2066 696c 7465 7220 6f70 7469 6f6e 7320   filter options 
-00006da0: 5f6f 6e6c 795f 2e0a 2020 2020 2020 2020  _only_..        
-00006db0: 2222 220a 2020 2020 2020 2020 7769 7468  """.        with
-00006dc0: 2073 656c 662e 6173 7365 7274 5261 6973   self.assertRais
-00006dd0: 6573 2843 6d64 4572 726f 7229 2061 7320  es(CmdError) as 
-00006de0: 636f 6e74 6578 743a 0a20 2020 2020 2020  context:.       
-00006df0: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
-00006e00: 2875 2266 756c 6c22 2c20 7522 7465 7374  (u"full", u"test
-00006e10: 6669 6c65 732f 7365 6c65 6374 3222 2c0a  files/select2",.
-00006e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006e30: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-00006e40: 5b75 222d 2d66 696c 7465 722d 676c 6f62  [u"--filter-glob
-00006e50: 6269 6e67 222c 2075 222d 2d66 696c 7465  bing", u"--filte
-00006e60: 722d 7374 7269 6374 6361 7365 222c 0a20  r-strictcase",. 
-00006e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006e90: 7522 2d2d 696e 636c 7564 6522 2c20 7522  u"--include", u"
-00006ea0: 7465 7374 6669 6c65 732f 6469 7231 2f66  testfiles/dir1/f
-00006eb0: 6966 6f22 2c0a 2020 2020 2020 2020 2020  ifo",.          
-00006ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ed0: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-00006ee0: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00006ef0: 2f64 6972 312f 7379 6d62 6f6c 6963 5f6c  /dir1/symbolic_l
-00006f00: 696e 6b22 2c0a 2020 2020 2020 2020 2020  ink",.          
-00006f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006f20: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-00006f30: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00006f40: 2f64 6972 312f 6c61 7267 6566 696c 6522  /dir1/largefile"
-00006f50: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00006f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006f70: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-00006f80: 2075 2274 6573 7466 696c 6573 2f64 6972   u"testfiles/dir
-00006f90: 3122 5d29 0a20 2020 2020 2020 2073 656c  1"]).        sel
-00006fa0: 662e 6173 7365 7274 4571 7561 6c28 636f  f.assertEqual(co
-00006fb0: 6e74 6578 742e 6578 6365 7074 696f 6e2e  ntext.exception.
-00006fc0: 6578 6974 5f73 7461 7475 732c 206c 6f67  exit_status, log
-00006fd0: 2e45 7272 6f72 436f 6465 2e72 6564 756e  .ErrorCode.redun
-00006fe0: 6461 6e74 5f66 696c 7465 7229 0a0a 2020  dant_filter)..  
-00006ff0: 2020 6465 6620 7465 7374 5f65 7272 6f72    def test_error
-00007000: 5f6f 6e5f 7472 6169 6c69 6e67 5f66 696c  _on_trailing_fil
-00007010: 7465 725f 6f70 7469 6f6e 2873 656c 6629  ter_option(self)
-00007020: 3a0a 2020 2020 2020 2020 7522 2222 2054  :.        u""" T
-00007030: 6573 7420 2d2d 6669 6c74 6572 2d2a 2061  est --filter-* a
-00007040: 7320 7468 6520 6c61 7374 2066 696c 6520  s the last file 
-00007050: 7365 6c65 6374 696f 6e20 6f70 7469 6f6e  selection option
-00007060: 2c20 7768 6963 6820 6861 7320 6e6f 0a20  , which has no. 
-00007070: 2020 2020 2020 2065 6666 6563 7420 616e         effect an
-00007080: 6420 7368 6f75 6c64 2072 6573 756c 7420  d should result 
-00007090: 696e 2061 6e20 6572 726f 722e 0a20 2020  in an error..   
-000070a0: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-000070b0: 2077 6974 6820 7365 6c66 2e61 7373 6572   with self.asser
-000070c0: 7452 6169 7365 7328 436d 6445 7272 6f72  tRaises(CmdError
-000070d0: 2920 6173 2063 6f6e 7465 7874 3a0a 2020  ) as context:.  
-000070e0: 2020 2020 2020 2020 2020 7365 6c66 2e62            self.b
-000070f0: 6163 6b75 7028 7522 6675 6c6c 222c 2075  ackup(u"full", u
-00007100: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00007110: 7432 222c 0a20 2020 2020 2020 2020 2020  t2",.           
-00007120: 2020 2020 2020 2020 2020 2020 206f 7074               opt
-00007130: 696f 6e73 3d5b 7522 2d2d 696e 636c 7564  ions=[u"--includ
-00007140: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-00007150: 6469 7231 2f66 6966 6f22 2c0a 2020 2020  dir1/fifo",.    
-00007160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007170: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00007180: 2d69 6e63 6c75 6465 222c 2075 2274 6573  -include", u"tes
-00007190: 7466 696c 6573 2f64 6972 312f 7379 6d62  tfiles/dir1/symb
-000071a0: 6f6c 6963 5f6c 696e 6b22 2c0a 2020 2020  olic_link",.    
-000071b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000071c0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-000071d0: 2d69 6e63 6c75 6465 222c 2075 2274 6573  -include", u"tes
-000071e0: 7466 696c 6573 2f64 6972 312f 6c61 7267  tfiles/dir1/larg
-000071f0: 6566 696c 6522 2c0a 2020 2020 2020 2020  efile",.        
-00007200: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007210: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00007220: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00007230: 6573 2f64 6972 3122 2c0a 2020 2020 2020  es/dir1",.      
+00005ec0: 2020 2020 2020 2022 2d2d 696e 636c 7564         "--includ
+00005ed0: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00005ee0: 656c 6563 7432 2f31 222c 0a20 2020 2020  elect2/1",.     
+00005ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005f00: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+00005f10: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00005f20: 7365 6c65 6374 322f 2a2a 225d 290a 2020  select2/**"]).  
+00005f30: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
+00005f40: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
+00005f50: 746f 7265 5f70 6174 6820 3d20 2274 6573  tore_path = "tes
+00005f60: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
+00005f70: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
+00005f80: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
+00005f90: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
+00005fa0: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
+00005fb0: 6f72 655f 7061 7468 290a 2020 2020 2020  ore_path).      
+00005fc0: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
+00005fd0: 616c 2872 6573 746f 7265 642c 2073 656c  al(restored, sel
+00005fe0: 662e 6578 7065 6374 6564 5f72 6573 746f  f.expected_resto
+00005ff0: 7265 645f 7472 6565 290a 0a20 2020 2064  red_tree)..    d
+00006000: 6566 2074 6573 745f 696e 636c 7564 655f  ef test_include_
+00006010: 6578 636c 7564 655f 7472 6169 6c69 6e67  exclude_trailing
+00006020: 5f77 6869 7465 7370 6163 6528 7365 6c66  _whitespace(self
+00006030: 293a 0a20 2020 2020 2020 2022 2222 5465  ):.        """Te
+00006040: 7374 2074 6861 7420 666f 6c64 6572 7320  st that folders 
+00006050: 7769 7468 2074 7261 696c 696e 6720 7768  with trailing wh
+00006060: 6974 6573 7061 6365 2069 6e20 7468 6520  itespace in the 
+00006070: 6e61 6d65 7320 776f 726b 2063 6f72 7265  names work corre
+00006080: 6374 6c79 2077 6865 6e20 7061 7373 696e  ctly when passin
+00006090: 6720 6173 2069 6e63 6c75 6465 2f65 7863  g as include/exc
+000060a0: 6c75 6465 2222 220a 2020 2020 2020 2020  lude""".        
+000060b0: 2320 4e6f 7465 2074 6861 742c 2062 6563  # Note that, bec
+000060c0: 6175 7365 2074 6869 7320 6f6e 6c79 2070  ause this only p
+000060d0: 6173 7365 7320 6974 656d 7320 696e 2061  asses items in a
+000060e0: 7320 6120 6c69 7374 206f 6620 6f70 7469  s a list of opti
+000060f0: 6f6e 732c 2074 6869 7320 7465 7374 2064  ons, this test d
+00006100: 6f65 7320 6e6f 7420 7465 7374 2077 6865  oes not test whe
+00006110: 7468 6572 2064 7570 6c69 6369 7479 0a20  ther duplicity. 
+00006120: 2020 2020 2020 2023 2077 6f75 6c64 2063         # would c
+00006130: 6f72 7265 6374 6c79 2069 6e74 6572 7072  orrectly interpr
+00006140: 6574 2063 6f6d 6d61 6e64 6c69 6e65 206f  et commandline o
+00006150: 7074 696f 6e73 2077 6974 6820 7370 6163  ptions with spac
+00006160: 6573 2e20 486f 7765 7665 722c 2062 696e  es. However, bin
+00006170: 2f64 7570 6c69 6369 7479 2075 7365 7320  /duplicity uses 
+00006180: 7379 732e 6172 6776 5b31 3a5d 2c20 7768  sys.argv[1:], wh
+00006190: 6963 680a 2020 2020 2020 2020 2320 7368  ich.        # sh
+000061a0: 6f75 6c64 2072 6574 7572 6e20 6120 6c69  ould return a li
+000061b0: 7374 206f 6620 7374 7269 6e67 7320 6166  st of strings af
+000061c0: 7465 7220 6861 7669 6e67 2063 6f72 7265  ter having corre
+000061d0: 6374 6c79 2070 726f 6365 7373 6564 2071  ctly processed q
+000061e0: 756f 7465 7320 6574 632e 0a20 2020 2020  uotes etc..     
+000061f0: 2020 2073 656c 662e 6261 636b 7570 2822     self.backup("
+00006200: 6675 6c6c 222c 2022 7465 7374 6669 6c65  full", "testfile
+00006210: 732f 7365 6c65 6374 3222 2c0a 2020 2020  s/select2",.    
+00006220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006230: 6f70 7469 6f6e 733d 5b22 2d2d 696e 636c  options=["--incl
+00006240: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00006250: 2f73 656c 6563 7432 2f74 7261 696c 696e  /select2/trailin
+00006260: 675f 7370 6163 6520 2f74 7261 696c 696e  g_space /trailin
+00006270: 675f 7370 6163 6520 220a 2020 2020 2020  g_space ".      
+00006280: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000062a0: 2020 2020 2273 7562 322f 7472 6169 6c69      "sub2/traili
+000062b0: 6e67 5f73 7061 6365 2073 7562 325f 6669  ng_space sub2_fi
+000062c0: 6c65 2e74 7874 222c 0a20 2020 2020 2020  le.txt",.       
+000062d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000062e0: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+000062f0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00006300: 6c65 6374 322f 7472 6169 6c69 6e67 5f73  lect2/trailing_s
+00006310: 7061 6365 202f 7472 6169 6c69 6e67 5f73  pace /trailing_s
+00006320: 7061 6365 2073 7562 3222 2c0a 2020 2020  pace sub2",.    
+00006330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006340: 2020 2020 2020 2020 2022 2d2d 696e 636c           "--incl
+00006350: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00006360: 2f73 656c 6563 7432 2f74 7261 696c 696e  /select2/trailin
+00006370: 675f 7370 6163 6520 222c 0a20 2020 2020  g_space ",.     
+00006380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006390: 2020 2020 2020 2020 222d 2d69 6e63 6c75          "--inclu
+000063a0: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+000063b0: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
+000063c0: 3373 7562 3373 7562 322f 3373 7562 3373  3sub3sub2/3sub3s
+000063d0: 7562 325f 6669 6c65 2e74 7874 222c 0a20  ub2_file.txt",. 
+000063e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000063f0: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00006400: 7863 6c75 6465 222c 2022 7465 7374 6669  xclude", "testfi
+00006410: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
+00006420: 7562 332f 3373 7562 3373 7562 3222 2c0a  ub3/3sub3sub2",.
+00006430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006440: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00006450: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+00006460: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
+00006470: 7375 6232 2f33 7375 6232 7375 6232 222c  sub2/3sub2sub2",
+00006480: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006490: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+000064a0: 2d69 6e63 6c75 6465 222c 2022 7465 7374  -include", "test
+000064b0: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
+000064c0: 3373 7562 3322 2c0a 2020 2020 2020 2020  3sub3",.        
+000064d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000064e0: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+000064f0: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00006500: 6563 7432 2f33 2f33 7375 6231 222c 0a20  ect2/3/3sub1",. 
+00006510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006520: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00006530: 7863 6c75 6465 222c 2022 7465 7374 6669  xclude", "testfi
+00006540: 6c65 732f 7365 6c65 6374 322f 322f 3273  les/select2/2/2s
+00006550: 7562 312f 3273 7562 3173 7562 3322 2c0a  ub1/2sub1sub3",.
+00006560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006570: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00006580: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+00006590: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
+000065a0: 7375 6231 2f32 7375 6231 7375 6232 222c  sub1/2sub1sub2",
+000065b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000065c0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+000065d0: 2d69 6e63 6c75 6465 222c 2022 7465 7374  -include", "test
+000065e0: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
+000065f0: 3273 7562 3122 2c0a 2020 2020 2020 2020  2sub1",.        
+00006600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006610: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+00006620: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00006630: 6563 7432 2f31 2f31 7375 6233 2f31 7375  ect2/1/1sub3/1su
+00006640: 6233 7375 6232 222c 0a20 2020 2020 2020  b3sub2",.       
+00006650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006660: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+00006670: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00006680: 6c65 6374 322f 312f 3173 7562 332f 3173  lect2/1/1sub3/1s
+00006690: 7562 3373 7562 3122 2c0a 2020 2020 2020  ub3sub1",.      
+000066a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000066b0: 2020 2020 2020 2022 2d2d 6578 636c 7564         "--exclud
+000066c0: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+000066d0: 656c 6563 7432 2f31 2f31 7375 6232 2f31  elect2/1/1sub2/1
+000066e0: 7375 6232 7375 6233 222c 0a20 2020 2020  sub2sub3",.     
+000066f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006700: 2020 2020 2020 2020 222d 2d69 6e63 6c75          "--inclu
+00006710: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00006720: 7365 6c65 6374 322f 312f 3173 7562 322f  select2/1/1sub2/
+00006730: 3173 7562 3273 7562 3122 2c0a 2020 2020  1sub2sub1",.    
+00006740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006750: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00006760: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00006770: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
+00006780: 2f31 7375 6231 7375 6233 2f31 7375 6231  /1sub1sub3/1sub1
+00006790: 7375 6233 5f66 696c 652e 7478 7422 2c0a  sub3_file.txt",.
+000067a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000067b0: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+000067c0: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+000067d0: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+000067e0: 7375 6231 2f31 7375 6231 7375 6232 222c  sub1/1sub1sub2",
+000067f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006800: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00006810: 2d65 7863 6c75 6465 222c 2022 7465 7374  -exclude", "test
+00006820: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
+00006830: 3173 7562 3222 2c0a 2020 2020 2020 2020  1sub2",.        
+00006840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006850: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+00006860: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00006870: 6563 7432 2f31 2e70 7922 2c0a 2020 2020  ect2/1.py",.    
+00006880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006890: 2020 2020 2020 2020 2022 2d2d 696e 636c           "--incl
+000068a0: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+000068b0: 2f73 656c 6563 7432 2f33 222c 0a20 2020  /select2/3",.   
+000068c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000068d0: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+000068e0: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+000068f0: 732f 7365 6c65 6374 322f 3122 2c0a 2020  s/select2/1",.  
+00006900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006910: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00006920: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00006930: 6573 2f73 656c 6563 7432 2f2a 2a22 5d29  es/select2/**"])
+00006940: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+00006950: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
+00006960: 7265 7374 6f72 655f 7061 7468 203d 2022  restore_path = "
+00006970: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
+00006980: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
+00006990: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
+000069a0: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
+000069b0: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
+000069c0: 6573 746f 7265 5f70 6174 6829 0a20 2020  estore_path).   
+000069d0: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
+000069e0: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
+000069f0: 7365 6c66 2e65 7870 6563 7465 645f 7265  self.expected_re
+00006a00: 7374 6f72 6564 5f74 7265 655f 7769 7468  stored_tree_with
+00006a10: 5f74 7261 696c 696e 675f 7370 6163 6529  _trailing_space)
+00006a20: 0a0a 0a63 6c61 7373 2054 6573 7449 6e63  ...class TestInc
+00006a30: 6c75 6465 4578 636c 7564 6546 696c 7465  ludeExcludeFilte
+00006a40: 724d 6f64 6573 2849 6e63 6c75 6465 4578  rModes(IncludeEx
+00006a50: 636c 7564 6546 756e 6374 696f 6e61 6c54  cludeFunctionalT
+00006a60: 6573 7429 3a0a 2020 2020 2222 220a 2020  est):.    """.  
+00006a70: 2020 4469 7265 6374 2075 7365 206f 6620    Direct use of 
+00006a80: 2d2d 696e 636c 7564 652f 2d2d 6578 636c  --include/--excl
+00006a90: 7564 6520 7769 7468 202d 2d66 696c 7465  ude with --filte
+00006aa0: 722d 2a20 6d6f 6465 2073 7769 7463 6865  r-* mode switche
+00006ab0: 7320 7573 6564 2e0a 2020 2020 2222 220a  s used..    """.
+00006ac0: 0a20 2020 2064 6566 2074 6573 745f 6572  .    def test_er
+00006ad0: 726f 725f 6f6e 5f72 6564 756e 6461 6e74  ror_on_redundant
+00006ae0: 5f66 696c 7465 725f 6f70 7469 6f6e 2873  _filter_option(s
+00006af0: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+00006b00: 2220 5465 7374 2066 6f72 2065 7870 6c69  " Test for expli
+00006b10: 6369 7420 7370 6563 6966 6963 6174 696f  cit specificatio
+00006b20: 6e20 6f66 2064 6566 6175 6c74 2066 696c  n of default fil
+00006b30: 7465 7220 6f70 7469 6f6e 7320 5f6f 6e6c  ter options _onl
+00006b40: 795f 2e0a 2020 2020 2020 2020 2222 220a  y_..        """.
+00006b50: 2020 2020 2020 2020 7769 7468 2073 656c          with sel
+00006b60: 662e 6173 7365 7274 5261 6973 6573 2843  f.assertRaises(C
+00006b70: 6d64 4572 726f 7229 2061 7320 636f 6e74  mdError) as cont
+00006b80: 6578 743a 0a20 2020 2020 2020 2020 2020  ext:.           
+00006b90: 2073 656c 662e 6261 636b 7570 2822 6675   self.backup("fu
+00006ba0: 6c6c 222c 2022 7465 7374 6669 6c65 732f  ll", "testfiles/
+00006bb0: 7365 6c65 6374 3222 2c0a 2020 2020 2020  select2",.      
+00006bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006bd0: 2020 6f70 7469 6f6e 733d 5b22 2d2d 6669    options=["--fi
+00006be0: 6c74 6572 2d67 6c6f 6262 696e 6722 2c20  lter-globbing", 
+00006bf0: 222d 2d66 696c 7465 722d 7374 7269 6374  "--filter-strict
+00006c00: 6361 7365 222c 0a20 2020 2020 2020 2020  case",.         
+00006c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006c20: 2020 2020 2020 2020 222d 2d69 6e63 6c75          "--inclu
+00006c30: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00006c40: 6469 7231 2f66 6966 6f22 2c0a 2020 2020  dir1/fifo",.    
+00006c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006c60: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00006c70: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+00006c80: 696c 6573 2f64 6972 312f 7379 6d62 6f6c  iles/dir1/symbol
+00006c90: 6963 5f6c 696e 6b22 2c0a 2020 2020 2020  ic_link",.      
+00006ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006cb0: 2020 2020 2020 2020 2020 2022 2d2d 696e             "--in
+00006cc0: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00006cd0: 6573 2f64 6972 312f 6c61 7267 6566 696c  es/dir1/largefil
+00006ce0: 6522 2c0a 2020 2020 2020 2020 2020 2020  e",.            
+00006cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006d00: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+00006d10: 2c20 2274 6573 7466 696c 6573 2f64 6972  , "testfiles/dir
+00006d20: 3122 5d29 0a20 2020 2020 2020 2073 656c  1"]).        sel
+00006d30: 662e 6173 7365 7274 4571 7561 6c28 636f  f.assertEqual(co
+00006d40: 6e74 6578 742e 6578 6365 7074 696f 6e2e  ntext.exception.
+00006d50: 6578 6974 5f73 7461 7475 732c 206c 6f67  exit_status, log
+00006d60: 2e45 7272 6f72 436f 6465 2e72 6564 756e  .ErrorCode.redun
+00006d70: 6461 6e74 5f66 696c 7465 7229 0a0a 2020  dant_filter)..  
+00006d80: 2020 6465 6620 7465 7374 5f65 7272 6f72    def test_error
+00006d90: 5f6f 6e5f 7472 6169 6c69 6e67 5f66 696c  _on_trailing_fil
+00006da0: 7465 725f 6f70 7469 6f6e 2873 656c 6629  ter_option(self)
+00006db0: 3a0a 2020 2020 2020 2020 2222 2220 5465  :.        """ Te
+00006dc0: 7374 202d 2d66 696c 7465 722d 2a20 6173  st --filter-* as
+00006dd0: 2074 6865 206c 6173 7420 6669 6c65 2073   the last file s
+00006de0: 656c 6563 7469 6f6e 206f 7074 696f 6e2c  election option,
+00006df0: 2077 6869 6368 2068 6173 206e 6f0a 2020   which has no.  
+00006e00: 2020 2020 2020 6566 6665 6374 2061 6e64        effect and
+00006e10: 2073 686f 756c 6420 7265 7375 6c74 2069   should result i
+00006e20: 6e20 616e 2065 7272 6f72 2e0a 2020 2020  n an error..    
+00006e30: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+00006e40: 7769 7468 2073 656c 662e 6173 7365 7274  with self.assert
+00006e50: 5261 6973 6573 2843 6d64 4572 726f 7229  Raises(CmdError)
+00006e60: 2061 7320 636f 6e74 6578 743a 0a20 2020   as context:.   
+00006e70: 2020 2020 2020 2020 2073 656c 662e 6261           self.ba
+00006e80: 636b 7570 2822 6675 6c6c 222c 2022 7465  ckup("full", "te
+00006e90: 7374 6669 6c65 732f 7365 6c65 6374 3222  stfiles/select2"
+00006ea0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00006eb0: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
+00006ec0: 733d 5b22 2d2d 696e 636c 7564 6522 2c20  s=["--include", 
+00006ed0: 2274 6573 7466 696c 6573 2f64 6972 312f  "testfiles/dir1/
+00006ee0: 6669 666f 222c 0a20 2020 2020 2020 2020  fifo",.         
+00006ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f00: 2020 2020 2020 2020 222d 2d69 6e63 6c75          "--inclu
+00006f10: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00006f20: 6469 7231 2f73 796d 626f 6c69 635f 6c69  dir1/symbolic_li
+00006f30: 6e6b 222c 0a20 2020 2020 2020 2020 2020  nk",.           
+00006f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f50: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+00006f60: 222c 2022 7465 7374 6669 6c65 732f 6469  ", "testfiles/di
+00006f70: 7231 2f6c 6172 6765 6669 6c65 222c 0a20  r1/largefile",. 
+00006f80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006fa0: 222d 2d65 7863 6c75 6465 222c 2022 7465  "--exclude", "te
+00006fb0: 7374 6669 6c65 732f 6469 7231 222c 0a20  stfiles/dir1",. 
+00006fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006fe0: 222d 2d66 696c 7465 722d 6c69 7465 7261  "--filter-litera
+00006ff0: 6c22 5d29 0a20 2020 2020 2020 2073 656c  l"]).        sel
+00007000: 662e 6173 7365 7274 4571 7561 6c28 636f  f.assertEqual(co
+00007010: 6e74 6578 742e 6578 6365 7074 696f 6e2e  ntext.exception.
+00007020: 6578 6974 5f73 7461 7475 732c 206c 6f67  exit_status, log
+00007030: 2e45 7272 6f72 436f 6465 2e74 7261 696c  .ErrorCode.trail
+00007040: 696e 675f 6669 6c74 6572 290a 0a20 2020  ing_filter)..   
+00007050: 2064 6566 2074 6573 745f 696e 636c 7564   def test_includ
+00007060: 655f 6578 636c 7564 655f 6261 7369 635f  e_exclude_basic_
+00007070: 7769 7468 5f6d 6f64 6573 2873 656c 6629  with_modes(self)
+00007080: 3a0a 2020 2020 2020 2020 2222 2220 5465  :.        """ Te
+00007090: 7374 202d 2d69 6e63 6c75 6465 2061 6e64  st --include and
+000070a0: 202d 2d65 7863 6c75 6465 2077 6f72 6b20   --exclude work 
+000070b0: 696e 2074 6865 2073 616d 6520 7761 7920  in the same way 
+000070c0: 6173 2064 6f6e 6520 6279 0a20 2020 2020  as done by.     
+000070d0: 2020 2054 6573 7449 6e63 6c75 6465 4578     TestIncludeEx
+000070e0: 636c 7564 6553 656c 6563 744f 7074 696f  cludeSelectOptio
+000070f0: 6e73 2c20 6275 7420 7768 656e 202d 2d66  ns, but when --f
+00007100: 696c 7465 722d 2a20 7377 6974 6368 6573  ilter-* switches
+00007110: 2069 6e20 6120 7761 790a 2020 2020 2020   in a way.      
+00007120: 2020 7768 6963 6820 7368 6f75 6c64 206e    which should n
+00007130: 6f74 2063 6861 6e67 6520 7468 6520 6f75  ot change the ou
+00007140: 7463 6f6d 6520 2877 6974 6820 7468 6973  tcome (with this
+00007150: 2073 7065 6369 6669 6320 6669 6c65 2073   specific file s
+00007160: 6574 292e 0a20 2020 2020 2020 2022 2222  et)..        """
+00007170: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
+00007180: 636b 7570 2822 6675 6c6c 222c 2022 7465  ckup("full", "te
+00007190: 7374 6669 6c65 732f 7365 6c65 6374 3222  stfiles/select2"
+000071a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000071b0: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+000071c0: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+000071d0: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
+000071e0: 2f33 7375 6233 2f33 7375 6233 7375 6232  /3sub3/3sub3sub2
+000071f0: 2f33 7375 6233 7375 6232 5f66 696c 652e  /3sub3sub2_file.
+00007200: 7478 7422 2c0a 2020 2020 2020 2020 2020  txt",.          
+00007210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007220: 2020 2022 2d2d 6669 6c74 6572 2d6c 6974     "--filter-lit
+00007230: 6572 616c 222c 0a20 2020 2020 2020 2020  eral",.         
 00007240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007250: 2020 2020 2020 2020 2020 2075 222d 2d66             u"--f
-00007260: 696c 7465 722d 6c69 7465 7261 6c22 5d29  ilter-literal"])
-00007270: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
-00007280: 7365 7274 4571 7561 6c28 636f 6e74 6578  sertEqual(contex
-00007290: 742e 6578 6365 7074 696f 6e2e 6578 6974  t.exception.exit
-000072a0: 5f73 7461 7475 732c 206c 6f67 2e45 7272  _status, log.Err
-000072b0: 6f72 436f 6465 2e74 7261 696c 696e 675f  orCode.trailing_
-000072c0: 6669 6c74 6572 290a 0a20 2020 2064 6566  filter)..    def
-000072d0: 2074 6573 745f 696e 636c 7564 655f 6578   test_include_ex
-000072e0: 636c 7564 655f 6261 7369 635f 7769 7468  clude_basic_with
-000072f0: 5f6d 6f64 6573 2873 656c 6629 3a0a 2020  _modes(self):.  
-00007300: 2020 2020 2020 7522 2222 2054 6573 7420        u""" Test 
-00007310: 2d2d 696e 636c 7564 6520 616e 6420 2d2d  --include and --
-00007320: 6578 636c 7564 6520 776f 726b 2069 6e20  exclude work in 
-00007330: 7468 6520 7361 6d65 2077 6179 2061 7320  the same way as 
-00007340: 646f 6e65 2062 790a 2020 2020 2020 2020  done by.        
-00007350: 5465 7374 496e 636c 7564 6545 7863 6c75  TestIncludeExclu
-00007360: 6465 5365 6c65 6374 4f70 7469 6f6e 732c  deSelectOptions,
-00007370: 2062 7574 2077 6865 6e20 2d2d 6669 6c74   but when --filt
-00007380: 6572 2d2a 2073 7769 7463 6865 7320 696e  er-* switches in
-00007390: 2061 2077 6179 0a20 2020 2020 2020 2077   a way.        w
-000073a0: 6869 6368 2073 686f 756c 6420 6e6f 7420  hich should not 
-000073b0: 6368 616e 6765 2074 6865 206f 7574 636f  change the outco
-000073c0: 6d65 2028 7769 7468 2074 6869 7320 7370  me (with this sp
-000073d0: 6563 6966 6963 2066 696c 6520 7365 7429  ecific file set)
-000073e0: 2e0a 2020 2020 2020 2020 2222 220a 2020  ..        """.  
-000073f0: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-00007400: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-00007410: 7466 696c 6573 2f73 656c 6563 7432 222c  tfiles/select2",
-00007420: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007430: 2020 2020 206f 7074 696f 6e73 3d5b 7522       options=[u"
-00007440: 2d2d 696e 636c 7564 6522 2c20 7522 7465  --include", u"te
-00007450: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00007460: 332f 3373 7562 332f 3373 7562 3373 7562  3/3sub3/3sub3sub
-00007470: 322f 3373 7562 3373 7562 325f 6669 6c65  2/3sub3sub2_file
-00007480: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
-00007490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000074a0: 2020 2020 7522 2d2d 6669 6c74 6572 2d6c      u"--filter-l
-000074b0: 6974 6572 616c 222c 0a20 2020 2020 2020  iteral",.       
-000074c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000074d0: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-000074e0: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-000074f0: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
-00007500: 3373 7562 3373 7562 3222 2c0a 2020 2020  3sub3sub2",.    
-00007510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007520: 2020 2020 2020 2020 2075 222d 2d69 6e63           u"--inc
-00007530: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00007540: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
-00007550: 6232 2f33 7375 6232 7375 6232 222c 0a20  b2/3sub2sub2",. 
-00007560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007570: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00007580: 696e 636c 7564 6522 2c20 7522 7465 7374  include", u"test
-00007590: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
-000075a0: 3373 7562 3322 2c0a 2020 2020 2020 2020  3sub3",.        
-000075b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000075c0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-000075d0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-000075e0: 656c 6563 7432 2f33 2f33 7375 6231 222c  elect2/3/3sub1",
-000075f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007600: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00007610: 2d2d 6578 636c 7564 6522 2c20 7522 7465  --exclude", u"te
-00007620: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00007630: 322f 3273 7562 312f 3273 7562 3173 7562  2/2sub1/2sub1sub
-00007640: 3322 2c0a 2020 2020 2020 2020 2020 2020  3",.            
-00007650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007660: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00007670: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00007680: 7432 2f32 2f32 7375 6231 2f32 7375 6231  t2/2/2sub1/2sub1
-00007690: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
-000076a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000076b0: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-000076c0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-000076d0: 6c65 6374 322f 322f 3273 7562 3122 2c0a  lect2/2/2sub1",.
-000076e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000076f0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00007700: 2d66 696c 7465 722d 676c 6f62 6269 6e67  -filter-globbing
-00007710: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00007720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007730: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00007740: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00007750: 322f 312f 3173 7562 332f 3173 7562 3373  2/1/1sub3/1sub3s
-00007760: 7562 3222 2c0a 2020 2020 2020 2020 2020  ub2",.          
+00007250: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00007260: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00007270: 6374 322f 332f 3373 7562 332f 3373 7562  ct2/3/3sub3/3sub
+00007280: 3373 7562 3222 2c0a 2020 2020 2020 2020  3sub2",.        
+00007290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000072a0: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+000072b0: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+000072c0: 6563 7432 2f33 2f33 7375 6232 2f33 7375  ect2/3/3sub2/3su
+000072d0: 6232 7375 6232 222c 0a20 2020 2020 2020  b2sub2",.       
+000072e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000072f0: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+00007300: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00007310: 6c65 6374 322f 332f 3373 7562 3322 2c0a  lect2/3/3sub3",.
+00007320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007330: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00007340: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+00007350: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
+00007360: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
+00007370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007380: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00007390: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+000073a0: 6374 322f 322f 3273 7562 312f 3273 7562  ct2/2/2sub1/2sub
+000073b0: 3173 7562 3322 2c0a 2020 2020 2020 2020  1sub3",.        
+000073c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000073d0: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+000073e0: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+000073f0: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
+00007400: 6231 7375 6232 222c 0a20 2020 2020 2020  b1sub2",.       
+00007410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007420: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+00007430: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00007440: 6c65 6374 322f 322f 3273 7562 3122 2c0a  lect2/2/2sub1",.
+00007450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007460: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00007470: 6669 6c74 6572 2d67 6c6f 6262 696e 6722  filter-globbing"
+00007480: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00007490: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000074a0: 2d2d 6578 636c 7564 6522 2c20 2274 6573  --exclude", "tes
+000074b0: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+000074c0: 2f31 7375 6233 2f31 7375 6233 7375 6232  /1sub3/1sub3sub2
+000074d0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+000074e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000074f0: 222d 2d65 7863 6c75 6465 222c 2022 7465  "--exclude", "te
+00007500: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+00007510: 312f 3173 7562 332f 3173 7562 3373 7562  1/1sub3/1sub3sub
+00007520: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
+00007530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007540: 2022 2d2d 6578 636c 7564 6522 2c20 2274   "--exclude", "t
+00007550: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+00007560: 2f31 2f31 7375 6232 2f31 7375 6232 7375  /1/1sub2/1sub2su
+00007570: 6233 222c 0a20 2020 2020 2020 2020 2020  b3",.           
+00007580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007590: 2020 222d 2d69 6e63 6c75 6465 222c 2022    "--include", "
+000075a0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+000075b0: 322f 312f 3173 7562 322f 3173 7562 3273  2/1/1sub2/1sub2s
+000075c0: 7562 3122 2c0a 2020 2020 2020 2020 2020  ub1",.          
+000075d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000075e0: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+000075f0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00007600: 7432 2f31 2f31 7375 6231 2f31 7375 6231  t2/1/1sub1/1sub1
+00007610: 7375 6233 2f31 7375 6231 7375 6233 5f66  sub3/1sub1sub3_f
+00007620: 696c 652e 7478 7422 2c0a 2020 2020 2020  ile.txt",.      
+00007630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007640: 2020 2020 2020 2022 2d2d 6578 636c 7564         "--exclud
+00007650: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00007660: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
+00007670: 7375 6231 7375 6232 222c 0a20 2020 2020  sub1sub2",.     
+00007680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007690: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+000076a0: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+000076b0: 7365 6c65 6374 322f 312f 3173 7562 3222  select2/1/1sub2"
+000076c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000076d0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000076e0: 2d2d 6669 6c74 6572 2d72 6567 6578 7022  --filter-regexp"
+000076f0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00007700: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00007710: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+00007720: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+00007730: 2e70 7924 222c 0a20 2020 2020 2020 2020  .py$",.         
+00007740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007750: 2020 2020 222d 2d66 696c 7465 722d 6c69      "--filter-li
+00007760: 7465 7261 6c22 2c0a 2020 2020 2020 2020  teral",.        
 00007770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007780: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-00007790: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-000077a0: 6563 7432 2f31 2f31 7375 6233 2f31 7375  ect2/1/1sub3/1su
-000077b0: 6233 7375 6231 222c 0a20 2020 2020 2020  b3sub1",.       
-000077c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077d0: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-000077e0: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-000077f0: 7365 6c65 6374 322f 312f 3173 7562 322f  select2/1/1sub2/
-00007800: 3173 7562 3273 7562 3322 2c0a 2020 2020  1sub2sub3",.    
-00007810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007820: 2020 2020 2020 2020 2075 222d 2d69 6e63           u"--inc
-00007830: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00007840: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-00007850: 6232 2f31 7375 6232 7375 6231 222c 0a20  b2/1sub2sub1",. 
-00007860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007870: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00007880: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-00007890: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-000078a0: 3173 7562 312f 3173 7562 3173 7562 332f  1sub1/1sub1sub3/
-000078b0: 3173 7562 3173 7562 335f 6669 6c65 2e74  1sub1sub3_file.t
-000078c0: 7874 222c 0a20 2020 2020 2020 2020 2020  xt",.           
-000078d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000078e0: 2020 7522 2d2d 6578 636c 7564 6522 2c20    u"--exclude", 
-000078f0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00007900: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
-00007910: 3173 7562 3222 2c0a 2020 2020 2020 2020  1sub2",.        
-00007920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007930: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00007940: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00007950: 656c 6563 7432 2f31 2f31 7375 6232 222c  elect2/1/1sub2",
-00007960: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007970: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00007980: 2d2d 6669 6c74 6572 2d72 6567 6578 7022  --filter-regexp"
-00007990: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000079a0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-000079b0: 222d 2d69 6e63 6c75 6465 222c 2075 2274  "--include", u"t
-000079c0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-000079d0: 2f31 2e70 7924 222c 0a20 2020 2020 2020  /1.py$",.       
-000079e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000079f0: 2020 2020 2020 7522 2d2d 6669 6c74 6572        u"--filter
-00007a00: 2d6c 6974 6572 616c 222c 0a20 2020 2020  -literal",.     
-00007a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007a20: 2020 2020 2020 2020 7522 2d2d 696e 636c          u"--incl
-00007a30: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-00007a40: 732f 7365 6c65 6374 322f 3322 2c0a 2020  s/select2/3",.  
-00007a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007a60: 2020 2020 2020 2020 2020 2075 222d 2d69             u"--i
-00007a70: 6e63 6c75 6465 222c 2075 2274 6573 7466  nclude", u"testf
-00007a80: 696c 6573 2f73 656c 6563 7432 2f31 222c  iles/select2/1",
-00007a90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007aa0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00007ab0: 2d2d 6669 6c74 6572 2d67 6c6f 6262 696e  --filter-globbin
-00007ac0: 6722 2c0a 2020 2020 2020 2020 2020 2020  g",.            
-00007ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ae0: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00007af0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00007b00: 7432 2f2a 2a22 5d29 0a20 2020 2020 2020  t2/**"]).       
-00007b10: 2073 656c 662e 7265 7374 6f72 6528 290a   self.restore().
-00007b20: 2020 2020 2020 2020 7265 7374 6f72 655f          restore_
-00007b30: 6469 7220 3d20 7522 7465 7374 6669 6c65  dir = u"testfile
-00007b40: 732f 7265 7374 6f72 655f 6f75 7422 0a20  s/restore_out". 
-00007b50: 2020 2020 2020 2072 6573 746f 7265 6420         restored 
-00007b60: 3d20 7365 6c66 2e64 6972 6563 746f 7279  = self.directory
-00007b70: 5f74 7265 655f 746f 5f6c 6973 745f 6f66  _tree_to_list_of
-00007b80: 5f6c 6973 7473 2872 6573 746f 7265 5f64  _lists(restore_d
-00007b90: 6972 290a 2020 2020 2020 2020 7365 6c66  ir).        self
-00007ba0: 2e61 7373 6572 7445 7175 616c 2872 6573  .assertEqual(res
-00007bb0: 746f 7265 642c 2073 656c 662e 6578 7065  tored, self.expe
-00007bc0: 6374 6564 5f72 6573 746f 7265 645f 7472  cted_restored_tr
-00007bd0: 6565 290a 0a20 2020 2064 6566 2074 6573  ee)..    def tes
-00007be0: 745f 696e 636c 7564 655f 6578 636c 7564  t_include_exclud
-00007bf0: 655f 7472 6169 6c69 6e67 5f77 6869 7465  e_trailing_white
-00007c00: 7370 6163 655f 7769 7468 5f6d 6f64 6573  space_with_modes
-00007c10: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00007c20: 7522 2222 0a20 2020 2020 2020 2054 6573  u""".        Tes
-00007c30: 7420 7468 6174 2066 6f6c 6465 7273 2077  t that folders w
-00007c40: 6974 6820 7472 6169 6c69 6e67 2077 6869  ith trailing whi
-00007c50: 7465 7370 6163 6520 696e 2074 6865 206e  tespace in the n
-00007c60: 616d 6573 2077 6f72 6b20 636f 7272 6563  ames work correc
-00007c70: 746c 790a 2020 2020 2020 2020 7768 656e  tly.        when
-00007c80: 2070 6173 7369 6e67 2061 7320 696e 636c   passing as incl
-00007c90: 7564 652f 6578 636c 7564 652c 2073 7065  ude/exclude, spe
-00007ca0: 6369 6669 6361 6c6c 7920 696e 206c 6974  cifically in lit
-00007cb0: 6572 616c 206d 6f64 652e 0a20 2020 2020  eral mode..     
-00007cc0: 2020 2022 2222 0a20 2020 2020 2020 2023     """.        #
-00007cd0: 204e 6f74 6520 7468 6174 2c20 6265 6361   Note that, beca
-00007ce0: 7573 6520 7468 6973 206f 6e6c 7920 7061  use this only pa
-00007cf0: 7373 6573 2069 7465 6d73 2069 6e20 6173  sses items in as
-00007d00: 2061 206c 6973 7420 6f66 206f 7074 696f   a list of optio
-00007d10: 6e73 2c20 7468 6973 2074 6573 7420 646f  ns, this test do
-00007d20: 6573 206e 6f74 2074 6573 7420 7768 6574  es not test whet
-00007d30: 6865 7220 6475 706c 6963 6974 790a 2020  her duplicity.  
-00007d40: 2020 2020 2020 2320 776f 756c 6420 636f        # would co
-00007d50: 7272 6563 746c 7920 696e 7465 7270 7265  rrectly interpre
-00007d60: 7420 636f 6d6d 616e 646c 696e 6520 6f70  t commandline op
-00007d70: 7469 6f6e 7320 7769 7468 2073 7061 6365  tions with space
-00007d80: 732e 2048 6f77 6576 6572 2c20 6269 6e2f  s. However, bin/
-00007d90: 6475 706c 6963 6974 7920 7573 6573 2073  duplicity uses s
-00007da0: 7973 2e61 7267 765b 313a 5d2c 2077 6869  ys.argv[1:], whi
-00007db0: 6368 0a20 2020 2020 2020 2023 2073 686f  ch.        # sho
-00007dc0: 756c 6420 7265 7475 726e 2061 206c 6973  uld return a lis
-00007dd0: 7420 6f66 2073 7472 696e 6773 2061 6674  t of strings aft
-00007de0: 6572 2068 6176 696e 6720 636f 7272 6563  er having correc
-00007df0: 746c 7920 7072 6f63 6573 7365 6420 7175  tly processed qu
-00007e00: 6f74 6573 2065 7463 2e0a 2020 2020 2020  otes etc..      
-00007e10: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-00007e20: 6675 6c6c 222c 2075 2274 6573 7466 696c  full", u"testfil
-00007e30: 6573 2f73 656c 6563 7432 222c 0a20 2020  es/select2",.   
-00007e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007e50: 206f 7074 696f 6e73 3d5b 7522 2d2d 6669   options=[u"--fi
-00007e60: 6c74 6572 2d6c 6974 6572 616c 222c 0a20  lter-literal",. 
+00007780: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+00007790: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+000077a0: 6563 7432 2f33 222c 0a20 2020 2020 2020  ect2/3",.       
+000077b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000077c0: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+000077d0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+000077e0: 6c65 6374 322f 3122 2c0a 2020 2020 2020  lect2/1",.      
+000077f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007800: 2020 2020 2020 2022 2d2d 6669 6c74 6572         "--filter
+00007810: 2d67 6c6f 6262 696e 6722 2c0a 2020 2020  -globbing",.    
+00007820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007830: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00007840: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00007850: 2f73 656c 6563 7432 2f2a 2a22 5d29 0a20  /select2/**"]). 
+00007860: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
+00007870: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
+00007880: 7374 6f72 655f 7061 7468 203d 2022 7465  store_path = "te
+00007890: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
+000078a0: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
+000078b0: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
+000078c0: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
+000078d0: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
+000078e0: 746f 7265 5f70 6174 6829 0a20 2020 2020  tore_path).     
+000078f0: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
+00007900: 7561 6c28 7265 7374 6f72 6564 2c20 7365  ual(restored, se
+00007910: 6c66 2e65 7870 6563 7465 645f 7265 7374  lf.expected_rest
+00007920: 6f72 6564 5f74 7265 6529 0a0a 2020 2020  ored_tree)..    
+00007930: 6465 6620 7465 7374 5f69 6e63 6c75 6465  def test_include
+00007940: 5f65 7863 6c75 6465 5f74 7261 696c 696e  _exclude_trailin
+00007950: 675f 7768 6974 6573 7061 6365 5f77 6974  g_whitespace_wit
+00007960: 685f 6d6f 6465 7328 7365 6c66 293a 0a20  h_modes(self):. 
+00007970: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
+00007980: 2020 2054 6573 7420 7468 6174 2066 6f6c     Test that fol
+00007990: 6465 7273 2077 6974 6820 7472 6169 6c69  ders with traili
+000079a0: 6e67 2077 6869 7465 7370 6163 6520 696e  ng whitespace in
+000079b0: 2074 6865 206e 616d 6573 2077 6f72 6b20   the names work 
+000079c0: 636f 7272 6563 746c 790a 2020 2020 2020  correctly.      
+000079d0: 2020 7768 656e 2070 6173 7369 6e67 2061    when passing a
+000079e0: 7320 696e 636c 7564 652f 6578 636c 7564  s include/exclud
+000079f0: 652c 2073 7065 6369 6669 6361 6c6c 7920  e, specifically 
+00007a00: 696e 206c 6974 6572 616c 206d 6f64 652e  in literal mode.
+00007a10: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00007a20: 2020 2020 2023 204e 6f74 6520 7468 6174       # Note that
+00007a30: 2c20 6265 6361 7573 6520 7468 6973 206f  , because this o
+00007a40: 6e6c 7920 7061 7373 6573 2069 7465 6d73  nly passes items
+00007a50: 2069 6e20 6173 2061 206c 6973 7420 6f66   in as a list of
+00007a60: 206f 7074 696f 6e73 2c20 7468 6973 2074   options, this t
+00007a70: 6573 7420 646f 6573 206e 6f74 2074 6573  est does not tes
+00007a80: 7420 7768 6574 6865 7220 6475 706c 6963  t whether duplic
+00007a90: 6974 790a 2020 2020 2020 2020 2320 776f  ity.        # wo
+00007aa0: 756c 6420 636f 7272 6563 746c 7920 696e  uld correctly in
+00007ab0: 7465 7270 7265 7420 636f 6d6d 616e 646c  terpret commandl
+00007ac0: 696e 6520 6f70 7469 6f6e 7320 7769 7468  ine options with
+00007ad0: 2073 7061 6365 732e 2048 6f77 6576 6572   spaces. However
+00007ae0: 2c20 6269 6e2f 6475 706c 6963 6974 7920  , bin/duplicity 
+00007af0: 7573 6573 2073 7973 2e61 7267 765b 313a  uses sys.argv[1:
+00007b00: 5d2c 2077 6869 6368 0a20 2020 2020 2020  ], which.       
+00007b10: 2023 2073 686f 756c 6420 7265 7475 726e   # should return
+00007b20: 2061 206c 6973 7420 6f66 2073 7472 696e   a list of strin
+00007b30: 6773 2061 6674 6572 2068 6176 696e 6720  gs after having 
+00007b40: 636f 7272 6563 746c 7920 7072 6f63 6573  correctly proces
+00007b50: 7365 6420 7175 6f74 6573 2065 7463 2e0a  sed quotes etc..
+00007b60: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
+00007b70: 6b75 7028 2266 756c 6c22 2c20 2274 6573  kup("full", "tes
+00007b80: 7466 696c 6573 2f73 656c 6563 7432 222c  tfiles/select2",
+00007b90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007ba0: 2020 2020 206f 7074 696f 6e73 3d5b 222d       options=["-
+00007bb0: 2d66 696c 7465 722d 6c69 7465 7261 6c22  -filter-literal"
+00007bc0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00007bd0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00007be0: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+00007bf0: 7466 696c 6573 2f73 656c 6563 7432 2f74  tfiles/select2/t
+00007c00: 7261 696c 696e 675f 7370 6163 6520 2f74  railing_space /t
+00007c10: 7261 696c 696e 675f 7370 6163 6520 7375  railing_space su
+00007c20: 6232 2f74 7261 696c 696e 675f 7370 6163  b2/trailing_spac
+00007c30: 6520 220a 2020 2020 2020 2020 2020 2020  e ".            
+00007c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c50: 2020 2020 2020 2020 2020 2020 2020 2273                "s
+00007c60: 7562 325f 6669 6c65 2e74 7874 222c 0a20  ub2_file.txt",. 
+00007c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007c80: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00007c90: 7863 6c75 6465 222c 2022 7465 7374 6669  xclude", "testfi
+00007ca0: 6c65 732f 7365 6c65 6374 322f 7472 6169  les/select2/trai
+00007cb0: 6c69 6e67 5f73 7061 6365 202f 7472 6169  ling_space /trai
+00007cc0: 6c69 6e67 5f73 7061 6365 2073 7562 3222  ling_space sub2"
+00007cd0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00007ce0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00007cf0: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+00007d00: 7466 696c 6573 2f73 656c 6563 7432 2f74  tfiles/select2/t
+00007d10: 7261 696c 696e 675f 7370 6163 6520 222c  railing_space ",
+00007d20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007d30: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00007d40: 2d69 6e63 6c75 6465 222c 2022 7465 7374  -include", "test
+00007d50: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
+00007d60: 3373 7562 332f 3373 7562 3373 7562 322f  3sub3/3sub3sub2/
+00007d70: 3373 7562 3373 7562 325f 6669 6c65 2e74  3sub3sub2_file.t
+00007d80: 7874 222c 0a20 2020 2020 2020 2020 2020  xt",.           
+00007d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007da0: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+00007db0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00007dc0: 322f 332f 3373 7562 332f 3373 7562 3373  2/3/3sub3/3sub3s
+00007dd0: 7562 3222 2c0a 2020 2020 2020 2020 2020  ub2",.          
+00007de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007df0: 2020 2022 2d2d 696e 636c 7564 6522 2c20     "--include", 
+00007e00: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00007e10: 7432 2f33 2f33 7375 6232 2f33 7375 6232  t2/3/3sub2/3sub2
+00007e20: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
+00007e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007e40: 2020 2020 222d 2d69 6e63 6c75 6465 222c      "--include",
+00007e50: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00007e60: 6374 322f 332f 3373 7562 3322 2c0a 2020  ct2/3/3sub3",.  
 00007e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007e80: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00007e90: 696e 636c 7564 6522 2c20 7522 7465 7374  include", u"test
-00007ea0: 6669 6c65 732f 7365 6c65 6374 322f 7472  files/select2/tr
-00007eb0: 6169 6c69 6e67 5f73 7061 6365 202f 7472  ailing_space /tr
-00007ec0: 6169 6c69 6e67 5f73 7061 6365 2073 7562  ailing_space sub
-00007ed0: 322f 7472 6169 6c69 6e67 5f73 7061 6365  2/trailing_space
-00007ee0: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
-00007ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007f00: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00007f10: 7375 6232 5f66 696c 652e 7478 7422 2c0a  sub2_file.txt",.
-00007f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007f30: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00007f40: 2d65 7863 6c75 6465 222c 2075 2274 6573  -exclude", u"tes
-00007f50: 7466 696c 6573 2f73 656c 6563 7432 2f74  tfiles/select2/t
-00007f60: 7261 696c 696e 675f 7370 6163 6520 2f74  railing_space /t
-00007f70: 7261 696c 696e 675f 7370 6163 6520 7375  railing_space su
-00007f80: 6232 222c 0a20 2020 2020 2020 2020 2020  b2",.           
-00007f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007fa0: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-00007fb0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00007fc0: 6374 322f 7472 6169 6c69 6e67 5f73 7061  ct2/trailing_spa
-00007fd0: 6365 2022 2c0a 2020 2020 2020 2020 2020  ce ",.          
-00007fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007ff0: 2020 2075 222d 2d69 6e63 6c75 6465 222c     u"--include",
-00008000: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00008010: 6563 7432 2f33 2f33 7375 6233 2f33 7375  ect2/3/3sub3/3su
-00008020: 6233 7375 6232 2f33 7375 6233 7375 6232  b3sub2/3sub3sub2
-00008030: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
+00007e80: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00007e90: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00007ea0: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
+00007eb0: 6231 222c 0a20 2020 2020 2020 2020 2020  b1",.           
+00007ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007ed0: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+00007ee0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00007ef0: 322f 322f 3273 7562 312f 3273 7562 3173  2/2/2sub1/2sub1s
+00007f00: 7562 3322 2c0a 2020 2020 2020 2020 2020  ub3",.          
+00007f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007f20: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00007f30: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00007f40: 7432 2f32 2f32 7375 6231 2f32 7375 6231  t2/2/2sub1/2sub1
+00007f50: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
+00007f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007f70: 2020 2020 222d 2d69 6e63 6c75 6465 222c      "--include",
+00007f80: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00007f90: 6374 322f 322f 3273 7562 3122 2c0a 2020  ct2/2/2sub1",.  
+00007fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007fb0: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00007fc0: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00007fd0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+00007fe0: 6233 2f31 7375 6233 7375 6232 222c 0a20  b3/1sub3sub2",. 
+00007ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008000: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00008010: 7863 6c75 6465 222c 2022 7465 7374 6669  xclude", "testfi
+00008020: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+00008030: 7562 332f 3173 7562 3373 7562 3122 2c0a  ub3/1sub3sub1",.
 00008040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008050: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00008060: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00008070: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
-00008080: 6233 2f33 7375 6233 7375 6232 222c 0a20  b3/3sub3sub2",. 
-00008090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000080a0: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-000080b0: 696e 636c 7564 6522 2c20 7522 7465 7374  include", u"test
-000080c0: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
-000080d0: 3373 7562 322f 3373 7562 3273 7562 3222  3sub2/3sub2sub2"
+00008050: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00008060: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+00008070: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+00008080: 7375 6232 2f31 7375 6232 7375 6233 222c  sub2/1sub2sub3",
+00008090: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000080a0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+000080b0: 2d69 6e63 6c75 6465 222c 2022 7465 7374  -include", "test
+000080c0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
+000080d0: 3173 7562 322f 3173 7562 3273 7562 3122  1sub2/1sub2sub1"
 000080e0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000080f0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00008100: 222d 2d69 6e63 6c75 6465 222c 2075 2274  "--include", u"t
-00008110: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00008120: 2f33 2f33 7375 6233 222c 0a20 2020 2020  /3/3sub3",.     
-00008130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008140: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-00008150: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-00008160: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-00008170: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
-00008180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008190: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-000081a0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-000081b0: 7432 2f32 2f32 7375 6231 2f32 7375 6231  t2/2/2sub1/2sub1
-000081c0: 7375 6233 222c 0a20 2020 2020 2020 2020  sub3",.         
-000081d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000081e0: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-000081f0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00008200: 6c65 6374 322f 322f 3273 7562 312f 3273  lect2/2/2sub1/2s
-00008210: 7562 3173 7562 3222 2c0a 2020 2020 2020  ub1sub2",.      
-00008220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008230: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-00008240: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00008250: 2f73 656c 6563 7432 2f32 2f32 7375 6231  /select2/2/2sub1
+000080f0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00008100: 2d2d 6578 636c 7564 6522 2c20 2274 6573  --exclude", "tes
+00008110: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+00008120: 2f31 7375 6231 2f31 7375 6231 7375 6233  /1sub1/1sub1sub3
+00008130: 2f31 7375 6231 7375 6233 5f66 696c 652e  /1sub1sub3_file.
+00008140: 7478 7422 2c0a 2020 2020 2020 2020 2020  txt",.          
+00008150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008160: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00008170: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00008180: 7432 2f31 2f31 7375 6231 2f31 7375 6231  t2/1/1sub1/1sub1
+00008190: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
+000081a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000081b0: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+000081c0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+000081d0: 6374 322f 312f 3173 7562 3222 2c0a 2020  ct2/1/1sub2",.  
+000081e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000081f0: 2020 2020 2020 2020 2020 2022 2d2d 696e             "--in
+00008200: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00008210: 6573 2f73 656c 6563 7432 2f31 2e70 7922  es/select2/1.py"
+00008220: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00008230: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00008240: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+00008250: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
 00008260: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
 00008270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008280: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00008290: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-000082a0: 322f 312f 3173 7562 332f 3173 7562 3373  2/1/1sub3/1sub3s
-000082b0: 7562 3222 2c0a 2020 2020 2020 2020 2020  ub2",.          
-000082c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000082d0: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-000082e0: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-000082f0: 6563 7432 2f31 2f31 7375 6233 2f31 7375  ect2/1/1sub3/1su
-00008300: 6233 7375 6231 222c 0a20 2020 2020 2020  b3sub1",.       
-00008310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008320: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-00008330: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-00008340: 7365 6c65 6374 322f 312f 3173 7562 322f  select2/1/1sub2/
-00008350: 3173 7562 3273 7562 3322 2c0a 2020 2020  1sub2sub3",.    
-00008360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008370: 2020 2020 2020 2020 2075 222d 2d69 6e63           u"--inc
-00008380: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00008390: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-000083a0: 6232 2f31 7375 6232 7375 6231 222c 0a20  b2/1sub2sub1",. 
-000083b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000083c0: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-000083d0: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-000083e0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-000083f0: 3173 7562 312f 3173 7562 3173 7562 332f  1sub1/1sub1sub3/
-00008400: 3173 7562 3173 7562 335f 6669 6c65 2e74  1sub1sub3_file.t
-00008410: 7874 222c 0a20 2020 2020 2020 2020 2020  xt",.           
-00008420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008430: 2020 7522 2d2d 6578 636c 7564 6522 2c20    u"--exclude", 
-00008440: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00008450: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
-00008460: 3173 7562 3222 2c0a 2020 2020 2020 2020  1sub2",.        
-00008470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008480: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00008490: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-000084a0: 656c 6563 7432 2f31 2f31 7375 6232 222c  elect2/1/1sub2",
-000084b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000084c0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-000084d0: 2d2d 696e 636c 7564 6522 2c20 7522 7465  --include", u"te
-000084e0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-000084f0: 312e 7079 222c 0a20 2020 2020 2020 2020  1.py",.         
-00008500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008510: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-00008520: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00008530: 6c65 6374 322f 3322 2c0a 2020 2020 2020  lect2/3",.      
-00008540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008550: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-00008560: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00008570: 2f73 656c 6563 7432 2f31 222c 0a20 2020  /select2/1",.   
-00008580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008590: 2020 2020 2020 2020 2020 7522 2d2d 6669            u"--fi
-000085a0: 6c74 6572 2d67 6c6f 6262 696e 6722 2c0a  lter-globbing",.
-000085b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000085c0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-000085d0: 2d65 7863 6c75 6465 222c 2075 2274 6573  -exclude", u"tes
-000085e0: 7466 696c 6573 2f73 656c 6563 7432 2f2a  tfiles/select2/*
-000085f0: 2a22 5d29 0a20 2020 2020 2020 2073 656c  *"]).        sel
-00008600: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
-00008610: 2020 2020 7265 7374 6f72 655f 6469 7220      restore_dir 
-00008620: 3d20 7522 7465 7374 6669 6c65 732f 7265  = u"testfiles/re
-00008630: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
-00008640: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
-00008650: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
-00008660: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
-00008670: 7473 2872 6573 746f 7265 5f64 6972 290a  ts(restore_dir).
-00008680: 2020 2020 2020 2020 7365 6c66 2e61 7373          self.ass
-00008690: 6572 7445 7175 616c 2872 6573 746f 7265  ertEqual(restore
-000086a0: 642c 2073 656c 662e 6578 7065 6374 6564  d, self.expected
-000086b0: 5f72 6573 746f 7265 645f 7472 6565 5f77  _restored_tree_w
-000086c0: 6974 685f 7472 6169 6c69 6e67 5f73 7061  ith_trailing_spa
-000086d0: 6365 290a 0a20 2020 2075 2222 220a 2020  ce)..    u""".  
-000086e0: 2020 5465 7374 2061 6c6c 202d 2d66 696c    Test all --fil
-000086f0: 7465 722d 2a20 6d6f 6465 7320 696e 2063  ter-* modes in c
-00008700: 6f6d 6269 6e61 7469 6f6e 2c20 7769 7468  ombination, with
-00008710: 2073 656c 6563 7469 6f6e 2070 6174 7465   selection patte
-00008720: 726e 7320 7768 6963 680a 2020 2020 7574  rns which.    ut
-00008730: 696c 6973 6520 7468 6520 7370 6563 6966  ilise the specif
-00008740: 6963 2063 6170 6162 696c 6974 6965 7320  ic capabilities 
-00008750: 6f66 2065 6163 682e 0a20 2020 2022 2222  of each..    """
-00008760: 0a20 2020 2023 2074 6869 7320 6973 2073  .    # this is s
-00008770: 6c69 6768 746c 7920 6469 6666 6572 656e  lightly differen
-00008780: 7420 6672 6f6d 2054 6573 7449 6e63 6c75  t from TestInclu
-00008790: 6465 4578 636c 7564 6546 696c 7465 724d  deExcludeFilterM
-000087a0: 6f64 6573 2077 6869 6368 2075 7365 0a20  odes which use. 
-000087b0: 2020 2023 2066 696c 7465 7220 6d6f 6465     # filter mode
-000087c0: 2073 7769 7463 6865 7320 666f 7220 7768   switches for wh
-000087d0: 6963 6820 7468 6579 2061 7265 2075 7365  ich they are use
-000087e0: 6420 286d 6f73 746c 7929 2074 6f20 6e6f  d (mostly) to no
-000087f0: 2065 6666 6563 742c 2074 6f0a 2020 2020   effect, to.    
-00008800: 2320 7072 6f64 7563 6520 7468 6520 616c  # produce the al
-00008810: 7265 6164 7920 6465 6669 6e65 6420 6578  ready defined ex
-00008820: 7065 6374 6564 5f72 6573 746f 7265 5f74  pected_restore_t
-00008830: 7265 6520 7374 7275 6374 7572 652e 0a20  ree structure.. 
-00008840: 2020 2064 6566 2074 6573 745f 6c69 7465     def test_lite
-00008850: 7261 6c5f 6d75 6c74 6970 6c65 5f6d 6f64  ral_multiple_mod
-00008860: 655f 7377 6974 6368 6573 2873 656c 6629  e_switches(self)
-00008870: 3a0a 2020 2020 2020 2020 7365 6c66 2e62  :.        self.b
-00008880: 6163 6b75 7028 7522 6675 6c6c 222c 2075  ackup(u"full", u
-00008890: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-000088a0: 7432 222c 0a20 2020 2020 2020 2020 2020  t2",.           
-000088b0: 2020 2020 2020 2020 206f 7074 696f 6e73           options
-000088c0: 3d5b 7522 2d2d 696e 636c 7564 6522 2c20  =[u"--include", 
-000088d0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-000088e0: 6374 322f 2a2a 646f 6322 2c0a 2020 2020  ct2/**doc",.    
-000088f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008900: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00008910: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00008920: 6573 2f73 656c 6563 7432 2f31 2f2a 2f2a  es/select2/1/*/*
-00008930: 2f2a 2e74 7874 222c 0a20 2020 2020 2020  /*.txt",.       
+00008280: 222d 2d69 6e63 6c75 6465 222c 2022 7465  "--include", "te
+00008290: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+000082a0: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
+000082b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000082c0: 2022 2d2d 6669 6c74 6572 2d67 6c6f 6262   "--filter-globb
+000082d0: 696e 6722 2c0a 2020 2020 2020 2020 2020  ing",.          
+000082e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000082f0: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00008300: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00008310: 7432 2f2a 2a22 5d29 0a20 2020 2020 2020  t2/**"]).       
+00008320: 2073 656c 662e 7265 7374 6f72 6528 290a   self.restore().
+00008330: 2020 2020 2020 2020 7265 7374 6f72 655f          restore_
+00008340: 7061 7468 203d 2022 7465 7374 6669 6c65  path = "testfile
+00008350: 732f 7265 7374 6f72 655f 6f75 7422 0a20  s/restore_out". 
+00008360: 2020 2020 2020 2072 6573 746f 7265 6420         restored 
+00008370: 3d20 7365 6c66 2e64 6972 6563 746f 7279  = self.directory
+00008380: 5f74 7265 655f 746f 5f6c 6973 745f 6f66  _tree_to_list_of
+00008390: 5f6c 6973 7473 2872 6573 746f 7265 5f70  _lists(restore_p
+000083a0: 6174 6829 0a20 2020 2020 2020 2073 656c  ath).        sel
+000083b0: 662e 6173 7365 7274 4571 7561 6c28 7265  f.assertEqual(re
+000083c0: 7374 6f72 6564 2c20 7365 6c66 2e65 7870  stored, self.exp
+000083d0: 6563 7465 645f 7265 7374 6f72 6564 5f74  ected_restored_t
+000083e0: 7265 655f 7769 7468 5f74 7261 696c 696e  ree_with_trailin
+000083f0: 675f 7370 6163 6529 0a0a 2020 2020 2222  g_space)..    ""
+00008400: 220a 2020 2020 5465 7374 2061 6c6c 202d  ".    Test all -
+00008410: 2d66 696c 7465 722d 2a20 6d6f 6465 7320  -filter-* modes 
+00008420: 696e 2063 6f6d 6269 6e61 7469 6f6e 2c20  in combination, 
+00008430: 7769 7468 2073 656c 6563 7469 6f6e 2070  with selection p
+00008440: 6174 7465 726e 7320 7768 6963 680a 2020  atterns which.  
+00008450: 2020 7574 696c 6973 6520 7468 6520 7370    utilise the sp
+00008460: 6563 6966 6963 2063 6170 6162 696c 6974  ecific capabilit
+00008470: 6965 7320 6f66 2065 6163 682e 0a20 2020  ies of each..   
+00008480: 2022 2222 0a0a 2020 2020 2320 7468 6973   """..    # this
+00008490: 2069 7320 736c 6967 6874 6c79 2064 6966   is slightly dif
+000084a0: 6665 7265 6e74 2066 726f 6d20 5465 7374  ferent from Test
+000084b0: 496e 636c 7564 6545 7863 6c75 6465 4669  IncludeExcludeFi
+000084c0: 6c74 6572 4d6f 6465 7320 7768 6963 6820  lterModes which 
+000084d0: 7573 650a 2020 2020 2320 6669 6c74 6572  use.    # filter
+000084e0: 206d 6f64 6520 7377 6974 6368 6573 2066   mode switches f
+000084f0: 6f72 2077 6869 6368 2074 6865 7920 6172  or which they ar
+00008500: 6520 7573 6564 2028 6d6f 7374 6c79 2920  e used (mostly) 
+00008510: 746f 206e 6f20 6566 6665 6374 2c20 746f  to no effect, to
+00008520: 0a20 2020 2023 2070 726f 6475 6365 2074  .    # produce t
+00008530: 6865 2061 6c72 6561 6479 2064 6566 696e  he already defin
+00008540: 6564 2065 7870 6563 7465 645f 7265 7374  ed expected_rest
+00008550: 6f72 655f 7472 6565 2073 7472 7563 7475  ore_tree structu
+00008560: 7265 2e0a 2020 2020 6465 6620 7465 7374  re..    def test
+00008570: 5f6c 6974 6572 616c 5f6d 756c 7469 706c  _literal_multipl
+00008580: 655f 6d6f 6465 5f73 7769 7463 6865 7328  e_mode_switches(
+00008590: 7365 6c66 293a 0a20 2020 2020 2020 2073  self):.        s
+000085a0: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+000085b0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+000085c0: 6c65 6374 3222 2c0a 2020 2020 2020 2020  lect2",.        
+000085d0: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
+000085e0: 6f6e 733d 5b22 2d2d 696e 636c 7564 6522  ons=["--include"
+000085f0: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00008600: 6563 7432 2f2a 2a64 6f63 222c 0a20 2020  ect2/**doc",.   
+00008610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008620: 2020 2020 2020 2020 2020 222d 2d65 7863            "--exc
+00008630: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00008640: 732f 7365 6c65 6374 322f 312f 2a2f 2a2f  s/select2/1/*/*/
+00008650: 2a2e 7478 7422 2c0a 2020 2020 2020 2020  *.txt",.        
+00008660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008670: 2020 2020 2022 2d2d 6669 6c74 6572 2d6c       "--filter-l
+00008680: 6974 6572 616c 222c 0a20 2020 2020 2020  iteral",.       
+00008690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000086a0: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+000086b0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+000086c0: 6c65 6374 322f 322f 3273 7562 312f 3273  lect2/2/2sub1/2s
+000086d0: 7562 3173 7562 312f 3273 7562 3173 7562  ub1sub1/2sub1sub
+000086e0: 315f 6669 6c65 2e74 7874 222c 0a20 2020  1_file.txt",.   
+000086f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008700: 2020 2020 2020 2020 2020 222d 2d66 696c            "--fil
+00008710: 7465 722d 7265 6765 7870 222c 0a20 2020  ter-regexp",.   
+00008720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008730: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+00008740: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00008750: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
+00008760: 5b31 335d 2f31 7375 625b 3133 5d73 7562  [13]/1sub[13]sub
+00008770: 5b31 3233 5d22 2c0a 2020 2020 2020 2020  [123]",.        
+00008780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008790: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+000087a0: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+000087b0: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
+000087c0: 6231 7375 625b 3132 5d22 2c0a 2020 2020  b1sub[12]",.    
+000087d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000087e0: 2020 2020 2020 2020 2022 2d2d 6669 6c74           "--filt
+000087f0: 6572 2d6c 6974 6572 616c 222c 0a20 2020  er-literal",.   
+00008800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008810: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+00008820: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00008830: 732f 7365 6c65 6374 322f 7472 6169 6c69  s/select2/traili
+00008840: 6e67 5f73 7061 6365 202f 7472 6169 6c69  ng_space /traili
+00008850: 6e67 5f73 7061 6365 2073 7562 322f 7472  ng_space sub2/tr
+00008860: 6169 6c69 6e67 5f73 7061 6365 2022 0a20  ailing_space ". 
+00008870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008880: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008890: 2020 2020 2020 2020 2022 7375 6232 5f66           "sub2_f
+000088a0: 696c 652e 7478 7422 2c0a 2020 2020 2020  ile.txt",.      
+000088b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000088c0: 2020 2020 2020 2022 2d2d 696e 636c 7564         "--includ
+000088d0: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+000088e0: 656c 6563 7432 2f33 2f33 7375 6233 2f33  elect2/3/3sub3/3
+000088f0: 7375 6233 7375 6232 2f33 7375 6233 7375  sub3sub2/3sub3su
+00008900: 6232 5f66 696c 652e 7478 7422 2c0a 2020  b2_file.txt",.  
+00008910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008920: 2020 2020 2020 2020 2020 2022 2d2d 6669             "--fi
+00008930: 6c74 6572 2d67 6c6f 6262 696e 6722 2c0a  lter-globbing",.
 00008940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008950: 2020 2020 2020 7522 2d2d 6669 6c74 6572        u"--filter
-00008960: 2d6c 6974 6572 616c 222c 0a20 2020 2020  -literal",.     
-00008970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008980: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-00008990: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-000089a0: 732f 7365 6c65 6374 322f 322f 3273 7562  s/select2/2/2sub
-000089b0: 312f 3273 7562 3173 7562 312f 3273 7562  1/2sub1sub1/2sub
-000089c0: 3173 7562 315f 6669 6c65 2e74 7874 222c  1sub1_file.txt",
-000089d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000089e0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-000089f0: 2d2d 6669 6c74 6572 2d72 6567 6578 7022  --filter-regexp"
-00008a00: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00008a10: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00008a20: 222d 2d69 6e63 6c75 6465 222c 2075 2274  "--include", u"t
-00008a30: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00008a40: 2f31 2f31 7375 625b 3133 5d2f 3173 7562  /1/1sub[13]/1sub
-00008a50: 5b31 335d 7375 625b 3132 335d 222c 0a20  [13]sub[123]",. 
+00008950: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00008960: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+00008970: 696c 6573 2f73 656c 6563 7432 2f2a 225d  iles/select2/*"]
+00008980: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
+00008990: 6573 746f 7265 2829 0a20 2020 2020 2020  estore().       
+000089a0: 2072 6573 746f 7265 5f70 6174 6820 3d20   restore_path = 
+000089b0: 2274 6573 7466 696c 6573 2f72 6573 746f  "testfiles/resto
+000089c0: 7265 5f6f 7574 220a 2020 2020 2020 2020  re_out".        
+000089d0: 7265 7374 6f72 6564 203d 2073 656c 662e  restored = self.
+000089e0: 6469 7265 6374 6f72 795f 7472 6565 5f74  directory_tree_t
+000089f0: 6f5f 6c69 7374 5f6f 665f 6c69 7374 7328  o_list_of_lists(
+00008a00: 7265 7374 6f72 655f 7061 7468 290a 2020  restore_path).  
+00008a10: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
+00008a20: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
+00008a30: 205b 5b22 3122 2c20 2232 222c 2022 3322   [["1", "2", "3"
+00008a40: 2c20 2274 7261 696c 696e 675f 7370 6163  , "trailing_spac
+00008a50: 6520 222c 2022 312e 646f 6322 5d2c 0a20  e ", "1.doc"],. 
 00008a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008a70: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00008a80: 696e 636c 7564 6522 2c20 7522 7465 7374  include", u"test
-00008a90: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-00008aa0: 3273 7562 312f 3273 7562 3173 7562 5b31  2sub1/2sub1sub[1
-00008ab0: 325d 222c 0a20 2020 2020 2020 2020 2020  2]",.           
-00008ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008ad0: 2020 7522 2d2d 6669 6c74 6572 2d6c 6974    u"--filter-lit
-00008ae0: 6572 616c 222c 0a20 2020 2020 2020 2020  eral",.         
+00008a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008a80: 2020 205b 2231 7375 6231 222c 2022 3173     ["1sub1", "1s
+00008a90: 7562 3322 5d2c 0a20 2020 2020 2020 2020  ub3"],.         
+00008aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008ab0: 2020 2020 2020 2020 2020 205b 2231 7375             ["1su
+00008ac0: 6231 7375 6231 222c 2022 3173 7562 3173  b1sub1", "1sub1s
+00008ad0: 7562 3222 2c20 2231 7375 6231 7375 6233  ub2", "1sub1sub3
+00008ae0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
 00008af0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008b00: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-00008b10: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00008b20: 6c65 6374 322f 7472 6169 6c69 6e67 5f73  lect2/trailing_s
-00008b30: 7061 6365 202f 7472 6169 6c69 6e67 5f73  pace /trailing_s
-00008b40: 7061 6365 2073 7562 322f 7472 6169 6c69  pace sub2/traili
-00008b50: 6e67 5f73 7061 6365 2022 0a20 2020 2020  ng_space ".     
-00008b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008b80: 2020 2020 2020 7522 7375 6232 5f66 696c        u"sub2_fil
-00008b90: 652e 7478 7422 2c0a 2020 2020 2020 2020  e.txt",.        
-00008ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008bb0: 2020 2020 2075 222d 2d69 6e63 6c75 6465       u"--include
-00008bc0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00008bd0: 656c 6563 7432 2f33 2f33 7375 6233 2f33  elect2/3/3sub3/3
-00008be0: 7375 6233 7375 6232 2f33 7375 6233 7375  sub3sub2/3sub3su
-00008bf0: 6232 5f66 696c 652e 7478 7422 2c0a 2020  b2_file.txt",.  
-00008c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008c10: 2020 2020 2020 2020 2020 2075 222d 2d66             u"--f
-00008c20: 696c 7465 722d 676c 6f62 6269 6e67 222c  ilter-globbing",
-00008c30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00008c40: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00008c50: 2d2d 6578 636c 7564 6522 2c20 7522 7465  --exclude", u"te
-00008c60: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00008c70: 2a22 5d29 0a20 2020 2020 2020 2073 656c  *"]).        sel
-00008c80: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
-00008c90: 2020 2020 7265 7374 6f72 655f 6469 7220      restore_dir 
-00008ca0: 3d20 7522 7465 7374 6669 6c65 732f 7265  = u"testfiles/re
-00008cb0: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
-00008cc0: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
-00008cd0: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
-00008ce0: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
-00008cf0: 7473 2872 6573 746f 7265 5f64 6972 290a  ts(restore_dir).
-00008d00: 2020 2020 2020 2020 7365 6c66 2e61 7373          self.ass
-00008d10: 6572 7445 7175 616c 2872 6573 746f 7265  ertEqual(restore
-00008d20: 642c 205b 5b75 2231 222c 2075 2232 222c  d, [[u"1", u"2",
-00008d30: 2075 2233 222c 2075 2274 7261 696c 696e   u"3", u"trailin
-00008d40: 675f 7370 6163 6520 222c 2075 2231 2e64  g_space ", u"1.d
-00008d50: 6f63 225d 2c0a 2020 2020 2020 2020 2020  oc"],.          
-00008d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008d70: 2020 2020 2020 2020 2020 5b75 2231 7375            [u"1su
-00008d80: 6231 222c 2075 2231 7375 6233 225d 2c0a  b1", u"1sub3"],.
-00008d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008db0: 2020 2020 5b75 2231 7375 6231 7375 6231      [u"1sub1sub1
-00008dc0: 222c 2075 2231 7375 6231 7375 6232 222c  ", u"1sub1sub2",
-00008dd0: 2075 2231 7375 6231 7375 6233 225d 2c0a   u"1sub1sub3"],.
-00008de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e00: 2020 2020 5b75 2231 7375 6233 7375 6231      [u"1sub3sub1
-00008e10: 222c 2075 2231 7375 6233 7375 6232 222c  ", u"1sub3sub2",
-00008e20: 2075 2231 7375 6233 7375 6233 225d 2c0a   u"1sub3sub3"],.
-00008e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e50: 2020 2020 5b75 2232 7375 6231 225d 2c20      [u"2sub1"], 
-00008e60: 5b75 2232 7375 6231 7375 6231 222c 2075  [u"2sub1sub1", u
-00008e70: 2232 7375 6231 7375 6232 225d 2c0a 2020  "2sub1sub2"],.  
+00008b00: 2020 2020 2020 2020 5b22 3173 7562 3373          ["1sub3s
+00008b10: 7562 3122 2c20 2231 7375 6233 7375 6232  ub1", "1sub3sub2
+00008b20: 222c 2022 3173 7562 3373 7562 3322 5d2c  ", "1sub3sub3"],
+00008b30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00008b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b50: 2020 2020 205b 2232 7375 6231 225d 2c20       ["2sub1"], 
+00008b60: 5b22 3273 7562 3173 7562 3122 2c20 2232  ["2sub1sub1", "2
+00008b70: 7375 6231 7375 6232 225d 2c0a 2020 2020  sub1sub2"],.    
+00008b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008ba0: 5b22 3373 7562 3322 5d2c 205b 2233 7375  ["3sub3"], ["3su
+00008bb0: 6233 7375 6232 225d 2c20 5b22 3373 7562  b3sub2"], ["3sub
+00008bc0: 3373 7562 325f 6669 6c65 2e74 7874 225d  3sub2_file.txt"]
+00008bd0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00008be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008bf0: 2020 2020 2020 5b22 7472 6169 6c69 6e67        ["trailing
+00008c00: 5f73 7061 6365 2073 7562 3222 5d2c 0a20  _space sub2"],. 
+00008c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008c30: 2020 205b 2274 7261 696c 696e 675f 7370     ["trailing_sp
+00008c40: 6163 6520 7375 6232 5f66 696c 652e 7478  ace sub2_file.tx
+00008c50: 7422 5d5d 290a 0a20 2020 2022 2222 0a20  t"]])..    """. 
+00008c60: 2020 2053 616d 6520 2061 7320 7465 7374     Same  as test
+00008c70: 5f6c 6974 6572 616c 5f6d 756c 7469 706c  _literal_multipl
+00008c80: 655f 6d6f 6465 5f73 7769 7463 6865 732c  e_mode_switches,
+00008c90: 2062 7574 2077 6974 686f 7574 2063 6173   but without cas
+00008ca0: 6520 7365 6e73 6974 6976 6974 790a 2020  e sensitivity.  
+00008cb0: 2020 6173 2073 7065 6369 6669 6564 2075    as specified u
+00008cc0: 7369 6e67 2074 6865 2065 7869 7374 696e  sing the existin
+00008cd0: 6720 6967 6e6f 7265 6361 7365 3a20 7072  g ignorecase: pr
+00008ce0: 6566 6978 2c20 6174 206c 6561 7374 2066  efix, at least f
+00008cf0: 6f72 2074 686f 7365 2066 696c 650a 2020  or those file.  
+00008d00: 2020 7365 6c65 6374 696f 6e20 6f70 7469    selection opti
+00008d10: 6f6e 7320 7375 7070 6f72 7420 6974 2e0a  ons support it..
+00008d20: 2020 2020 2222 220a 0a20 2020 2064 6566      """..    def
+00008d30: 2074 6573 745f 6c69 7465 7261 6c5f 6d75   test_literal_mu
+00008d40: 6c74 6970 6c65 5f6d 6f64 655f 7377 6974  ltiple_mode_swit
+00008d50: 6368 6573 5f77 6974 685f 6967 6e6f 7265  ches_with_ignore
+00008d60: 6361 7365 5f70 7265 6669 7828 7365 6c66  case_prefix(self
+00008d70: 293a 0a20 2020 2020 2020 2073 656c 662e  ):.        self.
+00008d80: 6261 636b 7570 2822 6675 6c6c 222c 2022  backup("full", "
+00008d90: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00008da0: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
+00008db0: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
+00008dc0: 5b22 2d2d 696e 636c 7564 6522 2c20 2269  ["--include", "i
+00008dd0: 676e 6f72 6563 6173 653a 7445 5374 6669  gnorecase:tEStfi
+00008de0: 6c65 732f 7345 6c65 6374 322f 2a2a 646f  les/sElect2/**do
+00008df0: 6322 2c0a 2020 2020 2020 2020 2020 2020  c",.            
+00008e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008e10: 2022 2d2d 6578 636c 7564 6522 2c20 2269   "--exclude", "i
+00008e20: 676e 6f72 6563 6173 653a 7465 7374 6649  gnorecase:testfI
+00008e30: 6c65 732f 7365 4c45 6374 322f 312f 2a2f  les/seLEct2/1/*/
+00008e40: 2a2f 2a2e 7478 7422 2c0a 2020 2020 2020  */*.txt",.      
+00008e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008e60: 2020 2020 2020 2022 2d2d 6669 6c74 6572         "--filter
+00008e70: 2d6c 6974 6572 616c 222c 0a20 2020 2020  -literal",.     
 00008e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008ea0: 2020 5b75 2233 7375 6233 225d 2c20 5b75    [u"3sub3"], [u
-00008eb0: 2233 7375 6233 7375 6232 225d 2c20 5b75  "3sub3sub2"], [u
-00008ec0: 2233 7375 6233 7375 6232 5f66 696c 652e  "3sub3sub2_file.
-00008ed0: 7478 7422 5d2c 0a20 2020 2020 2020 2020  txt"],.         
+00008e90: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+00008ea0: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00008eb0: 7365 6c65 6374 322f 322f 3273 7562 312f  select2/2/2sub1/
+00008ec0: 3273 7562 3173 7562 312f 3273 7562 3173  2sub1sub1/2sub1s
+00008ed0: 7562 315f 6669 6c65 2e74 7874 222c 0a20  ub1_file.txt",. 
 00008ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008ef0: 2020 2020 2020 2020 2020 205b 7522 7472             [u"tr
-00008f00: 6169 6c69 6e67 5f73 7061 6365 2073 7562  ailing_space sub
-00008f10: 3222 5d2c 0a20 2020 2020 2020 2020 2020  2"],.           
-00008f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00008f30: 2020 2020 2020 2020 205b 7522 7472 6169           [u"trai
-00008f40: 6c69 6e67 5f73 7061 6365 2073 7562 325f  ling_space sub2_
-00008f50: 6669 6c65 2e74 7874 225d 5d29 0a0a 2020  file.txt"]])..  
-00008f60: 2020 7522 2222 0a20 2020 2053 616d 6520    u""".    Same 
-00008f70: 2061 7320 7465 7374 5f6c 6974 6572 616c   as test_literal
-00008f80: 5f6d 756c 7469 706c 655f 6d6f 6465 5f73  _multiple_mode_s
-00008f90: 7769 7463 6865 732c 2062 7574 2077 6974  witches, but wit
-00008fa0: 686f 7574 2063 6173 6520 7365 6e73 6974  hout case sensit
-00008fb0: 6976 6974 790a 2020 2020 6173 2073 7065  ivity.    as spe
-00008fc0: 6369 6669 6564 2075 7369 6e67 2074 6865  cified using the
-00008fd0: 2065 7869 7374 696e 6720 6967 6e6f 7265   existing ignore
-00008fe0: 6361 7365 3a20 7072 6566 6978 2c20 6174  case: prefix, at
-00008ff0: 206c 6561 7374 2066 6f72 2074 686f 7365   least for those
-00009000: 2066 696c 650a 2020 2020 7365 6c65 6374   file.    select
-00009010: 696f 6e20 6f70 7469 6f6e 7320 7375 7070  ion options supp
-00009020: 6f72 7420 6974 2e0a 2020 2020 2222 220a  ort it..    """.
-00009030: 2020 2020 6465 6620 7465 7374 5f6c 6974      def test_lit
-00009040: 6572 616c 5f6d 756c 7469 706c 655f 6d6f  eral_multiple_mo
-00009050: 6465 5f73 7769 7463 6865 735f 7769 7468  de_switches_with
-00009060: 5f69 676e 6f72 6563 6173 655f 7072 6566  _ignorecase_pref
-00009070: 6978 2873 656c 6629 3a0a 2020 2020 2020  ix(self):.      
-00009080: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-00009090: 6675 6c6c 222c 2075 2274 6573 7466 696c  full", u"testfil
-000090a0: 6573 2f73 656c 6563 7432 222c 0a20 2020  es/select2",.   
-000090b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000090c0: 206f 7074 696f 6e73 3d5b 7522 2d2d 696e   options=[u"--in
-000090d0: 636c 7564 6522 2c20 7522 6967 6e6f 7265  clude", u"ignore
-000090e0: 6361 7365 3a74 4553 7466 696c 6573 2f73  case:tEStfiles/s
-000090f0: 456c 6563 7432 2f2a 2a64 6f63 222c 0a20  Elect2/**doc",. 
+00008ef0: 2020 2020 2020 2020 2020 2020 222d 2d66              "--f
+00008f00: 696c 7465 722d 7265 6765 7870 222c 0a20  ilter-regexp",. 
+00008f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f20: 2020 2020 2020 2020 2020 2020 222d 2d69              "--i
+00008f30: 6e63 6c75 6465 222c 2022 7465 7374 6669  nclude", "testfi
+00008f40: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+00008f50: 7562 5b31 335d 2f31 7375 625b 3133 5d73  ub[13]/1sub[13]s
+00008f60: 7562 5b31 3233 5d22 2c0a 2020 2020 2020  ub[123]",.      
+00008f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f80: 2020 2020 2020 2022 2d2d 696e 636c 7564         "--includ
+00008f90: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00008fa0: 656c 6563 7432 2f32 2f32 7375 6231 2f32  elect2/2/2sub1/2
+00008fb0: 7375 6231 7375 625b 3132 5d22 2c0a 2020  sub1sub[12]",.  
+00008fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008fd0: 2020 2020 2020 2020 2020 2022 2d2d 6669             "--fi
+00008fe0: 6c74 6572 2d6c 6974 6572 616c 222c 0a20  lter-literal",. 
+00008ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009000: 2020 2020 2020 2020 2020 2020 222d 2d69              "--i
+00009010: 6e63 6c75 6465 222c 2022 7465 7374 6669  nclude", "testfi
+00009020: 6c65 732f 7365 6c65 6374 322f 7472 6169  les/select2/trai
+00009030: 6c69 6e67 5f73 7061 6365 202f 7472 6169  ling_space /trai
+00009040: 6c69 6e67 5f73 7061 6365 2022 0a20 2020  ling_space ".   
+00009050: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009070: 2020 2020 2020 2022 7375 6232 2f74 7261         "sub2/tra
+00009080: 696c 696e 675f 7370 6163 6520 7375 6232  iling_space sub2
+00009090: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
+000090a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090b0: 2020 2020 2020 2020 2022 2d2d 696e 636c           "--incl
+000090c0: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+000090d0: 2f73 656c 6563 7432 2f33 2f33 7375 6233  /select2/3/3sub3
+000090e0: 2f33 7375 6233 7375 6232 2f33 7375 6233  /3sub3sub2/3sub3
+000090f0: 7375 6232 5f66 696c 652e 7478 7422 2c0a  sub2_file.txt",.
 00009100: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009110: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00009120: 6578 636c 7564 6522 2c20 7522 6967 6e6f  exclude", u"igno
-00009130: 7265 6361 7365 3a74 6573 7466 496c 6573  recase:testfIles
-00009140: 2f73 654c 4563 7432 2f31 2f2a 2f2a 2f2a  /seLEct2/1/*/*/*
-00009150: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
-00009160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009170: 2020 2020 7522 2d2d 6669 6c74 6572 2d6c      u"--filter-l
-00009180: 6974 6572 616c 222c 0a20 2020 2020 2020  iteral",.       
-00009190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000091a0: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-000091b0: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-000091c0: 7365 6c65 6374 322f 322f 3273 7562 312f  select2/2/2sub1/
-000091d0: 3273 7562 3173 7562 312f 3273 7562 3173  2sub1sub1/2sub1s
-000091e0: 7562 315f 6669 6c65 2e74 7874 222c 0a20  ub1_file.txt",. 
-000091f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009200: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00009210: 6669 6c74 6572 2d72 6567 6578 7022 2c0a  filter-regexp",.
-00009220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009230: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00009240: 2d69 6e63 6c75 6465 222c 2075 2274 6573  -include", u"tes
-00009250: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-00009260: 2f31 7375 625b 3133 5d2f 3173 7562 5b31  /1sub[13]/1sub[1
-00009270: 335d 7375 625b 3132 335d 222c 0a20 2020  3]sub[123]",.   
-00009280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009290: 2020 2020 2020 2020 2020 7522 2d2d 696e            u"--in
-000092a0: 636c 7564 6522 2c20 7522 7465 7374 6669  clude", u"testfi
-000092b0: 6c65 732f 7365 6c65 6374 322f 322f 3273  les/select2/2/2s
-000092c0: 7562 312f 3273 7562 3173 7562 5b31 325d  ub1/2sub1sub[12]
-000092d0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-000092e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000092f0: 7522 2d2d 6669 6c74 6572 2d6c 6974 6572  u"--filter-liter
-00009300: 616c 222c 0a20 2020 2020 2020 2020 2020  al",.           
-00009310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009320: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-00009330: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00009340: 6374 322f 7472 6169 6c69 6e67 5f73 7061  ct2/trailing_spa
-00009350: 6365 202f 7472 6169 6c69 6e67 5f73 7061  ce /trailing_spa
-00009360: 6365 2022 0a20 2020 2020 2020 2020 2020  ce ".           
-00009370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009110: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00009120: 6669 6c74 6572 2d67 6c6f 6262 696e 6722  filter-globbing"
+00009130: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00009140: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00009150: 2d2d 6578 636c 7564 6522 2c20 2269 676e  --exclude", "ign
+00009160: 6f72 6563 6173 653a 5465 7374 4669 6c65  orecase:TestFile
+00009170: 732f 5345 4c45 4354 322f 2a22 5d29 0a20  s/SELECT2/*"]). 
+00009180: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
+00009190: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
+000091a0: 7374 6f72 655f 7061 7468 203d 2022 7465  store_path = "te
+000091b0: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
+000091c0: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
+000091d0: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
+000091e0: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
+000091f0: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
+00009200: 746f 7265 5f70 6174 6829 0a20 2020 2020  tore_path).     
+00009210: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
+00009220: 7561 6c28 7265 7374 6f72 6564 2c20 5b5b  ual(restored, [[
+00009230: 2231 222c 2022 3222 2c20 2233 222c 2022  "1", "2", "3", "
+00009240: 7472 6169 6c69 6e67 5f73 7061 6365 2022  trailing_space "
+00009250: 2c20 2231 2e64 6f63 225d 2c0a 2020 2020  , "1.doc"],.    
+00009260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009280: 5b22 3173 7562 3122 2c20 2231 7375 6233  ["1sub1", "1sub3
+00009290: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+000092a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000092b0: 2020 2020 2020 2020 5b22 3173 7562 3173          ["1sub1s
+000092c0: 7562 3122 2c20 2231 7375 6231 7375 6232  ub1", "1sub1sub2
+000092d0: 222c 2022 3173 7562 3173 7562 3322 5d2c  ", "1sub1sub3"],
+000092e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000092f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009300: 2020 2020 205b 2231 7375 6233 7375 6231       ["1sub3sub1
+00009310: 222c 2022 3173 7562 3373 7562 3222 2c20  ", "1sub3sub2", 
+00009320: 2231 7375 6233 7375 6233 225d 2c0a 2020  "1sub3sub3"],.  
+00009330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009350: 2020 5b22 3273 7562 3122 5d2c 205b 2232    ["2sub1"], ["2
+00009360: 7375 6231 7375 6231 222c 2022 3273 7562  sub1sub1", "2sub
+00009370: 3173 7562 3222 5d2c 0a20 2020 2020 2020  1sub2"],.       
 00009380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009390: 7522 7375 6232 2f74 7261 696c 696e 675f  u"sub2/trailing_
-000093a0: 7370 6163 6520 7375 6232 5f66 696c 652e  space sub2_file.
-000093b0: 7478 7422 2c0a 2020 2020 2020 2020 2020  txt",.          
-000093c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000093d0: 2020 2075 222d 2d69 6e63 6c75 6465 222c     u"--include",
-000093e0: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-000093f0: 6563 7432 2f33 2f33 7375 6233 2f33 7375  ect2/3/3sub3/3su
-00009400: 6233 7375 6232 2f33 7375 6233 7375 6232  b3sub2/3sub3sub2
-00009410: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
+00009390: 2020 2020 2020 2020 2020 2020 205b 2233               ["3
+000093a0: 7375 6233 225d 2c20 5b22 3373 7562 3373  sub3"], ["3sub3s
+000093b0: 7562 3222 5d2c 205b 2233 7375 6233 7375  ub2"], ["3sub3su
+000093c0: 6232 5f66 696c 652e 7478 7422 5d2c 0a20  b2_file.txt"],. 
+000093d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000093e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000093f0: 2020 205b 2274 7261 696c 696e 675f 7370     ["trailing_sp
+00009400: 6163 6520 7375 6232 225d 2c0a 2020 2020  ace sub2"],.    
+00009410: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009420: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009430: 2020 2020 2020 2020 2075 222d 2d66 696c           u"--fil
-00009440: 7465 722d 676c 6f62 6269 6e67 222c 0a20  ter-globbing",. 
-00009450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009460: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00009470: 6578 636c 7564 6522 2c20 7522 6967 6e6f  exclude", u"igno
-00009480: 7265 6361 7365 3a54 6573 7446 696c 6573  recase:TestFiles
-00009490: 2f53 454c 4543 5432 2f2a 225d 290a 2020  /SELECT2/*"]).  
-000094a0: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
-000094b0: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
-000094c0: 746f 7265 5f64 6972 203d 2075 2274 6573  tore_dir = u"tes
-000094d0: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
-000094e0: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
-000094f0: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
-00009500: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
-00009510: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
-00009520: 6f72 655f 6469 7229 0a20 2020 2020 2020  ore_dir).       
-00009530: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
-00009540: 6c28 7265 7374 6f72 6564 2c20 5b5b 7522  l(restored, [[u"
-00009550: 3122 2c20 7522 3222 2c20 7522 3322 2c20  1", u"2", u"3", 
-00009560: 7522 7472 6169 6c69 6e67 5f73 7061 6365  u"trailing_space
-00009570: 2022 2c20 7522 312e 646f 6322 5d2c 0a20   ", u"1.doc"],. 
-00009580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000095a0: 2020 205b 7522 3173 7562 3122 2c20 7522     [u"1sub1", u"
-000095b0: 3173 7562 3322 5d2c 0a20 2020 2020 2020  1sub3"],.       
+00009430: 5b22 7472 6169 6c69 6e67 5f73 7061 6365  ["trailing_space
+00009440: 2073 7562 325f 6669 6c65 2e74 7874 225d   sub2_file.txt"]
+00009450: 5d29 0a0a 2020 2020 2222 220a 2020 2020  ])..    """.    
+00009460: 5361 6d65 2061 7320 7465 7374 5f6c 6974  Same as test_lit
+00009470: 6572 616c 5f6d 756c 7469 706c 655f 6d6f  eral_multiple_mo
+00009480: 6465 5f73 7769 7463 6865 7328 292c 2062  de_switches(), b
+00009490: 7574 2077 6974 686f 7574 2063 6173 6520  ut without case 
+000094a0: 7365 6e73 6974 6976 6974 790a 2020 2020  sensitivity.    
+000094b0: 666f 7220 2a61 6c6c 2a20 7365 6c65 6374  for *all* select
+000094c0: 696f 6e20 6f70 7469 6f6e 7320 7573 696e  ion options usin
+000094d0: 6720 7468 6520 2d2d 6669 6c74 6572 2d69  g the --filter-i
+000094e0: 676e 6f72 6563 6173 6520 636f 6d6d 616e  gnorecase comman
+000094f0: 6420 6c69 6e65 206f 7074 696f 6e2e 0a20  d line option.. 
+00009500: 2020 2022 2222 0a0a 2020 2020 6465 6620     """..    def 
+00009510: 7465 7374 5f6c 6974 6572 616c 5f6d 756c  test_literal_mul
+00009520: 7469 706c 655f 6d6f 6465 5f73 7769 7463  tiple_mode_switc
+00009530: 6865 735f 7769 7468 5f66 696c 7465 725f  hes_with_filter_
+00009540: 6967 6e6f 7265 6361 7365 2873 656c 6629  ignorecase(self)
+00009550: 3a0a 2020 2020 2020 2020 7365 6c66 2e62  :.        self.b
+00009560: 6163 6b75 7028 2266 756c 6c22 2c20 2274  ackup("full", "t
+00009570: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+00009580: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00009590: 2020 2020 2020 206f 7074 696f 6e73 3d5b         options=[
+000095a0: 222d 2d66 696c 7465 722d 6967 6e6f 7265  "--filter-ignore
+000095b0: 6361 7365 222c 0a20 2020 2020 2020 2020  case",.         
 000095c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000095d0: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-000095e0: 3173 7562 3173 7562 3122 2c20 7522 3173  1sub1sub1", u"1s
-000095f0: 7562 3173 7562 3222 2c20 7522 3173 7562  ub1sub2", u"1sub
-00009600: 3173 7562 3322 5d2c 0a20 2020 2020 2020  1sub3"],.       
-00009610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009620: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-00009630: 3173 7562 3373 7562 3122 2c20 7522 3173  1sub3sub1", u"1s
-00009640: 7562 3373 7562 3222 2c20 7522 3173 7562  ub3sub2", u"1sub
-00009650: 3373 7562 3322 5d2c 0a20 2020 2020 2020  3sub3"],.       
-00009660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009670: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-00009680: 3273 7562 3122 5d2c 205b 7522 3273 7562  2sub1"], [u"2sub
-00009690: 3173 7562 3122 2c20 7522 3273 7562 3173  1sub1", u"2sub1s
-000096a0: 7562 3222 5d2c 0a20 2020 2020 2020 2020  ub2"],.         
-000096b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000096c0: 2020 2020 2020 2020 2020 205b 7522 3373             [u"3s
-000096d0: 7562 3322 5d2c 205b 7522 3373 7562 3373  ub3"], [u"3sub3s
-000096e0: 7562 3222 5d2c 205b 7522 3373 7562 3373  ub2"], [u"3sub3s
-000096f0: 7562 325f 6669 6c65 2e74 7874 225d 2c0a  ub2_file.txt"],.
-00009700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000095d0: 2020 2020 222d 2d69 6e63 6c75 6465 222c      "--include",
+000095e0: 2022 7445 5374 6669 6c65 732f 7345 6c65   "tEStfiles/sEle
+000095f0: 6374 322f 2a2a 646f 6322 2c0a 2020 2020  ct2/**doc",.    
+00009600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009610: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00009620: 7564 6522 2c20 2274 6573 7466 496c 6573  ude", "testfIles
+00009630: 2f73 654c 4563 7432 2f31 2f2a 2f2a 2f2a  /seLEct2/1/*/*/*
+00009640: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
+00009650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009660: 2020 2020 222d 2d66 696c 7465 722d 6c69      "--filter-li
+00009670: 7465 7261 6c22 2c0a 2020 2020 2020 2020  teral",.        
+00009680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009690: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+000096a0: 2c20 2254 6573 7466 696c 6573 2f73 656c  , "Testfiles/sel
+000096b0: 6563 7432 2f32 2f32 5355 4231 2f32 7375  ect2/2/2SUB1/2su
+000096c0: 6231 7355 6231 2f32 7355 6231 7355 6231  b1sUb1/2sUb1sUb1
+000096d0: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
+000096e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000096f0: 2020 2020 2020 2020 2022 2d2d 6669 6c74           "--filt
+00009700: 6572 2d72 6567 6578 7022 2c0a 2020 2020  er-regexp",.    
 00009710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009720: 2020 2020 5b75 2274 7261 696c 696e 675f      [u"trailing_
-00009730: 7370 6163 6520 7375 6232 225d 2c0a 2020  space sub2"],.  
-00009740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009760: 2020 5b75 2274 7261 696c 696e 675f 7370    [u"trailing_sp
-00009770: 6163 6520 7375 6232 5f66 696c 652e 7478  ace sub2_file.tx
-00009780: 7422 5d5d 290a 0a20 2020 2075 2222 220a  t"]])..    u""".
-00009790: 2020 2020 5361 6d65 2061 7320 7465 7374      Same as test
-000097a0: 5f6c 6974 6572 616c 5f6d 756c 7469 706c  _literal_multipl
-000097b0: 655f 6d6f 6465 5f73 7769 7463 6865 7328  e_mode_switches(
-000097c0: 292c 2062 7574 2077 6974 686f 7574 2063  ), but without c
-000097d0: 6173 6520 7365 6e73 6974 6976 6974 790a  ase sensitivity.
-000097e0: 2020 2020 666f 7220 2a61 6c6c 2a20 7365      for *all* se
-000097f0: 6c65 6374 696f 6e20 6f70 7469 6f6e 7320  lection options 
-00009800: 7573 696e 6720 7468 6520 2d2d 6669 6c74  using the --filt
-00009810: 6572 2d69 676e 6f72 6563 6173 6520 636f  er-ignorecase co
-00009820: 6d6d 616e 6420 6c69 6e65 206f 7074 696f  mmand line optio
-00009830: 6e2e 0a20 2020 2022 2222 0a20 2020 2064  n..    """.    d
-00009840: 6566 2074 6573 745f 6c69 7465 7261 6c5f  ef test_literal_
-00009850: 6d75 6c74 6970 6c65 5f6d 6f64 655f 7377  multiple_mode_sw
-00009860: 6974 6368 6573 5f77 6974 685f 6669 6c74  itches_with_filt
-00009870: 6572 5f69 676e 6f72 6563 6173 6528 7365  er_ignorecase(se
-00009880: 6c66 293a 0a20 2020 2020 2020 2073 656c  lf):.        sel
-00009890: 662e 6261 636b 7570 2875 2266 756c 6c22  f.backup(u"full"
-000098a0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-000098b0: 6c65 6374 3222 2c0a 2020 2020 2020 2020  lect2",.        
-000098c0: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
-000098d0: 6f6e 733d 5b75 222d 2d66 696c 7465 722d  ons=[u"--filter-
-000098e0: 6967 6e6f 7265 6361 7365 222c 0a20 2020  ignorecase",.   
-000098f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009900: 2020 2020 2020 2020 2020 7522 2d2d 696e            u"--in
-00009910: 636c 7564 6522 2c20 7522 7445 5374 6669  clude", u"tEStfi
-00009920: 6c65 732f 7345 6c65 6374 322f 2a2a 646f  les/sElect2/**do
-00009930: 6322 2c0a 2020 2020 2020 2020 2020 2020  c",.            
-00009940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009950: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00009960: 2274 6573 7466 496c 6573 2f73 654c 4563  "testfIles/seLEc
-00009970: 7432 2f31 2f2a 2f2a 2f2a 2e74 7874 222c  t2/1/*/*/*.txt",
-00009980: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009990: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-000099a0: 2d2d 6669 6c74 6572 2d6c 6974 6572 616c  --filter-literal
-000099b0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-000099c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000099d0: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-000099e0: 5465 7374 6669 6c65 732f 7365 6c65 6374  Testfiles/select
-000099f0: 322f 322f 3253 5542 312f 3273 7562 3173  2/2/2SUB1/2sub1s
-00009a00: 5562 312f 3273 5562 3173 5562 315f 6669  Ub1/2sUb1sUb1_fi
-00009a10: 6c65 2e74 7874 222c 0a20 2020 2020 2020  le.txt",.       
-00009a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009a30: 2020 2020 2020 7522 2d2d 6669 6c74 6572        u"--filter
-00009a40: 2d72 6567 6578 7022 2c0a 2020 2020 2020  -regexp",.      
-00009a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009a60: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-00009a70: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00009a80: 2f73 656c 6563 7432 2f31 2f31 7375 625b  /select2/1/1sub[
-00009a90: 3133 5d2f 3173 7562 5b31 335d 7375 625b  13]/1sub[13]sub[
-00009aa0: 3132 335d 222c 0a20 2020 2020 2020 2020  123]",.         
-00009ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009ac0: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-00009ad0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00009ae0: 6c65 6374 322f 322f 3273 7562 312f 3253  lect2/2/2sub1/2S
-00009af0: 5542 3153 5542 5b31 325d 222c 0a20 2020  UB1SUB[12]",.   
-00009b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009b10: 2020 2020 2020 2020 2020 7522 2d2d 6669            u"--fi
-00009b20: 6c74 6572 2d6c 6974 6572 616c 222c 0a20  lter-literal",. 
-00009b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009b40: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00009b50: 696e 636c 7564 6522 2c20 7522 5445 5354  include", u"TEST
-00009b60: 4649 4c45 532f 7365 6c65 6374 322f 7472  FILES/select2/tr
-00009b70: 6169 6c69 6e67 5f73 7061 6365 202f 7472  ailing_space /tr
-00009b80: 6169 6c69 6e67 5f73 7061 6365 2073 7562  ailing_space sub
-00009b90: 322f 7472 6169 6c69 6e67 5f73 7061 6365  2/trailing_space
-00009ba0: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
+00009720: 2020 2020 2020 2020 2022 2d2d 696e 636c           "--incl
+00009730: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00009740: 2f73 656c 6563 7432 2f31 2f31 7375 625b  /select2/1/1sub[
+00009750: 3133 5d2f 3173 7562 5b31 335d 7375 625b  13]/1sub[13]sub[
+00009760: 3132 335d 222c 0a20 2020 2020 2020 2020  123]",.         
+00009770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009780: 2020 2020 222d 2d69 6e63 6c75 6465 222c      "--include",
+00009790: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+000097a0: 6374 322f 322f 3273 7562 312f 3253 5542  ct2/2/2sub1/2SUB
+000097b0: 3153 5542 5b31 325d 222c 0a20 2020 2020  1SUB[12]",.     
+000097c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000097d0: 2020 2020 2020 2020 222d 2d66 696c 7465          "--filte
+000097e0: 722d 6c69 7465 7261 6c22 2c0a 2020 2020  r-literal",.    
+000097f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009800: 2020 2020 2020 2020 2022 2d2d 696e 636c           "--incl
+00009810: 7564 6522 2c20 2254 4553 5446 494c 4553  ude", "TESTFILES
+00009820: 2f73 656c 6563 7432 2f74 7261 696c 696e  /select2/trailin
+00009830: 675f 7370 6163 6520 2f74 7261 696c 696e  g_space /trailin
+00009840: 675f 7370 6163 6520 7375 6232 2f74 7261  g_space sub2/tra
+00009850: 696c 696e 675f 7370 6163 6520 220a 2020  iling_space ".  
+00009860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009880: 2020 2020 2020 2020 2273 7562 325f 6669          "sub2_fi
+00009890: 6c65 2e74 7874 222c 0a20 2020 2020 2020  le.txt",.       
+000098a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000098b0: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+000098c0: 222c 2022 5465 7374 4669 6c65 732f 7365  ", "TestFiles/se
+000098d0: 6c65 6374 322f 332f 3373 7562 332f 3373  lect2/3/3sub3/3s
+000098e0: 7562 3373 7562 322f 3373 7562 3373 7562  ub3sub2/3sub3sub
+000098f0: 325f 6669 6c65 2e74 7874 222c 0a20 2020  2_file.txt",.   
+00009900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009910: 2020 2020 2020 2020 2020 222d 2d66 696c            "--fil
+00009920: 7465 722d 676c 6f62 6269 6e67 222c 0a20  ter-globbing",. 
+00009930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009940: 2020 2020 2020 2020 2020 2020 222d 2d66              "--f
+00009950: 696c 7465 722d 7374 7269 6374 6361 7365  ilter-strictcase
+00009960: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00009970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009980: 222d 2d65 7863 6c75 6465 222c 2022 7465  "--exclude", "te
+00009990: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+000099a0: 2a22 5d29 0a20 2020 2020 2020 2073 656c  *"]).        sel
+000099b0: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
+000099c0: 2020 2020 7265 7374 6f72 655f 7061 7468      restore_path
+000099d0: 203d 2022 7465 7374 6669 6c65 732f 7265   = "testfiles/re
+000099e0: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
+000099f0: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
+00009a00: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
+00009a10: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
+00009a20: 7473 2872 6573 746f 7265 5f70 6174 6829  ts(restore_path)
+00009a30: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
+00009a40: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
+00009a50: 6564 2c20 5b5b 2231 222c 2022 3222 2c20  ed, [["1", "2", 
+00009a60: 2233 222c 2022 7472 6169 6c69 6e67 5f73  "3", "trailing_s
+00009a70: 7061 6365 2022 2c20 2231 2e64 6f63 225d  pace ", "1.doc"]
+00009a80: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00009a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009aa0: 2020 2020 2020 5b22 3173 7562 3122 2c20        ["1sub1", 
+00009ab0: 2231 7375 6233 225d 2c0a 2020 2020 2020  "1sub3"],.      
+00009ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009ad0: 2020 2020 2020 2020 2020 2020 2020 5b22                ["
+00009ae0: 3173 7562 3173 7562 3122 2c20 2231 7375  1sub1sub1", "1su
+00009af0: 6231 7375 6232 222c 2022 3173 7562 3173  b1sub2", "1sub1s
+00009b00: 7562 3322 5d2c 0a20 2020 2020 2020 2020  ub3"],.         
+00009b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b20: 2020 2020 2020 2020 2020 205b 2231 7375             ["1su
+00009b30: 6233 7375 6231 222c 2022 3173 7562 3373  b3sub1", "1sub3s
+00009b40: 7562 3222 2c20 2231 7375 6233 7375 6233  ub2", "1sub3sub3
+00009b50: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00009b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009b70: 2020 2020 2020 2020 5b22 3273 7562 3122          ["2sub1"
+00009b80: 5d2c 205b 2232 7375 6231 7375 6231 222c  ], ["2sub1sub1",
+00009b90: 2022 3273 7562 3173 7562 3222 5d2c 0a20   "2sub1sub2"],. 
+00009ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00009bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009bc0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00009bd0: 7375 6232 5f66 696c 652e 7478 7422 2c0a  sub2_file.txt",.
-00009be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009bf0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00009c00: 2d69 6e63 6c75 6465 222c 2075 2254 6573  -include", u"Tes
-00009c10: 7446 696c 6573 2f73 656c 6563 7432 2f33  tFiles/select2/3
-00009c20: 2f33 7375 6233 2f33 7375 6233 7375 6232  /3sub3/3sub3sub2
-00009c30: 2f33 7375 6233 7375 6232 5f66 696c 652e  /3sub3sub2_file.
-00009c40: 7478 7422 2c0a 2020 2020 2020 2020 2020  txt",.          
-00009c50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009c60: 2020 2075 222d 2d66 696c 7465 722d 676c     u"--filter-gl
-00009c70: 6f62 6269 6e67 222c 0a20 2020 2020 2020  obbing",.       
-00009c80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009c90: 2020 2020 2020 7522 2d2d 6669 6c74 6572        u"--filter
-00009ca0: 2d73 7472 6963 7463 6173 6522 2c0a 2020  -strictcase",.  
-00009cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009cc0: 2020 2020 2020 2020 2020 2075 222d 2d65             u"--e
-00009cd0: 7863 6c75 6465 222c 2075 2274 6573 7466  xclude", u"testf
-00009ce0: 696c 6573 2f73 656c 6563 7432 2f2a 225d  iles/select2/*"]
-00009cf0: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
-00009d00: 6573 746f 7265 2829 0a20 2020 2020 2020  estore().       
-00009d10: 2072 6573 746f 7265 5f64 6972 203d 2075   restore_dir = u
-00009d20: 2274 6573 7466 696c 6573 2f72 6573 746f  "testfiles/resto
-00009d30: 7265 5f6f 7574 220a 2020 2020 2020 2020  re_out".        
-00009d40: 7265 7374 6f72 6564 203d 2073 656c 662e  restored = self.
-00009d50: 6469 7265 6374 6f72 795f 7472 6565 5f74  directory_tree_t
-00009d60: 6f5f 6c69 7374 5f6f 665f 6c69 7374 7328  o_list_of_lists(
-00009d70: 7265 7374 6f72 655f 6469 7229 0a20 2020  restore_dir).   
-00009d80: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
-00009d90: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
-00009da0: 5b5b 7522 3122 2c20 7522 3222 2c20 7522  [[u"1", u"2", u"
-00009db0: 3322 2c20 7522 7472 6169 6c69 6e67 5f73  3", u"trailing_s
-00009dc0: 7061 6365 2022 2c20 7522 312e 646f 6322  pace ", u"1.doc"
-00009dd0: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00009de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009df0: 2020 2020 2020 205b 7522 3173 7562 3122         [u"1sub1"
-00009e00: 2c20 7522 3173 7562 3322 5d2c 0a20 2020  , u"1sub3"],.   
-00009e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009e30: 205b 7522 3173 7562 3173 7562 3122 2c20   [u"1sub1sub1", 
-00009e40: 7522 3173 7562 3173 7562 3222 2c20 7522  u"1sub1sub2", u"
-00009e50: 3173 7562 3173 7562 3322 5d2c 0a20 2020  1sub1sub3"],.   
-00009e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009bc0: 2020 205b 2233 7375 6233 225d 2c20 5b22     ["3sub3"], ["
+00009bd0: 3373 7562 3373 7562 3222 5d2c 205b 2233  3sub3sub2"], ["3
+00009be0: 7375 6233 7375 6232 5f66 696c 652e 7478  sub3sub2_file.tx
+00009bf0: 7422 5d2c 0a20 2020 2020 2020 2020 2020  t"],.           
+00009c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009c10: 2020 2020 2020 2020 205b 2274 7261 696c           ["trail
+00009c20: 696e 675f 7370 6163 6520 7375 6232 225d  ing_space sub2"]
+00009c30: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00009c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009c50: 2020 2020 2020 5b22 7472 6169 6c69 6e67        ["trailing
+00009c60: 5f73 7061 6365 2073 7562 325f 6669 6c65  _space sub2_file
+00009c70: 2e74 7874 225d 5d29 0a0a 2020 2020 6465  .txt"]])..    de
+00009c80: 6620 7465 7374 5f6c 6974 6572 616c 5f73  f test_literal_s
+00009c90: 7065 6369 616c 5f66 696c 6573 2873 656c  pecial_files(sel
+00009ca0: 6629 3a0a 2020 2020 2020 2020 2222 2220  f):.        """ 
+00009cb0: 4e6f 2072 6561 736f 6e20 7468 6973 2073  No reason this s
+00009cc0: 686f 756c 646e 2774 2077 6f72 6b20 6173  houldn't work as
+00009cd0: 2074 6865 2064 6966 6665 7265 6e63 6573   the differences
+00009ce0: 2069 6e20 6669 6c65 2073 656c 6563 7469   in file selecti
+00009cf0: 6f6e 0a20 2020 2020 2020 2063 6f64 6520  on.        code 
+00009d00: 666f 7220 6c69 7465 7261 6c2d 7673 2d72  for literal-vs-r
+00009d10: 6567 6578 2d76 732d 676c 6f62 7320 6973  egex-vs-globs is
+00009d20: 2064 6561 6c69 6e67 206f 6e6c 7920 7769   dealing only wi
+00009d30: 7468 2073 7472 696e 6773 2e20 7468 6973  th strings. this
+00009d40: 2069 730a 2020 2020 2020 2020 696e 636c   is.        incl
+00009d50: 7564 6564 2066 6f72 2063 6f6d 706c 6574  uded for complet
+00009d60: 656e 6573 7320 616e 6420 6167 6169 6e73  eness and agains
+00009d70: 7420 7468 6520 7265 6d6f 7465 2066 7574  t the remote fut
+00009d80: 7572 6520 706f 7373 6962 696c 6974 7920  ure possibility 
+00009d90: 7468 6174 0a20 2020 2020 2020 2074 686f  that.        tho
+00009da0: 7365 2064 6966 6665 7265 6e74 2066 696c  se different fil
+00009db0: 7465 7220 696d 706c 656d 656e 7461 7469  ter implementati
+00009dc0: 6f6e 7320 6f6e 6520 6461 7920 746f 7563  ons one day touc
+00009dd0: 6820 6669 6c65 7379 7374 656d 206d 6574  h filesystem met
+00009de0: 6120 6461 7461 0a20 2020 2020 2020 2061  a data.        a
+00009df0: 6e64 2070 6963 6b20 7570 2069 6e74 6572  nd pick up inter
+00009e00: 6163 7469 6f6e 7320 7769 7468 2073 7065  actions with spe
+00009e10: 6369 616c 2066 696c 6520 7479 7065 7320  cial file types 
+00009e20: 6f72 2061 7474 7269 6275 7465 732e 2e2e  or attributes...
+00009e30: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
+00009e40: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
+00009e50: 2822 6675 6c6c 222c 2022 7465 7374 6669  ("full", "testfi
+00009e60: 6c65 732f 6469 7231 2f22 2c0a 2020 2020  les/dir1/",.    
 00009e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009e80: 205b 7522 3173 7562 3373 7562 3122 2c20   [u"1sub3sub1", 
-00009e90: 7522 3173 7562 3373 7562 3222 2c20 7522  u"1sub3sub2", u"
-00009ea0: 3173 7562 3373 7562 3322 5d2c 0a20 2020  1sub3sub3"],.   
-00009eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009ed0: 205b 7522 3273 7562 3122 5d2c 205b 7522   [u"2sub1"], [u"
-00009ee0: 3273 7562 3173 7562 3122 2c20 7522 3273  2sub1sub1", u"2s
-00009ef0: 7562 3173 7562 3222 5d2c 0a20 2020 2020  ub1sub2"],.     
-00009f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009f10: 2020 2020 2020 2020 2020 2020 2020 205b                 [
-00009f20: 7522 3373 7562 3322 5d2c 205b 7522 3373  u"3sub3"], [u"3s
-00009f30: 7562 3373 7562 3222 5d2c 205b 7522 3373  ub3sub2"], [u"3s
-00009f40: 7562 3373 7562 325f 6669 6c65 2e74 7874  ub3sub2_file.txt
-00009f50: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
-00009f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009f70: 2020 2020 2020 2020 5b75 2274 7261 696c          [u"trail
-00009f80: 696e 675f 7370 6163 6520 7375 6232 225d  ing_space sub2"]
-00009f90: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00009fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009fb0: 2020 2020 2020 5b75 2274 7261 696c 696e        [u"trailin
-00009fc0: 675f 7370 6163 6520 7375 6232 5f66 696c  g_space sub2_fil
-00009fd0: 652e 7478 7422 5d5d 290a 0a20 2020 2064  e.txt"]])..    d
-00009fe0: 6566 2074 6573 745f 6c69 7465 7261 6c5f  ef test_literal_
-00009ff0: 7370 6563 6961 6c5f 6669 6c65 7328 7365  special_files(se
-0000a000: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-0000a010: 2220 4e6f 2072 6561 736f 6e20 7468 6973  " No reason this
-0000a020: 2073 686f 756c 646e 2774 2077 6f72 6b20   shouldn't work 
-0000a030: 6173 2074 6865 2064 6966 6665 7265 6e63  as the differenc
-0000a040: 6573 2069 6e20 6669 6c65 2073 656c 6563  es in file selec
-0000a050: 7469 6f6e 0a20 2020 2020 2020 2063 6f64  tion.        cod
-0000a060: 6520 666f 7220 6c69 7465 7261 6c2d 7673  e for literal-vs
-0000a070: 2d72 6567 6578 2d76 732d 676c 6f62 7320  -regex-vs-globs 
-0000a080: 6973 2064 6561 6c69 6e67 206f 6e6c 7920  is dealing only 
-0000a090: 7769 7468 2073 7472 696e 6773 2e20 7468  with strings. th
-0000a0a0: 6973 2069 730a 2020 2020 2020 2020 696e  is is.        in
-0000a0b0: 636c 7564 6564 2066 6f72 2063 6f6d 706c  cluded for compl
-0000a0c0: 6574 656e 6573 7320 616e 6420 6167 6169  eteness and agai
-0000a0d0: 6e73 7420 7468 6520 7265 6d6f 7465 2066  nst the remote f
-0000a0e0: 7574 7572 6520 706f 7373 6962 696c 6974  uture possibilit
-0000a0f0: 7920 7468 6174 0a20 2020 2020 2020 2074  y that.        t
-0000a100: 686f 7365 2064 6966 6665 7265 6e74 2066  hose different f
-0000a110: 696c 7465 7220 696d 706c 656d 656e 7461  ilter implementa
-0000a120: 7469 6f6e 7320 6f6e 6520 6461 7920 746f  tions one day to
-0000a130: 7563 6820 6669 6c65 7379 7374 656d 206d  uch filesystem m
-0000a140: 6574 6120 6461 7461 0a20 2020 2020 2020  eta data.       
-0000a150: 2061 6e64 2070 6963 6b20 7570 2069 6e74   and pick up int
-0000a160: 6572 6163 7469 6f6e 7320 7769 7468 2073  eractions with s
-0000a170: 7065 6369 616c 2066 696c 6520 7479 7065  pecial file type
-0000a180: 7320 6f72 2061 7474 7269 6275 7465 732e  s or attributes.
-0000a190: 2e2e 0a20 2020 2020 2020 2022 2222 0a20  ...        """. 
-0000a1a0: 2020 2020 2020 2073 656c 662e 6261 636b         self.back
-0000a1b0: 7570 2875 2266 756c 6c22 2c20 7522 7465  up(u"full", u"te
-0000a1c0: 7374 6669 6c65 732f 6469 7231 2f22 2c0a  stfiles/dir1/",.
-0000a1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a1e0: 2020 2020 6f70 7469 6f6e 733d 5b75 222d      options=[u"-
-0000a1f0: 2d66 696c 7465 722d 6c69 7465 7261 6c22  -filter-literal"
-0000a200: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000a210: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000a220: 222d 2d69 6e63 6c75 6465 222c 2075 2274  "--include", u"t
-0000a230: 6573 7466 696c 6573 2f64 6972 312f 6669  estfiles/dir1/fi
-0000a240: 666f 222c 0a20 2020 2020 2020 2020 2020  fo",.           
-0000a250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a260: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-0000a270: 7522 7465 7374 6669 6c65 732f 6469 7231  u"testfiles/dir1
-0000a280: 2f73 796d 626f 6c69 635f 6c69 6e6b 222c  /symbolic_link",
-0000a290: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a2a0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000a2b0: 2d2d 696e 636c 7564 6522 2c20 7522 7465  --include", u"te
-0000a2c0: 7374 6669 6c65 732f 6469 7231 2f6c 6172  stfiles/dir1/lar
-0000a2d0: 6765 6669 6c65 222c 0a20 2020 2020 2020  gefile",.       
-0000a2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a2f0: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-0000a300: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-0000a310: 6469 7231 225d 290a 2020 2020 2020 2020  dir1"]).        
-0000a320: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
-0000a330: 2020 2020 2020 2072 6573 746f 7265 5f64         restore_d
-0000a340: 6972 203d 2075 2274 6573 7466 696c 6573  ir = u"testfiles
-0000a350: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
-0000a360: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
-0000a370: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
-0000a380: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
-0000a390: 6c69 7374 7328 7265 7374 6f72 655f 6469  lists(restore_di
-0000a3a0: 7229 0a20 2020 2020 2020 2073 656c 662e  r).        self.
-0000a3b0: 6173 7365 7274 4571 7561 6c28 7265 7374  assertEqual(rest
-0000a3c0: 6f72 6564 2c20 5b5b 7522 6669 666f 222c  ored, [[u"fifo",
-0000a3d0: 2075 226c 6172 6765 6669 6c65 222c 2075   u"largefile", u
-0000a3e0: 2273 796d 626f 6c69 635f 6c69 6e6b 225d  "symbolic_link"]
-0000a3f0: 5d29 0a0a 0a63 6c61 7373 2054 6573 7449  ])...class TestI
-0000a400: 6e63 6c75 6465 5370 6563 6961 6c47 6c6f  ncludeSpecialGlo
-0000a410: 6243 6861 7273 2849 6e63 6c75 6465 4578  bChars(IncludeEx
-0000a420: 636c 7564 6546 756e 6374 696f 6e61 6c54  cludeFunctionalT
-0000a430: 6573 7429 3a0a 2020 2020 7522 2222 0a20  est):.    u""". 
-0000a440: 2020 2055 7365 206f 6620 6c69 7465 7261     Use of litera
-0000a450: 6c20 7365 6c65 6374 696f 6e20 6675 6e63  l selection func
-0000a460: 7469 6f6e 7320 746f 206d 6174 6368 2073  tions to match s
-0000a470: 6865 6c6c 2067 6c6f 6262 696e 6720 6368  hell globbing ch
-0000a480: 6172 6163 7465 7273 0a20 2020 2022 2222  aracters.    """
-0000a490: 0a0a 2020 2020 6465 6620 7465 7374 5f6c  ..    def test_l
-0000a4a0: 6974 6572 616c 5f73 7065 6369 616c 5f73  iteral_special_s
-0000a4b0: 6865 6c6c 5f63 6861 7273 2873 656c 6629  hell_chars(self)
-0000a4c0: 3a0a 2020 2020 2020 2020 7522 2222 2053  :.        u""" S
-0000a4d0: 656c 6563 7469 6e67 2066 696c 6573 2075  electing files u
-0000a4e0: 7369 6e67 206c 6974 6572 616c 2073 656c  sing literal sel
-0000a4f0: 6563 7469 6f6e 2066 756e 6374 696f 6e73  ection functions
-0000a500: 2077 6869 6368 2077 6f75 6c64 2068 6176   which would hav
-0000a510: 650a 2020 2020 2020 2020 6469 6666 6572  e.        differ
-0000a520: 656e 7420 696e 7465 7261 6374 696f 6e73  ent interactions
-0000a530: 2069 6620 696e 7465 7270 7265 7465 6420   if interpreted 
-0000a540: 6173 2073 6865 6c6c 2067 6c6f 6273 2c20  as shell globs, 
-0000a550: 652e 672e 2027 5b30 315d 2720 7768 6963  e.g. '[01]' whic
-0000a560: 680a 2020 2020 2020 2020 7769 6c6c 206e  h.        will n
-0000a570: 6f74 206d 6174 6368 2074 6865 2073 616d  ot match the sam
-0000a580: 6520 6173 2061 2067 6c6f 622c 206f 7220  e as a glob, or 
-0000a590: 303f 3120 7768 6963 6820 776f 756c 6420  0?1 which would 
-0000a5a0: 616c 736f 206d 6174 6368 2030 2a31 2069  also match 0*1 i
-0000a5b0: 6e0a 2020 2020 2020 2020 7468 6520 7361  n.        the sa
-0000a5c0: 6d65 2066 6f6c 6465 7220 2877 6865 7265  me folder (where
-0000a5d0: 203f 2061 6e64 202a 2061 7070 6561 7220   ? and * appear 
-0000a5e0: 6c69 7465 7261 6c6c 7920 696e 2074 6865  literally in the
-0000a5f0: 2066 696c 656e 616d 6573 292e 0a20 2020   filenames)..   
-0000a600: 2020 2020 2022 2222 0a20 2020 2020 2020       """.       
-0000a610: 2073 656c 662e 6261 636b 7570 2875 2266   self.backup(u"f
-0000a620: 756c 6c22 2c20 7522 7465 7374 6669 6c65  ull", u"testfile
-0000a630: 732f 7368 656c 6c5f 676c 6f62 5f63 6861  s/shell_glob_cha
-0000a640: 7273 222c 0a20 2020 2020 2020 2020 2020  rs",.           
-0000a650: 2020 2020 2020 2020 206f 7074 696f 6e73           options
-0000a660: 3d5b 7522 2d2d 6669 6c74 6572 2d6c 6974  =[u"--filter-lit
-0000a670: 6572 616c 222c 0a20 2020 2020 2020 2020  eral",.         
-0000a680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a690: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-0000a6a0: 2c20 7522 7465 7374 6669 6c65 732f 7368  , u"testfiles/sh
-0000a6b0: 656c 6c5f 676c 6f62 5f63 6861 7273 2f30  ell_glob_chars/0
-0000a6c0: 3f31 2f31 3f31 2f30 3f31 7375 6231 3f31  ?1/1?1/0?1sub1?1
-0000a6d0: 5f66 696c 652e 7478 7422 2c0a 2020 2020  _file.txt",.    
-0000a6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a6f0: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-0000a700: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-0000a710: 6573 2f73 6865 6c6c 5f67 6c6f 625f 6368  es/shell_glob_ch
-0000a720: 6172 732f 303f 3122 2c0a 2020 2020 2020  ars/0?1",.      
-0000a730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a740: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-0000a750: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-0000a760: 2f73 6865 6c6c 5f67 6c6f 625f 6368 6172  /shell_glob_char
-0000a770: 732f 302a 312f 322a 322f 302a 3173 7562  s/0*1/2*2/0*1sub
-0000a780: 322a 325f 6669 6c65 2e74 7874 222c 0a20  2*2_file.txt",. 
-0000a790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a7a0: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-0000a7b0: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-0000a7c0: 6669 6c65 732f 7368 656c 6c5f 676c 6f62  files/shell_glob
-0000a7d0: 5f63 6861 7273 2f5b 3031 5d2f 333f 332f  _chars/[01]/3?3/
-0000a7e0: 5b30 315d 7375 6233 3f33 5f66 696c 652e  [01]sub3?3_file.
-0000a7f0: 7478 7422 5d29 0a20 2020 2020 2020 2073  txt"]).        s
-0000a800: 656c 662e 7265 7374 6f72 6528 290a 2020  elf.restore().  
-0000a810: 2020 2020 2020 7265 7374 6f72 655f 6469        restore_di
-0000a820: 7220 3d20 7522 7465 7374 6669 6c65 732f  r = u"testfiles/
-0000a830: 7265 7374 6f72 655f 6f75 7422 0a20 2020  restore_out".   
-0000a840: 2020 2020 2072 6573 746f 7265 6420 3d20       restored = 
-0000a850: 7365 6c66 2e64 6972 6563 746f 7279 5f74  self.directory_t
-0000a860: 7265 655f 746f 5f6c 6973 745f 6f66 5f6c  ree_to_list_of_l
-0000a870: 6973 7473 2872 6573 746f 7265 5f64 6972  ists(restore_dir
-0000a880: 290a 2020 2020 2020 2020 7365 6c66 2e61  ).        self.a
-0000a890: 7373 6572 7445 7175 616c 2872 6573 746f  ssertEqual(resto
-0000a8a0: 7265 642c 205b 5b75 2230 2a31 222c 2075  red, [[u"0*1", u
-0000a8b0: 2230 3f31 222c 2075 225b 3031 5d22 5d2c  "0?1", u"[01]"],
-0000a8c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000a8d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a8e0: 2020 2020 205b 7522 322a 3222 2c20 7522       [u"2*2", u"
-0000a8f0: 323f 3222 2c20 7522 5b30 325d 225d 2c20  2?2", u"[02]"], 
-0000a900: 5b75 2230 2a31 7375 6232 3f32 5f66 696c  [u"0*1sub2?2_fil
-0000a910: 652e 7478 7422 5d2c 205b 7522 302a 3173  e.txt"], [u"0*1s
-0000a920: 7562 5b30 325d 5f66 696c 652e 7478 7422  ub[02]_file.txt"
-0000a930: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+00009e80: 6f70 7469 6f6e 733d 5b22 2d2d 6669 6c74  options=["--filt
+00009e90: 6572 2d6c 6974 6572 616c 222c 0a20 2020  er-literal",.   
+00009ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009eb0: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+00009ec0: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00009ed0: 732f 6469 7231 2f66 6966 6f22 2c0a 2020  s/dir1/fifo",.  
+00009ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009ef0: 2020 2020 2020 2020 2020 2022 2d2d 696e             "--in
+00009f00: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00009f10: 6573 2f64 6972 312f 7379 6d62 6f6c 6963  es/dir1/symbolic
+00009f20: 5f6c 696e 6b22 2c0a 2020 2020 2020 2020  _link",.        
+00009f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f40: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+00009f50: 2c20 2274 6573 7466 696c 6573 2f64 6972  , "testfiles/dir
+00009f60: 312f 6c61 7267 6566 696c 6522 2c0a 2020  1/largefile",.  
+00009f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009f80: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00009f90: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00009fa0: 6573 2f64 6972 3122 5d29 0a20 2020 2020  es/dir1"]).     
+00009fb0: 2020 2073 656c 662e 7265 7374 6f72 6528     self.restore(
+00009fc0: 290a 2020 2020 2020 2020 7265 7374 6f72  ).        restor
+00009fd0: 655f 7061 7468 203d 2022 7465 7374 6669  e_path = "testfi
+00009fe0: 6c65 732f 7265 7374 6f72 655f 6f75 7422  les/restore_out"
+00009ff0: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+0000a000: 6420 3d20 7365 6c66 2e64 6972 6563 746f  d = self.directo
+0000a010: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
+0000a020: 6f66 5f6c 6973 7473 2872 6573 746f 7265  of_lists(restore
+0000a030: 5f70 6174 6829 0a20 2020 2020 2020 2073  _path).        s
+0000a040: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
+0000a050: 7265 7374 6f72 6564 2c20 5b5b 2266 6966  restored, [["fif
+0000a060: 6f22 2c20 226c 6172 6765 6669 6c65 222c  o", "largefile",
+0000a070: 2022 7379 6d62 6f6c 6963 5f6c 696e 6b22   "symbolic_link"
+0000a080: 5d5d 290a 0a0a 636c 6173 7320 5465 7374  ]])...class Test
+0000a090: 496e 636c 7564 6553 7065 6369 616c 476c  IncludeSpecialGl
+0000a0a0: 6f62 4368 6172 7328 496e 636c 7564 6545  obChars(IncludeE
+0000a0b0: 7863 6c75 6465 4675 6e63 7469 6f6e 616c  xcludeFunctional
+0000a0c0: 5465 7374 293a 0a20 2020 2022 2222 0a20  Test):.    """. 
+0000a0d0: 2020 2055 7365 206f 6620 6c69 7465 7261     Use of litera
+0000a0e0: 6c20 7365 6c65 6374 696f 6e20 6675 6e63  l selection func
+0000a0f0: 7469 6f6e 7320 746f 206d 6174 6368 2073  tions to match s
+0000a100: 6865 6c6c 2067 6c6f 6262 696e 6720 6368  hell globbing ch
+0000a110: 6172 6163 7465 7273 0a20 2020 2022 2222  aracters.    """
+0000a120: 0a0a 2020 2020 6465 6620 7465 7374 5f6c  ..    def test_l
+0000a130: 6974 6572 616c 5f73 7065 6369 616c 5f73  iteral_special_s
+0000a140: 6865 6c6c 5f63 6861 7273 2873 656c 6629  hell_chars(self)
+0000a150: 3a0a 2020 2020 2020 2020 2222 2220 5365  :.        """ Se
+0000a160: 6c65 6374 696e 6720 6669 6c65 7320 7573  lecting files us
+0000a170: 696e 6720 6c69 7465 7261 6c20 7365 6c65  ing literal sele
+0000a180: 6374 696f 6e20 6675 6e63 7469 6f6e 7320  ction functions 
+0000a190: 7768 6963 6820 776f 756c 6420 6861 7665  which would have
+0000a1a0: 0a20 2020 2020 2020 2064 6966 6665 7265  .        differe
+0000a1b0: 6e74 2069 6e74 6572 6163 7469 6f6e 7320  nt interactions 
+0000a1c0: 6966 2069 6e74 6572 7072 6574 6564 2061  if interpreted a
+0000a1d0: 7320 7368 656c 6c20 676c 6f62 732c 2065  s shell globs, e
+0000a1e0: 2e67 2e20 275b 3031 5d27 2077 6869 6368  .g. '[01]' which
+0000a1f0: 0a20 2020 2020 2020 2077 696c 6c20 6e6f  .        will no
+0000a200: 7420 6d61 7463 6820 7468 6520 7361 6d65  t match the same
+0000a210: 2061 7320 6120 676c 6f62 2c20 6f72 2030   as a glob, or 0
+0000a220: 3f31 2077 6869 6368 2077 6f75 6c64 2061  ?1 which would a
+0000a230: 6c73 6f20 6d61 7463 6820 302a 3120 696e  lso match 0*1 in
+0000a240: 0a20 2020 2020 2020 2074 6865 2073 616d  .        the sam
+0000a250: 6520 666f 6c64 6572 2028 7768 6572 6520  e folder (where 
+0000a260: 3f20 616e 6420 2a20 6170 7065 6172 206c  ? and * appear l
+0000a270: 6974 6572 616c 6c79 2069 6e20 7468 6520  iterally in the 
+0000a280: 6669 6c65 6e61 6d65 7329 2e0a 2020 2020  filenames)..    
+0000a290: 2020 2020 2222 220a 2020 2020 2020 2020      """.        
+0000a2a0: 7365 6c66 2e62 6163 6b75 7028 2266 756c  self.backup("ful
+0000a2b0: 6c22 2c20 2274 6573 7466 696c 6573 2f73  l", "testfiles/s
+0000a2c0: 6865 6c6c 5f67 6c6f 625f 6368 6172 7322  hell_glob_chars"
+0000a2d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a2e0: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+0000a2f0: 2d2d 6669 6c74 6572 2d6c 6974 6572 616c  --filter-literal
+0000a300: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+0000a310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a320: 222d 2d69 6e63 6c75 6465 222c 2022 7465  "--include", "te
+0000a330: 7374 6669 6c65 732f 7368 656c 6c5f 676c  stfiles/shell_gl
+0000a340: 6f62 5f63 6861 7273 2f30 3f31 2f31 3f31  ob_chars/0?1/1?1
+0000a350: 2f30 3f31 7375 6231 3f31 5f66 696c 652e  /0?1sub1?1_file.
+0000a360: 7478 7422 2c0a 2020 2020 2020 2020 2020  txt",.          
+0000a370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a380: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+0000a390: 2274 6573 7466 696c 6573 2f73 6865 6c6c  "testfiles/shell
+0000a3a0: 5f67 6c6f 625f 6368 6172 732f 303f 3122  _glob_chars/0?1"
+0000a3b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a3c0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000a3d0: 2d2d 6578 636c 7564 6522 2c20 2274 6573  --exclude", "tes
+0000a3e0: 7466 696c 6573 2f73 6865 6c6c 5f67 6c6f  tfiles/shell_glo
+0000a3f0: 625f 6368 6172 732f 302a 312f 322a 322f  b_chars/0*1/2*2/
+0000a400: 302a 3173 7562 322a 325f 6669 6c65 2e74  0*1sub2*2_file.t
+0000a410: 7874 222c 0a20 2020 2020 2020 2020 2020  xt",.           
+0000a420: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a430: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+0000a440: 7465 7374 6669 6c65 732f 7368 656c 6c5f  testfiles/shell_
+0000a450: 676c 6f62 5f63 6861 7273 2f5b 3031 5d2f  glob_chars/[01]/
+0000a460: 333f 332f 5b30 315d 7375 6233 3f33 5f66  3?3/[01]sub3?3_f
+0000a470: 696c 652e 7478 7422 5d29 0a20 2020 2020  ile.txt"]).     
+0000a480: 2020 2073 656c 662e 7265 7374 6f72 6528     self.restore(
+0000a490: 290a 2020 2020 2020 2020 7265 7374 6f72  ).        restor
+0000a4a0: 655f 7061 7468 203d 2022 7465 7374 6669  e_path = "testfi
+0000a4b0: 6c65 732f 7265 7374 6f72 655f 6f75 7422  les/restore_out"
+0000a4c0: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+0000a4d0: 6420 3d20 7365 6c66 2e64 6972 6563 746f  d = self.directo
+0000a4e0: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
+0000a4f0: 6f66 5f6c 6973 7473 2872 6573 746f 7265  of_lists(restore
+0000a500: 5f70 6174 6829 0a20 2020 2020 2020 2073  _path).        s
+0000a510: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
+0000a520: 7265 7374 6f72 6564 2c20 5b5b 2230 2a31  restored, [["0*1
+0000a530: 222c 2022 303f 3122 2c20 225b 3031 5d22  ", "0?1", "[01]"
+0000a540: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0000a550: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a560: 2020 2020 2020 205b 2232 2a32 222c 2022         ["2*2", "
+0000a570: 323f 3222 2c20 225b 3032 5d22 5d2c 205b  2?2", "[02]"], [
+0000a580: 2230 2a31 7375 6232 3f32 5f66 696c 652e  "0*1sub2?2_file.
+0000a590: 7478 7422 5d2c 205b 2230 2a31 7375 625b  txt"], ["0*1sub[
+0000a5a0: 3032 5d5f 6669 6c65 2e74 7874 225d 2c0a  02]_file.txt"],.
+0000a5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a5d0: 2020 2020 5b22 313f 3122 5d2c 205b 2230      ["1?1"], ["0
+0000a5e0: 3f31 7375 6231 3f31 5f66 696c 652e 7478  ?1sub1?1_file.tx
+0000a5f0: 7422 5d2c 0a20 2020 2020 2020 2020 2020  t"],.           
+0000a600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a610: 2020 2020 2020 2020 205b 2233 2a33 222c           ["3*3",
+0000a620: 2022 333f 3322 2c20 225b 3033 5d22 5d2c   "3?3", "[03]"],
+0000a630: 205b 225b 3031 5d73 7562 332a 335f 6669   ["[01]sub3*3_fi
+0000a640: 6c65 2e74 7874 225d 2c20 5b22 5b30 315d  le.txt"], ["[01]
+0000a650: 7375 625b 3033 5d5f 6669 6c65 2e74 7874  sub[03]_file.txt
+0000a660: 225d 5d29 0a0a 2020 2020 6465 6620 7465  "]])..    def te
+0000a670: 7374 5f67 6c6f 6262 696e 675f 7370 6563  st_globbing_spec
+0000a680: 6961 6c5f 7368 656c 6c5f 6368 6172 7328  ial_shell_chars(
+0000a690: 7365 6c66 293a 0a20 2020 2020 2020 2022  self):.        "
+0000a6a0: 2222 2053 656c 6563 7469 6e67 2066 696c  "" Selecting fil
+0000a6b0: 6573 2075 7369 6e67 2062 6f74 6820 6c69  es using both li
+0000a6c0: 7465 7261 6c20 616e 6420 676c 6f62 6269  teral and globbi
+0000a6d0: 6e67 2073 656c 6563 7469 6f6e 2066 756e  ng selection fun
+0000a6e0: 6374 696f 6e73 0a20 2020 2020 2020 206f  ctions.        o
+0000a6f0: 6e20 6120 6669 6c65 7365 7420 7768 6963  n a fileset whic
+0000a700: 6820 636f 6e74 6169 6e73 206c 6974 6572  h contains liter
+0000a710: 616c 2073 6865 6c6c 2063 6861 7261 6374  al shell charact
+0000a720: 6572 730a 2020 2020 2020 2020 2222 220a  ers.        """.
+0000a730: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
+0000a740: 6b75 7028 2266 756c 6c22 2c20 2274 6573  kup("full", "tes
+0000a750: 7466 696c 6573 2f73 6865 6c6c 5f67 6c6f  tfiles/shell_glo
+0000a760: 625f 6368 6172 7322 2c0a 2020 2020 2020  b_chars",.      
+0000a770: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+0000a780: 7469 6f6e 733d 5b22 2d2d 6669 6c74 6572  tions=["--filter
+0000a790: 2d6c 6974 6572 616c 222c 0a20 2020 2020  -literal",.     
+0000a7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a7b0: 2020 2020 2020 2020 222d 2d69 6e63 6c75          "--inclu
+0000a7c0: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+0000a7d0: 7368 656c 6c5f 676c 6f62 5f63 6861 7273  shell_glob_chars
+0000a7e0: 2f30 2a31 2f32 2a32 2f30 2a31 7375 6232  /0*1/2*2/0*1sub2
+0000a7f0: 2a32 5f66 696c 652e 7478 7422 2c0a 2020  *2_file.txt",.  
+0000a800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a810: 2020 2020 2020 2020 2020 2022 2d2d 6669             "--fi
+0000a820: 6c74 6572 2d67 6c6f 6262 696e 6722 2c0a  lter-globbing",.
+0000a830: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a840: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+0000a850: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+0000a860: 696c 6573 2f73 6865 6c6c 5f67 6c6f 625f  iles/shell_glob_
+0000a870: 6368 6172 732f 302a 3122 5d29 0a20 2020  chars/0*1"]).   
+0000a880: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
+0000a890: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
+0000a8a0: 6f72 655f 7061 7468 203d 2022 7465 7374  ore_path = "test
+0000a8b0: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
+0000a8c0: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
+0000a8d0: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
+0000a8e0: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
+0000a8f0: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
+0000a900: 7265 5f70 6174 6829 0a20 2020 2020 2020  re_path).       
+0000a910: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
+0000a920: 6c28 7265 7374 6f72 6564 2c20 5b5b 2230  l(restored, [["0
+0000a930: 2a31 222c 2022 5b30 315d 225d 2c0a 2020  *1", "[01]"],.  
 0000a940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a950: 2020 2020 2020 205b 7522 313f 3122 5d2c         [u"1?1"],
-0000a960: 205b 7522 303f 3173 7562 313f 315f 6669   [u"0?1sub1?1_fi
-0000a970: 6c65 2e74 7874 225d 2c0a 2020 2020 2020  le.txt"],.      
-0000a980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a990: 2020 2020 2020 2020 2020 2020 2020 5b75                [u
-0000a9a0: 2233 2a33 222c 2075 2233 3f33 222c 2075  "3*3", u"3?3", u
-0000a9b0: 225b 3033 5d22 5d2c 205b 7522 5b30 315d  "[03]"], [u"[01]
-0000a9c0: 7375 6233 2a33 5f66 696c 652e 7478 7422  sub3*3_file.txt"
-0000a9d0: 5d2c 205b 7522 5b30 315d 7375 625b 3033  ], [u"[01]sub[03
-0000a9e0: 5d5f 6669 6c65 2e74 7874 225d 5d29 0a0a  ]_file.txt"]])..
-0000a9f0: 2020 2020 6465 6620 7465 7374 5f67 6c6f      def test_glo
-0000aa00: 6262 696e 675f 7370 6563 6961 6c5f 7368  bbing_special_sh
-0000aa10: 656c 6c5f 6368 6172 7328 7365 6c66 293a  ell_chars(self):
-0000aa20: 0a20 2020 2020 2020 2075 2222 2220 5365  .        u""" Se
-0000aa30: 6c65 6374 696e 6720 6669 6c65 7320 7573  lecting files us
-0000aa40: 696e 6720 626f 7468 206c 6974 6572 616c  ing both literal
-0000aa50: 2061 6e64 2067 6c6f 6262 696e 6720 7365   and globbing se
-0000aa60: 6c65 6374 696f 6e20 6675 6e63 7469 6f6e  lection function
-0000aa70: 730a 2020 2020 2020 2020 6f6e 2061 2066  s.        on a f
-0000aa80: 696c 6573 6574 2077 6869 6368 2063 6f6e  ileset which con
-0000aa90: 7461 696e 7320 6c69 7465 7261 6c20 7368  tains literal sh
-0000aaa0: 656c 6c20 6368 6172 6163 7465 7273 0a20  ell characters. 
-0000aab0: 2020 2020 2020 2022 2222 0a20 2020 2020         """.     
-0000aac0: 2020 2073 656c 662e 6261 636b 7570 2875     self.backup(u
-0000aad0: 2266 756c 6c22 2c20 7522 7465 7374 6669  "full", u"testfi
-0000aae0: 6c65 732f 7368 656c 6c5f 676c 6f62 5f63  les/shell_glob_c
-0000aaf0: 6861 7273 222c 0a20 2020 2020 2020 2020  hars",.         
-0000ab00: 2020 2020 2020 2020 2020 206f 7074 696f             optio
-0000ab10: 6e73 3d5b 7522 2d2d 6669 6c74 6572 2d6c  ns=[u"--filter-l
-0000ab20: 6974 6572 616c 222c 0a20 2020 2020 2020  iteral",.       
-0000ab30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ab40: 2020 2020 2020 7522 2d2d 696e 636c 7564        u"--includ
-0000ab50: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-0000ab60: 7368 656c 6c5f 676c 6f62 5f63 6861 7273  shell_glob_chars
-0000ab70: 2f30 2a31 2f32 2a32 2f30 2a31 7375 6232  /0*1/2*2/0*1sub2
-0000ab80: 2a32 5f66 696c 652e 7478 7422 2c0a 2020  *2_file.txt",.  
-0000ab90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000aba0: 2020 2020 2020 2020 2020 2075 222d 2d66             u"--f
-0000abb0: 696c 7465 722d 676c 6f62 6269 6e67 222c  ilter-globbing",
-0000abc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000abd0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000abe0: 2d2d 6578 636c 7564 6522 2c20 7522 7465  --exclude", u"te
-0000abf0: 7374 6669 6c65 732f 7368 656c 6c5f 676c  stfiles/shell_gl
-0000ac00: 6f62 5f63 6861 7273 2f30 2a31 225d 290a  ob_chars/0*1"]).
-0000ac10: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-0000ac20: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
-0000ac30: 6573 746f 7265 5f64 6972 203d 2075 2274  estore_dir = u"t
-0000ac40: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
-0000ac50: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
-0000ac60: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
-0000ac70: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
-0000ac80: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
-0000ac90: 7374 6f72 655f 6469 7229 0a20 2020 2020  store_dir).     
-0000aca0: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
-0000acb0: 7561 6c28 7265 7374 6f72 6564 2c20 5b5b  ual(restored, [[
-0000acc0: 7522 302a 3122 2c20 7522 5b30 315d 225d  u"0*1", u"[01]"]
-0000acd0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000ace0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000acf0: 2020 2020 2020 5b75 2232 2a32 225d 2c20        [u"2*2"], 
-0000ad00: 5b75 2230 2a31 7375 6232 2a32 5f66 696c  [u"0*1sub2*2_fil
-0000ad10: 652e 7478 7422 5d2c 0a20 2020 2020 2020  e.txt"],.       
-0000ad20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ad30: 2020 2020 2020 2020 2020 2020 205b 7522               [u"
-0000ad40: 332a 3322 2c20 7522 333f 3322 2c20 7522  3*3", u"3?3", u"
-0000ad50: 5b30 335d 225d 2c20 5b75 225b 3031 5d73  [03]"], [u"[01]s
-0000ad60: 7562 332a 335f 6669 6c65 2e74 7874 225d  ub3*3_file.txt"]
-0000ad70: 2c20 5b75 225b 3031 5d73 7562 333f 335f  , [u"[01]sub3?3_
-0000ad80: 6669 6c65 2e74 7874 225d 2c0a 2020 2020  file.txt"],.    
-0000ad90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ada0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000adb0: 5b75 225b 3031 5d73 7562 5b30 335d 5f66  [u"[01]sub[03]_f
-0000adc0: 696c 652e 7478 7422 5d5d 290a 0a20 2020  ile.txt"]])..   
-0000add0: 2064 6566 2074 6573 745f 6669 6c65 6c69   def test_fileli
-0000ade0: 7374 5f73 7065 6369 616c 5f73 6865 6c6c  st_special_shell
-0000adf0: 5f63 6861 7273 2873 656c 6629 3a0a 2020  _chars(self):.  
-0000ae00: 2020 2020 2020 7522 2222 2054 6869 7320        u""" This 
-0000ae10: 7465 7374 2069 7320 7468 6520 7361 6d65  test is the same
-0000ae20: 2061 7320 7465 7374 5f6c 6974 6572 616c   as test_literal
-0000ae30: 5f73 7065 6369 616c 5f73 6865 6c6c 5f63  _special_shell_c
-0000ae40: 6861 7273 2829 2065 7863 6570 7420 7468  hars() except th
-0000ae50: 6174 0a20 2020 2020 2020 2061 6e20 696e  at.        an in
-0000ae60: 636c 7564 6520 6669 6c65 2d6c 6973 7420  clude file-list 
-0000ae70: 6973 2075 7365 6420 696e 7374 6561 642e  is used instead.
-0000ae80: 0a20 2020 2020 2020 2022 2222 0a20 2020  .        """.   
-0000ae90: 2020 2020 2077 6974 6820 696f 2e6f 7065       with io.ope
-0000aea0: 6e28 7522 7465 7374 6669 6c65 732f 696e  n(u"testfiles/in
-0000aeb0: 636c 7564 652e 7478 7422 2c20 7522 7722  clude.txt", u"w"
-0000aec0: 2920 6173 2066 3a0a 2020 2020 2020 2020  ) as f:.        
-0000aed0: 2020 2020 662e 7772 6974 6528 7522 7465      f.write(u"te
-0000aee0: 7374 6669 6c65 732f 7368 656c 6c5f 676c  stfiles/shell_gl
-0000aef0: 6f62 5f63 6861 7273 2f30 3f31 2f31 3f31  ob_chars/0?1/1?1
-0000af00: 2f30 3f31 7375 6231 3f31 5f66 696c 652e  /0?1sub1?1_file.
-0000af10: 7478 745c 6e22 0a20 2020 2020 2020 2020  txt\n".         
-0000af20: 2020 2020 2020 2020 2020 2075 222d 2074             u"- t
-0000af30: 6573 7466 696c 6573 2f73 6865 6c6c 5f67  estfiles/shell_g
-0000af40: 6c6f 625f 6368 6172 732f 303f 315c 6e22  lob_chars/0?1\n"
-0000af50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000af60: 2020 2020 2075 222d 2074 6573 7466 696c       u"- testfil
-0000af70: 6573 2f73 6865 6c6c 5f67 6c6f 625f 6368  es/shell_glob_ch
-0000af80: 6172 732f 302a 312f 322a 322f 302a 3173  ars/0*1/2*2/0*1s
-0000af90: 7562 322a 325f 6669 6c65 2e74 7874 5c6e  ub2*2_file.txt\n
-0000afa0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000afb0: 2020 2020 2020 7522 2d20 7465 7374 6669        u"- testfi
-0000afc0: 6c65 732f 7368 656c 6c5f 676c 6f62 5f63  les/shell_glob_c
-0000afd0: 6861 7273 2f5b 3031 5d2f 333f 332f 5b30  hars/[01]/3?3/[0
-0000afe0: 315d 7375 6233 3f33 5f66 696c 652e 7478  1]sub3?3_file.tx
-0000aff0: 745c 6e22 290a 0a20 2020 2020 2020 2073  t\n")..        s
-0000b000: 656c 662e 6261 636b 7570 2875 2266 756c  elf.backup(u"ful
-0000b010: 6c22 2c20 7522 7465 7374 6669 6c65 732f  l", u"testfiles/
-0000b020: 7368 656c 6c5f 676c 6f62 5f63 6861 7273  shell_glob_chars
-0000b030: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-0000b040: 2020 2020 2020 206f 7074 696f 6e73 3d5b         options=[
-0000b050: 7522 2d2d 6669 6c74 6572 2d6c 6974 6572  u"--filter-liter
-0000b060: 616c 222c 2075 222d 2d69 6e63 6c75 6465  al", u"--include
-0000b070: 2d66 696c 656c 6973 743d 7465 7374 6669  -filelist=testfi
-0000b080: 6c65 732f 696e 636c 7564 652e 7478 7422  les/include.txt"
-0000b090: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
-0000b0a0: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
-0000b0b0: 2020 7265 7374 6f72 655f 6469 7220 3d20    restore_dir = 
-0000b0c0: 7522 7465 7374 6669 6c65 732f 7265 7374  u"testfiles/rest
-0000b0d0: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
-0000b0e0: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
-0000b0f0: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
-0000b100: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-0000b110: 2872 6573 746f 7265 5f64 6972 290a 2020  (restore_dir).  
-0000b120: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
-0000b130: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
-0000b140: 205b 5b75 2230 2a31 222c 2075 2230 3f31   [[u"0*1", u"0?1
-0000b150: 222c 2075 225b 3031 5d22 5d2c 0a20 2020  ", u"[01]"],.   
-0000b160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b180: 205b 7522 322a 3222 2c20 7522 323f 3222   [u"2*2", u"2?2"
-0000b190: 2c20 7522 5b30 325d 225d 2c20 5b75 2230  , u"[02]"], [u"0
-0000b1a0: 2a31 7375 6232 3f32 5f66 696c 652e 7478  *1sub2?2_file.tx
-0000b1b0: 7422 5d2c 205b 7522 302a 3173 7562 5b30  t"], [u"0*1sub[0
-0000b1c0: 325d 5f66 696c 652e 7478 7422 5d2c 0a20  2]_file.txt"],. 
-0000b1d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b1e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b1f0: 2020 205b 7522 313f 3122 5d2c 205b 7522     [u"1?1"], [u"
-0000b200: 303f 3173 7562 313f 315f 6669 6c65 2e74  0?1sub1?1_file.t
-0000b210: 7874 225d 2c0a 2020 2020 2020 2020 2020  xt"],.          
+0000a950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a960: 2020 5b22 322a 3222 5d2c 205b 2230 2a31    ["2*2"], ["0*1
+0000a970: 7375 6232 2a32 5f66 696c 652e 7478 7422  sub2*2_file.txt"
+0000a980: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
+0000a990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000a9a0: 2020 2020 2020 205b 2233 2a33 222c 2022         ["3*3", "
+0000a9b0: 333f 3322 2c20 225b 3033 5d22 5d2c 205b  3?3", "[03]"], [
+0000a9c0: 225b 3031 5d73 7562 332a 335f 6669 6c65  "[01]sub3*3_file
+0000a9d0: 2e74 7874 225d 2c20 5b22 5b30 315d 7375  .txt"], ["[01]su
+0000a9e0: 6233 3f33 5f66 696c 652e 7478 7422 5d2c  b3?3_file.txt"],
+0000a9f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000aa00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000aa10: 2020 2020 205b 225b 3031 5d73 7562 5b30       ["[01]sub[0
+0000aa20: 335d 5f66 696c 652e 7478 7422 5d5d 290a  3]_file.txt"]]).
+0000aa30: 0a20 2020 2064 6566 2074 6573 745f 6669  .    def test_fi
+0000aa40: 6c65 6c69 7374 5f73 7065 6369 616c 5f73  lelist_special_s
+0000aa50: 6865 6c6c 5f63 6861 7273 2873 656c 6629  hell_chars(self)
+0000aa60: 3a0a 2020 2020 2020 2020 2222 2220 5468  :.        """ Th
+0000aa70: 6973 2074 6573 7420 6973 2074 6865 2073  is test is the s
+0000aa80: 616d 6520 6173 2074 6573 745f 6c69 7465  ame as test_lite
+0000aa90: 7261 6c5f 7370 6563 6961 6c5f 7368 656c  ral_special_shel
+0000aaa0: 6c5f 6368 6172 7328 2920 6578 6365 7074  l_chars() except
+0000aab0: 2074 6861 740a 2020 2020 2020 2020 616e   that.        an
+0000aac0: 2069 6e63 6c75 6465 2066 696c 652d 6c69   include file-li
+0000aad0: 7374 2069 7320 7573 6564 2069 6e73 7465  st is used inste
+0000aae0: 6164 2e0a 2020 2020 2020 2020 2222 220a  ad..        """.
+0000aaf0: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
+0000ab00: 6f70 656e 2822 7465 7374 6669 6c65 732f  open("testfiles/
+0000ab10: 696e 636c 7564 652e 7478 7422 2c20 2277  include.txt", "w
+0000ab20: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
+0000ab30: 2020 2020 2066 2e77 7269 7465 2822 7465       f.write("te
+0000ab40: 7374 6669 6c65 732f 7368 656c 6c5f 676c  stfiles/shell_gl
+0000ab50: 6f62 5f63 6861 7273 2f30 3f31 2f31 3f31  ob_chars/0?1/1?1
+0000ab60: 2f30 3f31 7375 6231 3f31 5f66 696c 652e  /0?1sub1?1_file.
+0000ab70: 7478 745c 6e22 0a20 2020 2020 2020 2020  txt\n".         
+0000ab80: 2020 2020 2020 2020 2020 2022 2d20 7465             "- te
+0000ab90: 7374 6669 6c65 732f 7368 656c 6c5f 676c  stfiles/shell_gl
+0000aba0: 6f62 5f63 6861 7273 2f30 3f31 5c6e 220a  ob_chars/0?1\n".
+0000abb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000abc0: 2020 2020 222d 2074 6573 7466 696c 6573      "- testfiles
+0000abd0: 2f73 6865 6c6c 5f67 6c6f 625f 6368 6172  /shell_glob_char
+0000abe0: 732f 302a 312f 322a 322f 302a 3173 7562  s/0*1/2*2/0*1sub
+0000abf0: 322a 325f 6669 6c65 2e74 7874 5c6e 220a  2*2_file.txt\n".
+0000ac00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ac10: 2020 2020 222d 2074 6573 7466 696c 6573      "- testfiles
+0000ac20: 2f73 6865 6c6c 5f67 6c6f 625f 6368 6172  /shell_glob_char
+0000ac30: 732f 5b30 315d 2f33 3f33 2f5b 3031 5d73  s/[01]/3?3/[01]s
+0000ac40: 7562 333f 335f 6669 6c65 2e74 7874 5c6e  ub3?3_file.txt\n
+0000ac50: 2229 0a0a 2020 2020 2020 2020 7365 6c66  ")..        self
+0000ac60: 2e62 6163 6b75 7028 2266 756c 6c22 2c20  .backup("full", 
+0000ac70: 2274 6573 7466 696c 6573 2f73 6865 6c6c  "testfiles/shell
+0000ac80: 5f67 6c6f 625f 6368 6172 7322 2c0a 2020  _glob_chars",.  
+0000ac90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000aca0: 2020 6f70 7469 6f6e 733d 5b22 2d2d 6669    options=["--fi
+0000acb0: 6c74 6572 2d6c 6974 6572 616c 222c 2022  lter-literal", "
+0000acc0: 2d2d 696e 636c 7564 652d 6669 6c65 6c69  --include-fileli
+0000acd0: 7374 3d74 6573 7466 696c 6573 2f69 6e63  st=testfiles/inc
+0000ace0: 6c75 6465 2e74 7874 225d 290a 2020 2020  lude.txt"]).    
+0000acf0: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
+0000ad00: 2829 0a20 2020 2020 2020 2072 6573 746f  ().        resto
+0000ad10: 7265 5f70 6174 6820 3d20 2274 6573 7466  re_path = "testf
+0000ad20: 696c 6573 2f72 6573 746f 7265 5f6f 7574  iles/restore_out
+0000ad30: 220a 2020 2020 2020 2020 7265 7374 6f72  ".        restor
+0000ad40: 6564 203d 2073 656c 662e 6469 7265 6374  ed = self.direct
+0000ad50: 6f72 795f 7472 6565 5f74 6f5f 6c69 7374  ory_tree_to_list
+0000ad60: 5f6f 665f 6c69 7374 7328 7265 7374 6f72  _of_lists(restor
+0000ad70: 655f 7061 7468 290a 2020 2020 2020 2020  e_path).        
+0000ad80: 7365 6c66 2e61 7373 6572 7445 7175 616c  self.assertEqual
+0000ad90: 2872 6573 746f 7265 642c 205b 5b22 302a  (restored, [["0*
+0000ada0: 3122 2c20 2230 3f31 222c 2022 5b30 315d  1", "0?1", "[01]
+0000adb0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+0000adc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000add0: 2020 2020 2020 2020 5b22 322a 3222 2c20          ["2*2", 
+0000ade0: 2232 3f32 222c 2022 5b30 325d 225d 2c20  "2?2", "[02]"], 
+0000adf0: 5b22 302a 3173 7562 323f 325f 6669 6c65  ["0*1sub2?2_file
+0000ae00: 2e74 7874 225d 2c20 5b22 302a 3173 7562  .txt"], ["0*1sub
+0000ae10: 5b30 325d 5f66 696c 652e 7478 7422 5d2c  [02]_file.txt"],
+0000ae20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ae30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ae40: 2020 2020 205b 2231 3f31 225d 2c20 5b22       ["1?1"], ["
+0000ae50: 303f 3173 7562 313f 315f 6669 6c65 2e74  0?1sub1?1_file.t
+0000ae60: 7874 225d 2c0a 2020 2020 2020 2020 2020  xt"],.          
+0000ae70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ae80: 2020 2020 2020 2020 2020 5b22 332a 3322            ["3*3"
+0000ae90: 2c20 2233 3f33 222c 2022 5b30 335d 225d  , "3?3", "[03]"]
+0000aea0: 2c20 5b22 5b30 315d 7375 6233 2a33 5f66  , ["[01]sub3*3_f
+0000aeb0: 696c 652e 7478 7422 5d2c 205b 225b 3031  ile.txt"], ["[01
+0000aec0: 5d73 7562 5b30 335d 5f66 696c 652e 7478  ]sub[03]_file.tx
+0000aed0: 7422 5d5d 290a 0a0a 636c 6173 7320 5465  t"]])...class Te
+0000aee0: 7374 4578 636c 7564 6546 696c 656c 6973  stExcludeFilelis
+0000aef0: 7454 6573 7428 496e 636c 7564 6545 7863  tTest(IncludeExc
+0000af00: 6c75 6465 4675 6e63 7469 6f6e 616c 5465  ludeFunctionalTe
+0000af10: 7374 293a 0a20 2020 2022 2222 0a20 2020  st):.    """.   
+0000af20: 2054 6573 7420 2d2d 6578 636c 7564 652d   Test --exclude-
+0000af30: 6669 6c65 6c69 7374 2075 7369 6e67 2064  filelist using d
+0000af40: 7570 6c69 6369 7479 2062 696e 6172 792e  uplicity binary.
+0000af50: 0a20 2020 2022 2222 0a0a 2020 2020 6465  .    """..    de
+0000af60: 6620 7465 7374 5f65 7863 6c75 6465 5f66  f test_exclude_f
+0000af70: 696c 656c 6973 7428 7365 6c66 293a 0a20  ilelist(self):. 
+0000af80: 2020 2020 2020 2022 2222 5465 7374 2074         """Test t
+0000af90: 6861 7420 6578 636c 7564 6520 6669 6c65  hat exclude file
+0000afa0: 6c69 7374 2077 6f72 6b73 2069 6e20 7468  list works in th
+0000afb0: 6520 6261 7369 6320 6361 7365 2022 2222  e basic case """
+0000afc0: 0a20 2020 2020 2020 2023 2041 7320 7468  .        # As th
+0000afd0: 6973 2069 7320 616e 2065 7863 6c75 6465  is is an exclude
+0000afe0: 2066 696c 656c 6973 7420 616e 7920 6c69   filelist any li
+0000aff0: 6e65 7320 7769 7468 206e 6f20 2b2f 2d20  nes with no +/- 
+0000b000: 6d6f 6469 6669 6572 2073 686f 756c 6420  modifier should 
+0000b010: 6265 2074 7265 6174 6564 2061 7320 6966  be treated as if
+0000b020: 2074 6865 7920 6861 7665 2061 202d 2e0a   they have a -..
+0000b030: 2020 2020 2020 2020 2320 4372 6561 7465          # Create
+0000b040: 2061 2066 696c 656c 6973 740a 2020 2020   a filelist.    
+0000b050: 2020 2020 7769 7468 2069 6f2e 6f70 656e      with io.open
+0000b060: 2822 7465 7374 6669 6c65 732f 6578 636c  ("testfiles/excl
+0000b070: 7564 652e 7478 7422 2c20 2277 2229 2061  ude.txt", "w") a
+0000b080: 7320 663a 0a20 2020 2020 2020 2020 2020  s f:.           
+0000b090: 2066 2e77 7269 7465 2822 2b20 7465 7374   f.write("+ test
+0000b0a0: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
+0000b0b0: 3373 7562 332f 3373 7562 3373 7562 322f  3sub3/3sub3sub2/
+0000b0c0: 3373 7562 3373 7562 325f 6669 6c65 2e74  3sub3sub2_file.t
+0000b0d0: 7874 5c6e 220a 2020 2020 2020 2020 2020  xt\n".          
+0000b0e0: 2020 2020 2020 2020 2020 2274 6573 7466            "testf
+0000b0f0: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
+0000b100: 7375 6233 2f33 7375 6233 7375 6232 5c6e  sub3/3sub3sub2\n
+0000b110: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000b120: 2020 2020 2020 222b 2074 6573 7466 696c        "+ testfil
+0000b130: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
+0000b140: 6232 2f33 7375 6232 7375 6232 5c6e 220a  b2/3sub2sub2\n".
+0000b150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b160: 2020 2020 222b 2074 6573 7466 696c 6573      "+ testfiles
+0000b170: 2f73 656c 6563 7432 2f33 2f33 7375 6233  /select2/3/3sub3
+0000b180: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000b190: 2020 2020 2020 2020 222d 2074 6573 7466          "- testf
+0000b1a0: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
+0000b1b0: 7375 6231 5c6e 2220 2023 202d 2061 6464  sub1\n"  # - add
+0000b1c0: 6564 2074 6f20 656e 7375 7265 2069 7420  ed to ensure it 
+0000b1d0: 6d61 6b65 7320 6e6f 2064 6966 6665 7265  makes no differe
+0000b1e0: 6e63 650a 2020 2020 2020 2020 2020 2020  nce.            
+0000b1f0: 2020 2020 2020 2020 2274 6573 7466 696c          "testfil
+0000b200: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
+0000b210: 6231 2f32 7375 6231 7375 6233 5c6e 220a  b1/2sub1sub3\n".
 0000b220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b230: 2020 2020 2020 2020 2020 5b75 2233 2a33            [u"3*3
-0000b240: 222c 2075 2233 3f33 222c 2075 225b 3033  ", u"3?3", u"[03
-0000b250: 5d22 5d2c 205b 7522 5b30 315d 7375 6233  ]"], [u"[01]sub3
-0000b260: 2a33 5f66 696c 652e 7478 7422 5d2c 205b  *3_file.txt"], [
-0000b270: 7522 5b30 315d 7375 625b 3033 5d5f 6669  u"[01]sub[03]_fi
-0000b280: 6c65 2e74 7874 225d 5d29 0a0a 0a63 6c61  le.txt"]])...cla
-0000b290: 7373 2054 6573 7445 7863 6c75 6465 4669  ss TestExcludeFi
-0000b2a0: 6c65 6c69 7374 5465 7374 2849 6e63 6c75  lelistTest(Inclu
-0000b2b0: 6465 4578 636c 7564 6546 756e 6374 696f  deExcludeFunctio
-0000b2c0: 6e61 6c54 6573 7429 3a0a 2020 2020 7522  nalTest):.    u"
-0000b2d0: 2222 0a20 2020 2054 6573 7420 2d2d 6578  "".    Test --ex
-0000b2e0: 636c 7564 652d 6669 6c65 6c69 7374 2075  clude-filelist u
-0000b2f0: 7369 6e67 2064 7570 6c69 6369 7479 2062  sing duplicity b
-0000b300: 696e 6172 792e 0a20 2020 2022 2222 0a0a  inary..    """..
-0000b310: 2020 2020 6465 6620 7465 7374 5f65 7863      def test_exc
-0000b320: 6c75 6465 5f66 696c 656c 6973 7428 7365  lude_filelist(se
-0000b330: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-0000b340: 2254 6573 7420 7468 6174 2065 7863 6c75  "Test that exclu
-0000b350: 6465 2066 696c 656c 6973 7420 776f 726b  de filelist work
-0000b360: 7320 696e 2074 6865 2062 6173 6963 2063  s in the basic c
-0000b370: 6173 6520 2222 220a 2020 2020 2020 2020  ase """.        
-0000b380: 2320 4173 2074 6869 7320 6973 2061 6e20  # As this is an 
-0000b390: 6578 636c 7564 6520 6669 6c65 6c69 7374  exclude filelist
-0000b3a0: 2061 6e79 206c 696e 6573 2077 6974 6820   any lines with 
-0000b3b0: 6e6f 202b 2f2d 206d 6f64 6966 6965 7220  no +/- modifier 
-0000b3c0: 7368 6f75 6c64 2062 6520 7472 6561 7465  should be treate
-0000b3d0: 6420 6173 2069 6620 7468 6579 2068 6176  d as if they hav
-0000b3e0: 6520 6120 2d2e 0a20 2020 2020 2020 2023  e a -..        #
-0000b3f0: 2043 7265 6174 6520 6120 6669 6c65 6c69   Create a fileli
-0000b400: 7374 0a20 2020 2020 2020 2077 6974 6820  st.        with 
-0000b410: 696f 2e6f 7065 6e28 7522 7465 7374 6669  io.open(u"testfi
-0000b420: 6c65 732f 6578 636c 7564 652e 7478 7422  les/exclude.txt"
-0000b430: 2c20 7522 7722 2920 6173 2066 3a0a 2020  , u"w") as f:.  
-0000b440: 2020 2020 2020 2020 2020 662e 7772 6974            f.writ
-0000b450: 6528 7522 2b20 7465 7374 6669 6c65 732f  e(u"+ testfiles/
-0000b460: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
-0000b470: 3373 7562 3373 7562 322f 3373 7562 3373  3sub3sub2/3sub3s
-0000b480: 7562 325f 6669 6c65 2e74 7874 5c6e 220a  ub2_file.txt\n".
-0000b490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b4a0: 2020 2020 7522 7465 7374 6669 6c65 732f      u"testfiles/
-0000b4b0: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
-0000b4c0: 3373 7562 3373 7562 325c 6e22 0a20 2020  3sub3sub2\n".   
+0000b230: 2020 2020 2274 6573 7466 696c 6573 2f73      "testfiles/s
+0000b240: 656c 6563 7432 2f32 2f32 7375 6231 2f32  elect2/2/2sub1/2
+0000b250: 7375 6231 7375 6232 5c6e 220a 2020 2020  sub1sub2\n".    
+0000b260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b270: 222b 2074 6573 7466 696c 6573 2f73 656c  "+ testfiles/sel
+0000b280: 6563 7432 2f32 2f32 7375 6231 5c6e 220a  ect2/2/2sub1\n".
+0000b290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b2a0: 2020 2020 2274 6573 7466 696c 6573 2f73      "testfiles/s
+0000b2b0: 656c 6563 7432 2f31 2f31 7375 6233 2f31  elect2/1/1sub3/1
+0000b2c0: 7375 6233 7375 6232 5c6e 220a 2020 2020  sub3sub2\n".    
+0000b2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b2e0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+0000b2f0: 7432 2f31 2f31 7375 6233 2f31 7375 6233  t2/1/1sub3/1sub3
+0000b300: 7375 6231 5c6e 220a 2020 2020 2020 2020  sub1\n".        
+0000b310: 2020 2020 2020 2020 2020 2020 2274 6573              "tes
+0000b320: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+0000b330: 2f31 7375 6232 2f31 7375 6232 7375 6233  /1sub2/1sub2sub3
+0000b340: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000b350: 2020 2020 2020 2020 222b 2074 6573 7466          "+ testf
+0000b360: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+0000b370: 7375 6232 2f31 7375 6232 7375 6231 5c6e  sub2/1sub2sub1\n
+0000b380: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000b390: 2020 2020 2020 2274 6573 7466 696c 6573        "testfiles
+0000b3a0: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
+0000b3b0: 2f31 7375 6231 7375 6233 2f31 7375 6231  /1sub1sub3/1sub1
+0000b3c0: 7375 6233 5f66 696c 652e 7478 745c 6e22  sub3_file.txt\n"
+0000b3d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000b3e0: 2020 2020 2022 7465 7374 6669 6c65 732f       "testfiles/
+0000b3f0: 7365 6c65 6374 322f 312f 3173 7562 312f  select2/1/1sub1/
+0000b400: 3173 7562 3173 7562 325c 6e22 0a20 2020  1sub1sub2\n".   
+0000b410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b420: 2022 2d20 7465 7374 6669 6c65 732f 7365   "- testfiles/se
+0000b430: 6c65 6374 322f 312f 3173 7562 325c 6e22  lect2/1/1sub2\n"
+0000b440: 2020 2320 2d20 6164 6465 6420 746f 2065    # - added to e
+0000b450: 6e73 7572 6520 6974 206d 616b 6573 206e  nsure it makes n
+0000b460: 6f20 6469 6666 6572 656e 6365 0a20 2020  o difference.   
+0000b470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b480: 2022 2b20 7465 7374 6669 6c65 732f 7365   "+ testfiles/se
+0000b490: 6c65 6374 322f 312e 7079 5c6e 220a 2020  lect2/1.py\n".  
+0000b4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000b4b0: 2020 222b 2074 6573 7466 696c 6573 2f73    "+ testfiles/s
+0000b4c0: 656c 6563 7432 2f33 5c6e 220a 2020 2020  elect2/3\n".    
 0000b4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b4e0: 2075 222b 2074 6573 7466 696c 6573 2f73   u"+ testfiles/s
-0000b4f0: 656c 6563 7432 2f33 2f33 7375 6232 2f33  elect2/3/3sub2/3
-0000b500: 7375 6232 7375 6232 5c6e 220a 2020 2020  sub2sub2\n".    
-0000b510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b520: 7522 2b20 7465 7374 6669 6c65 732f 7365  u"+ testfiles/se
-0000b530: 6c65 6374 322f 332f 3373 7562 335c 6e22  lect2/3/3sub3\n"
-0000b540: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b550: 2020 2020 2075 222d 2074 6573 7466 696c       u"- testfil
-0000b560: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
-0000b570: 6231 5c6e 2220 2023 202d 2061 6464 6564  b1\n"  # - added
-0000b580: 2074 6f20 656e 7375 7265 2069 7420 6d61   to ensure it ma
-0000b590: 6b65 7320 6e6f 2064 6966 6665 7265 6e63  kes no differenc
-0000b5a0: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-0000b5b0: 2020 2020 2020 7522 7465 7374 6669 6c65        u"testfile
-0000b5c0: 732f 7365 6c65 6374 322f 322f 3273 7562  s/select2/2/2sub
-0000b5d0: 312f 3273 7562 3173 7562 335c 6e22 0a20  1/2sub1sub3\n". 
-0000b5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b5f0: 2020 2075 2274 6573 7466 696c 6573 2f73     u"testfiles/s
-0000b600: 656c 6563 7432 2f32 2f32 7375 6231 2f32  elect2/2/2sub1/2
-0000b610: 7375 6231 7375 6232 5c6e 220a 2020 2020  sub1sub2\n".    
-0000b620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b630: 7522 2b20 7465 7374 6669 6c65 732f 7365  u"+ testfiles/se
-0000b640: 6c65 6374 322f 322f 3273 7562 315c 6e22  lect2/2/2sub1\n"
-0000b650: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b660: 2020 2020 2075 2274 6573 7466 696c 6573       u"testfiles
-0000b670: 2f73 656c 6563 7432 2f31 2f31 7375 6233  /select2/1/1sub3
-0000b680: 2f31 7375 6233 7375 6232 5c6e 220a 2020  /1sub3sub2\n".  
-0000b690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b6a0: 2020 7522 7465 7374 6669 6c65 732f 7365    u"testfiles/se
-0000b6b0: 6c65 6374 322f 312f 3173 7562 332f 3173  lect2/1/1sub3/1s
-0000b6c0: 7562 3373 7562 315c 6e22 0a20 2020 2020  ub3sub1\n".     
-0000b6d0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000b6e0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-0000b6f0: 7432 2f31 2f31 7375 6232 2f31 7375 6232  t2/1/1sub2/1sub2
-0000b700: 7375 6233 5c6e 220a 2020 2020 2020 2020  sub3\n".        
-0000b710: 2020 2020 2020 2020 2020 2020 7522 2b20              u"+ 
-0000b720: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-0000b730: 322f 312f 3173 7562 322f 3173 7562 3273  2/1/1sub2/1sub2s
-0000b740: 7562 315c 6e22 0a20 2020 2020 2020 2020  ub1\n".         
-0000b750: 2020 2020 2020 2020 2020 2075 2274 6573             u"tes
-0000b760: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-0000b770: 2f31 7375 6231 2f31 7375 6231 7375 6233  /1sub1/1sub1sub3
-0000b780: 2f31 7375 6231 7375 6233 5f66 696c 652e  /1sub1sub3_file.
-0000b790: 7478 745c 6e22 0a20 2020 2020 2020 2020  txt\n".         
-0000b7a0: 2020 2020 2020 2020 2020 2075 2274 6573             u"tes
-0000b7b0: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-0000b7c0: 2f31 7375 6231 2f31 7375 6231 7375 6232  /1sub1/1sub1sub2
-0000b7d0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000b7e0: 2020 2020 2020 2020 7522 2d20 7465 7374          u"- test
-0000b7f0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-0000b800: 3173 7562 325c 6e22 2020 2320 2d20 6164  1sub2\n"  # - ad
-0000b810: 6465 6420 746f 2065 6e73 7572 6520 6974  ded to ensure it
-0000b820: 206d 616b 6573 206e 6f20 6469 6666 6572   makes no differ
-0000b830: 656e 6365 0a20 2020 2020 2020 2020 2020  ence.           
-0000b840: 2020 2020 2020 2020 2075 222b 2074 6573           u"+ tes
-0000b850: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-0000b860: 2e70 795c 6e22 0a20 2020 2020 2020 2020  .py\n".         
-0000b870: 2020 2020 2020 2020 2020 2075 222b 2074             u"+ t
-0000b880: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-0000b890: 2f33 5c6e 220a 2020 2020 2020 2020 2020  /3\n".          
-0000b8a0: 2020 2020 2020 2020 2020 7522 2b20 7465            u"+ te
-0000b8b0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000b8c0: 315c 6e22 0a20 2020 2020 2020 2020 2020  1\n".           
-0000b8d0: 2020 2020 2020 2020 2075 2274 6573 7466           u"testf
-0000b8e0: 696c 6573 2f73 656c 6563 7432 2f2a 2a22  iles/select2/**"
-0000b8f0: 290a 2020 2020 2020 2020 7365 6c66 2e62  ).        self.b
-0000b900: 6163 6b75 7028 7522 6675 6c6c 222c 2075  ackup(u"full", u
-0000b910: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-0000b920: 7432 222c 206f 7074 696f 6e73 3d5b 7522  t2", options=[u"
-0000b930: 2d2d 6578 636c 7564 652d 6669 6c65 6c69  --exclude-fileli
-0000b940: 7374 3d74 6573 7466 696c 6573 2f65 7863  st=testfiles/exc
-0000b950: 6c75 6465 2e74 7874 225d 290a 2020 2020  lude.txt"]).    
-0000b960: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
-0000b970: 2829 0a20 2020 2020 2020 2072 6573 746f  ().        resto
-0000b980: 7265 5f64 6972 203d 2075 2274 6573 7466  re_dir = u"testf
-0000b990: 696c 6573 2f72 6573 746f 7265 5f6f 7574  iles/restore_out
-0000b9a0: 220a 2020 2020 2020 2020 7265 7374 6f72  ".        restor
-0000b9b0: 6564 203d 2073 656c 662e 6469 7265 6374  ed = self.direct
-0000b9c0: 6f72 795f 7472 6565 5f74 6f5f 6c69 7374  ory_tree_to_list
-0000b9d0: 5f6f 665f 6c69 7374 7328 7265 7374 6f72  _of_lists(restor
-0000b9e0: 655f 6469 7229 0a20 2020 2020 2020 2073  e_dir).        s
-0000b9f0: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
-0000ba00: 7265 7374 6f72 6564 2c20 7365 6c66 2e65  restored, self.e
-0000ba10: 7870 6563 7465 645f 7265 7374 6f72 6564  xpected_restored
-0000ba20: 5f74 7265 6529 0a0a 2020 2020 6465 6620  _tree)..    def 
-0000ba30: 7465 7374 5f65 7863 6c75 6465 5f66 696c  test_exclude_fil
-0000ba40: 656c 6973 745f 636f 6d62 696e 6564 5f69  elist_combined_i
-0000ba50: 6d70 6572 6665 6374 696f 6e73 2873 656c  mperfections(sel
-0000ba60: 6629 3a0a 2020 2020 2020 2020 7522 2222  f):.        u"""
-0000ba70: 5465 7374 2074 6861 7420 6578 636c 7564  Test that exclud
-0000ba80: 6520 6669 6c65 6c69 7374 2077 6f72 6b73  e filelist works
-0000ba90: 2077 6974 6820 696d 7065 7266 6563 7469   with imperfecti
-0000baa0: 6f6e 7320 696e 2074 6865 2069 6e70 7574  ons in the input
-0000bab0: 2066 696c 6522 2222 0a20 2020 2020 2020   file""".       
-0000bac0: 2023 2054 6869 7320 6973 2061 2063 6f6d   # This is a com
-0000bad0: 6269 6e65 6420 7465 7374 2066 6f72 2073  bined test for s
-0000bae0: 7065 6564 2072 6561 736f 6e73 2e20 5468  peed reasons. Th
-0000baf0: 6520 696e 6469 7669 6475 616c 2069 6d70  e individual imp
-0000bb00: 6572 6665 6374 696f 6e73 2061 7265 2074  erfections are t
-0000bb10: 6573 7465 6420 6173 2075 6e69 7474 6573  ested as unittes
-0000bb20: 7473 2069 6e0a 2020 2020 2020 2020 2320  ts in.        # 
-0000bb30: 756e 6974 2f74 6573 745f 7365 6c65 6374  unit/test_select
-0000bb40: 696f 6e2e 0a20 2020 2020 2020 2023 2049  ion..        # I
-0000bb50: 6d70 6572 6665 6374 696f 6e73 2074 6573  mperfections tes
-0000bb60: 7465 6420 6172 653b 0a20 2020 2020 2020  ted are;.       
-0000bb70: 2023 202a 204c 6561 6469 6e67 2073 7061   # * Leading spa
-0000bb80: 6365 2f73 7061 6365 7320 6265 666f 7265  ce/spaces before
-0000bb90: 2074 6865 206d 6f64 6966 6965 720a 2020   the modifier.  
-0000bba0: 2020 2020 2020 2320 2a20 5472 6169 6c69        # * Traili
-0000bbb0: 6e67 2073 7061 6365 2f73 7061 6365 7320  ng space/spaces 
-0000bbc0: 6166 7465 7220 7468 6520 6669 6c65 6e61  after the filena
-0000bbd0: 6d65 2028 6275 7420 6265 666f 7265 2074  me (but before t
-0000bbe0: 6865 206e 6577 6c69 6e65 290a 2020 2020  he newline).    
-0000bbf0: 2020 2020 2320 2a20 426c 616e 6b20 6c69      # * Blank li
-0000bc00: 6e65 7320 286e 6577 6c69 6e65 2063 6861  nes (newline cha
-0000bc10: 7261 6374 6572 206f 6e6c 7929 0a20 2020  racter only).   
-0000bc20: 2020 2020 2023 202a 204c 696e 6520 6f6e       # * Line on
-0000bc30: 6c79 2063 6f6e 7461 696e 696e 6720 7370  ly containing sp
-0000bc40: 6163 6573 0a20 2020 2020 2020 2023 202a  aces.        # *
-0000bc50: 2046 756c 6c2d 6c69 6e65 2063 6f6d 6d65   Full-line comme
-0000bc60: 6e74 7320 7769 7468 2023 2061 7320 7468  nts with # as th
-0000bc70: 6520 6669 7273 7420 6368 6172 6163 7465  e first characte
-0000bc80: 7220 616e 6420 7769 7468 206c 6561 6469  r and with leadi
-0000bc90: 6e67 2f74 7261 696c 696e 6720 7370 6163  ng/trailing spac
-0000bca0: 6573 0a20 2020 2020 2020 2023 202a 2055  es.        # * U
-0000bcb0: 6e6e 6563 6573 7361 7269 6c79 2071 756f  nnecessarily quo
-0000bcc0: 7465 6420 6669 6c65 6e61 6d65 7320 7769  ted filenames wi
-0000bcd0: 7468 2f77 6974 686f 7574 206d 6f64 6966  th/without modif
-0000bce0: 6965 7220 2862 6f74 6820 2220 616e 6420  ier (both " and 
-0000bcf0: 2729 0a20 2020 2020 2020 2023 2043 7265  ').        # Cre
-0000bd00: 6174 6520 6120 6669 6c65 6c69 7374 0a20  ate a filelist. 
-0000bd10: 2020 2020 2020 2077 6974 6820 696f 2e6f         with io.o
-0000bd20: 7065 6e28 7522 7465 7374 6669 6c65 732f  pen(u"testfiles/
-0000bd30: 6578 636c 7564 652e 7478 7422 2c20 7522  exclude.txt", u"
-0000bd40: 7722 2920 6173 2066 3a0a 2020 2020 2020  w") as f:.      
-0000bd50: 2020 2020 2020 662e 7772 6974 6528 7522        f.write(u"
-0000bd60: 2b20 7465 7374 6669 6c65 732f 7365 6c65  + testfiles/sele
-0000bd70: 6374 322f 332f 3373 7562 332f 3373 7562  ct2/3/3sub3/3sub
-0000bd80: 3373 7562 322f 3373 7562 3373 7562 325f  3sub2/3sub3sub2_
-0000bd90: 6669 6c65 2e74 7874 5c6e 220a 2020 2020  file.txt\n".    
-0000bda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bdb0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-0000bdc0: 6374 322f 332f 3373 7562 332f 3373 7562  ct2/3/3sub3/3sub
-0000bdd0: 3373 7562 325c 6e22 0a20 2020 2020 2020  3sub2\n".       
-0000bde0: 2020 2020 2020 2020 2020 2020 2075 222b               u"+
-0000bdf0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-0000be00: 7432 2f33 2f33 7375 6232 2f33 7375 6232  t2/3/3sub2/3sub2
-0000be10: 7375 6232 5c6e 220a 2020 2020 2020 2020  sub2\n".        
-0000be20: 2020 2020 2020 2020 2020 2020 7522 202b              u" +
-0000be30: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-0000be40: 7432 2f33 2f33 7375 6233 5c6e 2220 2023  t2/3/3sub3\n"  #
-0000be50: 204e 6f74 6520 6c65 6164 696e 6720 7370   Note leading sp
-0000be60: 6163 6520 6164 6465 6420 6865 7265 0a20  ace added here. 
-0000be70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000be80: 2020 2075 222d 2074 6573 7466 696c 6573     u"- testfiles
-0000be90: 2f73 656c 6563 7432 2f33 2f33 7375 6231  /select2/3/3sub1
-0000bea0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000beb0: 2020 2020 2020 2020 7522 2020 7465 7374          u"  test
-0000bec0: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-0000bed0: 3273 7562 312f 3273 7562 3173 7562 335c  2sub1/2sub1sub3\
-0000bee0: 6e22 2020 2320 4e6f 7465 206c 6561 6469  n"  # Note leadi
-0000bef0: 6e67 2073 7061 6365 7320 6164 6465 6420  ng spaces added 
-0000bf00: 6865 7265 0a20 2020 2020 2020 2020 2020  here.           
-0000bf10: 2020 2020 2020 2020 2075 225c 6e22 0a20           u"\n". 
+0000b4e0: 222b 2074 6573 7466 696c 6573 2f73 656c  "+ testfiles/sel
+0000b4f0: 6563 7432 2f31 5c6e 220a 2020 2020 2020  ect2/1\n".      
+0000b500: 2020 2020 2020 2020 2020 2020 2020 2274                "t
+0000b510: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000b520: 2f2a 2a22 290a 2020 2020 2020 2020 7365  /**").        se
+0000b530: 6c66 2e62 6163 6b75 7028 2266 756c 6c22  lf.backup("full"
+0000b540: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+0000b550: 6563 7432 222c 206f 7074 696f 6e73 3d5b  ect2", options=[
+0000b560: 222d 2d65 7863 6c75 6465 2d66 696c 656c  "--exclude-filel
+0000b570: 6973 743d 7465 7374 6669 6c65 732f 6578  ist=testfiles/ex
+0000b580: 636c 7564 652e 7478 7422 5d29 0a20 2020  clude.txt"]).   
+0000b590: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
+0000b5a0: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
+0000b5b0: 6f72 655f 7061 7468 203d 2022 7465 7374  ore_path = "test
+0000b5c0: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
+0000b5d0: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
+0000b5e0: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
+0000b5f0: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
+0000b600: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
+0000b610: 7265 5f70 6174 6829 0a20 2020 2020 2020  re_path).       
+0000b620: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
+0000b630: 6c28 7265 7374 6f72 6564 2c20 7365 6c66  l(restored, self
+0000b640: 2e65 7870 6563 7465 645f 7265 7374 6f72  .expected_restor
+0000b650: 6564 5f74 7265 6529 0a0a 2020 2020 6465  ed_tree)..    de
+0000b660: 6620 7465 7374 5f65 7863 6c75 6465 5f66  f test_exclude_f
+0000b670: 696c 656c 6973 745f 636f 6d62 696e 6564  ilelist_combined
+0000b680: 5f69 6d70 6572 6665 6374 696f 6e73 2873  _imperfections(s
+0000b690: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+0000b6a0: 2254 6573 7420 7468 6174 2065 7863 6c75  "Test that exclu
+0000b6b0: 6465 2066 696c 656c 6973 7420 776f 726b  de filelist work
+0000b6c0: 7320 7769 7468 2069 6d70 6572 6665 6374  s with imperfect
+0000b6d0: 696f 6e73 2069 6e20 7468 6520 696e 7075  ions in the inpu
+0000b6e0: 7420 6669 6c65 2222 220a 2020 2020 2020  t file""".      
+0000b6f0: 2020 2320 5468 6973 2069 7320 6120 636f    # This is a co
+0000b700: 6d62 696e 6564 2074 6573 7420 666f 7220  mbined test for 
+0000b710: 7370 6565 6420 7265 6173 6f6e 732e 2054  speed reasons. T
+0000b720: 6865 2069 6e64 6976 6964 7561 6c20 696d  he individual im
+0000b730: 7065 7266 6563 7469 6f6e 7320 6172 6520  perfections are 
+0000b740: 7465 7374 6564 2061 7320 756e 6974 7465  tested as unitte
+0000b750: 7374 7320 696e 0a20 2020 2020 2020 2023  sts in.        #
+0000b760: 2075 6e69 742f 7465 7374 5f73 656c 6563   unit/test_selec
+0000b770: 7469 6f6e 2e0a 2020 2020 2020 2020 2320  tion..        # 
+0000b780: 496d 7065 7266 6563 7469 6f6e 7320 7465  Imperfections te
+0000b790: 7374 6564 2061 7265 3b0a 2020 2020 2020  sted are;.      
+0000b7a0: 2020 2320 2a20 4c65 6164 696e 6720 7370    # * Leading sp
+0000b7b0: 6163 652f 7370 6163 6573 2062 6566 6f72  ace/spaces befor
+0000b7c0: 6520 7468 6520 6d6f 6469 6669 6572 0a20  e the modifier. 
+0000b7d0: 2020 2020 2020 2023 202a 2054 7261 696c         # * Trail
+0000b7e0: 696e 6720 7370 6163 652f 7370 6163 6573  ing space/spaces
+0000b7f0: 2061 6674 6572 2074 6865 2066 696c 656e   after the filen
+0000b800: 616d 6520 2862 7574 2062 6566 6f72 6520  ame (but before 
+0000b810: 7468 6520 6e65 776c 696e 6529 0a20 2020  the newline).   
+0000b820: 2020 2020 2023 202a 2042 6c61 6e6b 206c       # * Blank l
+0000b830: 696e 6573 2028 6e65 776c 696e 6520 6368  ines (newline ch
+0000b840: 6172 6163 7465 7220 6f6e 6c79 290a 2020  aracter only).  
+0000b850: 2020 2020 2020 2320 2a20 4c69 6e65 206f        # * Line o
+0000b860: 6e6c 7920 636f 6e74 6169 6e69 6e67 2073  nly containing s
+0000b870: 7061 6365 730a 2020 2020 2020 2020 2320  paces.        # 
+0000b880: 2a20 4675 6c6c 2d6c 696e 6520 636f 6d6d  * Full-line comm
+0000b890: 656e 7473 2077 6974 6820 2320 6173 2074  ents with # as t
+0000b8a0: 6865 2066 6972 7374 2063 6861 7261 6374  he first charact
+0000b8b0: 6572 2061 6e64 2077 6974 6820 6c65 6164  er and with lead
+0000b8c0: 696e 672f 7472 6169 6c69 6e67 2073 7061  ing/trailing spa
+0000b8d0: 6365 730a 2020 2020 2020 2020 2320 2a20  ces.        # * 
+0000b8e0: 556e 6e65 6365 7373 6172 696c 7920 7175  Unnecessarily qu
+0000b8f0: 6f74 6564 2066 696c 656e 616d 6573 2077  oted filenames w
+0000b900: 6974 682f 7769 7468 6f75 7420 6d6f 6469  ith/without modi
+0000b910: 6669 6572 2028 626f 7468 2022 2061 6e64  fier (both " and
+0000b920: 2027 290a 2020 2020 2020 2020 2320 4372   ').        # Cr
+0000b930: 6561 7465 2061 2066 696c 656c 6973 740a  eate a filelist.
+0000b940: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
+0000b950: 6f70 656e 2822 7465 7374 6669 6c65 732f  open("testfiles/
+0000b960: 6578 636c 7564 652e 7478 7422 2c20 2277  exclude.txt", "w
+0000b970: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
+0000b980: 2020 2020 2066 2e77 7269 7465 2822 2b20       f.write("+ 
+0000b990: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+0000b9a0: 322f 332f 3373 7562 332f 3373 7562 3373  2/3/3sub3/3sub3s
+0000b9b0: 7562 322f 3373 7562 3373 7562 325f 6669  ub2/3sub3sub2_fi
+0000b9c0: 6c65 2e74 7874 5c6e 220a 2020 2020 2020  le.txt\n".      
+0000b9d0: 2020 2020 2020 2020 2020 2020 2020 2274                "t
+0000b9e0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000b9f0: 2f33 2f33 7375 6233 2f33 7375 6233 7375  /3/3sub3/3sub3su
+0000ba00: 6232 5c6e 220a 2020 2020 2020 2020 2020  b2\n".          
+0000ba10: 2020 2020 2020 2020 2020 222b 2074 6573            "+ tes
+0000ba20: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
+0000ba30: 2f33 7375 6232 2f33 7375 6232 7375 6232  /3sub2/3sub2sub2
+0000ba40: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000ba50: 2020 2020 2020 2020 2220 2b20 7465 7374          " + test
+0000ba60: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
+0000ba70: 3373 7562 335c 6e22 2020 2320 4e6f 7465  3sub3\n"  # Note
+0000ba80: 206c 6561 6469 6e67 2073 7061 6365 2061   leading space a
+0000ba90: 6464 6564 2068 6572 650a 2020 2020 2020  dded here.      
+0000baa0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+0000bab0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
+0000bac0: 7432 2f33 2f33 7375 6231 5c6e 220a 2020  t2/3/3sub1\n".  
+0000bad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bae0: 2020 2220 2074 6573 7466 696c 6573 2f73    "  testfiles/s
+0000baf0: 656c 6563 7432 2f32 2f32 7375 6231 2f32  elect2/2/2sub1/2
+0000bb00: 7375 6231 7375 6233 5c6e 2220 2023 204e  sub1sub3\n"  # N
+0000bb10: 6f74 6520 6c65 6164 696e 6720 7370 6163  ote leading spac
+0000bb20: 6573 2061 6464 6564 2068 6572 650a 2020  es added here.  
+0000bb30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bb40: 2020 225c 6e22 0a20 2020 2020 2020 2020    "\n".         
+0000bb50: 2020 2020 2020 2020 2020 2022 7465 7374             "test
+0000bb60: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
+0000bb70: 3273 7562 312f 3273 7562 3173 7562 325c  2sub1/2sub1sub2\
+0000bb80: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+0000bb90: 2020 2020 2020 2022 202b 2074 6573 7466         " + testf
+0000bba0: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
+0000bbb0: 7375 6231 205c 6e22 2020 2320 4e6f 7465  sub1 \n"  # Note
+0000bbc0: 2061 6464 6564 2074 7261 696c 696e 672f   added trailing/
+0000bbd0: 6c65 6164 696e 6720 7370 6163 6520 6865  leading space he
+0000bbe0: 7265 0a20 2020 2020 2020 2020 2020 2020  re.             
+0000bbf0: 2020 2020 2020 2027 2d20 2274 6573 7466         '- "testf
+0000bc00: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+0000bc10: 7375 6233 2f31 7375 6233 7375 6232 225c  sub3/1sub3sub2"\
+0000bc20: 6e27 2020 2320 556e 6e65 6365 7373 6172  n'  # Unnecessar
+0000bc30: 7920 7175 6f74 6573 0a20 2020 2020 2020  y quotes.       
+0000bc40: 2020 2020 2020 2020 2020 2020 2022 2320               "# 
+0000bc50: 5465 7374 696e 6720 6120 6675 6c6c 2d6c  Testing a full-l
+0000bc60: 696e 6520 636f 6d6d 656e 745c 6e22 0a20  ine comment\n". 
+0000bc70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bc80: 2020 2022 2774 6573 7466 696c 6573 2f73     "'testfiles/s
+0000bc90: 656c 6563 7432 2f31 2f31 7375 6233 2f31  elect2/1/1sub3/1
+0000bca0: 7375 6233 7375 6231 2720 205c 6e22 2020  sub3sub1'  \n"  
+0000bcb0: 2320 4e6f 7465 2061 6464 6564 2073 7061  # Note added spa
+0000bcc0: 6365 7320 616e 6420 7175 6f74 6573 2068  ces and quotes h
+0000bcd0: 6572 650a 2020 2020 2020 2020 2020 2020  ere.            
+0000bce0: 2020 2020 2020 2020 2274 6573 7466 696c          "testfil
+0000bcf0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+0000bd00: 6232 2f31 7375 6232 7375 6233 5c6e 220a  b2/1sub2sub3\n".
+0000bd10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bd20: 2020 2020 2220 2020 205c 6e22 0a20 2020      "    \n".   
+0000bd30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bd40: 2022 2b20 7465 7374 6669 6c65 732f 7365   "+ testfiles/se
+0000bd50: 6c65 6374 322f 312f 3173 7562 322f 3173  lect2/1/1sub2/1s
+0000bd60: 7562 3273 7562 315c 6e22 0a20 2020 2020  ub2sub1\n".     
+0000bd70: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000bd80: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
+0000bd90: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
+0000bda0: 3173 7562 332f 3173 7562 3173 7562 335f  1sub3/1sub1sub3_
+0000bdb0: 6669 6c65 2e74 7874 5c6e 220a 2020 2020  file.txt\n".    
+0000bdc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bdd0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+0000bde0: 7432 2f31 2f31 7375 6231 2f31 7375 6231  t2/1/1sub1/1sub1
+0000bdf0: 7375 6232 5c6e 220a 2020 2020 2020 2020  sub2\n".        
+0000be00: 2020 2020 2020 2020 2020 2020 2220 2020              "   
+0000be10: 2020 2320 5465 7374 696e 6720 6120 6675    # Testing a fu
+0000be20: 6c6c 2d6c 696e 6520 636f 6d6d 656e 7420  ll-line comment 
+0000be30: 7769 7468 206c 6561 6469 6e67 2061 6e64  with leading and
+0000be40: 2074 7261 696c 696e 6720 7370 6163 6573   trailing spaces
+0000be50: 2020 2020 205c 6e22 0a20 2020 2020 2020       \n".       
+0000be60: 2020 2020 2020 2020 2020 2020 2022 7465               "te
+0000be70: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+0000be80: 312f 3173 7562 3220 205c 6e22 2020 2320  1/1sub2  \n"  # 
+0000be90: 4e6f 7465 2061 6464 6564 2073 7061 6365  Note added space
+0000bea0: 7320 6865 7265 0a20 2020 2020 2020 2020  s here.         
+0000beb0: 2020 2020 2020 2020 2020 2022 2b20 7465             "+ te
+0000bec0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+0000bed0: 312e 7079 5c6e 220a 2020 2020 2020 2020  1.py\n".        
+0000bee0: 2020 2020 2020 2020 2020 2020 222b 2074              "+ t
+0000bef0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000bf00: 2f33 205c 6e22 2020 2320 4e6f 7465 2061  /3 \n"  # Note a
+0000bf10: 6464 6564 2073 7061 6365 2068 6572 650a  dded space here.
 0000bf20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bf30: 2020 2075 2274 6573 7466 696c 6573 2f73     u"testfiles/s
-0000bf40: 656c 6563 7432 2f32 2f32 7375 6231 2f32  elect2/2/2sub1/2
-0000bf50: 7375 6231 7375 6232 5c6e 220a 2020 2020  sub1sub2\n".    
-0000bf60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bf70: 7522 202b 2074 6573 7466 696c 6573 2f73  u" + testfiles/s
-0000bf80: 656c 6563 7432 2f32 2f32 7375 6231 205c  elect2/2/2sub1 \
-0000bf90: 6e22 2020 2320 4e6f 7465 2061 6464 6564  n"  # Note added
-0000bfa0: 2074 7261 696c 696e 672f 6c65 6164 696e   trailing/leadin
-0000bfb0: 6720 7370 6163 6520 6865 7265 0a20 2020  g space here.   
-0000bfc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bfd0: 2075 272d 2022 7465 7374 6669 6c65 732f   u'- "testfiles/
-0000bfe0: 7365 6c65 6374 322f 312f 3173 7562 332f  select2/1/1sub3/
-0000bff0: 3173 7562 3373 7562 3222 5c6e 2720 2023  1sub3sub2"\n'  #
-0000c000: 2055 6e6e 6563 6573 7361 7279 2071 756f   Unnecessary quo
-0000c010: 7465 730a 2020 2020 2020 2020 2020 2020  tes.            
-0000c020: 2020 2020 2020 2020 7522 2320 5465 7374          u"# Test
-0000c030: 696e 6720 6120 6675 6c6c 2d6c 696e 6520  ing a full-line 
-0000c040: 636f 6d6d 656e 745c 6e22 0a20 2020 2020  comment\n".     
-0000c050: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000c060: 2227 7465 7374 6669 6c65 732f 7365 6c65  "'testfiles/sele
-0000c070: 6374 322f 312f 3173 7562 332f 3173 7562  ct2/1/1sub3/1sub
-0000c080: 3373 7562 3127 2020 5c6e 2220 2023 204e  3sub1'  \n"  # N
-0000c090: 6f74 6520 6164 6465 6420 7370 6163 6573  ote added spaces
-0000c0a0: 2061 6e64 2071 756f 7465 7320 6865 7265   and quotes here
-0000c0b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000c0c0: 2020 2020 2075 2274 6573 7466 696c 6573       u"testfiles
-0000c0d0: 2f73 656c 6563 7432 2f31 2f31 7375 6232  /select2/1/1sub2
-0000c0e0: 2f31 7375 6232 7375 6233 5c6e 220a 2020  /1sub2sub3\n".  
-0000c0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c100: 2020 7522 2020 2020 5c6e 220a 2020 2020    u"    \n".    
-0000c110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c120: 7522 2b20 7465 7374 6669 6c65 732f 7365  u"+ testfiles/se
-0000c130: 6c65 6374 322f 312f 3173 7562 322f 3173  lect2/1/1sub2/1s
-0000c140: 7562 3273 7562 315c 6e22 0a20 2020 2020  ub2sub1\n".     
-0000c150: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000c160: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
-0000c170: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
-0000c180: 6231 7375 6233 2f31 7375 6231 7375 6233  b1sub3/1sub1sub3
-0000c190: 5f66 696c 652e 7478 745c 6e22 0a20 2020  _file.txt\n".   
-0000c1a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c1b0: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-0000c1c0: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
-0000c1d0: 6231 7375 6232 5c6e 220a 2020 2020 2020  b1sub2\n".      
-0000c1e0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000c1f0: 2020 2020 2023 2054 6573 7469 6e67 2061       # Testing a
-0000c200: 2066 756c 6c2d 6c69 6e65 2063 6f6d 6d65   full-line comme
-0000c210: 6e74 2077 6974 6820 6c65 6164 696e 6720  nt with leading 
-0000c220: 616e 6420 7472 6169 6c69 6e67 2073 7061  and trailing spa
-0000c230: 6365 7320 2020 2020 5c6e 220a 2020 2020  ces     \n".    
-0000c240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c250: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-0000c260: 6374 322f 312f 3173 7562 3220 205c 6e22  ct2/1/1sub2  \n"
-0000c270: 2020 2320 4e6f 7465 2061 6464 6564 2073    # Note added s
-0000c280: 7061 6365 7320 6865 7265 0a20 2020 2020  paces here.     
-0000c290: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000c2a0: 222b 2074 6573 7466 696c 6573 2f73 656c  "+ testfiles/sel
-0000c2b0: 6563 7432 2f31 2e70 795c 6e22 0a20 2020  ect2/1.py\n".   
-0000c2c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c2d0: 2075 222b 2074 6573 7466 696c 6573 2f73   u"+ testfiles/s
-0000c2e0: 656c 6563 7432 2f33 205c 6e22 2020 2320  elect2/3 \n"  # 
-0000c2f0: 4e6f 7465 2061 6464 6564 2073 7061 6365  Note added space
-0000c300: 2068 6572 650a 2020 2020 2020 2020 2020   here.          
-0000c310: 2020 2020 2020 2020 2020 7522 2b20 7465            u"+ te
-0000c320: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000c330: 315c 6e22 0a20 2020 2020 2020 2020 2020  1\n".           
-0000c340: 2020 2020 2020 2020 2075 222d 2074 6573           u"- tes
-0000c350: 7466 696c 6573 2f73 656c 6563 7432 2f2a  tfiles/select2/*
-0000c360: 2a22 290a 2020 2020 2020 2020 7365 6c66  *").        self
-0000c370: 2e62 6163 6b75 7028 7522 6675 6c6c 222c  .backup(u"full",
-0000c380: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-0000c390: 6563 7432 222c 206f 7074 696f 6e73 3d5b  ect2", options=[
-0000c3a0: 7522 2d2d 6578 636c 7564 652d 6669 6c65  u"--exclude-file
-0000c3b0: 6c69 7374 3d74 6573 7466 696c 6573 2f65  list=testfiles/e
-0000c3c0: 7863 6c75 6465 2e74 7874 225d 290a 2020  xclude.txt"]).  
-0000c3d0: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
-0000c3e0: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
-0000c3f0: 746f 7265 5f64 6972 203d 2075 2274 6573  tore_dir = u"tes
-0000c400: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
-0000c410: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
-0000c420: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
-0000c430: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
-0000c440: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
-0000c450: 6f72 655f 6469 7229 0a20 2020 2020 2020  ore_dir).       
-0000c460: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
-0000c470: 6c28 7265 7374 6f72 6564 2c20 7365 6c66  l(restored, self
-0000c480: 2e65 7870 6563 7465 645f 7265 7374 6f72  .expected_restor
-0000c490: 6564 5f74 7265 6529 0a0a 2020 2020 6465  ed_tree)..    de
-0000c4a0: 6620 7465 7374 5f65 7863 6c75 6465 5f67  f test_exclude_g
-0000c4b0: 6c6f 6262 696e 675f 6669 6c65 6c69 7374  lobbing_filelist
-0000c4c0: 5f63 6f6d 6269 6e65 645f 696d 7065 7266  _combined_imperf
-0000c4d0: 6563 7469 6f6e 7328 7365 6c66 293a 0a20  ections(self):. 
-0000c4e0: 2020 2020 2020 2075 2222 2254 6573 7420         u"""Test 
-0000c4f0: 7468 6174 2065 7863 6c75 6465 2067 6c6f  that exclude glo
-0000c500: 6262 696e 6720 6669 6c65 6c69 7374 2077  bbing filelist w
-0000c510: 6f72 6b73 2077 6974 6820 696d 7065 7266  orks with imperf
-0000c520: 6563 7469 6f6e 7320 696e 2074 6865 2069  ections in the i
-0000c530: 6e70 7574 2066 696c 6522 2222 0a20 2020  nput file""".   
-0000c540: 2020 2020 2023 2049 6465 6e74 6963 616c       # Identical
-0000c550: 2074 6f20 7465 7374 5f65 7863 6c75 6465   to test_exclude
-0000c560: 5f66 696c 656c 6973 745f 636f 6d62 696e  _filelist_combin
-0000c570: 6564 5f69 6d70 6572 6665 6374 696f 6e73  ed_imperfections
-0000c580: 2061 6e64 2069 6e63 6c75 6465 6420 746f   and included to
-0000c590: 2065 6e73 7572 6520 7468 6174 0a20 2020   ensure that.   
-0000c5a0: 2020 2020 2023 2074 6865 2064 6570 7265       # the depre
-0000c5b0: 6361 7465 6420 2d2d 6578 636c 7564 652d  cated --exclude-
-0000c5c0: 676c 6f62 6269 6e67 2d66 696c 656c 6973  globbing-filelis
-0000c5d0: 7420 6675 6e63 7469 6f6e 2077 6f72 6b73  t function works
-0000c5e0: 2061 7320 6578 7065 6374 6564 2075 6e74   as expected unt
-0000c5f0: 696c 2069 7420 6973 2064 656c 6962 6572  il it is deliber
-0000c600: 6174 656c 7920 7265 6d6f 7665 642e 0a20  ately removed.. 
-0000c610: 2020 2020 2020 2023 2054 6869 7320 6973         # This is
-0000c620: 2061 2063 6f6d 6269 6e65 6420 7465 7374   a combined test
-0000c630: 2066 6f72 2073 7065 6564 2072 6561 736f   for speed reaso
-0000c640: 6e73 2e20 5468 6520 696e 6469 7669 6475  ns. The individu
-0000c650: 616c 2069 6d70 6572 6665 6374 696f 6e73  al imperfections
-0000c660: 2061 7265 2074 6573 7465 6420 6173 2075   are tested as u
-0000c670: 6e69 7474 6573 7473 2069 6e0a 2020 2020  nittests in.    
-0000c680: 2020 2020 2320 756e 6974 2f74 6573 745f      # unit/test_
-0000c690: 7365 6c65 6374 696f 6e2e 0a20 2020 2020  selection..     
-0000c6a0: 2020 2023 2049 6d70 6572 6665 6374 696f     # Imperfectio
-0000c6b0: 6e73 2074 6573 7465 6420 6172 653b 0a20  ns tested are;. 
-0000c6c0: 2020 2020 2020 2023 202a 204c 6561 6469         # * Leadi
-0000c6d0: 6e67 2073 7061 6365 2f73 7061 6365 7320  ng space/spaces 
-0000c6e0: 6265 666f 7265 2074 6865 206d 6f64 6966  before the modif
-0000c6f0: 6965 720a 2020 2020 2020 2020 2320 2a20  ier.        # * 
-0000c700: 5472 6169 6c69 6e67 2073 7061 6365 2f73  Trailing space/s
-0000c710: 7061 6365 7320 6166 7465 7220 7468 6520  paces after the 
-0000c720: 6669 6c65 6e61 6d65 2028 6275 7420 6265  filename (but be
-0000c730: 666f 7265 2074 6865 206e 6577 6c69 6e65  fore the newline
-0000c740: 290a 2020 2020 2020 2020 2320 2a20 426c  ).        # * Bl
-0000c750: 616e 6b20 6c69 6e65 7320 286e 6577 6c69  ank lines (newli
-0000c760: 6e65 2063 6861 7261 6374 6572 206f 6e6c  ne character onl
-0000c770: 7929 0a20 2020 2020 2020 2023 202a 204c  y).        # * L
-0000c780: 696e 6520 6f6e 6c79 2063 6f6e 7461 696e  ine only contain
-0000c790: 696e 6720 7370 6163 6573 0a20 2020 2020  ing spaces.     
-0000c7a0: 2020 2023 202a 2046 756c 6c2d 6c69 6e65     # * Full-line
-0000c7b0: 2063 6f6d 6d65 6e74 7320 7769 7468 2023   comments with #
-0000c7c0: 2061 7320 7468 6520 6669 7273 7420 6368   as the first ch
-0000c7d0: 6172 6163 7465 7220 616e 6420 7769 7468  aracter and with
-0000c7e0: 206c 6561 6469 6e67 2f74 7261 696c 696e   leading/trailin
-0000c7f0: 6720 7370 6163 6573 0a20 2020 2020 2020  g spaces.       
-0000c800: 2023 202a 2055 6e6e 6563 6573 7361 7269   # * Unnecessari
-0000c810: 6c79 2071 756f 7465 6420 6669 6c65 6e61  ly quoted filena
-0000c820: 6d65 7320 7769 7468 2f77 6974 686f 7574  mes with/without
-0000c830: 206d 6f64 6966 6965 7220 2862 6f74 6820   modifier (both 
-0000c840: 2220 616e 6420 2729 0a0a 2020 2020 2020  " and ')..      
-0000c850: 2020 2320 4372 6561 7465 2061 2066 696c    # Create a fil
-0000c860: 656c 6973 740a 2020 2020 2020 2020 7769  elist.        wi
-0000c870: 7468 2069 6f2e 6f70 656e 2875 2274 6573  th io.open(u"tes
-0000c880: 7466 696c 6573 2f65 7863 6c75 6465 2e74  tfiles/exclude.t
-0000c890: 7874 222c 2075 2277 2229 2061 7320 663a  xt", u"w") as f:
-0000c8a0: 0a20 2020 2020 2020 2020 2020 2066 2e77  .            f.w
-0000c8b0: 7269 7465 2875 222b 2074 6573 7466 696c  rite(u"+ testfil
-0000c8c0: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
-0000c8d0: 6233 2f33 7375 6233 7375 6232 2f33 7375  b3/3sub3sub2/3su
-0000c8e0: 6233 7375 6232 5f66 696c 652e 7478 745c  b3sub2_file.txt\
-0000c8f0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000c900: 2020 2020 2020 2075 2274 6573 7466 696c         u"testfil
-0000c910: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
-0000c920: 6233 2f33 7375 6233 7375 6232 5c6e 220a  b3/3sub3sub2\n".
-0000c930: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c940: 2020 2020 7522 2b20 7465 7374 6669 6c65      u"+ testfile
-0000c950: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-0000c960: 322f 3373 7562 3273 7562 325c 6e22 0a20  2/3sub2sub2\n". 
-0000c970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c980: 2020 2075 2220 2b20 7465 7374 6669 6c65     u" + testfile
-0000c990: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-0000c9a0: 335c 6e22 2020 2320 4e6f 7465 206c 6561  3\n"  # Note lea
-0000c9b0: 6469 6e67 2073 7061 6365 2061 6464 6564  ding space added
-0000c9c0: 2068 6572 650a 2020 2020 2020 2020 2020   here.          
-0000c9d0: 2020 2020 2020 2020 2020 7522 2d20 7465            u"- te
-0000c9e0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000c9f0: 332f 3373 7562 315c 6e22 0a20 2020 2020  3/3sub1\n".     
-0000ca00: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000ca10: 2220 2074 6573 7466 696c 6573 2f73 656c  "  testfiles/sel
-0000ca20: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
-0000ca30: 6231 7375 6233 5c6e 2220 2023 204e 6f74  b1sub3\n"  # Not
-0000ca40: 6520 6c65 6164 696e 6720 7370 6163 6573  e leading spaces
-0000ca50: 2061 6464 6564 2068 6572 650a 2020 2020   added here.    
-0000ca60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ca70: 7522 5c6e 220a 2020 2020 2020 2020 2020  u"\n".          
-0000ca80: 2020 2020 2020 2020 2020 7522 7465 7374            u"test
-0000ca90: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-0000caa0: 3273 7562 312f 3273 7562 3173 7562 325c  2sub1/2sub1sub2\
-0000cab0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000cac0: 2020 2020 2020 2075 2220 2b20 7465 7374         u" + test
-0000cad0: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-0000cae0: 3273 7562 3120 5c6e 2220 2023 204e 6f74  2sub1 \n"  # Not
-0000caf0: 6520 6164 6465 6420 7472 6169 6c69 6e67  e added trailing
-0000cb00: 2f6c 6561 6469 6e67 2073 7061 6365 2068  /leading space h
-0000cb10: 6572 650a 2020 2020 2020 2020 2020 2020  ere.            
-0000cb20: 2020 2020 2020 2020 7527 2d20 2274 6573          u'- "tes
-0000cb30: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-0000cb40: 2f31 7375 6233 2f31 7375 6233 7375 6232  /1sub3/1sub3sub2
-0000cb50: 225c 6e27 2020 2320 556e 6e65 6365 7373  "\n'  # Unnecess
-0000cb60: 6172 7920 7175 6f74 6573 0a20 2020 2020  ary quotes.     
-0000cb70: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000cb80: 2223 2054 6573 7469 6e67 2061 2066 756c  "# Testing a ful
-0000cb90: 6c2d 6c69 6e65 2063 6f6d 6d65 6e74 5c6e  l-line comment\n
-0000cba0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000cbb0: 2020 2020 2020 7522 2774 6573 7466 696c        u"'testfil
-0000cbc0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-0000cbd0: 6233 2f31 7375 6233 7375 6231 2720 205c  b3/1sub3sub1'  \
-0000cbe0: 6e22 2020 2320 4e6f 7465 2061 6464 6564  n"  # Note added
-0000cbf0: 2073 7061 6365 7320 616e 6420 7175 6f74   spaces and quot
-0000cc00: 6573 2068 6572 650a 2020 2020 2020 2020  es here.        
-0000cc10: 2020 2020 2020 2020 2020 2020 7522 7465              u"te
-0000cc20: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000cc30: 312f 3173 7562 322f 3173 7562 3273 7562  1/1sub2/1sub2sub
-0000cc40: 335c 6e22 0a20 2020 2020 2020 2020 2020  3\n".           
-0000cc50: 2020 2020 2020 2020 2075 2220 2020 205c           u"    \
-0000cc60: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000cc70: 2020 2020 2020 2075 222b 2074 6573 7466         u"+ testf
-0000cc80: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-0000cc90: 7375 6232 2f31 7375 6232 7375 6231 5c6e  sub2/1sub2sub1\n
-0000cca0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000ccb0: 2020 2020 2020 7522 2d20 7465 7374 6669        u"- testfi
-0000ccc0: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-0000ccd0: 7562 312f 3173 7562 3173 7562 332f 3173  ub1/1sub1sub3/1s
-0000cce0: 7562 3173 7562 335f 6669 6c65 2e74 7874  ub1sub3_file.txt
-0000ccf0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000cd00: 2020 2020 2020 2020 7522 7465 7374 6669          u"testfi
-0000cd10: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-0000cd20: 7562 312f 3173 7562 3173 7562 325c 6e22  ub1/1sub1sub2\n"
-0000cd30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000cd40: 2020 2020 2075 2220 2020 2020 2320 5465       u"     # Te
-0000cd50: 7374 696e 6720 6120 6675 6c6c 2d6c 696e  sting a full-lin
-0000cd60: 6520 636f 6d6d 656e 7420 7769 7468 206c  e comment with l
-0000cd70: 6561 6469 6e67 2061 6e64 2074 7261 696c  eading and trail
-0000cd80: 696e 6720 7370 6163 6573 2020 2020 205c  ing spaces     \
-0000cd90: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000cda0: 2020 2020 2020 2075 2274 6573 7466 696c         u"testfil
-0000cdb0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-0000cdc0: 6232 2020 5c6e 2220 2023 204e 6f74 6520  b2  \n"  # Note 
-0000cdd0: 6164 6465 6420 7370 6163 6573 2068 6572  added spaces her
-0000cde0: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-0000cdf0: 2020 2020 2020 7522 2b20 7465 7374 6669        u"+ testfi
-0000ce00: 6c65 732f 7365 6c65 6374 322f 312e 7079  les/select2/1.py
-0000ce10: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000ce20: 2020 2020 2020 2020 7522 2b20 7465 7374          u"+ test
-0000ce30: 6669 6c65 732f 7365 6c65 6374 322f 3320  files/select2/3 
-0000ce40: 5c6e 2220 2023 204e 6f74 6520 6164 6465  \n"  # Note adde
-0000ce50: 6420 7370 6163 6520 6865 7265 0a20 2020  d space here.   
-0000ce60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ce70: 2075 222b 2074 6573 7466 696c 6573 2f73   u"+ testfiles/s
-0000ce80: 656c 6563 7432 2f31 5c6e 220a 2020 2020  elect2/1\n".    
-0000ce90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cea0: 7522 2d20 7465 7374 6669 6c65 732f 7365  u"- testfiles/se
-0000ceb0: 6c65 6374 322f 2a2a 2229 0a20 2020 2020  lect2/**").     
-0000cec0: 2020 2073 656c 662e 6261 636b 7570 2875     self.backup(u
-0000ced0: 2266 756c 6c22 2c20 7522 7465 7374 6669  "full", u"testfi
-0000cee0: 6c65 732f 7365 6c65 6374 3222 2c20 6f70  les/select2", op
-0000cef0: 7469 6f6e 733d 5b75 222d 2d65 7863 6c75  tions=[u"--exclu
-0000cf00: 6465 2d67 6c6f 6262 696e 672d 6669 6c65  de-globbing-file
-0000cf10: 6c69 7374 3d74 6573 7466 696c 6573 2f65  list=testfiles/e
-0000cf20: 7863 6c75 6465 2e74 7874 225d 290a 2020  xclude.txt"]).  
-0000cf30: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
-0000cf40: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
-0000cf50: 746f 7265 5f64 6972 203d 2075 2274 6573  tore_dir = u"tes
-0000cf60: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
-0000cf70: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
-0000cf80: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
-0000cf90: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
-0000cfa0: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
-0000cfb0: 6f72 655f 6469 7229 0a20 2020 2020 2020  ore_dir).       
-0000cfc0: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
-0000cfd0: 6c28 7265 7374 6f72 6564 2c20 7365 6c66  l(restored, self
-0000cfe0: 2e65 7870 6563 7465 645f 7265 7374 6f72  .expected_restor
-0000cff0: 6564 5f74 7265 6529 0a0a 2020 2020 6465  ed_tree)..    de
-0000d000: 6620 7465 7374 5f65 7863 6c75 6465 5f67  f test_exclude_g
-0000d010: 6c6f 6262 696e 675f 6669 6c65 6c69 7374  lobbing_filelist
-0000d020: 5f69 735f 616c 7761 7973 5f67 6c6f 6262  _is_always_globb
-0000d030: 696e 6728 7365 6c66 293a 0a20 2020 2020  ing(self):.     
-0000d040: 2020 2075 2222 2254 6573 7420 7468 6174     u"""Test that
-0000d050: 2065 7863 6c75 6465 2067 6c6f 6262 696e   exclude globbin
-0000d060: 6720 6669 6c65 6c69 7374 2077 6f72 6b73  g filelist works
-0000d070: 2077 6974 6820 696d 7065 7266 6563 7469   with imperfecti
-0000d080: 6f6e 7320 696e 2074 6865 2069 6e70 7574  ons in the input
-0000d090: 2066 696c 6522 2222 0a20 2020 2020 2020   file""".       
-0000d0a0: 2023 2049 6465 6e74 6963 616c 2074 6f20   # Identical to 
-0000d0b0: 7465 7374 5f65 7863 6c75 6465 5f66 696c  test_exclude_fil
-0000d0c0: 656c 6973 745f 636f 6d62 696e 6564 5f69  elist_combined_i
-0000d0d0: 6d70 6572 6665 6374 696f 6e73 2061 6e64  mperfections and
-0000d0e0: 2069 6e63 6c75 6465 6420 746f 2065 6e73   included to ens
-0000d0f0: 7572 6520 7468 6174 0a20 2020 2020 2020  ure that.       
-0000d100: 2023 2074 6865 2064 6570 7265 6361 7465   # the deprecate
-0000d110: 6420 2d2d 6578 636c 7564 652d 676c 6f62  d --exclude-glob
-0000d120: 6269 6e67 2d66 696c 656c 6973 7420 6675  bing-filelist fu
-0000d130: 6e63 7469 6f6e 2077 6f72 6b73 2061 7320  nction works as 
-0000d140: 6578 7065 6374 6564 2075 6e74 696c 2069  expected until i
-0000d150: 7420 6973 2064 656c 6962 6572 6174 656c  t is deliberatel
-0000d160: 7920 7265 6d6f 7665 642e 0a20 2020 2020  y removed..     
-0000d170: 2020 2023 2054 6869 7320 7465 7374 2069     # This test i
-0000d180: 7320 7265 7175 6972 6564 2061 7320 7768  s required as wh
-0000d190: 656e 202d 2d66 696c 7465 722d 2a20 6f70  en --filter-* op
-0000d1a0: 7469 6f6e 7320 6172 6520 7573 6564 2074  tions are used t
-0000d1b0: 6865 2073 7461 6e64 6172 6420 2d2d 6578  he standard --ex
-0000d1c0: 636c 7564 652d 6669 6c65 6c69 7374 206f  clude-filelist o
-0000d1d0: 7074 696f 6e0a 2020 2020 2020 2020 2320  ption.        # 
-0000d1e0: 6d61 7920 6e6f 7420 6265 2069 6e20 676c  may not be in gl
-0000d1f0: 6f62 6269 6e67 206d 6f64 652c 2062 7574  obbing mode, but
-0000d200: 2074 6865 2064 6570 7265 6361 7465 6420   the deprecated 
-0000d210: 2d2d 6578 636c 7564 652d 676c 6f62 6269  --exclude-globbi
-0000d220: 6e67 2d66 696c 656c 6973 7420 7368 6f75  ng-filelist shou
-0000d230: 6c64 2062 6520 6576 656e 2069 660a 2020  ld be even if.  
-0000d240: 2020 2020 2020 2320 7072 6563 6564 6564        # preceded
-0000d250: 2062 7920 6120 6e6f 6e2d 676c 6f62 6269   by a non-globbi
-0000d260: 6e67 2066 696c 7465 7220 6d6f 6465 2073  ng filter mode s
-0000d270: 7769 7463 682e 0a20 2020 2020 2020 2023  witch..        #
-0000d280: 2043 7265 6174 6520 6120 6669 6c65 6c69   Create a fileli
-0000d290: 7374 0a20 2020 2020 2020 2077 6974 6820  st.        with 
-0000d2a0: 696f 2e6f 7065 6e28 7522 7465 7374 6669  io.open(u"testfi
-0000d2b0: 6c65 732f 6578 636c 7564 652e 7478 7422  les/exclude.txt"
-0000d2c0: 2c20 7522 7722 2920 6173 2066 3a0a 2020  , u"w") as f:.  
-0000d2d0: 2020 2020 2020 2020 2020 662e 7772 6974            f.writ
-0000d2e0: 6528 7522 2b20 7465 7374 6669 6c65 732f  e(u"+ testfiles/
-0000d2f0: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
-0000d300: 3373 7562 3373 7562 322f 3373 7562 3373  3sub3sub2/3sub3s
-0000d310: 7562 325f 6669 6c65 2e74 7874 5c6e 220a  ub2_file.txt\n".
-0000d320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d330: 2020 2020 7522 7465 7374 6669 6c65 732f      u"testfiles/
-0000d340: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
-0000d350: 3373 7562 3373 7562 325c 6e22 0a20 2020  3sub3sub2\n".   
-0000d360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d370: 2075 222b 2074 6573 7466 696c 6573 2f73   u"+ testfiles/s
-0000d380: 656c 6563 7432 2f33 2f33 7375 6232 2f33  elect2/3/3sub2/3
-0000d390: 7375 6232 7375 6232 5c6e 220a 2020 2020  sub2sub2\n".    
-0000d3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d3b0: 7522 202b 2074 6573 7466 696c 6573 2f73  u" + testfiles/s
-0000d3c0: 656c 6563 7432 2f33 2f33 7375 6233 5c6e  elect2/3/3sub3\n
-0000d3d0: 2220 2023 204e 6f74 6520 6c65 6164 696e  "  # Note leadin
-0000d3e0: 6720 7370 6163 6520 6164 6465 6420 6865  g space added he
-0000d3f0: 7265 0a20 2020 2020 2020 2020 2020 2020  re.             
-0000d400: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-0000d410: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
-0000d420: 7375 6231 5c6e 220a 2020 2020 2020 2020  sub1\n".        
-0000d430: 2020 2020 2020 2020 2020 2020 7522 2020              u"  
-0000d440: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-0000d450: 322f 322f 3273 7562 312f 3273 7562 3173  2/2/2sub1/2sub1s
-0000d460: 7562 335c 6e22 2020 2320 4e6f 7465 206c  ub3\n"  # Note l
-0000d470: 6561 6469 6e67 2073 7061 6365 7320 6164  eading spaces ad
-0000d480: 6465 6420 6865 7265 0a20 2020 2020 2020  ded here.       
-0000d490: 2020 2020 2020 2020 2020 2020 2075 225c               u"\
-0000d4a0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000d4b0: 2020 2020 2020 2075 2274 6573 7466 696c         u"testfil
-0000d4c0: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
-0000d4d0: 6231 2f32 7375 6231 7375 6232 5c6e 220a  b1/2sub1sub2\n".
-0000d4e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d4f0: 2020 2020 7522 202b 2074 6573 7466 696c      u" + testfil
-0000d500: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
-0000d510: 6231 205c 6e22 2020 2320 4e6f 7465 2061  b1 \n"  # Note a
-0000d520: 6464 6564 2074 7261 696c 696e 672f 6c65  dded trailing/le
-0000d530: 6164 696e 6720 7370 6163 6520 6865 7265  ading space here
-0000d540: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d550: 2020 2020 2075 272d 2022 7465 7374 6669       u'- "testfi
-0000d560: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-0000d570: 7562 332f 3173 7562 3373 7562 3222 5c6e  ub3/1sub3sub2"\n
-0000d580: 2720 2023 2055 6e6e 6563 6573 7361 7279  '  # Unnecessary
-0000d590: 2071 756f 7465 730a 2020 2020 2020 2020   quotes.        
-0000d5a0: 2020 2020 2020 2020 2020 2020 7522 2320              u"# 
-0000d5b0: 5465 7374 696e 6720 6120 6675 6c6c 2d6c  Testing a full-l
-0000d5c0: 696e 6520 636f 6d6d 656e 745c 6e22 0a20  ine comment\n". 
-0000d5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d5e0: 2020 2075 2227 7465 7374 6669 6c65 732f     u"'testfiles/
-0000d5f0: 7365 6c65 6374 322f 312f 3173 7562 332f  select2/1/1sub3/
-0000d600: 3173 7562 3373 7562 3127 2020 5c6e 2220  1sub3sub1'  \n" 
-0000d610: 2023 204e 6f74 6520 6164 6465 6420 7370   # Note added sp
-0000d620: 6163 6573 2061 6e64 2071 756f 7465 7320  aces and quotes 
-0000d630: 6865 7265 0a20 2020 2020 2020 2020 2020  here.           
-0000d640: 2020 2020 2020 2020 2075 2274 6573 7466           u"testf
-0000d650: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-0000d660: 7375 6232 2f31 7375 6232 7375 6233 5c6e  sub2/1sub2sub3\n
-0000d670: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000d680: 2020 2020 2020 7522 2020 2020 5c6e 220a        u"    \n".
-0000d690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d6a0: 2020 2020 7522 2b20 7465 7374 6669 6c65      u"+ testfile
-0000d6b0: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-0000d6c0: 322f 3173 7562 3273 7562 315c 6e22 0a20  2/1sub2sub1\n". 
-0000d6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d6e0: 2020 2075 222d 2074 6573 7466 696c 6573     u"- testfiles
-0000d6f0: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
-0000d700: 2f31 7375 6231 7375 6233 2f31 7375 6231  /1sub1sub3/1sub1
-0000d710: 7375 6233 5f66 696c 652e 7478 745c 6e22  sub3_file.txt\n"
-0000d720: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d730: 2020 2020 2075 2274 6573 7466 696c 6573       u"testfiles
-0000d740: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
-0000d750: 2f31 7375 6231 7375 6232 5c6e 220a 2020  /1sub1sub2\n".  
-0000d760: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d770: 2020 7522 2020 2020 2023 2054 6573 7469    u"     # Testi
-0000d780: 6e67 2061 2066 756c 6c2d 6c69 6e65 2063  ng a full-line c
-0000d790: 6f6d 6d65 6e74 2077 6974 6820 6c65 6164  omment with lead
-0000d7a0: 696e 6720 616e 6420 7472 6169 6c69 6e67  ing and trailing
-0000d7b0: 2073 7061 6365 7320 2020 2020 5c6e 220a   spaces     \n".
-0000d7c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d7d0: 2020 2020 7522 7465 7374 6669 6c65 732f      u"testfiles/
-0000d7e0: 7365 6c65 6374 322f 312f 3173 7562 3220  select2/1/1sub2 
-0000d7f0: 205c 6e22 2020 2320 4e6f 7465 2061 6464   \n"  # Note add
-0000d800: 6564 2073 7061 6365 7320 6865 7265 0a20  ed spaces here. 
-0000d810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d820: 2020 2075 222b 2074 6573 7466 696c 6573     u"+ testfiles
-0000d830: 2f73 656c 6563 7432 2f31 2e70 795c 6e22  /select2/1.py\n"
-0000d840: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d850: 2020 2020 2075 222b 2074 6573 7466 696c       u"+ testfil
-0000d860: 6573 2f73 656c 6563 7432 2f33 205c 6e22  es/select2/3 \n"
-0000d870: 2020 2320 4e6f 7465 2061 6464 6564 2073    # Note added s
-0000d880: 7061 6365 2068 6572 650a 2020 2020 2020  pace here.      
-0000d890: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000d8a0: 2b20 7465 7374 6669 6c65 732f 7365 6c65  + testfiles/sele
-0000d8b0: 6374 322f 315c 6e22 0a20 2020 2020 2020  ct2/1\n".       
-0000d8c0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-0000d8d0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-0000d8e0: 7432 2f2a 2a22 290a 2020 2020 2020 2020  t2/**").        
-0000d8f0: 7365 6c66 2e62 6163 6b75 7028 7522 6675  self.backup(u"fu
-0000d900: 6c6c 222c 2075 2274 6573 7466 696c 6573  ll", u"testfiles
-0000d910: 2f73 656c 6563 7432 222c 0a20 2020 2020  /select2",.     
-0000d920: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-0000d930: 7074 696f 6e73 3d5b 7522 2d2d 6669 6c74  ptions=[u"--filt
-0000d940: 6572 2d6c 6974 6572 616c 222c 0a20 2020  er-literal",.   
-0000d950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d960: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-0000d970: 636c 7564 652d 676c 6f62 6269 6e67 2d66  clude-globbing-f
-0000d980: 696c 656c 6973 743d 7465 7374 6669 6c65  ilelist=testfile
-0000d990: 732f 6578 636c 7564 652e 7478 7422 5d29  s/exclude.txt"])
-0000d9a0: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-0000d9b0: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
-0000d9c0: 7265 7374 6f72 655f 6469 7220 3d20 7522  restore_dir = u"
-0000d9d0: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
-0000d9e0: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
-0000d9f0: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
-0000da00: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
-0000da10: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
-0000da20: 6573 746f 7265 5f64 6972 290a 2020 2020  estore_dir).    
-0000da30: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
-0000da40: 7175 616c 2872 6573 746f 7265 642c 2073  qual(restored, s
-0000da50: 656c 662e 6578 7065 6374 6564 5f72 6573  elf.expected_res
-0000da60: 746f 7265 645f 7472 6565 290a 0a20 2020  tored_tree)..   
-0000da70: 2064 6566 2074 6573 745f 6578 636c 7564   def test_exclud
-0000da80: 655f 6669 6c65 6c69 7374 5f74 7261 696c  e_filelist_trail
-0000da90: 696e 675f 7768 6974 6573 7061 6365 5f66  ing_whitespace_f
-0000daa0: 6f6c 6465 7273 5f77 6f72 6b5f 7769 7468  olders_work_with
-0000dab0: 5f71 756f 7465 7328 7365 6c66 293a 0a20  _quotes(self):. 
-0000dac0: 2020 2020 2020 2075 2222 2254 6573 7420         u"""Test 
-0000dad0: 7468 6174 2066 6f6c 6465 7273 2077 6974  that folders wit
-0000dae0: 6820 7472 6169 6c69 6e67 2077 6869 7465  h trailing white
-0000daf0: 7370 6163 6520 696e 2074 6865 206e 616d  space in the nam
-0000db00: 6573 2077 6f72 6b20 636f 7272 6563 746c  es work correctl
-0000db10: 7920 6966 2074 6865 7920 6172 6520 656e  y if they are en
-0000db20: 636c 6f73 6564 2069 6e20 7175 6f74 6573  closed in quotes
-0000db30: 2222 220a 2020 2020 2020 2020 2320 4372  """.        # Cr
-0000db40: 6561 7465 2061 2066 696c 656c 6973 740a  eate a filelist.
-0000db50: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
-0000db60: 6f70 656e 2875 2274 6573 7466 696c 6573  open(u"testfiles
-0000db70: 2f65 7863 6c75 6465 2e74 7874 222c 2075  /exclude.txt", u
-0000db80: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
-0000db90: 2020 2020 2020 2066 2e77 7269 7465 2875         f.write(u
-0000dba0: 272b 2022 7465 7374 6669 6c65 732f 7365  '+ "testfiles/se
-0000dbb0: 6c65 6374 322f 7472 6169 6c69 6e67 5f73  lect2/trailing_s
-0000dbc0: 7061 6365 202f 7472 6169 6c69 6e67 5f73  pace /trailing_s
-0000dbd0: 7061 6365 2073 7562 322f 7472 6169 6c69  pace sub2/traili
-0000dbe0: 6e67 5f73 7061 6365 2073 7562 325f 6669  ng_space sub2_fi
-0000dbf0: 6c65 2e74 7874 225c 6e27 2020 2320 4e65  le.txt"\n'  # Ne
-0000dc00: 770a 2020 2020 2020 2020 2020 2020 2020  w.              
-0000dc10: 2020 2020 2020 7522 2d20 2774 6573 7466        u"- 'testf
-0000dc20: 696c 6573 2f73 656c 6563 7432 2f74 7261  iles/select2/tra
-0000dc30: 696c 696e 675f 7370 6163 6520 2f74 7261  iling_space /tra
-0000dc40: 696c 696e 675f 7370 6163 6520 7375 6232  iling_space sub2
-0000dc50: 275c 6e22 2020 2320 4e65 770a 2020 2020  '\n"  # New.    
-0000dc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dc70: 7527 2b20 2274 6573 7466 696c 6573 2f73  u'+ "testfiles/s
-0000dc80: 656c 6563 7432 2f74 7261 696c 696e 675f  elect2/trailing_
-0000dc90: 7370 6163 6520 225c 6e27 2020 2320 4e65  space "\n'  # Ne
-0000dca0: 770a 2020 2020 2020 2020 2020 2020 2020  w.              
-0000dcb0: 2020 2020 2020 7522 2b20 7465 7374 6669        u"+ testfi
-0000dcc0: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
-0000dcd0: 7562 332f 3373 7562 3373 7562 322f 3373  ub3/3sub3sub2/3s
-0000dce0: 7562 3373 7562 325f 6669 6c65 2e74 7874  ub3sub2_file.txt
-0000dcf0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000dd00: 2020 2020 2020 2020 7522 7465 7374 6669          u"testfi
-0000dd10: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
-0000dd20: 7562 332f 3373 7562 3373 7562 325c 6e22  ub3/3sub3sub2\n"
-0000dd30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000dd40: 2020 2020 2075 222b 2074 6573 7466 696c       u"+ testfil
-0000dd50: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
-0000dd60: 6232 2f33 7375 6232 7375 6232 5c6e 220a  b2/3sub2sub2\n".
-0000dd70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dd80: 2020 2020 7522 2b20 7465 7374 6669 6c65      u"+ testfile
-0000dd90: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-0000dda0: 335c 6e22 0a20 2020 2020 2020 2020 2020  3\n".           
-0000ddb0: 2020 2020 2020 2020 2075 222d 2074 6573           u"- tes
-0000ddc0: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
-0000ddd0: 2f33 7375 6231 5c6e 220a 2020 2020 2020  /3sub1\n".      
-0000dde0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000ddf0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-0000de00: 322f 322f 3273 7562 312f 3273 7562 3173  2/2/2sub1/2sub1s
-0000de10: 7562 335c 6e22 0a20 2020 2020 2020 2020  ub3\n".         
-0000de20: 2020 2020 2020 2020 2020 2075 2274 6573             u"tes
-0000de30: 7466 696c 6573 2f73 656c 6563 7432 2f32  tfiles/select2/2
-0000de40: 2f32 7375 6231 2f32 7375 6231 7375 6232  /2sub1/2sub1sub2
-0000de50: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000de60: 2020 2020 2020 2020 7522 2b20 7465 7374          u"+ test
-0000de70: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-0000de80: 3273 7562 315c 6e22 0a20 2020 2020 2020  2sub1\n".       
-0000de90: 2020 2020 2020 2020 2020 2020 2075 2274               u"t
-0000dea0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-0000deb0: 2f31 2f31 7375 6233 2f31 7375 6233 7375  /1/1sub3/1sub3su
-0000dec0: 6232 5c6e 220a 2020 2020 2020 2020 2020  b2\n".          
-0000ded0: 2020 2020 2020 2020 2020 7522 7465 7374            u"test
-0000dee0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-0000def0: 3173 7562 332f 3173 7562 3373 7562 315c  1sub3/1sub3sub1\
-0000df00: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000df10: 2020 2020 2020 2075 2274 6573 7466 696c         u"testfil
-0000df20: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-0000df30: 6232 2f31 7375 6232 7375 6233 5c6e 220a  b2/1sub2sub3\n".
-0000df40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df50: 2020 2020 7522 2b20 7465 7374 6669 6c65      u"+ testfile
-0000df60: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-0000df70: 322f 3173 7562 3273 7562 315c 6e22 0a20  2/1sub2sub1\n". 
-0000df80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df90: 2020 2075 2274 6573 7466 696c 6573 2f73     u"testfiles/s
-0000dfa0: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
-0000dfb0: 7375 6231 7375 6233 2f31 7375 6231 7375  sub1sub3/1sub1su
-0000dfc0: 6233 5f66 696c 652e 7478 745c 6e22 0a20  b3_file.txt\n". 
-0000dfd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dfe0: 2020 2075 2274 6573 7466 696c 6573 2f73     u"testfiles/s
-0000dff0: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
-0000e000: 7375 6231 7375 6232 5c6e 220a 2020 2020  sub1sub2\n".    
-0000e010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e020: 7522 2d20 7465 7374 6669 6c65 732f 7365  u"- testfiles/se
-0000e030: 6c65 6374 322f 312f 3173 7562 325c 6e22  lect2/1/1sub2\n"
-0000e040: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e050: 2020 2020 2075 222b 2074 6573 7466 696c       u"+ testfil
-0000e060: 6573 2f73 656c 6563 7432 2f31 2e70 795c  es/select2/1.py\
+0000bf30: 2020 2020 222b 2074 6573 7466 696c 6573      "+ testfiles
+0000bf40: 2f73 656c 6563 7432 2f31 5c6e 220a 2020  /select2/1\n".  
+0000bf50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bf60: 2020 222d 2074 6573 7466 696c 6573 2f73    "- testfiles/s
+0000bf70: 656c 6563 7432 2f2a 2a22 290a 2020 2020  elect2/**").    
+0000bf80: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
+0000bf90: 2266 756c 6c22 2c20 2274 6573 7466 696c  "full", "testfil
+0000bfa0: 6573 2f73 656c 6563 7432 222c 206f 7074  es/select2", opt
+0000bfb0: 696f 6e73 3d5b 222d 2d65 7863 6c75 6465  ions=["--exclude
+0000bfc0: 2d66 696c 656c 6973 743d 7465 7374 6669  -filelist=testfi
+0000bfd0: 6c65 732f 6578 636c 7564 652e 7478 7422  les/exclude.txt"
+0000bfe0: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
+0000bff0: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
+0000c000: 2020 7265 7374 6f72 655f 7061 7468 203d    restore_path =
+0000c010: 2022 7465 7374 6669 6c65 732f 7265 7374   "testfiles/rest
+0000c020: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
+0000c030: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
+0000c040: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
+0000c050: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
+0000c060: 2872 6573 746f 7265 5f70 6174 6829 0a20  (restore_path). 
+0000c070: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
+0000c080: 7274 4571 7561 6c28 7265 7374 6f72 6564  rtEqual(restored
+0000c090: 2c20 7365 6c66 2e65 7870 6563 7465 645f  , self.expected_
+0000c0a0: 7265 7374 6f72 6564 5f74 7265 6529 0a0a  restored_tree)..
+0000c0b0: 2020 2020 6465 6620 7465 7374 5f65 7863      def test_exc
+0000c0c0: 6c75 6465 5f66 696c 656c 6973 745f 7472  lude_filelist_tr
+0000c0d0: 6169 6c69 6e67 5f77 6869 7465 7370 6163  ailing_whitespac
+0000c0e0: 655f 666f 6c64 6572 735f 776f 726b 5f77  e_folders_work_w
+0000c0f0: 6974 685f 7175 6f74 6573 2873 656c 6629  ith_quotes(self)
+0000c100: 3a0a 2020 2020 2020 2020 2222 2254 6573  :.        """Tes
+0000c110: 7420 7468 6174 2066 6f6c 6465 7273 2077  t that folders w
+0000c120: 6974 6820 7472 6169 6c69 6e67 2077 6869  ith trailing whi
+0000c130: 7465 7370 6163 6520 696e 2074 6865 206e  tespace in the n
+0000c140: 616d 6573 2077 6f72 6b20 636f 7272 6563  ames work correc
+0000c150: 746c 7920 6966 2074 6865 7920 6172 6520  tly if they are 
+0000c160: 656e 636c 6f73 6564 2069 6e20 7175 6f74  enclosed in quot
+0000c170: 6573 2222 220a 2020 2020 2020 2020 2320  es""".        # 
+0000c180: 4372 6561 7465 2061 2066 696c 656c 6973  Create a filelis
+0000c190: 740a 2020 2020 2020 2020 7769 7468 2069  t.        with i
+0000c1a0: 6f2e 6f70 656e 2822 7465 7374 6669 6c65  o.open("testfile
+0000c1b0: 732f 6578 636c 7564 652e 7478 7422 2c20  s/exclude.txt", 
+0000c1c0: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
+0000c1d0: 2020 2020 2020 2066 2e77 7269 7465 2827         f.write('
+0000c1e0: 2b20 2274 6573 7466 696c 6573 2f73 656c  + "testfiles/sel
+0000c1f0: 6563 7432 2f74 7261 696c 696e 675f 7370  ect2/trailing_sp
+0000c200: 6163 6520 2f74 7261 696c 696e 675f 7370  ace /trailing_sp
+0000c210: 6163 6520 7375 6232 2f74 7261 696c 696e  ace sub2/trailin
+0000c220: 675f 7370 6163 6520 7375 6232 5f66 696c  g_space sub2_fil
+0000c230: 652e 7478 7422 5c6e 2720 2023 204e 6577  e.txt"\n'  # New
+0000c240: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c250: 2020 2020 2022 2d20 2774 6573 7466 696c       "- 'testfil
+0000c260: 6573 2f73 656c 6563 7432 2f74 7261 696c  es/select2/trail
+0000c270: 696e 675f 7370 6163 6520 2f74 7261 696c  ing_space /trail
+0000c280: 696e 675f 7370 6163 6520 7375 6232 275c  ing_space sub2'\
+0000c290: 6e22 2020 2320 4e65 770a 2020 2020 2020  n"  # New.      
+0000c2a0: 2020 2020 2020 2020 2020 2020 2020 272b                '+
+0000c2b0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+0000c2c0: 6374 322f 7472 6169 6c69 6e67 5f73 7061  ct2/trailing_spa
+0000c2d0: 6365 2022 5c6e 2720 2023 204e 6577 0a20  ce "\n'  # New. 
+0000c2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c2f0: 2020 2022 2b20 7465 7374 6669 6c65 732f     "+ testfiles/
+0000c300: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
+0000c310: 3373 7562 3373 7562 322f 3373 7562 3373  3sub3sub2/3sub3s
+0000c320: 7562 325f 6669 6c65 2e74 7874 5c6e 220a  ub2_file.txt\n".
+0000c330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c340: 2020 2020 2274 6573 7466 696c 6573 2f73      "testfiles/s
+0000c350: 656c 6563 7432 2f33 2f33 7375 6233 2f33  elect2/3/3sub3/3
+0000c360: 7375 6233 7375 6232 5c6e 220a 2020 2020  sub3sub2\n".    
+0000c370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c380: 222b 2074 6573 7466 696c 6573 2f73 656c  "+ testfiles/sel
+0000c390: 6563 7432 2f33 2f33 7375 6232 2f33 7375  ect2/3/3sub2/3su
+0000c3a0: 6232 7375 6232 5c6e 220a 2020 2020 2020  b2sub2\n".      
+0000c3b0: 2020 2020 2020 2020 2020 2020 2020 222b                "+
+0000c3c0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
+0000c3d0: 7432 2f33 2f33 7375 6233 5c6e 220a 2020  t2/3/3sub3\n".  
+0000c3e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c3f0: 2020 222d 2074 6573 7466 696c 6573 2f73    "- testfiles/s
+0000c400: 656c 6563 7432 2f33 2f33 7375 6231 5c6e  elect2/3/3sub1\n
+0000c410: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000c420: 2020 2020 2020 2274 6573 7466 696c 6573        "testfiles
+0000c430: 2f73 656c 6563 7432 2f32 2f32 7375 6231  /select2/2/2sub1
+0000c440: 2f32 7375 6231 7375 6233 5c6e 220a 2020  /2sub1sub3\n".  
+0000c450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c460: 2020 2274 6573 7466 696c 6573 2f73 656c    "testfiles/sel
+0000c470: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
+0000c480: 6231 7375 6232 5c6e 220a 2020 2020 2020  b1sub2\n".      
+0000c490: 2020 2020 2020 2020 2020 2020 2020 222b                "+
+0000c4a0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
+0000c4b0: 7432 2f32 2f32 7375 6231 5c6e 220a 2020  t2/2/2sub1\n".  
+0000c4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c4d0: 2020 2274 6573 7466 696c 6573 2f73 656c    "testfiles/sel
+0000c4e0: 6563 7432 2f31 2f31 7375 6233 2f31 7375  ect2/1/1sub3/1su
+0000c4f0: 6233 7375 6232 5c6e 220a 2020 2020 2020  b3sub2\n".      
+0000c500: 2020 2020 2020 2020 2020 2020 2020 2274                "t
+0000c510: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000c520: 2f31 2f31 7375 6233 2f31 7375 6233 7375  /1/1sub3/1sub3su
+0000c530: 6231 5c6e 220a 2020 2020 2020 2020 2020  b1\n".          
+0000c540: 2020 2020 2020 2020 2020 2274 6573 7466            "testf
+0000c550: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+0000c560: 7375 6232 2f31 7375 6232 7375 6233 5c6e  sub2/1sub2sub3\n
+0000c570: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000c580: 2020 2020 2020 222b 2074 6573 7466 696c        "+ testfil
+0000c590: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+0000c5a0: 6232 2f31 7375 6232 7375 6231 5c6e 220a  b2/1sub2sub1\n".
+0000c5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c5c0: 2020 2020 2274 6573 7466 696c 6573 2f73      "testfiles/s
+0000c5d0: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
+0000c5e0: 7375 6231 7375 6233 2f31 7375 6231 7375  sub1sub3/1sub1su
+0000c5f0: 6233 5f66 696c 652e 7478 745c 6e22 0a20  b3_file.txt\n". 
+0000c600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c610: 2020 2022 7465 7374 6669 6c65 732f 7365     "testfiles/se
+0000c620: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
+0000c630: 7562 3173 7562 325c 6e22 0a20 2020 2020  ub1sub2\n".     
+0000c640: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000c650: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
+0000c660: 6374 322f 312f 3173 7562 325c 6e22 0a20  ct2/1/1sub2\n". 
+0000c670: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c680: 2020 2022 2b20 7465 7374 6669 6c65 732f     "+ testfiles/
+0000c690: 7365 6c65 6374 322f 312e 7079 5c6e 220a  select2/1.py\n".
+0000c6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c6b0: 2020 2020 222b 2074 6573 7466 696c 6573      "+ testfiles
+0000c6c0: 2f73 656c 6563 7432 2f33 5c6e 220a 2020  /select2/3\n".  
+0000c6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c6e0: 2020 222b 2074 6573 7466 696c 6573 2f73    "+ testfiles/s
+0000c6f0: 656c 6563 7432 2f31 5c6e 220a 2020 2020  elect2/1\n".    
+0000c700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000c710: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+0000c720: 7432 2f2a 2a22 290a 2020 2020 2020 2020  t2/**").        
+0000c730: 7365 6c66 2e62 6163 6b75 7028 2266 756c  self.backup("ful
+0000c740: 6c22 2c20 2274 6573 7466 696c 6573 2f73  l", "testfiles/s
+0000c750: 656c 6563 7432 222c 206f 7074 696f 6e73  elect2", options
+0000c760: 3d5b 222d 2d65 7863 6c75 6465 2d66 696c  =["--exclude-fil
+0000c770: 656c 6973 743d 7465 7374 6669 6c65 732f  elist=testfiles/
+0000c780: 6578 636c 7564 652e 7478 7422 5d29 0a20  exclude.txt"]). 
+0000c790: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
+0000c7a0: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
+0000c7b0: 7374 6f72 655f 7061 7468 203d 2022 7465  store_path = "te
+0000c7c0: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
+0000c7d0: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
+0000c7e0: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
+0000c7f0: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
+0000c800: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
+0000c810: 746f 7265 5f70 6174 6829 0a20 2020 2020  tore_path).     
+0000c820: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
+0000c830: 7561 6c28 7265 7374 6f72 6564 2c20 7365  ual(restored, se
+0000c840: 6c66 2e65 7870 6563 7465 645f 7265 7374  lf.expected_rest
+0000c850: 6f72 6564 5f74 7265 655f 7769 7468 5f74  ored_tree_with_t
+0000c860: 7261 696c 696e 675f 7370 6163 6529 0a0a  railing_space)..
+0000c870: 2020 2020 6465 6620 7465 7374 5f65 7863      def test_exc
+0000c880: 6c75 6465 5f66 696c 656c 6973 745f 7072  lude_filelist_pr
+0000c890: 6f67 7265 7373 5f6f 7074 696f 6e28 7365  ogress_option(se
+0000c8a0: 6c66 293a 0a20 2020 2020 2020 2022 2222  lf):.        """
+0000c8b0: 5465 7374 2074 6861 7420 6578 636c 7564  Test that exclud
+0000c8c0: 6520 6669 6c65 6c69 7374 2069 7320 756e  e filelist is un
+0000c8d0: 6166 6665 6374 6564 2062 7920 7468 6520  affected by the 
+0000c8e0: 2d2d 7072 6f67 7265 7373 206f 7074 696f  --progress optio
+0000c8f0: 6e22 2222 0a20 2020 2020 2020 2023 2052  n""".        # R
+0000c900: 6567 7265 7373 696f 6e20 7465 7374 2066  egression test f
+0000c910: 6f72 2042 7567 2023 3132 3634 3734 3420  or Bug #1264744 
+0000c920: 2868 7474 7073 3a2f 2f62 7567 732e 6c61  (https://bugs.la
+0000c930: 756e 6368 7061 642e 6e65 742f 6475 706c  unchpad.net/dupl
+0000c940: 6963 6974 792f 2b62 7567 2f31 3236 3437  icity/+bug/12647
+0000c950: 3434 290a 2020 2020 2020 2020 2320 4372  44).        # Cr
+0000c960: 6561 7465 2061 2066 696c 656c 6973 7420  eate a filelist 
+0000c970: 6964 656e 7469 6361 6c20 746f 2074 6861  identical to tha
+0000c980: 7420 7573 6564 2069 6e20 7465 7374 5f65  t used in test_e
+0000c990: 7863 6c75 6465 5f66 696c 656c 6973 740a  xclude_filelist.
+0000c9a0: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
+0000c9b0: 6f70 656e 2822 7465 7374 6669 6c65 732f  open("testfiles/
+0000c9c0: 6578 636c 7564 652e 7478 7422 2c20 2277  exclude.txt", "w
+0000c9d0: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
+0000c9e0: 2020 2020 2066 2e77 7269 7465 2822 2b20       f.write("+ 
+0000c9f0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+0000ca00: 322f 332f 3373 7562 332f 3373 7562 3373  2/3/3sub3/3sub3s
+0000ca10: 7562 322f 3373 7562 3373 7562 325f 6669  ub2/3sub3sub2_fi
+0000ca20: 6c65 2e74 7874 5c6e 220a 2020 2020 2020  le.txt\n".      
+0000ca30: 2020 2020 2020 2020 2020 2020 2020 2274                "t
+0000ca40: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000ca50: 2f33 2f33 7375 6233 2f33 7375 6233 7375  /3/3sub3/3sub3su
+0000ca60: 6232 5c6e 220a 2020 2020 2020 2020 2020  b2\n".          
+0000ca70: 2020 2020 2020 2020 2020 222b 2074 6573            "+ tes
+0000ca80: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
+0000ca90: 2f33 7375 6232 2f33 7375 6232 7375 6232  /3sub2/3sub2sub2
+0000caa0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000cab0: 2020 2020 2020 2020 222b 2074 6573 7466          "+ testf
+0000cac0: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
+0000cad0: 7375 6233 5c6e 220a 2020 2020 2020 2020  sub3\n".        
+0000cae0: 2020 2020 2020 2020 2020 2020 222d 2074              "- t
+0000caf0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000cb00: 2f33 2f33 7375 6231 5c6e 2220 2023 202d  /3/3sub1\n"  # -
+0000cb10: 2061 6464 6564 2074 6f20 656e 7375 7265   added to ensure
+0000cb20: 2069 7420 6d61 6b65 7320 6e6f 2064 6966   it makes no dif
+0000cb30: 6665 7265 6e63 650a 2020 2020 2020 2020  ference.        
+0000cb40: 2020 2020 2020 2020 2020 2020 2274 6573              "tes
+0000cb50: 7466 696c 6573 2f73 656c 6563 7432 2f32  tfiles/select2/2
+0000cb60: 2f32 7375 6231 2f32 7375 6231 7375 6233  /2sub1/2sub1sub3
+0000cb70: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000cb80: 2020 2020 2020 2020 2274 6573 7466 696c          "testfil
+0000cb90: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
+0000cba0: 6231 2f32 7375 6231 7375 6232 5c6e 220a  b1/2sub1sub2\n".
+0000cbb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbc0: 2020 2020 222b 2074 6573 7466 696c 6573      "+ testfiles
+0000cbd0: 2f73 656c 6563 7432 2f32 2f32 7375 6231  /select2/2/2sub1
+0000cbe0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000cbf0: 2020 2020 2020 2020 2274 6573 7466 696c          "testfil
+0000cc00: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+0000cc10: 6233 2f31 7375 6233 7375 6232 5c6e 220a  b3/1sub3sub2\n".
+0000cc20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cc30: 2020 2020 2274 6573 7466 696c 6573 2f73      "testfiles/s
+0000cc40: 656c 6563 7432 2f31 2f31 7375 6233 2f31  elect2/1/1sub3/1
+0000cc50: 7375 6233 7375 6231 5c6e 220a 2020 2020  sub3sub1\n".    
+0000cc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cc70: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+0000cc80: 7432 2f31 2f31 7375 6232 2f31 7375 6232  t2/1/1sub2/1sub2
+0000cc90: 7375 6233 5c6e 220a 2020 2020 2020 2020  sub3\n".        
+0000cca0: 2020 2020 2020 2020 2020 2020 222b 2074              "+ t
+0000ccb0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000ccc0: 2f31 2f31 7375 6232 2f31 7375 6232 7375  /1/1sub2/1sub2su
+0000ccd0: 6231 5c6e 220a 2020 2020 2020 2020 2020  b1\n".          
+0000cce0: 2020 2020 2020 2020 2020 2274 6573 7466            "testf
+0000ccf0: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+0000cd00: 7375 6231 2f31 7375 6231 7375 6233 2f31  sub1/1sub1sub3/1
+0000cd10: 7375 6231 7375 6233 5f66 696c 652e 7478  sub1sub3_file.tx
+0000cd20: 745c 6e22 0a20 2020 2020 2020 2020 2020  t\n".           
+0000cd30: 2020 2020 2020 2020 2022 7465 7374 6669           "testfi
+0000cd40: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+0000cd50: 7562 312f 3173 7562 3173 7562 325c 6e22  ub1/1sub1sub2\n"
+0000cd60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000cd70: 2020 2020 2022 2d20 7465 7374 6669 6c65       "- testfile
+0000cd80: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
+0000cd90: 325c 6e22 2020 2320 2d20 6164 6465 6420  2\n"  # - added 
+0000cda0: 746f 2065 6e73 7572 6520 6974 206d 616b  to ensure it mak
+0000cdb0: 6573 206e 6f20 6469 6666 6572 656e 6365  es no difference
+0000cdc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000cdd0: 2020 2020 2022 2b20 7465 7374 6669 6c65       "+ testfile
+0000cde0: 732f 7365 6c65 6374 322f 312e 7079 5c6e  s/select2/1.py\n
+0000cdf0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000ce00: 2020 2020 2020 222b 2074 6573 7466 696c        "+ testfil
+0000ce10: 6573 2f73 656c 6563 7432 2f33 5c6e 220a  es/select2/3\n".
+0000ce20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce30: 2020 2020 222b 2074 6573 7466 696c 6573      "+ testfiles
+0000ce40: 2f73 656c 6563 7432 2f31 5c6e 220a 2020  /select2/1\n".  
+0000ce50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce60: 2020 2274 6573 7466 696c 6573 2f73 656c    "testfiles/sel
+0000ce70: 6563 7432 2f2a 2a22 290a 0a20 2020 2020  ect2/**")..     
+0000ce80: 2020 2023 2042 6163 6b75 7020 7468 6520     # Backup the 
+0000ce90: 6669 6c65 7320 6578 6163 746c 7920 6173  files exactly as
+0000cea0: 2069 6e20 7465 7374 5f65 7863 6c75 6465   in test_exclude
+0000ceb0: 5f66 696c 656c 6973 742c 2062 7574 2077  _filelist, but w
+0000cec0: 6974 6820 7468 6520 2d2d 7072 6f67 7265  ith the --progre
+0000ced0: 7373 206f 7074 696f 6e0a 2020 2020 2020  ss option.      
+0000cee0: 2020 7365 6c66 2e62 6163 6b75 7028 2266    self.backup("f
+0000cef0: 756c 6c22 2c20 2274 6573 7466 696c 6573  ull", "testfiles
+0000cf00: 2f73 656c 6563 7432 222c 206f 7074 696f  /select2", optio
+0000cf10: 6e73 3d5b 222d 2d65 7863 6c75 6465 2d66  ns=["--exclude-f
+0000cf20: 696c 656c 6973 743d 7465 7374 6669 6c65  ilelist=testfile
+0000cf30: 732f 6578 636c 7564 652e 7478 7422 2c0a  s/exclude.txt",.
+0000cf40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cf50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cf60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cf70: 2020 2020 2020 2020 2020 222d 2d70 726f            "--pro
+0000cf80: 6772 6573 7322 5d29 0a20 2020 2020 2020  gress"]).       
+0000cf90: 2073 656c 662e 7265 7374 6f72 6528 290a   self.restore().
+0000cfa0: 2020 2020 2020 2020 7265 7374 6f72 655f          restore_
+0000cfb0: 7061 7468 203d 2022 7465 7374 6669 6c65  path = "testfile
+0000cfc0: 732f 7265 7374 6f72 655f 6f75 7422 0a20  s/restore_out". 
+0000cfd0: 2020 2020 2020 2072 6573 746f 7265 6420         restored 
+0000cfe0: 3d20 7365 6c66 2e64 6972 6563 746f 7279  = self.directory
+0000cff0: 5f74 7265 655f 746f 5f6c 6973 745f 6f66  _tree_to_list_of
+0000d000: 5f6c 6973 7473 2872 6573 746f 7265 5f70  _lists(restore_p
+0000d010: 6174 6829 0a20 2020 2020 2020 2023 2054  ath).        # T
+0000d020: 6865 2072 6573 746f 7265 6420 6669 6c65  he restored file
+0000d030: 7320 7368 6f75 6c64 206d 6174 6368 2074  s should match t
+0000d040: 686f 7365 2072 6573 746f 7265 6420 696e  hose restored in
+0000d050: 2074 6573 745f 6578 636c 7564 655f 6669   test_exclude_fi
+0000d060: 6c65 6c69 7374 0a20 2020 2020 2020 2073  lelist.        s
+0000d070: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
+0000d080: 7265 7374 6f72 6564 2c20 7365 6c66 2e65  restored, self.e
+0000d090: 7870 6563 7465 645f 7265 7374 6f72 6564  xpected_restored
+0000d0a0: 5f74 7265 6529 0a0a 0a63 6c61 7373 2054  _tree)...class T
+0000d0b0: 6573 7449 6e63 6c75 6465 4669 6c65 6c69  estIncludeFileli
+0000d0c0: 7374 5465 7374 2849 6e63 6c75 6465 4578  stTest(IncludeEx
+0000d0d0: 636c 7564 6546 756e 6374 696f 6e61 6c54  cludeFunctionalT
+0000d0e0: 6573 7429 3a0a 2020 2020 2222 220a 2020  est):.    """.  
+0000d0f0: 2020 5465 7374 202d 2d69 6e63 6c75 6465    Test --include
+0000d100: 2d66 696c 656c 6973 7420 7573 696e 6720  -filelist using 
+0000d110: 6475 706c 6963 6974 7920 6269 6e61 7279  duplicity binary
+0000d120: 2e0a 2020 2020 2222 220a 0a20 2020 2064  ..    """..    d
+0000d130: 6566 2074 6573 745f 696e 636c 7564 655f  ef test_include_
+0000d140: 6669 6c65 6c69 7374 2873 656c 6629 3a0a  filelist(self):.
+0000d150: 2020 2020 2020 2020 2222 2254 6573 7420          """Test 
+0000d160: 7468 6174 2069 6e63 6c75 6465 2066 696c  that include fil
+0000d170: 656c 6973 7420 776f 726b 7320 696e 2074  elist works in t
+0000d180: 6865 2062 6173 6963 2063 6173 6522 2222  he basic case"""
+0000d190: 0a20 2020 2020 2020 2023 2053 6565 2074  .        # See t
+0000d1a0: 6573 745f 6578 636c 7564 655f 6669 6c65  est_exclude_file
+0000d1b0: 6c69 7374 2061 626f 7665 2066 6f72 2065  list above for e
+0000d1c0: 7870 6c61 6e61 7469 6f6e 206f 6620 7768  xplanation of wh
+0000d1d0: 6174 2069 7320 6578 7065 6374 6564 2e20  at is expected. 
+0000d1e0: 4173 2074 6869 7320 6973 2061 6e20 696e  As this is an in
+0000d1f0: 636c 7564 6520 6669 6c65 6c69 7374 0a20  clude filelist. 
+0000d200: 2020 2020 2020 2023 2061 6e79 206c 696e         # any lin
+0000d210: 6573 2077 6974 6820 6e6f 202b 2f2d 206d  es with no +/- m
+0000d220: 6f64 6966 6965 7220 7368 6f75 6c64 2062  odifier should b
+0000d230: 6520 7472 6561 7465 6420 6173 2069 6620  e treated as if 
+0000d240: 7468 6579 2068 6176 6520 6120 2b2e 0a20  they have a +.. 
+0000d250: 2020 2020 2020 2023 2043 7265 6174 6520         # Create 
+0000d260: 6120 6669 6c65 6c69 7374 0a20 2020 2020  a filelist.     
+0000d270: 2020 2077 6974 6820 696f 2e6f 7065 6e28     with io.open(
+0000d280: 2274 6573 7466 696c 6573 2f69 6e63 6c75  "testfiles/inclu
+0000d290: 6465 2e74 7874 222c 2022 7722 2920 6173  de.txt", "w") as
+0000d2a0: 2066 3a0a 2020 2020 2020 2020 2020 2020   f:.            
+0000d2b0: 662e 7772 6974 6528 2274 6573 7466 696c  f.write("testfil
+0000d2c0: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
+0000d2d0: 6233 2f33 7375 6233 7375 6232 2f33 7375  b3/3sub3sub2/3su
+0000d2e0: 6233 7375 6232 5f66 696c 652e 7478 745c  b3sub2_file.txt\
+0000d2f0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+0000d300: 2020 2020 2020 2022 2d20 7465 7374 6669         "- testfi
+0000d310: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
+0000d320: 7562 332f 3373 7562 3373 7562 325c 6e22  ub3/3sub3sub2\n"
+0000d330: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d340: 2020 2020 2022 7465 7374 6669 6c65 732f       "testfiles/
+0000d350: 7365 6c65 6374 322f 332f 3373 7562 322f  select2/3/3sub2/
+0000d360: 3373 7562 3273 7562 325c 6e22 0a20 2020  3sub2sub2\n".   
+0000d370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d380: 2022 2b20 7465 7374 6669 6c65 732f 7365   "+ testfiles/se
+0000d390: 6c65 6374 322f 332f 3373 7562 335c 6e22  lect2/3/3sub3\n"
+0000d3a0: 2020 2320 2b20 6164 6465 6420 746f 2065    # + added to e
+0000d3b0: 6e73 7572 6520 6974 206d 616b 6573 206e  nsure it makes n
+0000d3c0: 6f20 6469 6666 6572 656e 6365 0a20 2020  o difference.   
+0000d3d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d3e0: 2022 2d20 7465 7374 6669 6c65 732f 7365   "- testfiles/se
+0000d3f0: 6c65 6374 322f 332f 3373 7562 315c 6e22  lect2/3/3sub1\n"
+0000d400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d410: 2020 2020 2022 2d20 7465 7374 6669 6c65       "- testfile
+0000d420: 732f 7365 6c65 6374 322f 322f 3273 7562  s/select2/2/2sub
+0000d430: 312f 3273 7562 3173 7562 335c 6e22 0a20  1/2sub1sub3\n". 
+0000d440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d450: 2020 2022 2d20 7465 7374 6669 6c65 732f     "- testfiles/
+0000d460: 7365 6c65 6374 322f 322f 3273 7562 312f  select2/2/2sub1/
+0000d470: 3273 7562 3173 7562 325c 6e22 0a20 2020  2sub1sub2\n".   
+0000d480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d490: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+0000d4a0: 6374 322f 322f 3273 7562 315c 6e22 0a20  ct2/2/2sub1\n". 
+0000d4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d4c0: 2020 2022 2d20 7465 7374 6669 6c65 732f     "- testfiles/
+0000d4d0: 7365 6c65 6374 322f 312f 3173 7562 332f  select2/1/1sub3/
+0000d4e0: 3173 7562 3373 7562 325c 6e22 0a20 2020  1sub3sub2\n".   
+0000d4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d500: 2022 2d20 7465 7374 6669 6c65 732f 7365   "- testfiles/se
+0000d510: 6c65 6374 322f 312f 3173 7562 332f 3173  lect2/1/1sub3/1s
+0000d520: 7562 3373 7562 315c 6e22 0a20 2020 2020  ub3sub1\n".     
+0000d530: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000d540: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
+0000d550: 6374 322f 312f 3173 7562 322f 3173 7562  ct2/1/1sub2/1sub
+0000d560: 3273 7562 335c 6e22 0a20 2020 2020 2020  2sub3\n".       
+0000d570: 2020 2020 2020 2020 2020 2020 2022 2b20               "+ 
+0000d580: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+0000d590: 322f 312f 3173 7562 322f 3173 7562 3273  2/1/1sub2/1sub2s
+0000d5a0: 7562 315c 6e22 2020 2320 2b20 6164 6465  ub1\n"  # + adde
+0000d5b0: 6420 746f 2065 6e73 7572 6520 6974 206d  d to ensure it m
+0000d5c0: 616b 6573 206e 6f20 6469 6666 6572 656e  akes no differen
+0000d5d0: 6365 0a20 2020 2020 2020 2020 2020 2020  ce.             
+0000d5e0: 2020 2020 2020 2022 2d20 7465 7374 6669         "- testfi
+0000d5f0: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+0000d600: 7562 312f 3173 7562 3173 7562 332f 3173  ub1/1sub1sub3/1s
+0000d610: 7562 3173 7562 335f 6669 6c65 2e74 7874  ub1sub3_file.txt
+0000d620: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000d630: 2020 2020 2020 2020 222d 2074 6573 7466          "- testf
+0000d640: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+0000d650: 7375 6231 2f31 7375 6231 7375 6232 5c6e  sub1/1sub1sub2\n
+0000d660: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000d670: 2020 2020 2020 222d 2074 6573 7466 696c        "- testfil
+0000d680: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+0000d690: 6232 5c6e 220a 2020 2020 2020 2020 2020  b2\n".          
+0000d6a0: 2020 2020 2020 2020 2020 2274 6573 7466            "testf
+0000d6b0: 696c 6573 2f73 656c 6563 7432 2f31 2e70  iles/select2/1.p
+0000d6c0: 795c 6e22 0a20 2020 2020 2020 2020 2020  y\n".           
+0000d6d0: 2020 2020 2020 2020 2022 7465 7374 6669           "testfi
+0000d6e0: 6c65 732f 7365 6c65 6374 322f 335c 6e22  les/select2/3\n"
+0000d6f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d700: 2020 2020 2022 7465 7374 6669 6c65 732f       "testfiles/
+0000d710: 7365 6c65 6374 322f 315c 6e22 0a20 2020  select2/1\n".   
+0000d720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000d730: 2022 2d20 7465 7374 6669 6c65 732f 7365   "- testfiles/se
+0000d740: 6c65 6374 322f 2a2a 2229 0a20 2020 2020  lect2/**").     
+0000d750: 2020 2073 656c 662e 6261 636b 7570 2822     self.backup("
+0000d760: 6675 6c6c 222c 2022 7465 7374 6669 6c65  full", "testfile
+0000d770: 732f 7365 6c65 6374 3222 2c20 6f70 7469  s/select2", opti
+0000d780: 6f6e 733d 5b22 2d2d 696e 636c 7564 652d  ons=["--include-
+0000d790: 6669 6c65 6c69 7374 3d74 6573 7466 696c  filelist=testfil
+0000d7a0: 6573 2f69 6e63 6c75 6465 2e74 7874 225d  es/include.txt"]
+0000d7b0: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
+0000d7c0: 6573 746f 7265 2829 0a20 2020 2020 2020  estore().       
+0000d7d0: 2072 6573 746f 7265 5f70 6174 6820 3d20   restore_path = 
+0000d7e0: 2274 6573 7466 696c 6573 2f72 6573 746f  "testfiles/resto
+0000d7f0: 7265 5f6f 7574 220a 2020 2020 2020 2020  re_out".        
+0000d800: 7265 7374 6f72 6564 203d 2073 656c 662e  restored = self.
+0000d810: 6469 7265 6374 6f72 795f 7472 6565 5f74  directory_tree_t
+0000d820: 6f5f 6c69 7374 5f6f 665f 6c69 7374 7328  o_list_of_lists(
+0000d830: 7265 7374 6f72 655f 7061 7468 290a 2020  restore_path).  
+0000d840: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
+0000d850: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
+0000d860: 2073 656c 662e 6578 7065 6374 6564 5f72   self.expected_r
+0000d870: 6573 746f 7265 645f 7472 6565 290a 0a20  estored_tree).. 
+0000d880: 2020 2064 6566 2074 6573 745f 696e 636c     def test_incl
+0000d890: 7564 655f 6669 6c65 6c69 7374 5f63 6f6d  ude_filelist_com
+0000d8a0: 6269 6e65 645f 696d 7065 7266 6563 7469  bined_imperfecti
+0000d8b0: 6f6e 7328 7365 6c66 293a 0a20 2020 2020  ons(self):.     
+0000d8c0: 2020 2022 2222 5465 7374 2074 6861 7420     """Test that 
+0000d8d0: 696e 636c 7564 6520 6669 6c65 6c69 7374  include filelist
+0000d8e0: 2077 6f72 6b73 2077 6974 6820 696d 7065   works with impe
+0000d8f0: 7266 6563 7469 6f6e 7320 696e 2074 6865  rfections in the
+0000d900: 2069 6e70 7574 2066 696c 6522 2222 0a20   input file""". 
+0000d910: 2020 2020 2020 2023 2054 6869 7320 6973         # This is
+0000d920: 2061 2063 6f6d 6269 6e65 6420 7465 7374   a combined test
+0000d930: 2066 6f72 2073 7065 6564 2072 6561 736f   for speed reaso
+0000d940: 6e73 2e20 5468 6520 696e 6469 7669 6475  ns. The individu
+0000d950: 616c 2069 6d70 6572 6665 6374 696f 6e73  al imperfections
+0000d960: 2061 7265 2074 6573 7465 6420 6173 2075   are tested as u
+0000d970: 6e69 7474 6573 7473 2069 6e0a 2020 2020  nittests in.    
+0000d980: 2020 2020 2320 756e 6974 2f74 6573 745f      # unit/test_
+0000d990: 7365 6c65 6374 696f 6e2e 0a20 2020 2020  selection..     
+0000d9a0: 2020 2023 2049 6d70 6572 6665 6374 696f     # Imperfectio
+0000d9b0: 6e73 2074 6573 7465 6420 6172 653b 0a20  ns tested are;. 
+0000d9c0: 2020 2020 2020 2023 202a 204c 6561 6469         # * Leadi
+0000d9d0: 6e67 2073 7061 6365 2f73 7061 6365 7320  ng space/spaces 
+0000d9e0: 6265 666f 7265 2074 6865 206d 6f64 6966  before the modif
+0000d9f0: 6965 720a 2020 2020 2020 2020 2320 2a20  ier.        # * 
+0000da00: 5472 6169 6c69 6e67 2073 7061 6365 2f73  Trailing space/s
+0000da10: 7061 6365 7320 6166 7465 7220 7468 6520  paces after the 
+0000da20: 6669 6c65 6e61 6d65 2028 6275 7420 6265  filename (but be
+0000da30: 666f 7265 2074 6865 206e 6577 6c69 6e65  fore the newline
+0000da40: 290a 2020 2020 2020 2020 2320 2a20 426c  ).        # * Bl
+0000da50: 616e 6b20 6c69 6e65 7320 286e 6577 6c69  ank lines (newli
+0000da60: 6e65 2063 6861 7261 6374 6572 206f 6e6c  ne character onl
+0000da70: 7929 0a20 2020 2020 2020 2023 202a 204c  y).        # * L
+0000da80: 696e 6520 6f6e 6c79 2063 6f6e 7461 696e  ine only contain
+0000da90: 696e 6720 7370 6163 6573 0a20 2020 2020  ing spaces.     
+0000daa0: 2020 2023 202a 2046 756c 6c2d 6c69 6e65     # * Full-line
+0000dab0: 2063 6f6d 6d65 6e74 7320 7769 7468 2023   comments with #
+0000dac0: 2061 7320 7468 6520 6669 7273 7420 6368   as the first ch
+0000dad0: 6172 6163 7465 7220 616e 6420 7769 7468  aracter and with
+0000dae0: 206c 6561 6469 6e67 2f74 7261 696c 696e   leading/trailin
+0000daf0: 6720 7370 6163 6573 0a20 2020 2020 2020  g spaces.       
+0000db00: 2023 202a 2055 6e6e 6563 6573 7361 7269   # * Unnecessari
+0000db10: 6c79 2071 756f 7465 6420 6669 6c65 6e61  ly quoted filena
+0000db20: 6d65 7320 7769 7468 2f77 6974 686f 7574  mes with/without
+0000db30: 206d 6f64 6966 6965 7220 2028 626f 7468   modifier  (both
+0000db40: 2022 2061 6e64 2027 290a 2020 2020 2020   " and ').      
+0000db50: 2020 2320 4372 6561 7465 2061 2066 696c    # Create a fil
+0000db60: 656c 6973 740a 2020 2020 2020 2020 7769  elist.        wi
+0000db70: 7468 2069 6f2e 6f70 656e 2822 7465 7374  th io.open("test
+0000db80: 6669 6c65 732f 696e 636c 7564 652e 7478  files/include.tx
+0000db90: 7422 2c20 2277 2229 2061 7320 663a 0a20  t", "w") as f:. 
+0000dba0: 2020 2020 2020 2020 2020 2066 2e77 7269             f.wri
+0000dbb0: 7465 2822 7465 7374 6669 6c65 732f 7365  te("testfiles/se
+0000dbc0: 6c65 6374 322f 332f 3373 7562 332f 3373  lect2/3/3sub3/3s
+0000dbd0: 7562 3373 7562 322f 3373 7562 3373 7562  ub3sub2/3sub3sub
+0000dbe0: 325f 6669 6c65 2e74 7874 5c6e 220a 2020  2_file.txt\n".  
+0000dbf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dc00: 2020 222d 2074 6573 7466 696c 6573 2f73    "- testfiles/s
+0000dc10: 656c 6563 7432 2f33 2f33 7375 6233 2f33  elect2/3/3sub3/3
+0000dc20: 7375 6233 7375 6232 5c6e 220a 2020 2020  sub3sub2\n".    
+0000dc30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dc40: 2722 7465 7374 6669 6c65 732f 7365 6c65  '"testfiles/sele
+0000dc50: 6374 322f 332f 3373 7562 322f 3373 7562  ct2/3/3sub2/3sub
+0000dc60: 3273 7562 3222 5c6e 270a 2020 2020 2020  2sub2"\n'.      
+0000dc70: 2020 2020 2020 2020 2020 2020 2020 2220                " 
+0000dc80: 202b 2074 6573 7466 696c 6573 2f73 656c   + testfiles/sel
+0000dc90: 6563 7432 2f33 2f33 7375 6233 5c6e 2220  ect2/3/3sub3\n" 
+0000dca0: 2023 202b 2061 6464 6564 2074 6f20 656e   # + added to en
+0000dcb0: 7375 7265 2069 7420 6d61 6b65 7320 6e6f  sure it makes no
+0000dcc0: 2064 6966 6665 7265 6e63 650a 2020 2020   difference.    
+0000dcd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dce0: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
+0000dcf0: 6563 7432 2f33 2f33 7375 6231 5c6e 220a  ect2/3/3sub1\n".
+0000dd00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dd10: 2020 2020 222d 2074 6573 7466 696c 6573      "- testfiles
+0000dd20: 2f73 656c 6563 7432 2f32 2f32 7375 6231  /select2/2/2sub1
+0000dd30: 2f32 7375 6231 7375 6233 5c6e 220a 2020  /2sub1sub3\n".  
+0000dd40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dd50: 2020 2720 2d20 2274 6573 7466 696c 6573    ' - "testfiles
+0000dd60: 2f73 656c 6563 7432 2f32 2f32 7375 6231  /select2/2/2sub1
+0000dd70: 2f32 7375 6231 7375 6232 225c 6e27 0a20  /2sub1sub2"\n'. 
+0000dd80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dd90: 2020 2022 7465 7374 6669 6c65 732f 7365     "testfiles/se
+0000dda0: 6c65 6374 322f 322f 3273 7562 3120 205c  lect2/2/2sub1  \
+0000ddb0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+0000ddc0: 2020 2020 2020 2022 5c6e 220a 2020 2020         "\n".    
+0000ddd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dde0: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
+0000ddf0: 6563 7432 2f31 2f31 7375 6233 2f31 7375  ect2/1/1sub3/1su
+0000de00: 6233 7375 6232 5c6e 220a 2020 2020 2020  b3sub2\n".      
+0000de10: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+0000de20: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
+0000de30: 7432 2f31 2f31 7375 6233 2f31 7375 6233  t2/1/1sub3/1sub3
+0000de40: 7375 6231 205c 6e22 0a20 2020 2020 2020  sub1 \n".       
+0000de50: 2020 2020 2020 2020 2020 2020 2022 2d20               "- 
+0000de60: 2774 6573 7466 696c 6573 2f73 656c 6563  'testfiles/selec
+0000de70: 7432 2f31 2f31 7375 6232 2f31 7375 6232  t2/1/1sub2/1sub2
+0000de80: 7375 6233 275c 6e22 0a20 2020 2020 2020  sub3'\n".       
+0000de90: 2020 2020 2020 2020 2020 2020 2022 2020               "  
+0000dea0: 2020 2020 2020 2020 2020 205c 6e22 0a20             \n". 
+0000deb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dec0: 2020 2022 202b 2074 6573 7466 696c 6573     " + testfiles
+0000ded0: 2f73 656c 6563 7432 2f31 2f31 7375 6232  /select2/1/1sub2
+0000dee0: 2f31 7375 6232 7375 6231 205c 6e22 2020  /1sub2sub1 \n"  
+0000def0: 2320 2b20 6164 6465 6420 746f 2065 6e73  # + added to ens
+0000df00: 7572 6520 6974 206d 616b 6573 206e 6f20  ure it makes no 
+0000df10: 6469 6666 6572 656e 6365 0a20 2020 2020  difference.     
+0000df20: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000df30: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
+0000df40: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
+0000df50: 3173 7562 332f 3173 7562 3173 7562 335f  1sub3/1sub1sub3_
+0000df60: 6669 6c65 2e74 7874 5c6e 220a 2020 2020  file.txt\n".    
+0000df70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000df80: 2220 202d 2074 6573 7466 696c 6573 2f73  "  - testfiles/s
+0000df90: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
+0000dfa0: 7375 6231 7375 6232 2020 5c6e 220a 2020  sub1sub2  \n".  
+0000dfb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000dfc0: 2020 2223 2054 6573 7469 6e67 2066 756c    "# Testing ful
+0000dfd0: 6c2d 6c69 6e65 2063 6f6d 6d65 6e74 5c6e  l-line comment\n
+0000dfe0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+0000dff0: 2020 2020 2020 222d 2074 6573 7466 696c        "- testfil
+0000e000: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+0000e010: 6232 5c6e 220a 2020 2020 2020 2020 2020  b2\n".          
+0000e020: 2020 2020 2020 2020 2020 2227 7465 7374            "'test
+0000e030: 6669 6c65 732f 7365 6c65 6374 322f 312e  files/select2/1.
+0000e040: 7079 275c 6e22 0a20 2020 2020 2020 2020  py'\n".         
+0000e050: 2020 2020 2020 2020 2020 2022 7465 7374             "test
+0000e060: 6669 6c65 732f 7365 6c65 6374 322f 335c  files/select2/3\
 0000e070: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000e080: 2020 2020 2020 2075 222b 2074 6573 7466         u"+ testf
-0000e090: 696c 6573 2f73 656c 6563 7432 2f33 5c6e  iles/select2/3\n
-0000e0a0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000e0b0: 2020 2020 2020 7522 2b20 7465 7374 6669        u"+ testfi
-0000e0c0: 6c65 732f 7365 6c65 6374 322f 315c 6e22  les/select2/1\n"
-0000e0d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e0e0: 2020 2020 2075 2274 6573 7466 696c 6573       u"testfiles
-0000e0f0: 2f73 656c 6563 7432 2f2a 2a22 290a 2020  /select2/**").  
-0000e100: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-0000e110: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-0000e120: 7466 696c 6573 2f73 656c 6563 7432 222c  tfiles/select2",
-0000e130: 206f 7074 696f 6e73 3d5b 7522 2d2d 6578   options=[u"--ex
-0000e140: 636c 7564 652d 6669 6c65 6c69 7374 3d74  clude-filelist=t
-0000e150: 6573 7466 696c 6573 2f65 7863 6c75 6465  estfiles/exclude
-0000e160: 2e74 7874 225d 290a 2020 2020 2020 2020  .txt"]).        
-0000e170: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
-0000e180: 2020 2020 2020 2072 6573 746f 7265 5f64         restore_d
-0000e190: 6972 203d 2075 2274 6573 7466 696c 6573  ir = u"testfiles
-0000e1a0: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
-0000e1b0: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
-0000e1c0: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
-0000e1d0: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
-0000e1e0: 6c69 7374 7328 7265 7374 6f72 655f 6469  lists(restore_di
-0000e1f0: 7229 0a20 2020 2020 2020 2073 656c 662e  r).        self.
-0000e200: 6173 7365 7274 4571 7561 6c28 7265 7374  assertEqual(rest
-0000e210: 6f72 6564 2c20 7365 6c66 2e65 7870 6563  ored, self.expec
-0000e220: 7465 645f 7265 7374 6f72 6564 5f74 7265  ted_restored_tre
-0000e230: 655f 7769 7468 5f74 7261 696c 696e 675f  e_with_trailing_
-0000e240: 7370 6163 6529 0a0a 2020 2020 6465 6620  space)..    def 
-0000e250: 7465 7374 5f65 7863 6c75 6465 5f66 696c  test_exclude_fil
-0000e260: 656c 6973 745f 7072 6f67 7265 7373 5f6f  elist_progress_o
-0000e270: 7074 696f 6e28 7365 6c66 293a 0a20 2020  ption(self):.   
-0000e280: 2020 2020 2075 2222 2254 6573 7420 7468       u"""Test th
-0000e290: 6174 2065 7863 6c75 6465 2066 696c 656c  at exclude filel
-0000e2a0: 6973 7420 6973 2075 6e61 6666 6563 7465  ist is unaffecte
-0000e2b0: 6420 6279 2074 6865 202d 2d70 726f 6772  d by the --progr
-0000e2c0: 6573 7320 6f70 7469 6f6e 2222 220a 2020  ess option""".  
-0000e2d0: 2020 2020 2020 2320 5265 6772 6573 7369        # Regressi
-0000e2e0: 6f6e 2074 6573 7420 666f 7220 4275 6720  on test for Bug 
-0000e2f0: 2331 3236 3437 3434 2028 6874 7470 733a  #1264744 (https:
-0000e300: 2f2f 6275 6773 2e6c 6175 6e63 6870 6164  //bugs.launchpad
-0000e310: 2e6e 6574 2f64 7570 6c69 6369 7479 2f2b  .net/duplicity/+
-0000e320: 6275 672f 3132 3634 3734 3429 0a20 2020  bug/1264744).   
-0000e330: 2020 2020 2023 2043 7265 6174 6520 6120       # Create a 
-0000e340: 6669 6c65 6c69 7374 2069 6465 6e74 6963  filelist identic
-0000e350: 616c 2074 6f20 7468 6174 2075 7365 6420  al to that used 
-0000e360: 696e 2074 6573 745f 6578 636c 7564 655f  in test_exclude_
-0000e370: 6669 6c65 6c69 7374 0a20 2020 2020 2020  filelist.       
-0000e380: 2077 6974 6820 696f 2e6f 7065 6e28 7522   with io.open(u"
-0000e390: 7465 7374 6669 6c65 732f 6578 636c 7564  testfiles/exclud
-0000e3a0: 652e 7478 7422 2c20 7522 7722 2920 6173  e.txt", u"w") as
-0000e3b0: 2066 3a0a 2020 2020 2020 2020 2020 2020   f:.            
-0000e3c0: 662e 7772 6974 6528 7522 2b20 7465 7374  f.write(u"+ test
-0000e3d0: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
-0000e3e0: 3373 7562 332f 3373 7562 3373 7562 322f  3sub3/3sub3sub2/
-0000e3f0: 3373 7562 3373 7562 325f 6669 6c65 2e74  3sub3sub2_file.t
-0000e400: 7874 5c6e 220a 2020 2020 2020 2020 2020  xt\n".          
-0000e410: 2020 2020 2020 2020 2020 7522 7465 7374            u"test
-0000e420: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
-0000e430: 3373 7562 332f 3373 7562 3373 7562 325c  3sub3/3sub3sub2\
-0000e440: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000e450: 2020 2020 2020 2075 222b 2074 6573 7466         u"+ testf
-0000e460: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
-0000e470: 7375 6232 2f33 7375 6232 7375 6232 5c6e  sub2/3sub2sub2\n
-0000e480: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000e490: 2020 2020 2020 7522 2b20 7465 7374 6669        u"+ testfi
-0000e4a0: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
-0000e4b0: 7562 335c 6e22 0a20 2020 2020 2020 2020  ub3\n".         
-0000e4c0: 2020 2020 2020 2020 2020 2075 222d 2074             u"- t
-0000e4d0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-0000e4e0: 2f33 2f33 7375 6231 5c6e 2220 2023 202d  /3/3sub1\n"  # -
-0000e4f0: 2061 6464 6564 2074 6f20 656e 7375 7265   added to ensure
-0000e500: 2069 7420 6d61 6b65 7320 6e6f 2064 6966   it makes no dif
-0000e510: 6665 7265 6e63 650a 2020 2020 2020 2020  ference.        
-0000e520: 2020 2020 2020 2020 2020 2020 7522 7465              u"te
-0000e530: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000e540: 322f 3273 7562 312f 3273 7562 3173 7562  2/2sub1/2sub1sub
-0000e550: 335c 6e22 0a20 2020 2020 2020 2020 2020  3\n".           
-0000e560: 2020 2020 2020 2020 2075 2274 6573 7466           u"testf
-0000e570: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
-0000e580: 7375 6231 2f32 7375 6231 7375 6232 5c6e  sub1/2sub1sub2\n
-0000e590: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000e5a0: 2020 2020 2020 7522 2b20 7465 7374 6669        u"+ testfi
-0000e5b0: 6c65 732f 7365 6c65 6374 322f 322f 3273  les/select2/2/2s
-0000e5c0: 7562 315c 6e22 0a20 2020 2020 2020 2020  ub1\n".         
-0000e5d0: 2020 2020 2020 2020 2020 2075 2274 6573             u"tes
-0000e5e0: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-0000e5f0: 2f31 7375 6233 2f31 7375 6233 7375 6232  /1sub3/1sub3sub2
-0000e600: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000e610: 2020 2020 2020 2020 7522 7465 7374 6669          u"testfi
-0000e620: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-0000e630: 7562 332f 3173 7562 3373 7562 315c 6e22  ub3/1sub3sub1\n"
-0000e640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e650: 2020 2020 2075 2274 6573 7466 696c 6573       u"testfiles
-0000e660: 2f73 656c 6563 7432 2f31 2f31 7375 6232  /select2/1/1sub2
-0000e670: 2f31 7375 6232 7375 6233 5c6e 220a 2020  /1sub2sub3\n".  
-0000e680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e690: 2020 7522 2b20 7465 7374 6669 6c65 732f    u"+ testfiles/
-0000e6a0: 7365 6c65 6374 322f 312f 3173 7562 322f  select2/1/1sub2/
-0000e6b0: 3173 7562 3273 7562 315c 6e22 0a20 2020  1sub2sub1\n".   
-0000e6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e6d0: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-0000e6e0: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
-0000e6f0: 6231 7375 6233 2f31 7375 6231 7375 6233  b1sub3/1sub1sub3
-0000e700: 5f66 696c 652e 7478 745c 6e22 0a20 2020  _file.txt\n".   
-0000e710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e720: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-0000e730: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
-0000e740: 6231 7375 6232 5c6e 220a 2020 2020 2020  b1sub2\n".      
-0000e750: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000e760: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
-0000e770: 6374 322f 312f 3173 7562 325c 6e22 2020  ct2/1/1sub2\n"  
-0000e780: 2320 2d20 6164 6465 6420 746f 2065 6e73  # - added to ens
-0000e790: 7572 6520 6974 206d 616b 6573 206e 6f20  ure it makes no 
-0000e7a0: 6469 6666 6572 656e 6365 0a20 2020 2020  difference.     
-0000e7b0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000e7c0: 222b 2074 6573 7466 696c 6573 2f73 656c  "+ testfiles/sel
-0000e7d0: 6563 7432 2f31 2e70 795c 6e22 0a20 2020  ect2/1.py\n".   
-0000e7e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e7f0: 2075 222b 2074 6573 7466 696c 6573 2f73   u"+ testfiles/s
-0000e800: 656c 6563 7432 2f33 5c6e 220a 2020 2020  elect2/3\n".    
-0000e810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e820: 7522 2b20 7465 7374 6669 6c65 732f 7365  u"+ testfiles/se
-0000e830: 6c65 6374 322f 315c 6e22 0a20 2020 2020  lect2/1\n".     
-0000e840: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000e850: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-0000e860: 7432 2f2a 2a22 290a 0a20 2020 2020 2020  t2/**")..       
-0000e870: 2023 2042 6163 6b75 7020 7468 6520 6669   # Backup the fi
-0000e880: 6c65 7320 6578 6163 746c 7920 6173 2069  les exactly as i
-0000e890: 6e20 7465 7374 5f65 7863 6c75 6465 5f66  n test_exclude_f
-0000e8a0: 696c 656c 6973 742c 2062 7574 2077 6974  ilelist, but wit
-0000e8b0: 6820 7468 6520 2d2d 7072 6f67 7265 7373  h the --progress
-0000e8c0: 206f 7074 696f 6e0a 2020 2020 2020 2020   option.        
-0000e8d0: 7365 6c66 2e62 6163 6b75 7028 7522 6675  self.backup(u"fu
-0000e8e0: 6c6c 222c 2075 2274 6573 7466 696c 6573  ll", u"testfiles
-0000e8f0: 2f73 656c 6563 7432 222c 206f 7074 696f  /select2", optio
-0000e900: 6e73 3d5b 7522 2d2d 6578 636c 7564 652d  ns=[u"--exclude-
-0000e910: 6669 6c65 6c69 7374 3d74 6573 7466 696c  filelist=testfil
-0000e920: 6573 2f65 7863 6c75 6465 2e74 7874 222c  es/exclude.txt",
-0000e930: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e940: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e960: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-0000e970: 2d70 726f 6772 6573 7322 5d29 0a20 2020  -progress"]).   
-0000e980: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
-0000e990: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
-0000e9a0: 6f72 655f 6469 7220 3d20 7522 7465 7374  ore_dir = u"test
-0000e9b0: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
-0000e9c0: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
-0000e9d0: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
-0000e9e0: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
-0000e9f0: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
-0000ea00: 7265 5f64 6972 290a 2020 2020 2020 2020  re_dir).        
-0000ea10: 2320 5468 6520 7265 7374 6f72 6564 2066  # The restored f
-0000ea20: 696c 6573 2073 686f 756c 6420 6d61 7463  iles should matc
-0000ea30: 6820 7468 6f73 6520 7265 7374 6f72 6564  h those restored
-0000ea40: 2069 6e20 7465 7374 5f65 7863 6c75 6465   in test_exclude
-0000ea50: 5f66 696c 656c 6973 740a 2020 2020 2020  _filelist.      
-0000ea60: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
-0000ea70: 616c 2872 6573 746f 7265 642c 2073 656c  al(restored, sel
-0000ea80: 662e 6578 7065 6374 6564 5f72 6573 746f  f.expected_resto
-0000ea90: 7265 645f 7472 6565 290a 0a0a 636c 6173  red_tree)...clas
-0000eaa0: 7320 5465 7374 496e 636c 7564 6546 696c  s TestIncludeFil
-0000eab0: 656c 6973 7454 6573 7428 496e 636c 7564  elistTest(Includ
-0000eac0: 6545 7863 6c75 6465 4675 6e63 7469 6f6e  eExcludeFunction
-0000ead0: 616c 5465 7374 293a 0a20 2020 2075 2222  alTest):.    u""
-0000eae0: 220a 2020 2020 5465 7374 202d 2d69 6e63  ".    Test --inc
-0000eaf0: 6c75 6465 2d66 696c 656c 6973 7420 7573  lude-filelist us
-0000eb00: 696e 6720 6475 706c 6963 6974 7920 6269  ing duplicity bi
-0000eb10: 6e61 7279 2e0a 2020 2020 2222 220a 0a20  nary..    """.. 
-0000eb20: 2020 2064 6566 2074 6573 745f 696e 636c     def test_incl
-0000eb30: 7564 655f 6669 6c65 6c69 7374 2873 656c  ude_filelist(sel
-0000eb40: 6629 3a0a 2020 2020 2020 2020 7522 2222  f):.        u"""
-0000eb50: 5465 7374 2074 6861 7420 696e 636c 7564  Test that includ
-0000eb60: 6520 6669 6c65 6c69 7374 2077 6f72 6b73  e filelist works
-0000eb70: 2069 6e20 7468 6520 6261 7369 6320 6361   in the basic ca
-0000eb80: 7365 2222 220a 2020 2020 2020 2020 2320  se""".        # 
-0000eb90: 5365 6520 7465 7374 5f65 7863 6c75 6465  See test_exclude
-0000eba0: 5f66 696c 656c 6973 7420 6162 6f76 6520  _filelist above 
-0000ebb0: 666f 7220 6578 706c 616e 6174 696f 6e20  for explanation 
-0000ebc0: 6f66 2077 6861 7420 6973 2065 7870 6563  of what is expec
-0000ebd0: 7465 642e 2041 7320 7468 6973 2069 7320  ted. As this is 
-0000ebe0: 616e 2069 6e63 6c75 6465 2066 696c 656c  an include filel
-0000ebf0: 6973 740a 2020 2020 2020 2020 2320 616e  ist.        # an
-0000ec00: 7920 6c69 6e65 7320 7769 7468 206e 6f20  y lines with no 
-0000ec10: 2b2f 2d20 6d6f 6469 6669 6572 2073 686f  +/- modifier sho
-0000ec20: 756c 6420 6265 2074 7265 6174 6564 2061  uld be treated a
-0000ec30: 7320 6966 2074 6865 7920 6861 7665 2061  s if they have a
-0000ec40: 202b 2e0a 2020 2020 2020 2020 2320 4372   +..        # Cr
-0000ec50: 6561 7465 2061 2066 696c 656c 6973 740a  eate a filelist.
-0000ec60: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
-0000ec70: 6f70 656e 2875 2274 6573 7466 696c 6573  open(u"testfiles
-0000ec80: 2f69 6e63 6c75 6465 2e74 7874 222c 2075  /include.txt", u
-0000ec90: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
-0000eca0: 2020 2020 2020 2066 2e77 7269 7465 2875         f.write(u
-0000ecb0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-0000ecc0: 7432 2f33 2f33 7375 6233 2f33 7375 6233  t2/3/3sub3/3sub3
-0000ecd0: 7375 6232 2f33 7375 6233 7375 6232 5f66  sub2/3sub3sub2_f
-0000ece0: 696c 652e 7478 745c 6e22 0a20 2020 2020  ile.txt\n".     
-0000ecf0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000ed00: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
-0000ed10: 6563 7432 2f33 2f33 7375 6233 2f33 7375  ect2/3/3sub3/3su
-0000ed20: 6233 7375 6232 5c6e 220a 2020 2020 2020  b3sub2\n".      
-0000ed30: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000ed40: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-0000ed50: 322f 332f 3373 7562 322f 3373 7562 3273  2/3/3sub2/3sub2s
-0000ed60: 7562 325c 6e22 0a20 2020 2020 2020 2020  ub2\n".         
-0000ed70: 2020 2020 2020 2020 2020 2075 222b 2074             u"+ t
-0000ed80: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-0000ed90: 2f33 2f33 7375 6233 5c6e 2220 2023 202b  /3/3sub3\n"  # +
-0000eda0: 2061 6464 6564 2074 6f20 656e 7375 7265   added to ensure
-0000edb0: 2069 7420 6d61 6b65 7320 6e6f 2064 6966   it makes no dif
-0000edc0: 6665 7265 6e63 650a 2020 2020 2020 2020  ference.        
-0000edd0: 2020 2020 2020 2020 2020 2020 7522 2d20              u"- 
-0000ede0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-0000edf0: 322f 332f 3373 7562 315c 6e22 0a20 2020  2/3/3sub1\n".   
-0000ee00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ee10: 2075 222d 2074 6573 7466 696c 6573 2f73   u"- testfiles/s
-0000ee20: 656c 6563 7432 2f32 2f32 7375 6231 2f32  elect2/2/2sub1/2
-0000ee30: 7375 6231 7375 6233 5c6e 220a 2020 2020  sub1sub3\n".    
-0000ee40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ee50: 7522 2d20 7465 7374 6669 6c65 732f 7365  u"- testfiles/se
-0000ee60: 6c65 6374 322f 322f 3273 7562 312f 3273  lect2/2/2sub1/2s
-0000ee70: 7562 3173 7562 325c 6e22 0a20 2020 2020  ub1sub2\n".     
-0000ee80: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000ee90: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-0000eea0: 7432 2f32 2f32 7375 6231 5c6e 220a 2020  t2/2/2sub1\n".  
-0000eeb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eec0: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-0000eed0: 7365 6c65 6374 322f 312f 3173 7562 332f  select2/1/1sub3/
-0000eee0: 3173 7562 3373 7562 325c 6e22 0a20 2020  1sub3sub2\n".   
-0000eef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef00: 2075 222d 2074 6573 7466 696c 6573 2f73   u"- testfiles/s
-0000ef10: 656c 6563 7432 2f31 2f31 7375 6233 2f31  elect2/1/1sub3/1
-0000ef20: 7375 6233 7375 6231 5c6e 220a 2020 2020  sub3sub1\n".    
-0000ef30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ef40: 7522 2d20 7465 7374 6669 6c65 732f 7365  u"- testfiles/se
-0000ef50: 6c65 6374 322f 312f 3173 7562 322f 3173  lect2/1/1sub2/1s
-0000ef60: 7562 3273 7562 335c 6e22 0a20 2020 2020  ub2sub3\n".     
-0000ef70: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000ef80: 222b 2074 6573 7466 696c 6573 2f73 656c  "+ testfiles/sel
-0000ef90: 6563 7432 2f31 2f31 7375 6232 2f31 7375  ect2/1/1sub2/1su
-0000efa0: 6232 7375 6231 5c6e 2220 2023 202b 2061  b2sub1\n"  # + a
-0000efb0: 6464 6564 2074 6f20 656e 7375 7265 2069  dded to ensure i
-0000efc0: 7420 6d61 6b65 7320 6e6f 2064 6966 6665  t makes no diffe
-0000efd0: 7265 6e63 650a 2020 2020 2020 2020 2020  rence.          
-0000efe0: 2020 2020 2020 2020 2020 7522 2d20 7465            u"- te
-0000eff0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000f000: 312f 3173 7562 312f 3173 7562 3173 7562  1/1sub1/1sub1sub
-0000f010: 332f 3173 7562 3173 7562 335f 6669 6c65  3/1sub1sub3_file
-0000f020: 2e74 7874 5c6e 220a 2020 2020 2020 2020  .txt\n".        
-0000f030: 2020 2020 2020 2020 2020 2020 7522 2d20              u"- 
-0000f040: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-0000f050: 322f 312f 3173 7562 312f 3173 7562 3173  2/1/1sub1/1sub1s
-0000f060: 7562 325c 6e22 0a20 2020 2020 2020 2020  ub2\n".         
-0000f070: 2020 2020 2020 2020 2020 2075 222d 2074             u"- t
-0000f080: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-0000f090: 2f31 2f31 7375 6232 5c6e 220a 2020 2020  /1/1sub2\n".    
-0000f0a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0b0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-0000f0c0: 6374 322f 312e 7079 5c6e 220a 2020 2020  ct2/1.py\n".    
-0000f0d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f0e0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-0000f0f0: 6374 322f 335c 6e22 0a20 2020 2020 2020  ct2/3\n".       
-0000f100: 2020 2020 2020 2020 2020 2020 2075 2274               u"t
-0000f110: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-0000f120: 2f31 5c6e 220a 2020 2020 2020 2020 2020  /1\n".          
-0000f130: 2020 2020 2020 2020 2020 7522 2d20 7465            u"- te
-0000f140: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000f150: 2a2a 2229 0a20 2020 2020 2020 2073 656c  **").        sel
-0000f160: 662e 6261 636b 7570 2875 2266 756c 6c22  f.backup(u"full"
-0000f170: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-0000f180: 6c65 6374 3222 2c20 6f70 7469 6f6e 733d  lect2", options=
-0000f190: 5b75 222d 2d69 6e63 6c75 6465 2d66 696c  [u"--include-fil
-0000f1a0: 656c 6973 743d 7465 7374 6669 6c65 732f  elist=testfiles/
-0000f1b0: 696e 636c 7564 652e 7478 7422 5d29 0a20  include.txt"]). 
-0000f1c0: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
-0000f1d0: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
-0000f1e0: 7374 6f72 655f 6469 7220 3d20 7522 7465  store_dir = u"te
-0000f1f0: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
-0000f200: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
-0000f210: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
-0000f220: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
-0000f230: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
-0000f240: 746f 7265 5f64 6972 290a 2020 2020 2020  tore_dir).      
-0000f250: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
-0000f260: 616c 2872 6573 746f 7265 642c 2073 656c  al(restored, sel
-0000f270: 662e 6578 7065 6374 6564 5f72 6573 746f  f.expected_resto
-0000f280: 7265 645f 7472 6565 290a 0a20 2020 2064  red_tree)..    d
-0000f290: 6566 2074 6573 745f 696e 636c 7564 655f  ef test_include_
-0000f2a0: 6669 6c65 6c69 7374 5f63 6f6d 6269 6e65  filelist_combine
-0000f2b0: 645f 696d 7065 7266 6563 7469 6f6e 7328  d_imperfections(
-0000f2c0: 7365 6c66 293a 0a20 2020 2020 2020 2075  self):.        u
-0000f2d0: 2222 2254 6573 7420 7468 6174 2069 6e63  """Test that inc
-0000f2e0: 6c75 6465 2066 696c 656c 6973 7420 776f  lude filelist wo
-0000f2f0: 726b 7320 7769 7468 2069 6d70 6572 6665  rks with imperfe
-0000f300: 6374 696f 6e73 2069 6e20 7468 6520 696e  ctions in the in
-0000f310: 7075 7420 6669 6c65 2222 220a 2020 2020  put file""".    
-0000f320: 2020 2020 2320 5468 6973 2069 7320 6120      # This is a 
-0000f330: 636f 6d62 696e 6564 2074 6573 7420 666f  combined test fo
-0000f340: 7220 7370 6565 6420 7265 6173 6f6e 732e  r speed reasons.
-0000f350: 2054 6865 2069 6e64 6976 6964 7561 6c20   The individual 
-0000f360: 696d 7065 7266 6563 7469 6f6e 7320 6172  imperfections ar
-0000f370: 6520 7465 7374 6564 2061 7320 756e 6974  e tested as unit
-0000f380: 7465 7374 7320 696e 0a20 2020 2020 2020  tests in.       
-0000f390: 2023 2075 6e69 742f 7465 7374 5f73 656c   # unit/test_sel
-0000f3a0: 6563 7469 6f6e 2e0a 2020 2020 2020 2020  ection..        
-0000f3b0: 2320 496d 7065 7266 6563 7469 6f6e 7320  # Imperfections 
-0000f3c0: 7465 7374 6564 2061 7265 3b0a 2020 2020  tested are;.    
-0000f3d0: 2020 2020 2320 2a20 4c65 6164 696e 6720      # * Leading 
-0000f3e0: 7370 6163 652f 7370 6163 6573 2062 6566  space/spaces bef
-0000f3f0: 6f72 6520 7468 6520 6d6f 6469 6669 6572  ore the modifier
-0000f400: 0a20 2020 2020 2020 2023 202a 2054 7261  .        # * Tra
-0000f410: 696c 696e 6720 7370 6163 652f 7370 6163  iling space/spac
-0000f420: 6573 2061 6674 6572 2074 6865 2066 696c  es after the fil
-0000f430: 656e 616d 6520 2862 7574 2062 6566 6f72  ename (but befor
-0000f440: 6520 7468 6520 6e65 776c 696e 6529 0a20  e the newline). 
-0000f450: 2020 2020 2020 2023 202a 2042 6c61 6e6b         # * Blank
-0000f460: 206c 696e 6573 2028 6e65 776c 696e 6520   lines (newline 
-0000f470: 6368 6172 6163 7465 7220 6f6e 6c79 290a  character only).
-0000f480: 2020 2020 2020 2020 2320 2a20 4c69 6e65          # * Line
-0000f490: 206f 6e6c 7920 636f 6e74 6169 6e69 6e67   only containing
-0000f4a0: 2073 7061 6365 730a 2020 2020 2020 2020   spaces.        
-0000f4b0: 2320 2a20 4675 6c6c 2d6c 696e 6520 636f  # * Full-line co
-0000f4c0: 6d6d 656e 7473 2077 6974 6820 2320 6173  mments with # as
-0000f4d0: 2074 6865 2066 6972 7374 2063 6861 7261   the first chara
-0000f4e0: 6374 6572 2061 6e64 2077 6974 6820 6c65  cter and with le
-0000f4f0: 6164 696e 672f 7472 6169 6c69 6e67 2073  ading/trailing s
-0000f500: 7061 6365 730a 2020 2020 2020 2020 2320  paces.        # 
-0000f510: 2a20 556e 6e65 6365 7373 6172 696c 7920  * Unnecessarily 
-0000f520: 7175 6f74 6564 2066 696c 656e 616d 6573  quoted filenames
-0000f530: 2077 6974 682f 7769 7468 6f75 7420 6d6f   with/without mo
-0000f540: 6469 6669 6572 2020 2862 6f74 6820 2220  difier  (both " 
-0000f550: 616e 6420 2729 0a20 2020 2020 2020 2023  and ').        #
-0000f560: 2043 7265 6174 6520 6120 6669 6c65 6c69   Create a fileli
-0000f570: 7374 0a20 2020 2020 2020 2077 6974 6820  st.        with 
-0000f580: 696f 2e6f 7065 6e28 7522 7465 7374 6669  io.open(u"testfi
-0000f590: 6c65 732f 696e 636c 7564 652e 7478 7422  les/include.txt"
-0000f5a0: 2c20 7522 7722 2920 6173 2066 3a0a 2020  , u"w") as f:.  
-0000f5b0: 2020 2020 2020 2020 2020 662e 7772 6974            f.writ
-0000f5c0: 6528 7522 7465 7374 6669 6c65 732f 7365  e(u"testfiles/se
-0000f5d0: 6c65 6374 322f 332f 3373 7562 332f 3373  lect2/3/3sub3/3s
-0000f5e0: 7562 3373 7562 322f 3373 7562 3373 7562  ub3sub2/3sub3sub
-0000f5f0: 325f 6669 6c65 2e74 7874 5c6e 220a 2020  2_file.txt\n".  
-0000f600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f610: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-0000f620: 7365 6c65 6374 322f 332f 3373 7562 332f  select2/3/3sub3/
-0000f630: 3373 7562 3373 7562 325c 6e22 0a20 2020  3sub3sub2\n".   
-0000f640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f650: 2075 2722 7465 7374 6669 6c65 732f 7365   u'"testfiles/se
-0000f660: 6c65 6374 322f 332f 3373 7562 322f 3373  lect2/3/3sub2/3s
-0000f670: 7562 3273 7562 3222 5c6e 270a 2020 2020  ub2sub2"\n'.    
-0000f680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f690: 7522 2020 2b20 7465 7374 6669 6c65 732f  u"  + testfiles/
-0000f6a0: 7365 6c65 6374 322f 332f 3373 7562 335c  select2/3/3sub3\
-0000f6b0: 6e22 2020 2320 2b20 6164 6465 6420 746f  n"  # + added to
-0000f6c0: 2065 6e73 7572 6520 6974 206d 616b 6573   ensure it makes
-0000f6d0: 206e 6f20 6469 6666 6572 656e 6365 0a20   no difference. 
-0000f6e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f6f0: 2020 2075 222d 2074 6573 7466 696c 6573     u"- testfiles
-0000f700: 2f73 656c 6563 7432 2f33 2f33 7375 6231  /select2/3/3sub1
-0000f710: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000f720: 2020 2020 2020 2020 7522 2d20 7465 7374          u"- test
-0000f730: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-0000f740: 3273 7562 312f 3273 7562 3173 7562 335c  2sub1/2sub1sub3\
-0000f750: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000f760: 2020 2020 2020 2075 2720 2d20 2274 6573         u' - "tes
-0000f770: 7466 696c 6573 2f73 656c 6563 7432 2f32  tfiles/select2/2
-0000f780: 2f32 7375 6231 2f32 7375 6231 7375 6232  /2sub1/2sub1sub2
-0000f790: 225c 6e27 0a20 2020 2020 2020 2020 2020  "\n'.           
-0000f7a0: 2020 2020 2020 2020 2075 2274 6573 7466           u"testf
-0000f7b0: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
-0000f7c0: 7375 6231 2020 5c6e 220a 2020 2020 2020  sub1  \n".      
-0000f7d0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000f7e0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000f7f0: 2020 2020 2020 2020 7522 2d20 7465 7374          u"- test
-0000f800: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-0000f810: 3173 7562 332f 3173 7562 3373 7562 325c  1sub3/1sub3sub2\
-0000f820: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000f830: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-0000f840: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-0000f850: 7375 6233 2f31 7375 6233 7375 6231 205c  sub3/1sub3sub1 \
-0000f860: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0000f870: 2020 2020 2020 2075 222d 2027 7465 7374         u"- 'test
-0000f880: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-0000f890: 3173 7562 322f 3173 7562 3273 7562 3327  1sub2/1sub2sub3'
-0000f8a0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-0000f8b0: 2020 2020 2020 2020 7522 2020 2020 2020          u"      
-0000f8c0: 2020 2020 2020 205c 6e22 0a20 2020 2020         \n".     
-0000f8d0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-0000f8e0: 2220 2b20 7465 7374 6669 6c65 732f 7365  " + testfiles/se
-0000f8f0: 6c65 6374 322f 312f 3173 7562 322f 3173  lect2/1/1sub2/1s
-0000f900: 7562 3273 7562 3120 5c6e 2220 2023 202b  ub2sub1 \n"  # +
-0000f910: 2061 6464 6564 2074 6f20 656e 7375 7265   added to ensure
-0000f920: 2069 7420 6d61 6b65 7320 6e6f 2064 6966   it makes no dif
-0000f930: 6665 7265 6e63 650a 2020 2020 2020 2020  ference.        
-0000f940: 2020 2020 2020 2020 2020 2020 7522 2d20              u"- 
-0000f950: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-0000f960: 322f 312f 3173 7562 312f 3173 7562 3173  2/1/1sub1/1sub1s
-0000f970: 7562 332f 3173 7562 3173 7562 335f 6669  ub3/1sub1sub3_fi
-0000f980: 6c65 2e74 7874 5c6e 220a 2020 2020 2020  le.txt\n".      
-0000f990: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0000f9a0: 2020 2d20 7465 7374 6669 6c65 732f 7365    - testfiles/se
-0000f9b0: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
-0000f9c0: 7562 3173 7562 3220 205c 6e22 0a20 2020  ub1sub2  \n".   
-0000f9d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f9e0: 2075 2223 2054 6573 7469 6e67 2066 756c   u"# Testing ful
-0000f9f0: 6c2d 6c69 6e65 2063 6f6d 6d65 6e74 5c6e  l-line comment\n
-0000fa00: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000fa10: 2020 2020 2020 7522 2d20 7465 7374 6669        u"- testfi
-0000fa20: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-0000fa30: 7562 325c 6e22 0a20 2020 2020 2020 2020  ub2\n".         
-0000fa40: 2020 2020 2020 2020 2020 2075 2227 7465             u"'te
-0000fa50: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-0000fa60: 312e 7079 275c 6e22 0a20 2020 2020 2020  1.py'\n".       
-0000fa70: 2020 2020 2020 2020 2020 2020 2075 2274               u"t
-0000fa80: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-0000fa90: 2f33 5c6e 220a 2020 2020 2020 2020 2020  /3\n".          
-0000faa0: 2020 2020 2020 2020 2020 7522 2020 2020            u"    
-0000fab0: 2020 2020 2320 2054 6573 7469 6e67 2061      #  Testing a
-0000fac0: 6e6f 7468 6572 2066 756c 6c2d 6c69 6e65  nother full-line
-0000fad0: 2063 6f6d 6d65 6e74 2020 2020 2020 5c6e   comment      \n
-0000fae0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0000faf0: 2020 2020 2020 7522 7465 7374 6669 6c65        u"testfile
-0000fb00: 732f 7365 6c65 6374 322f 315c 6e22 0a20  s/select2/1\n". 
-0000fb10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fb20: 2020 2075 222d 2074 6573 7466 696c 6573     u"- testfiles
-0000fb30: 2f73 656c 6563 7432 2f2a 2a22 290a 2020  /select2/**").  
-0000fb40: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-0000fb50: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-0000fb60: 7466 696c 6573 2f73 656c 6563 7432 222c  tfiles/select2",
-0000fb70: 206f 7074 696f 6e73 3d5b 7522 2d2d 696e   options=[u"--in
-0000fb80: 636c 7564 652d 6669 6c65 6c69 7374 3d74  clude-filelist=t
-0000fb90: 6573 7466 696c 6573 2f69 6e63 6c75 6465  estfiles/include
-0000fba0: 2e74 7874 225d 290a 2020 2020 2020 2020  .txt"]).        
-0000fbb0: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
-0000fbc0: 2020 2020 2020 2072 6573 746f 7265 5f64         restore_d
-0000fbd0: 6972 203d 2075 2274 6573 7466 696c 6573  ir = u"testfiles
-0000fbe0: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
-0000fbf0: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
-0000fc00: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
-0000fc10: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
-0000fc20: 6c69 7374 7328 7265 7374 6f72 655f 6469  lists(restore_di
-0000fc30: 7229 0a20 2020 2020 2020 2073 656c 662e  r).        self.
-0000fc40: 6173 7365 7274 4571 7561 6c28 7265 7374  assertEqual(rest
-0000fc50: 6f72 6564 2c20 7365 6c66 2e65 7870 6563  ored, self.expec
-0000fc60: 7465 645f 7265 7374 6f72 6564 5f74 7265  ted_restored_tre
-0000fc70: 6529 0a0a 2020 2020 6465 6620 7465 7374  e)..    def test
-0000fc80: 5f69 6e63 6c75 6465 5f66 696c 656c 6973  _include_filelis
-0000fc90: 745f 776f 726b 6172 6f75 6e64 5f63 6f6d  t_workaround_com
-0000fca0: 6269 6e65 645f 696d 7065 7266 6563 7469  bined_imperfecti
-0000fcb0: 6f6e 735f 6e6f 5f77 696c 6463 6172 6473  ons_no_wildcards
-0000fcc0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-0000fcd0: 7522 2222 5465 7374 2074 6861 7420 696e  u"""Test that in
-0000fce0: 636c 7564 6520 6669 6c65 6c69 7374 2077  clude filelist w
-0000fcf0: 6f72 6b73 2077 6974 6820 696d 7065 7266  orks with imperf
-0000fd00: 6563 7469 6f6e 7320 696e 2074 6865 2069  ections in the i
-0000fd10: 6e70 7574 2066 696c 6522 2222 0a20 2020  nput file""".   
-0000fd20: 2020 2020 2023 2054 6869 7320 6973 2061       # This is a
-0000fd30: 206d 6f64 6966 6965 6420 7665 7273 696f   modified versio
-0000fd40: 6e20 6f66 2074 6573 745f 696e 636c 7564  n of test_includ
-0000fd50: 655f 6669 6c65 6c69 7374 2074 6861 7420  e_filelist that 
-0000fd60: 7061 7373 6573 2c20 6465 7370 6974 6520  passes, despite 
-0000fd70: 4275 6720 2331 3430 3834 3131 0a20 2020  Bug #1408411.   
-0000fd80: 2020 2020 2023 2049 7420 6973 2073 7469       # It is sti
-0000fd90: 6c6c 2061 2076 616c 6964 2074 6573 742c  ll a valid test,
-0000fda0: 2069 7420 6a75 7374 2064 6f65 7320 6e6f   it just does no
-0000fdb0: 7420 7465 7374 2061 7320 6d61 6e79 2073  t test as many s
-0000fdc0: 656c 6563 7469 6f6e 2066 6561 7475 7265  election feature
-0000fdd0: 7320 6173 2074 6865 2061 626f 7665 2e0a  s as the above..
-0000fde0: 2020 2020 2020 2020 2320 5468 6973 2069          # This i
-0000fdf0: 7320 6120 636f 6d62 696e 6564 2074 6573  s a combined tes
-0000fe00: 7420 666f 7220 7370 6565 6420 7265 6173  t for speed reas
-0000fe10: 6f6e 732e 2054 6865 2069 6e64 6976 6964  ons. The individ
-0000fe20: 7561 6c20 696d 7065 7266 6563 7469 6f6e  ual imperfection
-0000fe30: 7320 6172 6520 7465 7374 6564 2061 7320  s are tested as 
-0000fe40: 756e 6974 7465 7374 7320 696e 0a20 2020  unittests in.   
-0000fe50: 2020 2020 2023 2075 6e69 742f 7465 7374       # unit/test
-0000fe60: 5f73 656c 6563 7469 6f6e 2e0a 2020 2020  _selection..    
-0000fe70: 2020 2020 2320 496d 7065 7266 6563 7469      # Imperfecti
-0000fe80: 6f6e 7320 7465 7374 6564 2061 7265 3b0a  ons tested are;.
-0000fe90: 2020 2020 2020 2020 2320 2a20 4c65 6164          # * Lead
-0000fea0: 696e 6720 7370 6163 652f 7370 6163 6573  ing space/spaces
-0000feb0: 2062 6566 6f72 6520 7468 6520 6d6f 6469   before the modi
-0000fec0: 6669 6572 0a20 2020 2020 2020 2023 202a  fier.        # *
-0000fed0: 2054 7261 696c 696e 6720 7370 6163 652f   Trailing space/
-0000fee0: 7370 6163 6573 2061 6674 6572 2074 6865  spaces after the
-0000fef0: 2066 696c 656e 616d 6520 2862 7574 2062   filename (but b
-0000ff00: 6566 6f72 6520 7468 6520 6e65 776c 696e  efore the newlin
-0000ff10: 6529 0a20 2020 2020 2020 2023 202a 2042  e).        # * B
-0000ff20: 6c61 6e6b 206c 696e 6573 2028 6e65 776c  lank lines (newl
-0000ff30: 696e 6520 6368 6172 6163 7465 7220 6f6e  ine character on
-0000ff40: 6c79 290a 2020 2020 2020 2020 2320 2a20  ly).        # * 
-0000ff50: 4c69 6e65 206f 6e6c 7920 636f 6e74 6169  Line only contai
-0000ff60: 6e69 6e67 2073 7061 6365 730a 2020 2020  ning spaces.    
-0000ff70: 2020 2020 2320 2a20 4675 6c6c 2d6c 696e      # * Full-lin
-0000ff80: 6520 636f 6d6d 656e 7473 2077 6974 6820  e comments with 
-0000ff90: 2320 6173 2074 6865 2066 6972 7374 2063  # as the first c
-0000ffa0: 6861 7261 6374 6572 2061 6e64 2077 6974  haracter and wit
-0000ffb0: 6820 6c65 6164 696e 672f 7472 6169 6c69  h leading/traili
-0000ffc0: 6e67 2073 7061 6365 730a 2020 2020 2020  ng spaces.      
-0000ffd0: 2020 2320 2a20 556e 6e65 6365 7373 6172    # * Unnecessar
-0000ffe0: 696c 7920 7175 6f74 6564 2066 696c 656e  ily quoted filen
-0000fff0: 616d 6573 2077 6974 682f 7769 7468 6f75  ames with/withou
-00010000: 7420 6d6f 6469 6669 6572 2020 2862 6f74  t modifier  (bot
-00010010: 6820 2220 616e 6420 2729 0a20 2020 2020  h " and ').     
-00010020: 2020 2023 2043 7265 6174 6520 6120 6669     # Create a fi
-00010030: 6c65 6c69 7374 0a20 2020 2020 2020 2077  lelist.        w
-00010040: 6974 6820 696f 2e6f 7065 6e28 7522 7465  ith io.open(u"te
-00010050: 7374 6669 6c65 732f 696e 636c 7564 652e  stfiles/include.
-00010060: 7478 7422 2c20 7522 7722 2920 6173 2066  txt", u"w") as f
-00010070: 3a0a 2020 2020 2020 2020 2020 2020 662e  :.            f.
-00010080: 7772 6974 6528 7522 7465 7374 6669 6c65  write(u"testfile
-00010090: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-000100a0: 332f 3373 7562 3373 7562 322f 3373 7562  3/3sub3sub2/3sub
-000100b0: 3373 7562 325f 6669 6c65 2e74 7874 5c6e  3sub2_file.txt\n
-000100c0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-000100d0: 2020 2020 2020 7522 7465 7374 6669 6c65        u"testfile
-000100e0: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-000100f0: 322f 3373 7562 3273 7562 3220 5c6e 220a  2/3sub2sub2 \n".
-00010100: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010110: 2020 2020 7522 2020 2b20 7465 7374 6669      u"  + testfi
-00010120: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
-00010130: 7562 335c 6e22 2020 2320 2b20 6164 6465  ub3\n"  # + adde
-00010140: 6420 746f 2065 6e73 7572 6520 6974 206d  d to ensure it m
-00010150: 616b 6573 206e 6f20 6469 6666 6572 656e  akes no differen
-00010160: 6365 0a20 2020 2020 2020 2020 2020 2020  ce.             
-00010170: 2020 2020 2020 2075 2220 2d20 7465 7374         u" - test
-00010180: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
-00010190: 3373 7562 3120 205c 6e22 0a20 2020 2020  3sub1  \n".     
-000101a0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-000101b0: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
-000101c0: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
-000101d0: 6231 7375 6233 5c6e 220a 2020 2020 2020  b1sub3\n".      
-000101e0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-000101f0: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
-00010200: 6374 322f 322f 3273 7562 312f 3273 7562  ct2/2/2sub1/2sub
-00010210: 3173 7562 325c 6e22 0a20 2020 2020 2020  1sub2\n".       
-00010220: 2020 2020 2020 2020 2020 2020 2075 2722               u'"
-00010230: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00010240: 322f 322f 3273 7562 3122 5c6e 270a 2020  2/2/2sub1"\n'.  
-00010250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010260: 2020 7522 2020 202d 2074 6573 7466 696c    u"   - testfil
-00010270: 6573 2f73 656c 6563 7432 2f32 2f32 7375  es/select2/2/2su
-00010280: 6233 205c 6e22 2020 2320 4164 6465 6420  b3 \n"  # Added 
-00010290: 6265 6361 7573 6520 6f66 2042 7567 2023  because of Bug #
-000102a0: 3134 3038 3431 310a 2020 2020 2020 2020  1408411.        
-000102b0: 2020 2020 2020 2020 2020 2020 7522 2d20              u"- 
-000102c0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-000102d0: 322f 322f 3273 7562 325c 6e22 2020 2320  2/2/2sub2\n"  # 
-000102e0: 4164 6465 6420 6265 6361 7573 6520 6f66  Added because of
-000102f0: 2042 7567 2023 3134 3038 3431 310a 2020   Bug #1408411.  
-00010300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010310: 2020 7522 2d20 2774 6573 7466 696c 6573    u"- 'testfiles
-00010320: 2f73 656c 6563 7432 2f31 2f31 7375 6233  /select2/1/1sub3
-00010330: 2f31 7375 6233 7375 6232 275c 6e22 0a20  /1sub3sub2'\n". 
-00010340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010350: 2020 2075 225c 6e22 0a20 2020 2020 2020     u"\n".       
-00010360: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00010370: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-00010380: 7432 2f31 2f31 7375 6233 2f31 7375 6233  t2/1/1sub3/1sub3
-00010390: 7375 6231 5c6e 220a 2020 2020 2020 2020  sub1\n".        
-000103a0: 2020 2020 2020 2020 2020 2020 7522 2d20              u"- 
-000103b0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-000103c0: 322f 312f 3173 7562 322f 3173 7562 3273  2/1/1sub2/1sub2s
-000103d0: 7562 335c 6e22 0a20 2020 2020 2020 2020  ub3\n".         
-000103e0: 2020 2020 2020 2020 2020 2075 272d 2022             u'- "
-000103f0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00010400: 322f 312f 3173 7562 322f 3173 7562 3273  2/1/1sub2/1sub2s
-00010410: 7562 3222 5c6e 2720 2023 2041 6464 6564  ub2"\n'  # Added
-00010420: 2062 6563 6175 7365 206f 6620 4275 6720   because of Bug 
-00010430: 2331 3430 3834 3131 0a20 2020 2020 2020  #1408411.       
-00010440: 2020 2020 2020 2020 2020 2020 2075 2223               u"#
-00010450: 2054 6869 7320 6973 2061 2066 756c 6c2d   This is a full-
-00010460: 6c69 6e65 2063 6f6d 6d65 6e74 5c6e 220a  line comment\n".
-00010470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010480: 2020 2020 7522 2b20 7465 7374 6669 6c65      u"+ testfile
-00010490: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-000104a0: 322f 3173 7562 3273 7562 3120 205c 6e22  2/1sub2sub1  \n"
-000104b0: 2020 2320 2b20 6164 6465 6420 746f 2065    # + added to e
-000104c0: 6e73 7572 6520 6974 206d 616b 6573 206e  nsure it makes n
-000104d0: 6f20 6469 6666 6572 656e 6365 0a20 2020  o difference.   
-000104e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000104f0: 2075 222d 2074 6573 7466 696c 6573 2f73   u"- testfiles/s
-00010500: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
-00010510: 7375 6231 7375 6233 2f31 7375 6231 7375  sub1sub3/1sub1su
-00010520: 6233 5f66 696c 652e 7478 745c 6e22 0a20  b3_file.txt\n". 
-00010530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010540: 2020 2075 2220 2020 2020 2020 2020 205c     u"          \
-00010550: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00010560: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-00010570: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00010580: 7375 6231 2f31 7375 6231 7375 6232 5c6e  sub1/1sub1sub2\n
-00010590: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-000105a0: 2020 2020 2020 2320 2075 222d 2074 6573        #  u"- tes
-000105b0: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-000105c0: 2f31 7375 6232 5c6e 2220 2023 2043 6f6d  /1sub2\n"  # Com
-000105d0: 6d65 6e74 6564 206f 7574 2062 6563 6175  mented out becau
-000105e0: 7365 206f 6620 4275 6720 2331 3430 3834  se of Bug #14084
-000105f0: 3131 0a20 2020 2020 2020 2020 2020 2020  11.             
-00010600: 2020 2020 2020 2075 2227 7465 7374 6669         u"'testfi
-00010610: 6c65 732f 7365 6c65 6374 322f 312e 7079  les/select2/1.py
-00010620: 275c 6e22 0a20 2020 2020 2020 2020 2020  '\n".           
-00010630: 2020 2020 2020 2020 2075 2220 2020 2020           u"     
-00010640: 2020 2320 5468 6973 2069 7320 616e 6f74    # This is anot
-00010650: 6865 7220 6675 6c6c 2d6c 696e 6520 636f  her full-line co
-00010660: 6d6d 656e 742c 2077 6974 6820 7370 6163  mment, with spac
-00010670: 6573 2020 2020 205c 6e22 0a20 2020 2020  es     \n".     
-00010680: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00010690: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-000106a0: 7432 2f33 5c6e 220a 2020 2020 2020 2020  t2/3\n".        
-000106b0: 2020 2020 2020 2020 2020 2020 2320 2075              #  u
-000106c0: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
-000106d0: 6563 7432 2f32 5c6e 2220 2320 436f 6d6d  ect2/2\n" # Comm
-000106e0: 656e 7465 6420 6f75 7420 6265 6361 7573  ented out becaus
-000106f0: 6520 6f66 2042 7567 2023 3134 3038 3431  e of Bug #140841
-00010700: 310a 2020 2020 2020 2020 2020 2020 2020  1.              
-00010710: 2020 2020 2020 7522 7465 7374 6669 6c65        u"testfile
-00010720: 732f 7365 6c65 6374 322f 315c 6e22 0a20  s/select2/1\n". 
-00010730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010740: 2020 2075 272d 2022 7465 7374 6669 6c65     u'- "testfile
-00010750: 732f 7365 6c65 6374 322f 7472 6169 6c69  s/select2/traili
-00010760: 6e67 5f73 7061 6365 2022 5c6e 2720 2023  ng_space "\n'  #
-00010770: 2065 7320 696e 7374 6561 6420 6f66 2065   es instead of e
-00010780: 6120 6173 206e 6f20 7769 6c64 6361 7264  a as no wildcard
-00010790: 202d 202a 2a0a 2020 2020 2020 2020 2020   - **.          
-000107a0: 2020 2020 2020 2020 2020 7522 2d20 7465            u"- te
-000107b0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-000107c0: 312e 646f 6322 2920 2023 2065 7320 696e  1.doc")  # es in
-000107d0: 7374 6561 6420 6f66 2065 6120 6173 206e  stead of ea as n
-000107e0: 6f20 7769 6c64 6361 7264 202d 202a 2a0a  o wildcard - **.
-000107f0: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
-00010800: 6b75 7028 7522 6675 6c6c 222c 2075 2274  kup(u"full", u"t
-00010810: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00010820: 222c 206f 7074 696f 6e73 3d5b 7522 2d2d  ", options=[u"--
-00010830: 696e 636c 7564 652d 6669 6c65 6c69 7374  include-filelist
-00010840: 3d74 6573 7466 696c 6573 2f69 6e63 6c75  =testfiles/inclu
-00010850: 6465 2e74 7874 225d 290a 2020 2020 2020  de.txt"]).      
-00010860: 2020 7365 6c66 2e72 6573 746f 7265 2829    self.restore()
-00010870: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
-00010880: 5f64 6972 203d 2075 2274 6573 7466 696c  _dir = u"testfil
-00010890: 6573 2f72 6573 746f 7265 5f6f 7574 220a  es/restore_out".
-000108a0: 2020 2020 2020 2020 7265 7374 6f72 6564          restored
-000108b0: 203d 2073 656c 662e 6469 7265 6374 6f72   = self.director
-000108c0: 795f 7472 6565 5f74 6f5f 6c69 7374 5f6f  y_tree_to_list_o
-000108d0: 665f 6c69 7374 7328 7265 7374 6f72 655f  f_lists(restore_
-000108e0: 6469 7229 0a20 2020 2020 2020 2073 656c  dir).        sel
-000108f0: 662e 6173 7365 7274 4571 7561 6c28 7265  f.assertEqual(re
-00010900: 7374 6f72 6564 2c20 7365 6c66 2e65 7870  stored, self.exp
-00010910: 6563 7465 645f 7265 7374 6f72 6564 5f74  ected_restored_t
-00010920: 7265 6529 0a0a 2020 2020 6465 6620 7465  ree)..    def te
-00010930: 7374 5f69 6e63 6c75 6465 5f67 6c6f 6262  st_include_globb
-00010940: 696e 675f 6669 6c65 6c69 7374 5f63 6f6d  ing_filelist_com
-00010950: 6269 6e65 645f 696d 7065 7266 6563 7469  bined_imperfecti
-00010960: 6f6e 7328 7365 6c66 293a 0a20 2020 2020  ons(self):.     
-00010970: 2020 2075 2222 2254 6573 7420 7468 6174     u"""Test that
-00010980: 2069 6e63 6c75 6465 2067 6c6f 6262 696e   include globbin
-00010990: 6720 6669 6c65 6c69 7374 2077 6f72 6b73  g filelist works
-000109a0: 2077 6974 6820 696d 7065 7266 6563 7469   with imperfecti
-000109b0: 6f6e 7320 696e 2074 6865 2069 6e70 7574  ons in the input
-000109c0: 2066 696c 6522 2222 0a20 2020 2020 2020   file""".       
-000109d0: 2023 2049 6465 6e74 6963 616c 2074 6f20   # Identical to 
-000109e0: 7465 7374 5f69 6e63 6c75 6465 5f66 696c  test_include_fil
-000109f0: 656c 6973 745f 636f 6d62 696e 6564 5f69  elist_combined_i
-00010a00: 6d70 6572 6665 6374 696f 6e73 2061 6e64  mperfections and
-00010a10: 2069 6e63 6c75 6465 6420 746f 2065 6e73   included to ens
-00010a20: 7572 6520 7468 6174 0a20 2020 2020 2020  ure that.       
-00010a30: 2023 2074 6865 2064 6570 7265 6361 7465   # the deprecate
-00010a40: 6420 2d2d 696e 636c 7564 652d 676c 6f62  d --include-glob
-00010a50: 6269 6e67 2d66 696c 656c 6973 7420 6675  bing-filelist fu
-00010a60: 6e63 7469 6f6e 2077 6f72 6b73 2061 7320  nction works as 
-00010a70: 6578 7065 6374 6564 2075 6e74 696c 2069  expected until i
-00010a80: 7420 6973 2064 656c 6962 6572 6174 656c  t is deliberatel
-00010a90: 7920 7265 6d6f 7665 642e 0a20 2020 2020  y removed..     
-00010aa0: 2020 2023 2054 6869 7320 6973 2061 2063     # This is a c
-00010ab0: 6f6d 6269 6e65 6420 7465 7374 2066 6f72  ombined test for
-00010ac0: 2073 7065 6564 2072 6561 736f 6e73 2e20   speed reasons. 
-00010ad0: 5468 6520 696e 6469 7669 6475 616c 2069  The individual i
-00010ae0: 6d70 6572 6665 6374 696f 6e73 2061 7265  mperfections are
-00010af0: 2074 6573 7465 6420 6173 2075 6e69 7474   tested as unitt
-00010b00: 6573 7473 2069 6e0a 2020 2020 2020 2020  ests in.        
-00010b10: 2320 756e 6974 2f74 6573 745f 7365 6c65  # unit/test_sele
-00010b20: 6374 696f 6e2e 0a20 2020 2020 2020 2023  ction..        #
-00010b30: 2049 6d70 6572 6665 6374 696f 6e73 2074   Imperfections t
-00010b40: 6573 7465 6420 6172 653b 0a20 2020 2020  ested are;.     
-00010b50: 2020 2023 202a 204c 6561 6469 6e67 2073     # * Leading s
-00010b60: 7061 6365 2f73 7061 6365 7320 6265 666f  pace/spaces befo
-00010b70: 7265 2074 6865 206d 6f64 6966 6965 720a  re the modifier.
-00010b80: 2020 2020 2020 2020 2320 2a20 5472 6169          # * Trai
-00010b90: 6c69 6e67 2073 7061 6365 2f73 7061 6365  ling space/space
-00010ba0: 7320 6166 7465 7220 7468 6520 6669 6c65  s after the file
-00010bb0: 6e61 6d65 2028 6275 7420 6265 666f 7265  name (but before
-00010bc0: 2074 6865 206e 6577 6c69 6e65 290a 2020   the newline).  
-00010bd0: 2020 2020 2020 2320 2a20 426c 616e 6b20        # * Blank 
-00010be0: 6c69 6e65 7320 286e 6577 6c69 6e65 2063  lines (newline c
-00010bf0: 6861 7261 6374 6572 206f 6e6c 7929 0a20  haracter only). 
-00010c00: 2020 2020 2020 2023 202a 204c 696e 6520         # * Line 
-00010c10: 6f6e 6c79 2063 6f6e 7461 696e 696e 6720  only containing 
-00010c20: 7370 6163 6573 0a20 2020 2020 2020 2023  spaces.        #
-00010c30: 202a 2046 756c 6c2d 6c69 6e65 2063 6f6d   * Full-line com
-00010c40: 6d65 6e74 7320 7769 7468 2023 2061 7320  ments with # as 
-00010c50: 7468 6520 6669 7273 7420 6368 6172 6163  the first charac
-00010c60: 7465 7220 616e 6420 7769 7468 206c 6561  ter and with lea
-00010c70: 6469 6e67 2f74 7261 696c 696e 6720 7370  ding/trailing sp
-00010c80: 6163 6573 0a20 2020 2020 2020 2023 202a  aces.        # *
-00010c90: 2055 6e6e 6563 6573 7361 7269 6c79 2071   Unnecessarily q
-00010ca0: 756f 7465 6420 6669 6c65 6e61 6d65 7320  uoted filenames 
-00010cb0: 7769 7468 2f77 6974 686f 7574 206d 6f64  with/without mod
-00010cc0: 6966 6965 7220 2028 626f 7468 2022 2061  ifier  (both " a
-00010cd0: 6e64 2027 290a 2020 2020 2020 2020 2320  nd ').        # 
-00010ce0: 4372 6561 7465 2061 2066 696c 656c 6973  Create a filelis
-00010cf0: 740a 2020 2020 2020 2020 7769 7468 2069  t.        with i
-00010d00: 6f2e 6f70 656e 2875 2274 6573 7466 696c  o.open(u"testfil
-00010d10: 6573 2f69 6e63 6c75 6465 2e74 7874 222c  es/include.txt",
-00010d20: 2075 2277 2229 2061 7320 663a 0a20 2020   u"w") as f:.   
-00010d30: 2020 2020 2020 2020 2066 2e77 7269 7465           f.write
-00010d40: 2875 2274 6573 7466 696c 6573 2f73 656c  (u"testfiles/sel
-00010d50: 6563 7432 2f33 2f33 7375 6233 2f33 7375  ect2/3/3sub3/3su
-00010d60: 6233 7375 6232 2f33 7375 6233 7375 6232  b3sub2/3sub3sub2
-00010d70: 5f66 696c 652e 7478 745c 6e22 0a20 2020  _file.txt\n".   
-00010d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010d90: 2075 222d 2074 6573 7466 696c 6573 2f73   u"- testfiles/s
-00010da0: 656c 6563 7432 2f33 2f33 7375 6233 2f33  elect2/3/3sub3/3
-00010db0: 7375 6233 7375 6232 5c6e 220a 2020 2020  sub3sub2\n".    
-00010dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010dd0: 7527 2274 6573 7466 696c 6573 2f73 656c  u'"testfiles/sel
-00010de0: 6563 7432 2f33 2f33 7375 6232 2f33 7375  ect2/3/3sub2/3su
-00010df0: 6232 7375 6232 225c 6e27 0a20 2020 2020  b2sub2"\n'.     
-00010e00: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00010e10: 2220 202b 2074 6573 7466 696c 6573 2f73  "  + testfiles/s
-00010e20: 656c 6563 7432 2f33 2f33 7375 6233 5c6e  elect2/3/3sub3\n
-00010e30: 2220 2023 202b 2061 6464 6564 2074 6f20  "  # + added to 
-00010e40: 656e 7375 7265 2069 7420 6d61 6b65 7320  ensure it makes 
-00010e50: 6e6f 2064 6966 6665 7265 6e63 650a 2020  no difference.  
-00010e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010e70: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-00010e80: 7365 6c65 6374 322f 332f 3373 7562 315c  select2/3/3sub1\
-00010e90: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00010ea0: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-00010eb0: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
-00010ec0: 7375 6231 2f32 7375 6231 7375 6233 5c6e  sub1/2sub1sub3\n
-00010ed0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00010ee0: 2020 2020 2020 7527 202d 2022 7465 7374        u' - "test
-00010ef0: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-00010f00: 3273 7562 312f 3273 7562 3173 7562 3222  2sub1/2sub1sub2"
-00010f10: 5c6e 270a 2020 2020 2020 2020 2020 2020  \n'.            
-00010f20: 2020 2020 2020 2020 7522 7465 7374 6669          u"testfi
-00010f30: 6c65 732f 7365 6c65 6374 322f 322f 3273  les/select2/2/2s
-00010f40: 7562 3120 205c 6e22 0a20 2020 2020 2020  ub1  \n".       
-00010f50: 2020 2020 2020 2020 2020 2020 2075 225c               u"\
-00010f60: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00010f70: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-00010f80: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00010f90: 7375 6233 2f31 7375 6233 7375 6232 5c6e  sub3/1sub3sub2\n
-00010fa0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00010fb0: 2020 2020 2020 7522 2d20 7465 7374 6669        u"- testfi
-00010fc0: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-00010fd0: 7562 332f 3173 7562 3373 7562 3120 5c6e  ub3/1sub3sub1 \n
-00010fe0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00010ff0: 2020 2020 2020 7522 2d20 2774 6573 7466        u"- 'testf
-00011000: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00011010: 7375 6232 2f31 7375 6232 7375 6233 275c  sub2/1sub2sub3'\
-00011020: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00011030: 2020 2020 2020 2075 2220 2020 2020 2020         u"       
-00011040: 2020 2020 2020 5c6e 220a 2020 2020 2020        \n".      
-00011050: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00011060: 202b 2074 6573 7466 696c 6573 2f73 656c   + testfiles/sel
-00011070: 6563 7432 2f31 2f31 7375 6232 2f31 7375  ect2/1/1sub2/1su
-00011080: 6232 7375 6231 205c 6e22 2020 2320 2b20  b2sub1 \n"  # + 
-00011090: 6164 6465 6420 746f 2065 6e73 7572 6520  added to ensure 
-000110a0: 6974 206d 616b 6573 206e 6f20 6469 6666  it makes no diff
-000110b0: 6572 656e 6365 0a20 2020 2020 2020 2020  erence.         
-000110c0: 2020 2020 2020 2020 2020 2075 222d 2074             u"- t
-000110d0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-000110e0: 2f31 2f31 7375 6231 2f31 7375 6231 7375  /1/1sub1/1sub1su
-000110f0: 6233 2f31 7375 6231 7375 6233 5f66 696c  b3/1sub1sub3_fil
-00011100: 652e 7478 745c 6e22 0a20 2020 2020 2020  e.txt\n".       
-00011110: 2020 2020 2020 2020 2020 2020 2075 2220               u" 
-00011120: 202d 2074 6573 7466 696c 6573 2f73 656c   - testfiles/sel
-00011130: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
-00011140: 6231 7375 6232 2020 5c6e 220a 2020 2020  b1sub2  \n".    
-00011150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011160: 7522 2320 5465 7374 696e 6720 6675 6c6c  u"# Testing full
-00011170: 2d6c 696e 6520 636f 6d6d 656e 745c 6e22  -line comment\n"
-00011180: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011190: 2020 2020 2075 222d 2074 6573 7466 696c       u"- testfil
-000111a0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-000111b0: 6232 5c6e 220a 2020 2020 2020 2020 2020  b2\n".          
-000111c0: 2020 2020 2020 2020 2020 7522 2774 6573            u"'tes
-000111d0: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-000111e0: 2e70 7927 5c6e 220a 2020 2020 2020 2020  .py'\n".        
-000111f0: 2020 2020 2020 2020 2020 2020 7522 7465              u"te
-00011200: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00011210: 335c 6e22 0a20 2020 2020 2020 2020 2020  3\n".           
-00011220: 2020 2020 2020 2020 2075 2220 2020 2020           u"     
-00011230: 2020 2023 2020 5465 7374 696e 6720 616e     #  Testing an
-00011240: 6f74 6865 7220 6675 6c6c 2d6c 696e 6520  other full-line 
-00011250: 636f 6d6d 656e 7420 2020 2020 205c 6e22  comment      \n"
-00011260: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011270: 2020 2020 2075 2274 6573 7466 696c 6573       u"testfiles
-00011280: 2f73 656c 6563 7432 2f31 5c6e 220a 2020  /select2/1\n".  
-00011290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000112a0: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-000112b0: 7365 6c65 6374 322f 2a2a 2229 0a20 2020  select2/**").   
-000112c0: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
-000112d0: 2875 2266 756c 6c22 2c20 7522 7465 7374  (u"full", u"test
-000112e0: 6669 6c65 732f 7365 6c65 6374 3222 2c20  files/select2", 
-000112f0: 6f70 7469 6f6e 733d 5b75 222d 2d69 6e63  options=[u"--inc
-00011300: 6c75 6465 2d67 6c6f 6262 696e 672d 6669  lude-globbing-fi
-00011310: 6c65 6c69 7374 3d74 6573 7466 696c 6573  lelist=testfiles
-00011320: 2f69 6e63 6c75 6465 2e74 7874 225d 290a  /include.txt"]).
-00011330: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-00011340: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
-00011350: 6573 746f 7265 5f64 6972 203d 2075 2274  estore_dir = u"t
-00011360: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
-00011370: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
-00011380: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
-00011390: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
-000113a0: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
-000113b0: 7374 6f72 655f 6469 7229 0a20 2020 2020  store_dir).     
-000113c0: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
-000113d0: 7561 6c28 7265 7374 6f72 6564 2c20 7365  ual(restored, se
-000113e0: 6c66 2e65 7870 6563 7465 645f 7265 7374  lf.expected_rest
-000113f0: 6f72 6564 5f74 7265 6529 0a0a 2020 2020  ored_tree)..    
-00011400: 6465 6620 7465 7374 5f69 6e63 6c75 6465  def test_include
-00011410: 5f67 6c6f 6262 696e 675f 6669 6c65 6c69  _globbing_fileli
-00011420: 7374 5f69 735f 616c 7761 7973 5f67 6c6f  st_is_always_glo
-00011430: 6262 696e 6728 7365 6c66 293a 0a20 2020  bbing(self):.   
-00011440: 2020 2020 2075 2222 2254 6573 7420 7468       u"""Test th
-00011450: 6174 2069 6e63 6c75 6465 2067 6c6f 6262  at include globb
-00011460: 696e 6720 6669 6c65 6c69 7374 2077 6f72  ing filelist wor
-00011470: 6b73 2077 6974 6820 696d 7065 7266 6563  ks with imperfec
-00011480: 7469 6f6e 7320 696e 2074 6865 2069 6e70  tions in the inp
-00011490: 7574 2066 696c 6522 2222 0a20 2020 2020  ut file""".     
-000114a0: 2020 2023 2049 6465 6e74 6963 616c 2074     # Identical t
-000114b0: 6f20 7465 7374 5f69 6e63 6c75 6465 5f67  o test_include_g
-000114c0: 6c6f 6262 696e 672b 6669 6c65 6c69 7374  lobbing+filelist
-000114d0: 5f63 6f6d 6269 6e65 645f 696d 7065 7266  _combined_imperf
-000114e0: 6563 7469 6f6e 7320 616e 6420 696e 636c  ections and incl
-000114f0: 7564 6564 2074 6f20 656e 7375 7265 2074  uded to ensure t
-00011500: 6861 740a 2020 2020 2020 2020 2320 7468  hat.        # th
-00011510: 6520 6465 7072 6563 6174 6564 202d 2d69  e deprecated --i
-00011520: 6e63 6c75 6465 2d67 6c6f 6262 696e 672d  nclude-globbing-
-00011530: 6669 6c65 6c69 7374 2066 756e 6374 696f  filelist functio
-00011540: 6e20 776f 726b 7320 6173 2065 7870 6563  n works as expec
-00011550: 7465 6420 756e 7469 6c20 6974 2069 7320  ted until it is 
-00011560: 6465 6c69 6265 7261 7465 6c79 2072 656d  deliberately rem
-00011570: 6f76 6564 2e0a 2020 2020 2020 2020 2320  oved..        # 
-00011580: 5468 6973 2074 6573 7420 6973 2072 6571  This test is req
-00011590: 7569 7265 6420 6173 2077 6865 6e20 2d2d  uired as when --
-000115a0: 6669 6c74 6572 2d2a 206f 7074 696f 6e73  filter-* options
-000115b0: 2061 7265 2075 7365 6420 7468 6520 7374   are used the st
-000115c0: 616e 6461 7264 202d 2d69 6e63 6c75 6465  andard --include
-000115d0: 2d66 696c 656c 6973 7420 6f70 7469 6f6e  -filelist option
-000115e0: 0a20 2020 2020 2020 2023 206d 6179 206e  .        # may n
-000115f0: 6f74 2062 6520 696e 2067 6c6f 6262 696e  ot be in globbin
-00011600: 6720 6d6f 6465 2c20 6275 7420 7468 6520  g mode, but the 
-00011610: 6465 7072 6563 6174 6564 202d 2d69 6e63  deprecated --inc
-00011620: 6c75 6465 2d67 6c6f 6262 696e 672d 6669  lude-globbing-fi
-00011630: 6c65 6c69 7374 2073 686f 756c 6420 6265  lelist should be
-00011640: 2065 7665 6e20 6966 0a20 2020 2020 2020   even if.       
-00011650: 2023 2070 7265 6365 6465 6420 6279 2061   # preceded by a
-00011660: 206e 6f6e 2d67 6c6f 6262 696e 6720 6669   non-globbing fi
-00011670: 6c74 6572 206d 6f64 6520 7377 6974 6368  lter mode switch
-00011680: 2e0a 2020 2020 2020 2020 2320 4372 6561  ..        # Crea
-00011690: 7465 2061 2066 696c 656c 6973 740a 2020  te a filelist.  
-000116a0: 2020 2020 2020 7769 7468 2069 6f2e 6f70        with io.op
-000116b0: 656e 2875 2274 6573 7466 696c 6573 2f69  en(u"testfiles/i
-000116c0: 6e63 6c75 6465 2e74 7874 222c 2075 2277  nclude.txt", u"w
-000116d0: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
-000116e0: 2020 2020 2066 2e77 7269 7465 2875 2274       f.write(u"t
-000116f0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00011700: 2f33 2f33 7375 6233 2f33 7375 6233 7375  /3/3sub3/3sub3su
-00011710: 6232 2f33 7375 6233 7375 6232 5f66 696c  b2/3sub3sub2_fil
-00011720: 652e 7478 745c 6e22 0a20 2020 2020 2020  e.txt\n".       
-00011730: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00011740: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-00011750: 7432 2f33 2f33 7375 6233 2f33 7375 6233  t2/3/3sub3/3sub3
-00011760: 7375 6232 5c6e 220a 2020 2020 2020 2020  sub2\n".        
-00011770: 2020 2020 2020 2020 2020 2020 7527 2274              u'"t
-00011780: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00011790: 2f33 2f33 7375 6232 2f33 7375 6232 7375  /3/3sub2/3sub2su
-000117a0: 6232 225c 6e27 0a20 2020 2020 2020 2020  b2"\n'.         
-000117b0: 2020 2020 2020 2020 2020 2075 2220 202b             u"  +
-000117c0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-000117d0: 7432 2f33 2f33 7375 6233 5c6e 2220 2023  t2/3/3sub3\n"  #
-000117e0: 202b 2061 6464 6564 2074 6f20 656e 7375   + added to ensu
-000117f0: 7265 2069 7420 6d61 6b65 7320 6e6f 2064  re it makes no d
-00011800: 6966 6665 7265 6e63 650a 2020 2020 2020  ifference.      
-00011810: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00011820: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
-00011830: 6374 322f 332f 3373 7562 315c 6e22 0a20  ct2/3/3sub1\n". 
-00011840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011850: 2020 2075 222d 2074 6573 7466 696c 6573     u"- testfiles
-00011860: 2f73 656c 6563 7432 2f32 2f32 7375 6231  /select2/2/2sub1
-00011870: 2f32 7375 6231 7375 6233 5c6e 220a 2020  /2sub1sub3\n".  
-00011880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011890: 2020 7527 202d 2022 7465 7374 6669 6c65    u' - "testfile
-000118a0: 732f 7365 6c65 6374 322f 322f 3273 7562  s/select2/2/2sub
-000118b0: 312f 3273 7562 3173 7562 3222 5c6e 270a  1/2sub1sub2"\n'.
-000118c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000118d0: 2020 2020 7522 7465 7374 6669 6c65 732f      u"testfiles/
-000118e0: 7365 6c65 6374 322f 322f 3273 7562 3120  select2/2/2sub1 
-000118f0: 205c 6e22 0a20 2020 2020 2020 2020 2020   \n".           
-00011900: 2020 2020 2020 2020 2075 225c 6e22 0a20           u"\n". 
-00011910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011920: 2020 2075 222d 2074 6573 7466 696c 6573     u"- testfiles
-00011930: 2f73 656c 6563 7432 2f31 2f31 7375 6233  /select2/1/1sub3
-00011940: 2f31 7375 6233 7375 6232 5c6e 220a 2020  /1sub3sub2\n".  
-00011950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011960: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-00011970: 7365 6c65 6374 322f 312f 3173 7562 332f  select2/1/1sub3/
-00011980: 3173 7562 3373 7562 3120 5c6e 220a 2020  1sub3sub1 \n".  
-00011990: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000119a0: 2020 7522 2d20 2774 6573 7466 696c 6573    u"- 'testfiles
-000119b0: 2f73 656c 6563 7432 2f31 2f31 7375 6232  /select2/1/1sub2
-000119c0: 2f31 7375 6232 7375 6233 275c 6e22 0a20  /1sub2sub3'\n". 
-000119d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000119e0: 2020 2075 2220 2020 2020 2020 2020 2020     u"           
-000119f0: 2020 5c6e 220a 2020 2020 2020 2020 2020    \n".          
-00011a00: 2020 2020 2020 2020 2020 7522 202b 2074            u" + t
-00011a10: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00011a20: 2f31 2f31 7375 6232 2f31 7375 6232 7375  /1/1sub2/1sub2su
-00011a30: 6231 205c 6e22 2020 2320 2b20 6164 6465  b1 \n"  # + adde
-00011a40: 6420 746f 2065 6e73 7572 6520 6974 206d  d to ensure it m
-00011a50: 616b 6573 206e 6f20 6469 6666 6572 656e  akes no differen
-00011a60: 6365 0a20 2020 2020 2020 2020 2020 2020  ce.             
-00011a70: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-00011a80: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00011a90: 7375 6231 2f31 7375 6231 7375 6233 2f31  sub1/1sub1sub3/1
-00011aa0: 7375 6231 7375 6233 5f66 696c 652e 7478  sub1sub3_file.tx
-00011ab0: 745c 6e22 0a20 2020 2020 2020 2020 2020  t\n".           
-00011ac0: 2020 2020 2020 2020 2075 2220 202d 2074           u"  - t
-00011ad0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00011ae0: 2f31 2f31 7375 6231 2f31 7375 6231 7375  /1/1sub1/1sub1su
-00011af0: 6232 2020 5c6e 220a 2020 2020 2020 2020  b2  \n".        
-00011b00: 2020 2020 2020 2020 2020 2020 7522 2320              u"# 
-00011b10: 5465 7374 696e 6720 6675 6c6c 2d6c 696e  Testing full-lin
-00011b20: 6520 636f 6d6d 656e 745c 6e22 0a20 2020  e comment\n".   
-00011b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011b40: 2075 222d 2074 6573 7466 696c 6573 2f73   u"- testfiles/s
-00011b50: 656c 6563 7432 2f31 2f31 7375 6232 5c6e  elect2/1/1sub2\n
-00011b60: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00011b70: 2020 2020 2020 7522 2774 6573 7466 696c        u"'testfil
-00011b80: 6573 2f73 656c 6563 7432 2f31 2e70 7927  es/select2/1.py'
-00011b90: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-00011ba0: 2020 2020 2020 2020 7522 7465 7374 6669          u"testfi
-00011bb0: 6c65 732f 7365 6c65 6374 322f 335c 6e22  les/select2/3\n"
-00011bc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00011bd0: 2020 2020 2075 2220 2020 2020 2020 2023       u"        #
-00011be0: 2020 5465 7374 696e 6720 616e 6f74 6865    Testing anothe
-00011bf0: 7220 6675 6c6c 2d6c 696e 6520 636f 6d6d  r full-line comm
-00011c00: 656e 7420 2020 2020 205c 6e22 0a20 2020  ent      \n".   
-00011c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c20: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00011c30: 6563 7432 2f31 5c6e 220a 2020 2020 2020  ect2/1\n".      
-00011c40: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00011c50: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
-00011c60: 6374 322f 2a2a 2229 0a20 2020 2020 2020  ct2/**").       
-00011c70: 2073 656c 662e 6261 636b 7570 2875 2266   self.backup(u"f
-00011c80: 756c 6c22 2c20 7522 7465 7374 6669 6c65  ull", u"testfile
-00011c90: 732f 7365 6c65 6374 3222 2c0a 2020 2020  s/select2",.    
-00011ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011cb0: 6f70 7469 6f6e 733d 5b75 222d 2d66 696c  options=[u"--fil
-00011cc0: 7465 722d 6c69 7465 7261 6c22 2c0a 2020  ter-literal",.  
-00011cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ce0: 2020 2020 2020 2020 2020 2075 222d 2d69             u"--i
-00011cf0: 6e63 6c75 6465 2d67 6c6f 6262 696e 672d  nclude-globbing-
-00011d00: 6669 6c65 6c69 7374 3d74 6573 7466 696c  filelist=testfil
-00011d10: 6573 2f69 6e63 6c75 6465 2e74 7874 225d  es/include.txt"]
-00011d20: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
-00011d30: 6573 746f 7265 2829 0a20 2020 2020 2020  estore().       
-00011d40: 2072 6573 746f 7265 5f64 6972 203d 2075   restore_dir = u
-00011d50: 2274 6573 7466 696c 6573 2f72 6573 746f  "testfiles/resto
-00011d60: 7265 5f6f 7574 220a 2020 2020 2020 2020  re_out".        
-00011d70: 7265 7374 6f72 6564 203d 2073 656c 662e  restored = self.
-00011d80: 6469 7265 6374 6f72 795f 7472 6565 5f74  directory_tree_t
-00011d90: 6f5f 6c69 7374 5f6f 665f 6c69 7374 7328  o_list_of_lists(
-00011da0: 7265 7374 6f72 655f 6469 7229 0a20 2020  restore_dir).   
-00011db0: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
-00011dc0: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
-00011dd0: 7365 6c66 2e65 7870 6563 7465 645f 7265  self.expected_re
-00011de0: 7374 6f72 6564 5f74 7265 6529 0a0a 0a63  stored_tree)...c
-00011df0: 6c61 7373 2054 6573 7449 6e63 6c75 6465  lass TestInclude
-00011e00: 4578 636c 7564 6564 466f 7243 6f6e 7465  ExcludedForConte
-00011e10: 6e74 7328 496e 636c 7564 6545 7863 6c75  nts(IncludeExclu
-00011e20: 6465 4675 6e63 7469 6f6e 616c 5465 7374  deFunctionalTest
-00011e30: 293a 0a20 2020 2075 2222 2220 5465 7374  ):.    u""" Test
-00011e40: 2074 6f20 6368 6563 6b20 7468 6174 2066   to check that f
-00011e50: 6f6c 6465 7273 2074 6861 7420 6172 6520  olders that are 
-00011e60: 6578 636c 7564 6564 2061 7265 2069 6e63  excluded are inc
-00011e70: 6c75 6465 6420 6966 2074 6865 7920 636f  luded if they co
-00011e80: 6e74 6169 6e20 696e 636c 7564 6573 206f  ntain includes o
-00011e90: 6620 6869 6768 6572 2070 7269 6f72 6974  f higher priorit
-00011ea0: 792e 0a20 2020 2020 4578 6869 6269 7473  y..     Exhibits
-00011eb0: 2074 6865 2069 7373 7565 2072 6570 6f72   the issue repor
-00011ec0: 7465 6420 696e 2042 7567 2023 3134 3038  ted in Bug #1408
-00011ed0: 3431 3120 2868 7474 7073 3a2f 2f62 7567  411 (https://bug
-00011ee0: 732e 6c61 756e 6368 7061 642e 6e65 742f  s.launchpad.net/
-00011ef0: 6475 706c 6963 6974 792f 2b62 7567 2f31  duplicity/+bug/1
-00011f00: 3430 3834 3131 292e 2022 2222 0a0a 2020  408411). """..  
-00011f10: 2020 6465 6620 7772 6974 655f 6669 6c65    def write_file
-00011f20: 6c69 7374 2873 656c 662c 2066 696c 656c  list(self, filel
-00011f30: 6973 745f 6e61 6d65 293a 0a20 2020 2020  ist_name):.     
-00011f40: 2020 2075 2222 2255 7365 6420 6279 2074     u"""Used by t
-00011f50: 6865 2062 656c 6f77 2074 6573 7473 2074  he below tests t
-00011f60: 6f20 7772 6974 6520 7468 6520 6669 6c65  o write the file
-00011f70: 6c69 7374 2222 220a 2020 2020 2020 2020  list""".        
-00011f80: 6173 7365 7274 2066 696c 656c 6973 745f  assert filelist_
-00011f90: 6e61 6d65 2069 7320 6e6f 7420 4e6f 6e65  name is not None
-00011fa0: 0a20 2020 2020 2020 2077 6974 6820 696f  .        with io
-00011fb0: 2e6f 7065 6e28 6669 6c65 6c69 7374 5f6e  .open(filelist_n
-00011fc0: 616d 652c 2075 2277 2229 2061 7320 663a  ame, u"w") as f:
-00011fd0: 0a20 2020 2020 2020 2020 2020 2066 2e77  .            f.w
-00011fe0: 7269 7465 2875 222b 2074 6573 7466 696c  rite(u"+ testfil
-00011ff0: 6573 2f73 656c 6563 742f 312f 322f 315c  es/select/1/2/1\
-00012000: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00012010: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-00012020: 696c 6573 2f73 656c 6563 742f 312f 325c  iles/select/1/2\
-00012030: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00012040: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-00012050: 696c 6573 2f73 656c 6563 742f 312f 315c  iles/select/1/1\
-00012060: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-00012070: 2020 2020 2020 2075 222d 2074 6573 7466         u"- testf
-00012080: 696c 6573 2f73 656c 6563 742f 312f 3322  iles/select/1/3"
-00012090: 290a 0a20 2020 2064 6566 2072 6573 746f  )..    def resto
-000120a0: 7265 5f61 6e64 5f63 6865 636b 2873 656c  re_and_check(sel
-000120b0: 6629 3a0a 2020 2020 2020 2020 7522 2222  f):.        u"""
-000120c0: 5265 7374 6f72 6573 2074 6865 2062 6163  Restores the bac
-000120d0: 6b75 7020 616e 6420 636f 6d70 6172 6573  kup and compares
-000120e0: 2074 6f20 7768 6174 2077 6173 2065 7870   to what was exp
-000120f0: 6563 7465 6420 2862 6173 6564 206f 6e20  ected (based on 
-00012100: 7468 6520 6669 6c65 6c69 7374 2069 6e20  the filelist in 
-00012110: 7772 6974 655f 6669 6c65 6c69 7374 2922  write_filelist)"
-00012120: 2222 0a20 2020 2020 2020 2073 656c 662e  "".        self.
-00012130: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
-00012140: 2020 7265 7374 6f72 655f 6469 7220 3d20    restore_dir = 
-00012150: 7522 7465 7374 6669 6c65 732f 7265 7374  u"testfiles/rest
-00012160: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
-00012170: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
-00012180: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
-00012190: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-000121a0: 2872 6573 746f 7265 5f64 6972 290a 2020  (restore_dir).  
-000121b0: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
-000121c0: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
-000121d0: 205b 5b75 2232 225d 2c20 5b75 2231 225d   [[u"2"], [u"1"]
-000121e0: 5d29 0a0a 2020 2020 6465 6620 7465 7374  ])..    def test
-000121f0: 5f63 6f6d 6d61 6e64 6c69 6e65 5f69 6e63  _commandline_inc
-00012200: 6c75 6465 5f65 7863 6c75 6465 2873 656c  lude_exclude(sel
-00012210: 6629 3a0a 2020 2020 2020 2020 7522 2222  f):.        u"""
-00012220: 7465 7374 2061 6e20 6578 636c 7564 6564  test an excluded
-00012230: 2066 6f6c 6465 7220 6973 2069 6e63 6c75   folder is inclu
-00012240: 6465 6420 666f 7220 696e 636c 7564 6564  ded for included
-00012250: 2063 6f6e 7465 6e74 7320 7768 656e 2075   contents when u
-00012260: 7369 6e67 2063 6f6d 6d61 6e64 6c69 6e65  sing commandline
-00012270: 2069 6e63 6c75 6465 7320 616e 6420 6578   includes and ex
-00012280: 636c 7564 6573 2222 220a 2020 2020 2020  cludes""".      
-00012290: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-000122a0: 6675 6c6c 222c 2075 2274 6573 7466 696c  full", u"testfil
-000122b0: 6573 2f73 656c 6563 742f 3122 2c0a 2020  es/select/1",.  
-000122c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000122d0: 2020 6f70 7469 6f6e 733d 5b75 222d 2d69    options=[u"--i
-000122e0: 6e63 6c75 6465 222c 2075 2274 6573 7466  nclude", u"testf
-000122f0: 696c 6573 2f73 656c 6563 742f 312f 322f  iles/select/1/2/
-00012300: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
-00012310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012320: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00012330: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00012340: 742f 312f 3222 2c0a 2020 2020 2020 2020  t/1/2",.        
+0000e080: 2020 2020 2020 2022 2020 2020 2020 2020         "        
+0000e090: 2320 2054 6573 7469 6e67 2061 6e6f 7468  #  Testing anoth
+0000e0a0: 6572 2066 756c 6c2d 6c69 6e65 2063 6f6d  er full-line com
+0000e0b0: 6d65 6e74 2020 2020 2020 5c6e 220a 2020  ment      \n".  
+0000e0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e0d0: 2020 2274 6573 7466 696c 6573 2f73 656c    "testfiles/sel
+0000e0e0: 6563 7432 2f31 5c6e 220a 2020 2020 2020  ect2/1\n".      
+0000e0f0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+0000e100: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
+0000e110: 7432 2f2a 2a22 290a 2020 2020 2020 2020  t2/**").        
+0000e120: 7365 6c66 2e62 6163 6b75 7028 2266 756c  self.backup("ful
+0000e130: 6c22 2c20 2274 6573 7466 696c 6573 2f73  l", "testfiles/s
+0000e140: 656c 6563 7432 222c 206f 7074 696f 6e73  elect2", options
+0000e150: 3d5b 222d 2d69 6e63 6c75 6465 2d66 696c  =["--include-fil
+0000e160: 656c 6973 743d 7465 7374 6669 6c65 732f  elist=testfiles/
+0000e170: 696e 636c 7564 652e 7478 7422 5d29 0a20  include.txt"]). 
+0000e180: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
+0000e190: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
+0000e1a0: 7374 6f72 655f 7061 7468 203d 2022 7465  store_path = "te
+0000e1b0: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
+0000e1c0: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
+0000e1d0: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
+0000e1e0: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
+0000e1f0: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
+0000e200: 746f 7265 5f70 6174 6829 0a20 2020 2020  tore_path).     
+0000e210: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
+0000e220: 7561 6c28 7265 7374 6f72 6564 2c20 7365  ual(restored, se
+0000e230: 6c66 2e65 7870 6563 7465 645f 7265 7374  lf.expected_rest
+0000e240: 6f72 6564 5f74 7265 6529 0a0a 2020 2020  ored_tree)..    
+0000e250: 6465 6620 7465 7374 5f69 6e63 6c75 6465  def test_include
+0000e260: 5f66 696c 656c 6973 745f 776f 726b 6172  _filelist_workar
+0000e270: 6f75 6e64 5f63 6f6d 6269 6e65 645f 696d  ound_combined_im
+0000e280: 7065 7266 6563 7469 6f6e 735f 6e6f 5f77  perfections_no_w
+0000e290: 696c 6463 6172 6473 2873 656c 6629 3a0a  ildcards(self):.
+0000e2a0: 2020 2020 2020 2020 2222 2254 6573 7420          """Test 
+0000e2b0: 7468 6174 2069 6e63 6c75 6465 2066 696c  that include fil
+0000e2c0: 656c 6973 7420 776f 726b 7320 7769 7468  elist works with
+0000e2d0: 2069 6d70 6572 6665 6374 696f 6e73 2069   imperfections i
+0000e2e0: 6e20 7468 6520 696e 7075 7420 6669 6c65  n the input file
+0000e2f0: 2222 220a 2020 2020 2020 2020 2320 5468  """.        # Th
+0000e300: 6973 2069 7320 6120 6d6f 6469 6669 6564  is is a modified
+0000e310: 2076 6572 7369 6f6e 206f 6620 7465 7374   version of test
+0000e320: 5f69 6e63 6c75 6465 5f66 696c 656c 6973  _include_filelis
+0000e330: 7420 7468 6174 2070 6173 7365 732c 2064  t that passes, d
+0000e340: 6573 7069 7465 2042 7567 2023 3134 3038  espite Bug #1408
+0000e350: 3431 310a 2020 2020 2020 2020 2320 4974  411.        # It
+0000e360: 2069 7320 7374 696c 6c20 6120 7661 6c69   is still a vali
+0000e370: 6420 7465 7374 2c20 6974 206a 7573 7420  d test, it just 
+0000e380: 646f 6573 206e 6f74 2074 6573 7420 6173  does not test as
+0000e390: 206d 616e 7920 7365 6c65 6374 696f 6e20   many selection 
+0000e3a0: 6665 6174 7572 6573 2061 7320 7468 6520  features as the 
+0000e3b0: 6162 6f76 652e 0a20 2020 2020 2020 2023  above..        #
+0000e3c0: 2054 6869 7320 6973 2061 2063 6f6d 6269   This is a combi
+0000e3d0: 6e65 6420 7465 7374 2066 6f72 2073 7065  ned test for spe
+0000e3e0: 6564 2072 6561 736f 6e73 2e20 5468 6520  ed reasons. The 
+0000e3f0: 696e 6469 7669 6475 616c 2069 6d70 6572  individual imper
+0000e400: 6665 6374 696f 6e73 2061 7265 2074 6573  fections are tes
+0000e410: 7465 6420 6173 2075 6e69 7474 6573 7473  ted as unittests
+0000e420: 2069 6e0a 2020 2020 2020 2020 2320 756e   in.        # un
+0000e430: 6974 2f74 6573 745f 7365 6c65 6374 696f  it/test_selectio
+0000e440: 6e2e 0a20 2020 2020 2020 2023 2049 6d70  n..        # Imp
+0000e450: 6572 6665 6374 696f 6e73 2074 6573 7465  erfections teste
+0000e460: 6420 6172 653b 0a20 2020 2020 2020 2023  d are;.        #
+0000e470: 202a 204c 6561 6469 6e67 2073 7061 6365   * Leading space
+0000e480: 2f73 7061 6365 7320 6265 666f 7265 2074  /spaces before t
+0000e490: 6865 206d 6f64 6966 6965 720a 2020 2020  he modifier.    
+0000e4a0: 2020 2020 2320 2a20 5472 6169 6c69 6e67      # * Trailing
+0000e4b0: 2073 7061 6365 2f73 7061 6365 7320 6166   space/spaces af
+0000e4c0: 7465 7220 7468 6520 6669 6c65 6e61 6d65  ter the filename
+0000e4d0: 2028 6275 7420 6265 666f 7265 2074 6865   (but before the
+0000e4e0: 206e 6577 6c69 6e65 290a 2020 2020 2020   newline).      
+0000e4f0: 2020 2320 2a20 426c 616e 6b20 6c69 6e65    # * Blank line
+0000e500: 7320 286e 6577 6c69 6e65 2063 6861 7261  s (newline chara
+0000e510: 6374 6572 206f 6e6c 7929 0a20 2020 2020  cter only).     
+0000e520: 2020 2023 202a 204c 696e 6520 6f6e 6c79     # * Line only
+0000e530: 2063 6f6e 7461 696e 696e 6720 7370 6163   containing spac
+0000e540: 6573 0a20 2020 2020 2020 2023 202a 2046  es.        # * F
+0000e550: 756c 6c2d 6c69 6e65 2063 6f6d 6d65 6e74  ull-line comment
+0000e560: 7320 7769 7468 2023 2061 7320 7468 6520  s with # as the 
+0000e570: 6669 7273 7420 6368 6172 6163 7465 7220  first character 
+0000e580: 616e 6420 7769 7468 206c 6561 6469 6e67  and with leading
+0000e590: 2f74 7261 696c 696e 6720 7370 6163 6573  /trailing spaces
+0000e5a0: 0a20 2020 2020 2020 2023 202a 2055 6e6e  .        # * Unn
+0000e5b0: 6563 6573 7361 7269 6c79 2071 756f 7465  ecessarily quote
+0000e5c0: 6420 6669 6c65 6e61 6d65 7320 7769 7468  d filenames with
+0000e5d0: 2f77 6974 686f 7574 206d 6f64 6966 6965  /without modifie
+0000e5e0: 7220 2028 626f 7468 2022 2061 6e64 2027  r  (both " and '
+0000e5f0: 290a 2020 2020 2020 2020 2320 4372 6561  ).        # Crea
+0000e600: 7465 2061 2066 696c 656c 6973 740a 2020  te a filelist.  
+0000e610: 2020 2020 2020 7769 7468 2069 6f2e 6f70        with io.op
+0000e620: 656e 2822 7465 7374 6669 6c65 732f 696e  en("testfiles/in
+0000e630: 636c 7564 652e 7478 7422 2c20 2277 2229  clude.txt", "w")
+0000e640: 2061 7320 663a 0a20 2020 2020 2020 2020   as f:.         
+0000e650: 2020 2066 2e77 7269 7465 2822 7465 7374     f.write("test
+0000e660: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
+0000e670: 3373 7562 332f 3373 7562 3373 7562 322f  3sub3/3sub3sub2/
+0000e680: 3373 7562 3373 7562 325f 6669 6c65 2e74  3sub3sub2_file.t
+0000e690: 7874 5c6e 220a 2020 2020 2020 2020 2020  xt\n".          
+0000e6a0: 2020 2020 2020 2020 2020 2274 6573 7466            "testf
+0000e6b0: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
+0000e6c0: 7375 6232 2f33 7375 6232 7375 6232 205c  sub2/3sub2sub2 \
+0000e6d0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+0000e6e0: 2020 2020 2020 2022 2020 2b20 7465 7374         "  + test
+0000e6f0: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
+0000e700: 3373 7562 335c 6e22 2020 2320 2b20 6164  3sub3\n"  # + ad
+0000e710: 6465 6420 746f 2065 6e73 7572 6520 6974  ded to ensure it
+0000e720: 206d 616b 6573 206e 6f20 6469 6666 6572   makes no differ
+0000e730: 656e 6365 0a20 2020 2020 2020 2020 2020  ence.           
+0000e740: 2020 2020 2020 2020 2022 202d 2074 6573           " - tes
+0000e750: 7466 696c 6573 2f73 656c 6563 7432 2f33  tfiles/select2/3
+0000e760: 2f33 7375 6231 2020 5c6e 220a 2020 2020  /3sub1  \n".    
+0000e770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e780: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
+0000e790: 6563 7432 2f32 2f32 7375 6231 2f32 7375  ect2/2/2sub1/2su
+0000e7a0: 6231 7375 6233 5c6e 220a 2020 2020 2020  b1sub3\n".      
+0000e7b0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+0000e7c0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
+0000e7d0: 7432 2f32 2f32 7375 6231 2f32 7375 6231  t2/2/2sub1/2sub1
+0000e7e0: 7375 6232 5c6e 220a 2020 2020 2020 2020  sub2\n".        
+0000e7f0: 2020 2020 2020 2020 2020 2020 2722 7465              '"te
+0000e800: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+0000e810: 322f 3273 7562 3122 5c6e 270a 2020 2020  2/2sub1"\n'.    
+0000e820: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e830: 2220 2020 2d20 7465 7374 6669 6c65 732f  "   - testfiles/
+0000e840: 7365 6c65 6374 322f 322f 3273 7562 3320  select2/2/2sub3 
+0000e850: 5c6e 2220 2023 2041 6464 6564 2062 6563  \n"  # Added bec
+0000e860: 6175 7365 206f 6620 4275 6720 2331 3430  ause of Bug #140
+0000e870: 3834 3131 0a20 2020 2020 2020 2020 2020  8411.           
+0000e880: 2020 2020 2020 2020 2022 2d20 7465 7374           "- test
+0000e890: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
+0000e8a0: 3273 7562 325c 6e22 2020 2320 4164 6465  2sub2\n"  # Adde
+0000e8b0: 6420 6265 6361 7573 6520 6f66 2042 7567  d because of Bug
+0000e8c0: 2023 3134 3038 3431 310a 2020 2020 2020   #1408411.      
+0000e8d0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+0000e8e0: 2027 7465 7374 6669 6c65 732f 7365 6c65   'testfiles/sele
+0000e8f0: 6374 322f 312f 3173 7562 332f 3173 7562  ct2/1/1sub3/1sub
+0000e900: 3373 7562 3227 5c6e 220a 2020 2020 2020  3sub2'\n".      
+0000e910: 2020 2020 2020 2020 2020 2020 2020 225c                "\
+0000e920: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+0000e930: 2020 2020 2020 2022 2d20 7465 7374 6669         "- testfi
+0000e940: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+0000e950: 7562 332f 3173 7562 3373 7562 315c 6e22  ub3/1sub3sub1\n"
+0000e960: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e970: 2020 2020 2022 2d20 7465 7374 6669 6c65       "- testfile
+0000e980: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
+0000e990: 322f 3173 7562 3273 7562 335c 6e22 0a20  2/1sub2sub3\n". 
+0000e9a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e9b0: 2020 2027 2d20 2274 6573 7466 696c 6573     '- "testfiles
+0000e9c0: 2f73 656c 6563 7432 2f31 2f31 7375 6232  /select2/1/1sub2
+0000e9d0: 2f31 7375 6232 7375 6232 225c 6e27 2020  /1sub2sub2"\n'  
+0000e9e0: 2320 4164 6465 6420 6265 6361 7573 6520  # Added because 
+0000e9f0: 6f66 2042 7567 2023 3134 3038 3431 310a  of Bug #1408411.
+0000ea00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ea10: 2020 2020 2223 2054 6869 7320 6973 2061      "# This is a
+0000ea20: 2066 756c 6c2d 6c69 6e65 2063 6f6d 6d65   full-line comme
+0000ea30: 6e74 5c6e 220a 2020 2020 2020 2020 2020  nt\n".          
+0000ea40: 2020 2020 2020 2020 2020 222b 2074 6573            "+ tes
+0000ea50: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+0000ea60: 2f31 7375 6232 2f31 7375 6232 7375 6231  /1sub2/1sub2sub1
+0000ea70: 2020 5c6e 2220 2023 202b 2061 6464 6564    \n"  # + added
+0000ea80: 2074 6f20 656e 7375 7265 2069 7420 6d61   to ensure it ma
+0000ea90: 6b65 7320 6e6f 2064 6966 6665 7265 6e63  kes no differenc
+0000eaa0: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+0000eab0: 2020 2020 2020 222d 2074 6573 7466 696c        "- testfil
+0000eac0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+0000ead0: 6231 2f31 7375 6231 7375 6233 2f31 7375  b1/1sub1sub3/1su
+0000eae0: 6231 7375 6233 5f66 696c 652e 7478 745c  b1sub3_file.txt\
+0000eaf0: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
+0000eb00: 2020 2020 2020 2022 2020 2020 2020 2020         "        
+0000eb10: 2020 5c6e 220a 2020 2020 2020 2020 2020    \n".          
+0000eb20: 2020 2020 2020 2020 2020 222d 2074 6573            "- tes
+0000eb30: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+0000eb40: 2f31 7375 6231 2f31 7375 6231 7375 6232  /1sub1/1sub1sub2
+0000eb50: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000eb60: 2020 2020 2020 2020 2320 2022 2d20 7465          #  "- te
+0000eb70: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+0000eb80: 312f 3173 7562 325c 6e22 2020 2320 436f  1/1sub2\n"  # Co
+0000eb90: 6d6d 656e 7465 6420 6f75 7420 6265 6361  mmented out beca
+0000eba0: 7573 6520 6f66 2042 7567 2023 3134 3038  use of Bug #1408
+0000ebb0: 3431 310a 2020 2020 2020 2020 2020 2020  411.            
+0000ebc0: 2020 2020 2020 2020 2227 7465 7374 6669          "'testfi
+0000ebd0: 6c65 732f 7365 6c65 6374 322f 312e 7079  les/select2/1.py
+0000ebe0: 275c 6e22 0a20 2020 2020 2020 2020 2020  '\n".           
+0000ebf0: 2020 2020 2020 2020 2022 2020 2020 2020           "      
+0000ec00: 2023 2054 6869 7320 6973 2061 6e6f 7468   # This is anoth
+0000ec10: 6572 2066 756c 6c2d 6c69 6e65 2063 6f6d  er full-line com
+0000ec20: 6d65 6e74 2c20 7769 7468 2073 7061 6365  ment, with space
+0000ec30: 7320 2020 2020 5c6e 220a 2020 2020 2020  s     \n".      
+0000ec40: 2020 2020 2020 2020 2020 2020 2020 2274                "t
+0000ec50: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+0000ec60: 2f33 5c6e 220a 2020 2020 2020 2020 2020  /3\n".          
+0000ec70: 2020 2020 2020 2020 2020 2320 2022 2d20            #  "- 
+0000ec80: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+0000ec90: 322f 325c 6e22 2023 2043 6f6d 6d65 6e74  2/2\n" # Comment
+0000eca0: 6564 206f 7574 2062 6563 6175 7365 206f  ed out because o
+0000ecb0: 6620 4275 6720 2331 3430 3834 3131 0a20  f Bug #1408411. 
+0000ecc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ecd0: 2020 2022 7465 7374 6669 6c65 732f 7365     "testfiles/se
+0000ece0: 6c65 6374 322f 315c 6e22 0a20 2020 2020  lect2/1\n".     
+0000ecf0: 2020 2020 2020 2020 2020 2020 2020 2027                 '
+0000ed00: 2d20 2274 6573 7466 696c 6573 2f73 656c  - "testfiles/sel
+0000ed10: 6563 7432 2f74 7261 696c 696e 675f 7370  ect2/trailing_sp
+0000ed20: 6163 6520 225c 6e27 2020 2320 6573 2069  ace "\n'  # es i
+0000ed30: 6e73 7465 6164 206f 6620 6561 2061 7320  nstead of ea as 
+0000ed40: 6e6f 2077 696c 6463 6172 6420 2d20 2a2a  no wildcard - **
+0000ed50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ed60: 2020 2020 2022 2d20 7465 7374 6669 6c65       "- testfile
+0000ed70: 732f 7365 6c65 6374 322f 312e 646f 6322  s/select2/1.doc"
+0000ed80: 2920 2023 2065 7320 696e 7374 6561 6420  )  # es instead 
+0000ed90: 6f66 2065 6120 6173 206e 6f20 7769 6c64  of ea as no wild
+0000eda0: 6361 7264 202d 202a 2a0a 2020 2020 2020  card - **.      
+0000edb0: 2020 7365 6c66 2e62 6163 6b75 7028 2266    self.backup("f
+0000edc0: 756c 6c22 2c20 2274 6573 7466 696c 6573  ull", "testfiles
+0000edd0: 2f73 656c 6563 7432 222c 206f 7074 696f  /select2", optio
+0000ede0: 6e73 3d5b 222d 2d69 6e63 6c75 6465 2d66  ns=["--include-f
+0000edf0: 696c 656c 6973 743d 7465 7374 6669 6c65  ilelist=testfile
+0000ee00: 732f 696e 636c 7564 652e 7478 7422 5d29  s/include.txt"])
+0000ee10: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+0000ee20: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
+0000ee30: 7265 7374 6f72 655f 7061 7468 203d 2022  restore_path = "
+0000ee40: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
+0000ee50: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
+0000ee60: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
+0000ee70: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
+0000ee80: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
+0000ee90: 6573 746f 7265 5f70 6174 6829 0a20 2020  estore_path).   
+0000eea0: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
+0000eeb0: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
+0000eec0: 7365 6c66 2e65 7870 6563 7465 645f 7265  self.expected_re
+0000eed0: 7374 6f72 6564 5f74 7265 6529 0a0a 0a63  stored_tree)...c
+0000eee0: 6c61 7373 2054 6573 7449 6e63 6c75 6465  lass TestInclude
+0000eef0: 4578 636c 7564 6564 466f 7243 6f6e 7465  ExcludedForConte
+0000ef00: 6e74 7328 496e 636c 7564 6545 7863 6c75  nts(IncludeExclu
+0000ef10: 6465 4675 6e63 7469 6f6e 616c 5465 7374  deFunctionalTest
+0000ef20: 293a 0a20 2020 2022 2222 2054 6573 7420  ):.    """ Test 
+0000ef30: 746f 2063 6865 636b 2074 6861 7420 666f  to check that fo
+0000ef40: 6c64 6572 7320 7468 6174 2061 7265 2065  lders that are e
+0000ef50: 7863 6c75 6465 6420 6172 6520 696e 636c  xcluded are incl
+0000ef60: 7564 6564 2069 6620 7468 6579 2063 6f6e  uded if they con
+0000ef70: 7461 696e 2069 6e63 6c75 6465 7320 6f66  tain includes of
+0000ef80: 2068 6967 6865 7220 7072 696f 7269 7479   higher priority
+0000ef90: 2e0a 2020 2020 2045 7868 6962 6974 7320  ..     Exhibits 
+0000efa0: 7468 6520 6973 7375 6520 7265 706f 7274  the issue report
+0000efb0: 6564 2069 6e20 4275 6720 2331 3430 3834  ed in Bug #14084
+0000efc0: 3131 2028 6874 7470 733a 2f2f 6275 6773  11 (https://bugs
+0000efd0: 2e6c 6175 6e63 6870 6164 2e6e 6574 2f64  .launchpad.net/d
+0000efe0: 7570 6c69 6369 7479 2f2b 6275 672f 3134  uplicity/+bug/14
+0000eff0: 3038 3431 3129 2e20 2222 220a 0a20 2020  08411). """..   
+0000f000: 2064 6566 2077 7269 7465 5f66 696c 656c   def write_filel
+0000f010: 6973 7428 7365 6c66 2c20 6669 6c65 6c69  ist(self, fileli
+0000f020: 7374 5f6e 616d 6529 3a0a 2020 2020 2020  st_name):.      
+0000f030: 2020 2222 2255 7365 6420 6279 2074 6865    """Used by the
+0000f040: 2062 656c 6f77 2074 6573 7473 2074 6f20   below tests to 
+0000f050: 7772 6974 6520 7468 6520 6669 6c65 6c69  write the fileli
+0000f060: 7374 2222 220a 2020 2020 2020 2020 6173  st""".        as
+0000f070: 7365 7274 2066 696c 656c 6973 745f 6e61  sert filelist_na
+0000f080: 6d65 2069 7320 6e6f 7420 4e6f 6e65 0a20  me is not None. 
+0000f090: 2020 2020 2020 2077 6974 6820 696f 2e6f         with io.o
+0000f0a0: 7065 6e28 6669 6c65 6c69 7374 5f6e 616d  pen(filelist_nam
+0000f0b0: 652c 2022 7722 2920 6173 2066 3a0a 2020  e, "w") as f:.  
+0000f0c0: 2020 2020 2020 2020 2020 662e 7772 6974            f.writ
+0000f0d0: 6528 222b 2074 6573 7466 696c 6573 2f73  e("+ testfiles/s
+0000f0e0: 656c 6563 742f 312f 322f 315c 6e22 0a20  elect/1/2/1\n". 
+0000f0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f100: 2020 2022 2d20 7465 7374 6669 6c65 732f     "- testfiles/
+0000f110: 7365 6c65 6374 2f31 2f32 5c6e 220a 2020  select/1/2\n".  
+0000f120: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f130: 2020 222d 2074 6573 7466 696c 6573 2f73    "- testfiles/s
+0000f140: 656c 6563 742f 312f 315c 6e22 0a20 2020  elect/1/1\n".   
+0000f150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f160: 2022 2d20 7465 7374 6669 6c65 732f 7365   "- testfiles/se
+0000f170: 6c65 6374 2f31 2f33 2229 0a0a 2020 2020  lect/1/3")..    
+0000f180: 6465 6620 7265 7374 6f72 655f 616e 645f  def restore_and_
+0000f190: 6368 6563 6b28 7365 6c66 293a 0a20 2020  check(self):.   
+0000f1a0: 2020 2020 2022 2222 5265 7374 6f72 6573       """Restores
+0000f1b0: 2074 6865 2062 6163 6b75 7020 616e 6420   the backup and 
+0000f1c0: 636f 6d70 6172 6573 2074 6f20 7768 6174  compares to what
+0000f1d0: 2077 6173 2065 7870 6563 7465 6420 2862   was expected (b
+0000f1e0: 6173 6564 206f 6e20 7468 6520 6669 6c65  ased on the file
+0000f1f0: 6c69 7374 2069 6e20 7772 6974 655f 6669  list in write_fi
+0000f200: 6c65 6c69 7374 2922 2222 0a20 2020 2020  lelist)""".     
+0000f210: 2020 2073 656c 662e 7265 7374 6f72 6528     self.restore(
+0000f220: 290a 2020 2020 2020 2020 7265 7374 6f72  ).        restor
+0000f230: 655f 7061 7468 203d 2022 7465 7374 6669  e_path = "testfi
+0000f240: 6c65 732f 7265 7374 6f72 655f 6f75 7422  les/restore_out"
+0000f250: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+0000f260: 6420 3d20 7365 6c66 2e64 6972 6563 746f  d = self.directo
+0000f270: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
+0000f280: 6f66 5f6c 6973 7473 2872 6573 746f 7265  of_lists(restore
+0000f290: 5f70 6174 6829 0a20 2020 2020 2020 2073  _path).        s
+0000f2a0: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
+0000f2b0: 7265 7374 6f72 6564 2c20 5b5b 2232 225d  restored, [["2"]
+0000f2c0: 2c20 5b22 3122 5d5d 290a 0a20 2020 2064  , ["1"]])..    d
+0000f2d0: 6566 2074 6573 745f 636f 6d6d 616e 646c  ef test_commandl
+0000f2e0: 696e 655f 696e 636c 7564 655f 6578 636c  ine_include_excl
+0000f2f0: 7564 6528 7365 6c66 293a 0a20 2020 2020  ude(self):.     
+0000f300: 2020 2022 2222 7465 7374 2061 6e20 6578     """test an ex
+0000f310: 636c 7564 6564 2066 6f6c 6465 7220 6973  cluded folder is
+0000f320: 2069 6e63 6c75 6465 6420 666f 7220 696e   included for in
+0000f330: 636c 7564 6564 2063 6f6e 7465 6e74 7320  cluded contents 
+0000f340: 7768 656e 2075 7369 6e67 2063 6f6d 6d61  when using comma
+0000f350: 6e64 6c69 6e65 2069 6e63 6c75 6465 7320  ndline includes 
+0000f360: 616e 6420 6578 636c 7564 6573 2222 220a  and excludes""".
+0000f370: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
+0000f380: 6b75 7028 2266 756c 6c22 2c20 2274 6573  kup("full", "tes
+0000f390: 7466 696c 6573 2f73 656c 6563 742f 3122  tfiles/select/1"
+0000f3a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000f3b0: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+0000f3c0: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+0000f3d0: 7466 696c 6573 2f73 656c 6563 742f 312f  tfiles/select/1/
+0000f3e0: 322f 3122 2c0a 2020 2020 2020 2020 2020  2/1",.          
+0000f3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f400: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+0000f410: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+0000f420: 742f 312f 3222 2c0a 2020 2020 2020 2020  t/1/2",.        
+0000f430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f440: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+0000f450: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+0000f460: 6563 742f 312f 3122 2c0a 2020 2020 2020  ect/1/1",.      
+0000f470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f480: 2020 2020 2020 2022 2d2d 6578 636c 7564         "--exclud
+0000f490: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+0000f4a0: 656c 6563 742f 312f 3322 5d29 0a20 2020  elect/1/3"]).   
+0000f4b0: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
+0000f4c0: 655f 616e 645f 6368 6563 6b28 290a 0a20  e_and_check().. 
+0000f4d0: 2020 2064 6566 2074 6573 745f 696e 636c     def test_incl
+0000f4e0: 7564 655f 6669 6c65 6c69 7374 2873 656c  ude_filelist(sel
+0000f4f0: 6629 3a0a 2020 2020 2020 2020 2222 2274  f):.        """t
+0000f500: 6573 7420 616e 2065 7863 6c75 6465 6420  est an excluded 
+0000f510: 666f 6c64 6572 2069 7320 696e 636c 7564  folder is includ
+0000f520: 6564 2066 6f72 2069 6e63 6c75 6465 6420  ed for included 
+0000f530: 636f 6e74 656e 7473 2077 6974 6820 616e  contents with an
+0000f540: 2069 6e63 6c75 6465 2d66 696c 656c 6973   include-filelis
+0000f550: 7420 286e 6f6e 2d67 6c6f 6262 696e 6729  t (non-globbing)
+0000f560: 2022 2222 0a20 2020 2020 2020 2023 2052   """.        # R
+0000f570: 6567 7265 7373 696f 6e20 7465 7374 2066  egression test f
+0000f580: 6f72 2042 7567 2023 3134 3038 3431 3120  or Bug #1408411 
+0000f590: 2868 7474 7073 3a2f 2f62 7567 732e 6c61  (https://bugs.la
+0000f5a0: 756e 6368 7061 642e 6e65 742f 6475 706c  unchpad.net/dupl
+0000f5b0: 6963 6974 792f 2b62 7567 2f31 3430 3834  icity/+bug/14084
+0000f5c0: 3131 290a 2020 2020 2020 2020 7365 6c66  11).        self
+0000f5d0: 2e77 7269 7465 5f66 696c 656c 6973 7428  .write_filelist(
+0000f5e0: 2274 6573 7466 696c 6573 2f69 6e63 6c75  "testfiles/inclu
+0000f5f0: 6465 2e74 7874 2229 0a20 2020 2020 2020  de.txt").       
+0000f600: 2073 656c 662e 6261 636b 7570 2822 6675   self.backup("fu
+0000f610: 6c6c 222c 2022 7465 7374 6669 6c65 732f  ll", "testfiles/
+0000f620: 7365 6c65 6374 2f31 222c 206f 7074 696f  select/1", optio
+0000f630: 6e73 3d5b 222d 2d69 6e63 6c75 6465 2d66  ns=["--include-f
+0000f640: 696c 656c 6973 743d 7465 7374 6669 6c65  ilelist=testfile
+0000f650: 732f 696e 636c 7564 652e 7478 7422 5d29  s/include.txt"])
+0000f660: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+0000f670: 7374 6f72 655f 616e 645f 6368 6563 6b28  store_and_check(
+0000f680: 290a 0a20 2020 2064 6566 2074 6573 745f  )..    def test_
+0000f690: 6578 636c 7564 655f 6669 6c65 6c69 7374  exclude_filelist
+0000f6a0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0000f6b0: 2222 2274 6573 7420 616e 2065 7863 6c75  """test an exclu
+0000f6c0: 6465 6420 666f 6c64 6572 2069 7320 696e  ded folder is in
+0000f6d0: 636c 7564 6564 2066 6f72 2069 6e63 6c75  cluded for inclu
+0000f6e0: 6465 6420 636f 6e74 656e 7473 2077 6974  ded contents wit
+0000f6f0: 6820 616e 2065 7863 6c75 6465 2d66 696c  h an exclude-fil
+0000f700: 656c 6973 7420 2028 6e6f 6e2d 676c 6f62  elist  (non-glob
+0000f710: 6269 6e67 2920 2222 220a 2020 2020 2020  bing) """.      
+0000f720: 2020 2320 5265 6772 6573 7369 6f6e 2074    # Regression t
+0000f730: 6573 7420 666f 7220 4275 6720 2331 3430  est for Bug #140
+0000f740: 3834 3131 2028 6874 7470 733a 2f2f 6275  8411 (https://bu
+0000f750: 6773 2e6c 6175 6e63 6870 6164 2e6e 6574  gs.launchpad.net
+0000f760: 2f64 7570 6c69 6369 7479 2f2b 6275 672f  /duplicity/+bug/
+0000f770: 3134 3038 3431 3129 0a20 2020 2020 2020  1408411).       
+0000f780: 2073 656c 662e 7772 6974 655f 6669 6c65   self.write_file
+0000f790: 6c69 7374 2822 7465 7374 6669 6c65 732f  list("testfiles/
+0000f7a0: 6578 636c 7564 652e 7478 7422 290a 2020  exclude.txt").  
+0000f7b0: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
+0000f7c0: 7028 2266 756c 6c22 2c20 2274 6573 7466  p("full", "testf
+0000f7d0: 696c 6573 2f73 656c 6563 742f 3122 2c20  iles/select/1", 
+0000f7e0: 6f70 7469 6f6e 733d 5b22 2d2d 6578 636c  options=["--excl
+0000f7f0: 7564 652d 6669 6c65 6c69 7374 3d74 6573  ude-filelist=tes
+0000f800: 7466 696c 6573 2f65 7863 6c75 6465 2e74  tfiles/exclude.t
+0000f810: 7874 225d 290a 2020 2020 2020 2020 7365  xt"]).        se
+0000f820: 6c66 2e72 6573 746f 7265 5f61 6e64 5f63  lf.restore_and_c
+0000f830: 6865 636b 2829 0a0a 0a63 6c61 7373 2054  heck()...class T
+0000f840: 6573 7441 7374 6572 6973 6b73 2849 6e63  estAsterisks(Inc
+0000f850: 6c75 6465 4578 636c 7564 6546 756e 6374  ludeExcludeFunct
+0000f860: 696f 6e61 6c54 6573 7429 3a0a 2020 2020  ionalTest):.    
+0000f870: 2222 2220 5465 7374 2074 6f20 6368 6563  """ Test to chec
+0000f880: 6b20 7468 6174 2061 7374 6572 6973 6b73  k that asterisks
+0000f890: 2077 6f72 6b20 6173 2065 7870 6563 7465   work as expecte
+0000f8a0: 640a 2020 2020 2045 7868 6962 6974 7320  d.     Exhibits 
+0000f8b0: 7468 6520 6973 7375 6520 7265 706f 7274  the issue report
+0000f8c0: 6564 2069 6e20 4275 6720 2338 3834 3337  ed in Bug #88437
+0000f8d0: 3120 2868 7474 7073 3a2f 2f62 7567 732e  1 (https://bugs.
+0000f8e0: 6c61 756e 6368 7061 642e 6e65 742f 6475  launchpad.net/du
+0000f8f0: 706c 6963 6974 792f 2b62 7567 2f38 3834  plicity/+bug/884
+0000f900: 3337 3129 2e0a 2020 2020 2053 6565 2074  371)..     See t
+0000f910: 6865 2075 6e69 7420 7465 7374 7320 666f  he unit tests fo
+0000f920: 7220 6d6f 7265 2067 7261 6e75 6c61 7269  r more granulari
+0000f930: 7479 206f 6e20 7468 6520 6973 7375 652e  ty on the issue.
+0000f940: 2222 220a 0a20 2020 2064 6566 2072 6573  """..    def res
+0000f950: 746f 7265 5f61 6e64 5f63 6865 636b 2873  tore_and_check(s
+0000f960: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+0000f970: 2252 6573 746f 7265 7320 7468 6520 6261  "Restores the ba
+0000f980: 636b 7570 2061 6e64 2063 6f6d 7061 7265  ckup and compare
+0000f990: 7320 746f 2077 6861 7420 6973 2065 7870  s to what is exp
+0000f9a0: 6563 7465 642e 2222 220a 2020 2020 2020  ected.""".      
+0000f9b0: 2020 7365 6c66 2e72 6573 746f 7265 2829    self.restore()
+0000f9c0: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+0000f9d0: 5f70 6174 6820 3d20 2274 6573 7466 696c  _path = "testfil
+0000f9e0: 6573 2f72 6573 746f 7265 5f6f 7574 220a  es/restore_out".
+0000f9f0: 2020 2020 2020 2020 7265 7374 6f72 6564          restored
+0000fa00: 203d 2073 656c 662e 6469 7265 6374 6f72   = self.director
+0000fa10: 795f 7472 6565 5f74 6f5f 6c69 7374 5f6f  y_tree_to_list_o
+0000fa20: 665f 6c69 7374 7328 7265 7374 6f72 655f  f_lists(restore_
+0000fa30: 7061 7468 290a 2020 2020 2020 2020 7365  path).        se
+0000fa40: 6c66 2e61 7373 6572 7445 7175 616c 2872  lf.assertEqual(r
+0000fa50: 6573 746f 7265 642c 205b 5b22 3222 5d2c  estored, [["2"],
+0000fa60: 205b 2231 225d 5d29 0a0a 2020 2020 6465   ["1"]])..    de
+0000fa70: 6620 7465 7374 5f65 7863 6c75 6465 5f66  f test_exclude_f
+0000fa80: 696c 656c 6973 745f 6173 7465 7269 736b  ilelist_asterisk
+0000fa90: 735f 6e6f 6e65 2873 656c 6629 3a0a 2020  s_none(self):.  
+0000faa0: 2020 2020 2020 2222 2242 6173 6963 2065        """Basic e
+0000fab0: 7863 6c75 6465 2066 696c 656c 6973 742e  xclude filelist.
+0000fac0: 2222 220a 2020 2020 2020 2020 7769 7468  """.        with
+0000fad0: 2069 6f2e 6f70 656e 2822 7465 7374 6669   io.open("testfi
+0000fae0: 6c65 732f 6669 6c65 6c69 7374 2e74 7874  les/filelist.txt
+0000faf0: 222c 2022 7722 2920 6173 2066 3a0a 2020  ", "w") as f:.  
+0000fb00: 2020 2020 2020 2020 2020 662e 7772 6974            f.writ
+0000fb10: 6528 222b 2074 6573 7466 696c 6573 2f73  e("+ testfiles/s
+0000fb20: 656c 6563 742f 312f 322f 315c 6e22 0a20  elect/1/2/1\n". 
+0000fb30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb40: 2020 2022 2d20 7465 7374 6669 6c65 732f     "- testfiles/
+0000fb50: 7365 6c65 6374 2f31 2f32 5c6e 220a 2020  select/1/2\n".  
+0000fb60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fb70: 2020 222d 2074 6573 7466 696c 6573 2f73    "- testfiles/s
+0000fb80: 656c 6563 742f 312f 315c 6e22 0a20 2020  elect/1/1\n".   
+0000fb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fba0: 2022 2d20 7465 7374 6669 6c65 732f 7365   "- testfiles/se
+0000fbb0: 6c65 6374 2f31 2f33 2229 0a20 2020 2020  lect/1/3").     
+0000fbc0: 2020 2073 656c 662e 6261 636b 7570 2822     self.backup("
+0000fbd0: 6675 6c6c 222c 2022 7465 7374 6669 6c65  full", "testfile
+0000fbe0: 732f 7365 6c65 6374 2f31 222c 206f 7074  s/select/1", opt
+0000fbf0: 696f 6e73 3d5b 222d 2d65 7863 6c75 6465  ions=["--exclude
+0000fc00: 2d66 696c 656c 6973 743d 7465 7374 6669  -filelist=testfi
+0000fc10: 6c65 732f 6669 6c65 6c69 7374 2e74 7874  les/filelist.txt
+0000fc20: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
+0000fc30: 2e72 6573 746f 7265 5f61 6e64 5f63 6865  .restore_and_che
+0000fc40: 636b 2829 0a0a 2020 2020 6465 6620 7465  ck()..    def te
+0000fc50: 7374 5f65 7863 6c75 6465 5f66 696c 656c  st_exclude_filel
+0000fc60: 6973 745f 6173 7465 7269 736b 735f 7369  ist_asterisks_si
+0000fc70: 6e67 6c65 2873 656c 6629 3a0a 2020 2020  ngle(self):.    
+0000fc80: 2020 2020 2222 2245 7863 6c75 6465 2066      """Exclude f
+0000fc90: 696c 656c 6973 7420 7769 7468 2061 7374  ilelist with ast
+0000fca0: 6572 6973 6b73 2072 6570 6c61 6369 6e67  erisks replacing
+0000fcb0: 2066 6f6c 6465 7273 2e22 2222 0a20 2020   folders.""".   
+0000fcc0: 2020 2020 2023 2052 6567 7265 7373 696f       # Regressio
+0000fcd0: 6e20 7465 7374 2066 6f72 2042 7567 2023  n test for Bug #
+0000fce0: 3838 3433 3731 2028 6874 7470 733a 2f2f  884371 (https://
+0000fcf0: 6275 6773 2e6c 6175 6e63 6870 6164 2e6e  bugs.launchpad.n
+0000fd00: 6574 2f64 7570 6c69 6369 7479 2f2b 6275  et/duplicity/+bu
+0000fd10: 672f 3838 3433 3731 290a 2020 2020 2020  g/884371).      
+0000fd20: 2020 7769 7468 2069 6f2e 6f70 656e 2822    with io.open("
+0000fd30: 7465 7374 6669 6c65 732f 6669 6c65 6c69  testfiles/fileli
+0000fd40: 7374 2e74 7874 222c 2022 7722 2920 6173  st.txt", "w") as
+0000fd50: 2066 3a0a 2020 2020 2020 2020 2020 2020   f:.            
+0000fd60: 662e 7772 6974 6528 222b 202a 2f73 656c  f.write("+ */sel
+0000fd70: 6563 742f 312f 322f 315c 6e22 0a20 2020  ect/1/2/1\n".   
+0000fd80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd90: 2022 2d20 2a2f 7365 6c65 6374 2f31 2f32   "- */select/1/2
+0000fda0: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
+0000fdb0: 2020 2020 2020 2020 222d 2074 6573 7466          "- testf
+0000fdc0: 696c 6573 2f2a 2f31 2f31 5c6e 220a 2020  iles/*/1/1\n".  
+0000fdd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fde0: 2020 222d 202a 2f2a 2f31 2f33 2229 0a20    "- */*/1/3"). 
+0000fdf0: 2020 2020 2020 2073 656c 662e 6261 636b         self.back
+0000fe00: 7570 2822 6675 6c6c 222c 2022 7465 7374  up("full", "test
+0000fe10: 6669 6c65 732f 7365 6c65 6374 2f31 222c  files/select/1",
+0000fe20: 206f 7074 696f 6e73 3d5b 222d 2d65 7863   options=["--exc
+0000fe30: 6c75 6465 2d66 696c 656c 6973 743d 7465  lude-filelist=te
+0000fe40: 7374 6669 6c65 732f 6669 6c65 6c69 7374  stfiles/filelist
+0000fe50: 2e74 7874 225d 290a 2020 2020 2020 2020  .txt"]).        
+0000fe60: 7365 6c66 2e72 6573 746f 7265 5f61 6e64  self.restore_and
+0000fe70: 5f63 6865 636b 2829 0a0a 2020 2020 6465  _check()..    de
+0000fe80: 6620 7465 7374 5f65 7863 6c75 6465 5f66  f test_exclude_f
+0000fe90: 696c 656c 6973 745f 6173 7465 7269 736b  ilelist_asterisk
+0000fea0: 735f 646f 7562 6c65 5f61 7374 6572 6973  s_double_asteris
+0000feb0: 6b73 2873 656c 6629 3a0a 2020 2020 2020  ks(self):.      
+0000fec0: 2020 2222 2245 7863 6c75 6465 2066 696c    """Exclude fil
+0000fed0: 656c 6973 7420 7769 7468 2064 6f75 626c  elist with doubl
+0000fee0: 6520 6173 7465 7269 736b 7320 7265 706c  e asterisks repl
+0000fef0: 6163 696e 6720 666f 6c64 6572 732e 2222  acing folders.""
+0000ff00: 220a 2020 2020 2020 2020 2320 5265 6772  ".        # Regr
+0000ff10: 6573 7369 6f6e 2074 6573 7420 666f 7220  ession test for 
+0000ff20: 4275 6720 2338 3834 3337 3120 2868 7474  Bug #884371 (htt
+0000ff30: 7073 3a2f 2f62 7567 732e 6c61 756e 6368  ps://bugs.launch
+0000ff40: 7061 642e 6e65 742f 6475 706c 6963 6974  pad.net/duplicit
+0000ff50: 792f 2b62 7567 2f38 3834 3337 3129 0a20  y/+bug/884371). 
+0000ff60: 2020 2020 2020 2077 6974 6820 696f 2e6f         with io.o
+0000ff70: 7065 6e28 2274 6573 7466 696c 6573 2f66  pen("testfiles/f
+0000ff80: 696c 656c 6973 742e 7478 7422 2c20 2277  ilelist.txt", "w
+0000ff90: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
+0000ffa0: 2020 2020 2066 2e77 7269 7465 2822 2b20       f.write("+ 
+0000ffb0: 2a2a 2f31 2f32 2f31 5c6e 220a 2020 2020  **/1/2/1\n".    
+0000ffc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ffd0: 222d 202a 2a2f 312f 325c 6e22 0a20 2020  "- **/1/2\n".   
+0000ffe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fff0: 2022 2d20 2a2a 2f73 656c 6563 742f 312f   "- **/select/1/
+00010000: 315c 6e22 0a20 2020 2020 2020 2020 2020  1\n".           
+00010010: 2020 2020 2020 2020 2022 2d20 7465 7374           "- test
+00010020: 6669 6c65 732f 7365 6c65 6374 2f31 2f33  files/select/1/3
+00010030: 2229 0a20 2020 2020 2020 2073 656c 662e  ").        self.
+00010040: 6261 636b 7570 2822 6675 6c6c 222c 2022  backup("full", "
+00010050: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00010060: 2f31 222c 206f 7074 696f 6e73 3d5b 222d  /1", options=["-
+00010070: 2d65 7863 6c75 6465 2d66 696c 656c 6973  -exclude-filelis
+00010080: 743d 7465 7374 6669 6c65 732f 6669 6c65  t=testfiles/file
+00010090: 6c69 7374 2e74 7874 225d 290a 2020 2020  list.txt"]).    
+000100a0: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
+000100b0: 5f61 6e64 5f63 6865 636b 2829 0a0a 2020  _and_check()..  
+000100c0: 2020 6465 6620 7465 7374 5f63 6f6d 6d61    def test_comma
+000100d0: 6e64 6c69 6e65 5f61 7374 6572 6973 6b73  ndline_asterisks
+000100e0: 5f73 696e 676c 655f 6578 636c 7564 6573  _single_excludes
+000100f0: 5f6f 6e6c 7928 7365 6c66 293a 0a20 2020  _only(self):.   
+00010100: 2020 2020 2022 2222 7465 7374 5f63 6f6d       """test_com
+00010110: 6d61 6e64 6c69 6e65 5f69 6e63 6c75 6465  mandline_include
+00010120: 5f65 7863 6c75 6465 2077 6974 6820 7369  _exclude with si
+00010130: 6e67 6c65 2061 7374 6572 6973 6b73 206f  ngle asterisks o
+00010140: 6e20 6578 636c 7564 6520 6c69 6e65 732e  n exclude lines.
+00010150: 2222 220a 2020 2020 2020 2020 7365 6c66  """.        self
+00010160: 2e62 6163 6b75 7028 2266 756c 6c22 2c20  .backup("full", 
+00010170: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00010180: 742f 3122 2c0a 2020 2020 2020 2020 2020  t/1",.          
+00010190: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
+000101a0: 733d 5b22 2d2d 696e 636c 7564 6522 2c20  s=["--include", 
+000101b0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+000101c0: 742f 312f 322f 3122 2c0a 2020 2020 2020  t/1/2/1",.      
+000101d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000101e0: 2020 2020 2020 2022 2d2d 6578 636c 7564         "--exclud
+000101f0: 6522 2c20 2274 6573 7466 696c 6573 2f2a  e", "testfiles/*
+00010200: 2f31 2f32 222c 0a20 2020 2020 2020 2020  /1/2",.         
+00010210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010220: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00010230: 2022 2a2f 7365 6c65 6374 2f31 2f31 222c   "*/select/1/1",
+00010240: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010250: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00010260: 2d65 7863 6c75 6465 222c 2022 2a2f 7365  -exclude", "*/se
+00010270: 6c65 6374 2f31 2f33 225d 290a 2020 2020  lect/1/3"]).    
+00010280: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
+00010290: 5f61 6e64 5f63 6865 636b 2829 0a0a 2020  _and_check()..  
+000102a0: 2020 6465 6620 7465 7374 5f63 6f6d 6d61    def test_comma
+000102b0: 6e64 6c69 6e65 5f61 7374 6572 6973 6b73  ndline_asterisks
+000102c0: 5f73 696e 676c 655f 626f 7468 2873 656c  _single_both(sel
+000102d0: 6629 3a0a 2020 2020 2020 2020 2222 2274  f):.        """t
+000102e0: 6573 745f 636f 6d6d 616e 646c 696e 655f  est_commandline_
+000102f0: 696e 636c 7564 655f 6578 636c 7564 6520  include_exclude 
+00010300: 7769 7468 2073 696e 676c 6520 6173 7465  with single aste
+00010310: 7269 736b 7320 6f6e 2062 6f74 6820 6578  risks on both ex
+00010320: 636c 7564 6520 616e 6420 696e 636c 7564  clude and includ
+00010330: 6520 6c69 6e65 732e 2222 220a 2020 2020  e lines.""".    
+00010340: 2020 2020 2320 5265 6772 6573 7369 6f6e      # Regression
+00010350: 2074 6573 7420 666f 7220 4275 6720 2338   test for Bug #8
+00010360: 3834 3337 3120 2868 7474 7073 3a2f 2f62  84371 (https://b
+00010370: 7567 732e 6c61 756e 6368 7061 642e 6e65  ugs.launchpad.ne
+00010380: 742f 6475 706c 6963 6974 792f 2b62 7567  t/duplicity/+bug
+00010390: 2f38 3834 3337 3129 0a20 2020 2020 2020  /884371).       
+000103a0: 2073 656c 662e 6261 636b 7570 2822 6675   self.backup("fu
+000103b0: 6c6c 222c 2022 7465 7374 6669 6c65 732f  ll", "testfiles/
+000103c0: 7365 6c65 6374 2f31 222c 0a20 2020 2020  select/1",.     
+000103d0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+000103e0: 7074 696f 6e73 3d5b 222d 2d69 6e63 6c75  ptions=["--inclu
+000103f0: 6465 222c 2022 2a2f 7365 6c65 6374 2f31  de", "*/select/1
+00010400: 2f32 2f31 222c 0a20 2020 2020 2020 2020  /2/1",.         
+00010410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010420: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00010430: 2022 7465 7374 6669 6c65 732f 2a2f 312f   "testfiles/*/1/
+00010440: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
+00010450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010460: 2022 2d2d 6578 636c 7564 6522 2c20 222a   "--exclude", "*
+00010470: 2f73 656c 6563 742f 312f 3122 2c0a 2020  /select/1/1",.  
+00010480: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010490: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+000104a0: 636c 7564 6522 2c20 222a 2f73 656c 6563  clude", "*/selec
+000104b0: 742f 312f 3322 5d29 0a20 2020 2020 2020  t/1/3"]).       
+000104c0: 2073 656c 662e 7265 7374 6f72 655f 616e   self.restore_an
+000104d0: 645f 6368 6563 6b28 290a 0a20 2020 2064  d_check()..    d
+000104e0: 6566 2074 6573 745f 636f 6d6d 616e 646c  ef test_commandl
+000104f0: 696e 655f 6173 7465 7269 736b 735f 646f  ine_asterisks_do
+00010500: 7562 6c65 5f65 7863 6c75 6465 5f6f 6e6c  uble_exclude_onl
+00010510: 7928 7365 6c66 293a 0a20 2020 2020 2020  y(self):.       
+00010520: 2022 2222 7465 7374 5f63 6f6d 6d61 6e64   """test_command
+00010530: 6c69 6e65 5f69 6e63 6c75 6465 5f65 7863  line_include_exc
+00010540: 6c75 6465 2077 6974 6820 646f 7562 6c65  lude with double
+00010550: 2061 7374 6572 6973 6b73 206f 6e20 6578   asterisks on ex
+00010560: 636c 7564 6520 6c69 6e65 732e 2222 220a  clude lines.""".
+00010570: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
+00010580: 6b75 7028 2266 756c 6c22 2c20 2274 6573  kup("full", "tes
+00010590: 7466 696c 6573 2f73 656c 6563 742f 3122  tfiles/select/1"
+000105a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000105b0: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+000105c0: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+000105d0: 7466 696c 6573 2f73 656c 6563 742f 312f  tfiles/select/1/
+000105e0: 322f 3122 2c0a 2020 2020 2020 2020 2020  2/1",.          
+000105f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010600: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00010610: 222a 2a2f 312f 3222 2c0a 2020 2020 2020  "**/1/2",.      
+00010620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010630: 2020 2020 2020 2022 2d2d 6578 636c 7564         "--exclud
+00010640: 6522 2c20 222a 2a2f 312f 3122 2c0a 2020  e", "**/1/1",.  
+00010650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010660: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00010670: 636c 7564 6522 2c20 222a 2a2f 312f 3322  clude", "**/1/3"
+00010680: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
+00010690: 7265 7374 6f72 655f 616e 645f 6368 6563  restore_and_chec
+000106a0: 6b28 290a 0a20 2020 2064 6566 2074 6573  k()..    def tes
+000106b0: 745f 636f 6d6d 616e 646c 696e 655f 6173  t_commandline_as
+000106c0: 7465 7269 736b 735f 646f 7562 6c65 5f62  terisks_double_b
+000106d0: 6f74 6828 7365 6c66 293a 0a20 2020 2020  oth(self):.     
+000106e0: 2020 2022 2222 7465 7374 5f63 6f6d 6d61     """test_comma
+000106f0: 6e64 6c69 6e65 5f69 6e63 6c75 6465 5f65  ndline_include_e
+00010700: 7863 6c75 6465 2077 6974 6820 646f 7562  xclude with doub
+00010710: 6c65 2061 7374 6572 6973 6b73 206f 6e20  le asterisks on 
+00010720: 626f 7468 2065 7863 6c75 6465 2061 6e64  both exclude and
+00010730: 2069 6e63 6c75 6465 206c 696e 6573 2e22   include lines."
+00010740: 2222 0a20 2020 2020 2020 2023 2052 6567  "".        # Reg
+00010750: 7265 7373 696f 6e20 7465 7374 2066 6f72  ression test for
+00010760: 2042 7567 2023 3838 3433 3731 2028 6874   Bug #884371 (ht
+00010770: 7470 733a 2f2f 6275 6773 2e6c 6175 6e63  tps://bugs.launc
+00010780: 6870 6164 2e6e 6574 2f64 7570 6c69 6369  hpad.net/duplici
+00010790: 7479 2f2b 6275 672f 3838 3433 3731 290a  ty/+bug/884371).
+000107a0: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
+000107b0: 6b75 7028 2266 756c 6c22 2c20 2274 6573  kup("full", "tes
+000107c0: 7466 696c 6573 2f73 656c 6563 742f 3122  tfiles/select/1"
+000107d0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+000107e0: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+000107f0: 2d2d 696e 636c 7564 6522 2c20 222a 2a2f  --include", "**/
+00010800: 312f 322f 3122 2c0a 2020 2020 2020 2020  1/2/1",.        
+00010810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010820: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+00010830: 2c20 222a 2a2f 312f 3222 2c0a 2020 2020  , "**/1/2",.    
+00010840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010850: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00010860: 7564 6522 2c20 222a 2a2f 312f 3122 2c0a  ude", "**/1/1",.
+00010870: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010880: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00010890: 6578 636c 7564 6522 2c20 222a 2a2f 312f  exclude", "**/1/
+000108a0: 3322 5d29 0a20 2020 2020 2020 2073 656c  3"]).        sel
+000108b0: 662e 7265 7374 6f72 655f 616e 645f 6368  f.restore_and_ch
+000108c0: 6563 6b28 290a 0a20 2020 2064 6566 2074  eck()..    def t
+000108d0: 6573 745f 7369 6e67 6c65 5f61 6e64 5f64  est_single_and_d
+000108e0: 6f75 626c 655f 6173 7465 7269 736b 735f  ouble_asterisks_
+000108f0: 696e 636c 7564 6573 5f65 7863 6c75 6465  includes_exclude
+00010900: 7328 7365 6c66 293a 0a20 2020 2020 2020  s(self):.       
+00010910: 2022 2222 5468 6973 2063 6f6d 7061 7265   """This compare
+00010920: 7320 6120 6261 636b 7570 2075 7369 6e67  s a backup using
+00010930: 202d 2d69 6e63 6c75 6465 732f 2d2d 6578   --includes/--ex
+00010940: 636c 7564 6573 2077 6974 6820 6120 7369  cludes with a si
+00010950: 6e67 6c65 2061 6e64 2064 6f75 626c 6520  ngle and double 
+00010960: 2a2e 2222 220a 2020 2020 2020 2020 7365  *.""".        se
+00010970: 6c66 2e62 6163 6b75 7028 2266 756c 6c22  lf.backup("full"
+00010980: 2c20 2274 6573 7466 696c 6573 2f22 2c0a  , "testfiles/",.
+00010990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000109a0: 2020 2020 6f70 7469 6f6e 733d 5b22 2d2d      options=["--
+000109b0: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+000109c0: 696c 6573 2f73 656c 6563 7432 2f2a 222c  iles/select2/*",
+000109d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000109e0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+000109f0: 2d65 7863 6c75 6465 222c 2022 7465 7374  -exclude", "test
+00010a00: 6669 6c65 732f 7365 6c65 6374 225d 290a  files/select"]).
+00010a10: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
+00010a20: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
+00010a30: 6573 746f 7265 5f70 6174 6820 3d20 2274  estore_path = "t
+00010a40: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
+00010a50: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
+00010a60: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
+00010a70: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
+00010a80: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
+00010a90: 7374 6f72 655f 7061 7468 202b 2022 2f73  store_path + "/s
+00010aa0: 656c 6563 7432 2229 0a20 2020 2020 2020  elect2").       
+00010ab0: 2073 656c 662e 6261 636b 7570 2822 6675   self.backup("fu
+00010ac0: 6c6c 222c 2022 7465 7374 6669 6c65 732f  ll", "testfiles/
+00010ad0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+00010ae0: 2020 2020 2020 206f 7074 696f 6e73 3d5b         options=[
+00010af0: 222d 2d69 6e63 6c75 6465 222c 2022 7465  "--include", "te
+00010b00: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+00010b10: 2a2a 222c 0a20 2020 2020 2020 2020 2020  **",.           
+00010b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010b30: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+00010b40: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00010b50: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
+00010b60: 2e72 6573 746f 7265 2829 0a20 2020 2020  .restore().     
+00010b70: 2020 2072 6573 746f 7265 5f70 6174 6820     restore_path 
+00010b80: 3d20 2274 6573 7466 696c 6573 2f72 6573  = "testfiles/res
+00010b90: 746f 7265 5f6f 7574 220a 2020 2020 2020  tore_out".      
+00010ba0: 2020 7265 7374 6f72 6564 3220 3d20 7365    restored2 = se
+00010bb0: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
+00010bc0: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
+00010bd0: 7473 2872 6573 746f 7265 5f70 6174 6820  ts(restore_path 
+00010be0: 2b20 222f 7365 6c65 6374 3222 290a 2020  + "/select2").  
+00010bf0: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
+00010c00: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
+00010c10: 2072 6573 746f 7265 6432 290a 0a0a 636c   restored2)...cl
+00010c20: 6173 7320 5465 7374 5472 6169 6c69 6e67  ass TestTrailing
+00010c30: 536c 6173 6828 496e 636c 7564 6545 7863  Slash(IncludeExc
+00010c40: 6c75 6465 4675 6e63 7469 6f6e 616c 5465  ludeFunctionalTe
+00010c50: 7374 293a 0a20 2020 2022 2222 2054 6573  st):.    """ Tes
+00010c60: 7420 746f 2063 6865 636b 2074 6861 7420  t to check that 
+00010c70: 6120 7472 6169 6c69 6e67 2073 6c61 7368  a trailing slash
+00010c80: 2077 6f72 6b73 2061 7320 6578 7065 6374   works as expect
+00010c90: 6564 0a20 2020 2020 4578 6869 6269 7473  ed.     Exhibits
+00010ca0: 2074 6865 2069 7373 7565 2072 6570 6f72   the issue repor
+00010cb0: 7465 6420 696e 2042 7567 2023 3933 3234  ted in Bug #9324
+00010cc0: 3832 2028 6874 7470 733a 2f2f 6275 6773  82 (https://bugs
+00010cd0: 2e6c 6175 6e63 6870 6164 2e6e 6574 2f64  .launchpad.net/d
+00010ce0: 7570 6c69 6369 7479 2f2b 6275 672f 3933  uplicity/+bug/93
+00010cf0: 3234 3832 292e 2222 220a 0a20 2020 2064  2482)."""..    d
+00010d00: 6566 2072 6573 746f 7265 5f61 6e64 5f63  ef restore_and_c
+00010d10: 6865 636b 2873 656c 6629 3a0a 2020 2020  heck(self):.    
+00010d20: 2020 2020 2222 2252 6573 746f 7265 7320      """Restores 
+00010d30: 7468 6520 6261 636b 7570 2061 6e64 2063  the backup and c
+00010d40: 6f6d 7061 7265 7320 746f 2077 6861 7420  ompares to what 
+00010d50: 6973 2065 7870 6563 7465 642e 2222 220a  is expected.""".
+00010d60: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
+00010d70: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
+00010d80: 6573 746f 7265 5f70 6174 6820 3d20 2274  estore_path = "t
+00010d90: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
+00010da0: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
+00010db0: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
+00010dc0: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
+00010dd0: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
+00010de0: 7374 6f72 655f 7061 7468 290a 2020 2020  store_path).    
+00010df0: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
+00010e00: 7175 616c 2872 6573 746f 7265 642c 205b  qual(restored, [
+00010e10: 5b22 3222 5d2c 205b 2231 225d 5d29 0a0a  ["2"], ["1"]])..
+00010e20: 2020 2020 6465 6620 7465 7374 5f65 7863      def test_exc
+00010e30: 6c75 6465 5f66 696c 656c 6973 745f 7472  lude_filelist_tr
+00010e40: 6169 6c69 6e67 5f73 6c61 7368 6573 2873  ailing_slashes(s
+00010e50: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+00010e60: 2274 6573 745f 6578 636c 7564 655f 6669  "test_exclude_fi
+00010e70: 6c65 6c69 7374 5f61 7374 6572 6973 6b73  lelist_asterisks
+00010e80: 5f6e 6f6e 6520 7769 7468 2074 7261 696c  _none with trail
+00010e90: 696e 6720 736c 6173 6865 732e 2222 220a  ing slashes.""".
+00010ea0: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
+00010eb0: 6f70 656e 2822 7465 7374 6669 6c65 732f  open("testfiles/
+00010ec0: 6669 6c65 6c69 7374 2e74 7874 222c 2022  filelist.txt", "
+00010ed0: 7722 2920 6173 2066 3a0a 2020 2020 2020  w") as f:.      
+00010ee0: 2020 2020 2020 662e 7772 6974 6528 222b        f.write("+
+00010ef0: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
+00010f00: 742f 312f 322f 312f 5c6e 220a 2020 2020  t/1/2/1/\n".    
+00010f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f20: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
+00010f30: 6563 742f 312f 322f 5c6e 220a 2020 2020  ect/1/2/\n".    
+00010f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f50: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
+00010f60: 6563 742f 312f 312f 5c6e 220a 2020 2020  ect/1/1/\n".    
+00010f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010f80: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
+00010f90: 6563 742f 312f 332f 2229 0a20 2020 2020  ect/1/3/").     
+00010fa0: 2020 2073 656c 662e 6261 636b 7570 2822     self.backup("
+00010fb0: 6675 6c6c 222c 2022 7465 7374 6669 6c65  full", "testfile
+00010fc0: 732f 7365 6c65 6374 2f31 222c 206f 7074  s/select/1", opt
+00010fd0: 696f 6e73 3d5b 222d 2d65 7863 6c75 6465  ions=["--exclude
+00010fe0: 2d66 696c 656c 6973 743d 7465 7374 6669  -filelist=testfi
+00010ff0: 6c65 732f 6669 6c65 6c69 7374 2e74 7874  les/filelist.txt
+00011000: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
+00011010: 2e72 6573 746f 7265 5f61 6e64 5f63 6865  .restore_and_che
+00011020: 636b 2829 0a0a 2020 2020 6465 6620 7465  ck()..    def te
+00011030: 7374 5f65 7863 6c75 6465 5f66 696c 656c  st_exclude_filel
+00011040: 6973 745f 7472 6169 6c69 6e67 5f73 6c61  ist_trailing_sla
+00011050: 7368 6573 5f73 696e 676c 655f 7769 6c64  shes_single_wild
+00011060: 6361 7264 735f 6578 636c 7564 6573 2873  cards_excludes(s
+00011070: 656c 6629 3a0a 2020 2020 2020 2020 2222  elf):.        ""
+00011080: 2274 6573 745f 6578 636c 7564 655f 6669  "test_exclude_fi
+00011090: 6c65 6c69 7374 5f74 7261 696c 696e 675f  lelist_trailing_
+000110a0: 736c 6173 6865 7320 7769 7468 2073 696e  slashes with sin
+000110b0: 676c 6520 7769 6c64 6361 7264 7320 696e  gle wildcards in
+000110c0: 2065 7863 6c75 6465 732e 2222 220a 2020   excludes.""".  
+000110d0: 2020 2020 2020 2320 5265 6772 6573 7369        # Regressi
+000110e0: 6f6e 2074 6573 7420 666f 7220 4275 6720  on test for Bug 
+000110f0: 2339 3332 3438 3220 2868 7474 7073 3a2f  #932482 (https:/
+00011100: 2f62 7567 732e 6c61 756e 6368 7061 642e  /bugs.launchpad.
+00011110: 6e65 742f 6475 706c 6963 6974 792f 2b62  net/duplicity/+b
+00011120: 7567 2f39 3332 3438 3229 0a20 2020 2020  ug/932482).     
+00011130: 2020 2077 6974 6820 696f 2e6f 7065 6e28     with io.open(
+00011140: 2274 6573 7466 696c 6573 2f66 696c 656c  "testfiles/filel
+00011150: 6973 742e 7478 7422 2c20 2277 2229 2061  ist.txt", "w") a
+00011160: 7320 663a 0a20 2020 2020 2020 2020 2020  s f:.           
+00011170: 2066 2e77 7269 7465 2822 2b20 7465 7374   f.write("+ test
+00011180: 6669 6c65 732f 7365 6c65 6374 2f31 2f32  files/select/1/2
+00011190: 2f31 2f5c 6e22 0a20 2020 2020 2020 2020  /1/\n".         
+000111a0: 2020 2020 2020 2020 2020 2022 2d20 2a2f             "- */
+000111b0: 7365 6c65 6374 2f31 2f32 2f5c 6e22 0a20  select/1/2/\n". 
+000111c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000111d0: 2020 2022 2d20 7465 7374 6669 6c65 732f     "- testfiles/
+000111e0: 2a2f 312f 312f 5c6e 220a 2020 2020 2020  */1/1/\n".      
+000111f0: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00011200: 202a 2f2a 2f31 2f33 2f22 290a 2020 2020   */*/1/3/").    
+00011210: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
+00011220: 2266 756c 6c22 2c20 2274 6573 7466 696c  "full", "testfil
+00011230: 6573 2f73 656c 6563 742f 3122 2c20 6f70  es/select/1", op
+00011240: 7469 6f6e 733d 5b22 2d2d 6578 636c 7564  tions=["--exclud
+00011250: 652d 6669 6c65 6c69 7374 3d74 6573 7466  e-filelist=testf
+00011260: 696c 6573 2f66 696c 656c 6973 742e 7478  iles/filelist.tx
+00011270: 7422 5d29 0a20 2020 2020 2020 2073 656c  t"]).        sel
+00011280: 662e 7265 7374 6f72 655f 616e 645f 6368  f.restore_and_ch
+00011290: 6563 6b28 290a 0a20 2020 2064 6566 2074  eck()..    def t
+000112a0: 6573 745f 6578 636c 7564 655f 6669 6c65  est_exclude_file
+000112b0: 6c69 7374 5f74 7261 696c 696e 675f 736c  list_trailing_sl
+000112c0: 6173 6865 735f 646f 7562 6c65 5f77 696c  ashes_double_wil
+000112d0: 6463 6172 6473 5f65 7863 6c75 6465 7328  dcards_excludes(
+000112e0: 7365 6c66 293a 0a20 2020 2020 2020 2022  self):.        "
+000112f0: 2222 7465 7374 5f65 7863 6c75 6465 5f66  ""test_exclude_f
+00011300: 696c 656c 6973 745f 7472 6169 6c69 6e67  ilelist_trailing
+00011310: 5f73 6c61 7368 6573 2077 6974 6820 646f  _slashes with do
+00011320: 7562 6c65 2077 696c 6463 6172 6473 2069  uble wildcards i
+00011330: 6e20 6578 636c 7564 6573 2e22 2222 0a20  n excludes.""". 
+00011340: 2020 2020 2020 2023 2052 6567 7265 7373         # Regress
+00011350: 696f 6e20 7465 7374 2066 6f72 2042 7567  ion test for Bug
+00011360: 2023 3933 3234 3832 2028 6874 7470 733a   #932482 (https:
+00011370: 2f2f 6275 6773 2e6c 6175 6e63 6870 6164  //bugs.launchpad
+00011380: 2e6e 6574 2f64 7570 6c69 6369 7479 2f2b  .net/duplicity/+
+00011390: 6275 672f 3933 3234 3832 290a 2020 2020  bug/932482).    
+000113a0: 2020 2020 7769 7468 2069 6f2e 6f70 656e      with io.open
+000113b0: 2822 7465 7374 6669 6c65 732f 6669 6c65  ("testfiles/file
+000113c0: 6c69 7374 2e74 7874 222c 2022 7722 2920  list.txt", "w") 
+000113d0: 6173 2066 3a0a 2020 2020 2020 2020 2020  as f:.          
+000113e0: 2020 662e 7772 6974 6528 222b 2074 6573    f.write("+ tes
+000113f0: 7466 696c 6573 2f73 656c 6563 742f 312f  tfiles/select/1/
+00011400: 322f 312f 5c6e 220a 2020 2020 2020 2020  2/1/\n".        
+00011410: 2020 2020 2020 2020 2020 2020 222d 202a              "- *
+00011420: 2a2f 312f 322f 5c6e 220a 2020 2020 2020  */1/2/\n".      
+00011430: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00011440: 202a 2a2f 312f 312f 5c6e 220a 2020 2020   **/1/1/\n".    
+00011450: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011460: 222d 202a 2a2f 312f 332f 2229 0a20 2020  "- **/1/3/").   
+00011470: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
+00011480: 2822 6675 6c6c 222c 2022 7465 7374 6669  ("full", "testfi
+00011490: 6c65 732f 7365 6c65 6374 2f31 222c 206f  les/select/1", o
+000114a0: 7074 696f 6e73 3d5b 222d 2d65 7863 6c75  ptions=["--exclu
+000114b0: 6465 2d66 696c 656c 6973 743d 7465 7374  de-filelist=test
+000114c0: 6669 6c65 732f 6669 6c65 6c69 7374 2e74  files/filelist.t
+000114d0: 7874 225d 290a 2020 2020 2020 2020 7365  xt"]).        se
+000114e0: 6c66 2e72 6573 746f 7265 5f61 6e64 5f63  lf.restore_and_c
+000114f0: 6865 636b 2829 0a0a 2020 2020 6465 6620  heck()..    def 
+00011500: 7465 7374 5f65 7863 6c75 6465 5f66 696c  test_exclude_fil
+00011510: 656c 6973 745f 7472 6169 6c69 6e67 5f73  elist_trailing_s
+00011520: 6c61 7368 6573 5f64 6f75 626c 655f 7769  lashes_double_wi
+00011530: 6c64 6361 7264 735f 6578 636c 7564 6573  ldcards_excludes
+00011540: 5f32 2873 656c 6629 3a0a 2020 2020 2020  _2(self):.      
+00011550: 2020 2222 2273 6563 6f6e 6420 7465 7374    """second test
+00011560: 5f65 7863 6c75 6465 5f66 696c 656c 6973  _exclude_filelis
+00011570: 745f 7472 6169 6c69 6e67 5f73 6c61 7368  t_trailing_slash
+00011580: 6573 2077 6974 6820 646f 7562 6c65 2077  es with double w
+00011590: 696c 6463 6172 6473 2069 6e20 6578 636c  ildcards in excl
+000115a0: 7564 6573 2e22 2222 0a20 2020 2020 2020  udes.""".       
+000115b0: 2023 2052 6567 7265 7373 696f 6e20 7465   # Regression te
+000115c0: 7374 2066 6f72 2042 7567 2023 3933 3234  st for Bug #9324
+000115d0: 3832 2028 6874 7470 733a 2f2f 6275 6773  82 (https://bugs
+000115e0: 2e6c 6175 6e63 6870 6164 2e6e 6574 2f64  .launchpad.net/d
+000115f0: 7570 6c69 6369 7479 2f2b 6275 672f 3933  uplicity/+bug/93
+00011600: 3234 3832 2920 616e 640a 2020 2020 2020  2482) and.      
+00011610: 2020 2320 5265 6772 6573 7369 6f6e 2074    # Regression t
+00011620: 6573 7420 666f 7220 4275 6720 2338 3834  est for Bug #884
+00011630: 3337 3120 2868 7474 7073 3a2f 2f62 7567  371 (https://bug
+00011640: 732e 6c61 756e 6368 7061 642e 6e65 742f  s.launchpad.net/
+00011650: 6475 706c 6963 6974 792f 2b62 7567 2f38  duplicity/+bug/8
+00011660: 3834 3337 3129 0a20 2020 2020 2020 2077  84371).        w
+00011670: 6974 6820 696f 2e6f 7065 6e28 2274 6573  ith io.open("tes
+00011680: 7466 696c 6573 2f66 696c 656c 6973 742e  tfiles/filelist.
+00011690: 7478 7422 2c20 2277 2229 2061 7320 663a  txt", "w") as f:
+000116a0: 0a20 2020 2020 2020 2020 2020 2066 2e77  .            f.w
+000116b0: 7269 7465 2822 2b20 2a2a 2f31 2f32 2f31  rite("+ **/1/2/1
+000116c0: 2f5c 6e22 0a20 2020 2020 2020 2020 2020  /\n".           
+000116d0: 2020 2020 2020 2020 2022 2d20 2a2a 2f31           "- **/1
+000116e0: 2f32 2f5c 6e22 0a20 2020 2020 2020 2020  /2/\n".         
+000116f0: 2020 2020 2020 2020 2020 2022 2d20 2a2a             "- **
+00011700: 2f31 2f31 2f5c 6e22 0a20 2020 2020 2020  /1/1/\n".       
+00011710: 2020 2020 2020 2020 2020 2020 2022 2d20               "- 
+00011720: 2a2a 2f31 2f33 2f22 290a 2020 2020 2020  **/1/3/").      
+00011730: 2020 7365 6c66 2e62 6163 6b75 7028 2266    self.backup("f
+00011740: 756c 6c22 2c20 2274 6573 7466 696c 6573  ull", "testfiles
+00011750: 2f73 656c 6563 742f 3122 2c20 6f70 7469  /select/1", opti
+00011760: 6f6e 733d 5b22 2d2d 6578 636c 7564 652d  ons=["--exclude-
+00011770: 6669 6c65 6c69 7374 3d74 6573 7466 696c  filelist=testfil
+00011780: 6573 2f66 696c 656c 6973 742e 7478 7422  es/filelist.txt"
+00011790: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
+000117a0: 7265 7374 6f72 655f 616e 645f 6368 6563  restore_and_chec
+000117b0: 6b28 290a 0a20 2020 2064 6566 2074 6573  k()..    def tes
+000117c0: 745f 6578 636c 7564 655f 6669 6c65 6c69  t_exclude_fileli
+000117d0: 7374 5f74 7261 696c 696e 675f 736c 6173  st_trailing_slas
+000117e0: 6865 735f 7769 6c64 6361 7264 7328 7365  hes_wildcards(se
+000117f0: 6c66 293a 0a20 2020 2020 2020 2022 2222  lf):.        """
+00011800: 7465 7374 5f63 6f6d 6d61 6e64 6c69 6e65  test_commandline
+00011810: 5f61 7374 6572 6973 6b73 5f73 696e 676c  _asterisks_singl
+00011820: 655f 6578 636c 7564 6573 5f6f 6e6c 7920  e_excludes_only 
+00011830: 7769 7468 2074 7261 696c 696e 6720 736c  with trailing sl
+00011840: 6173 6865 732e 2222 220a 2020 2020 2020  ashes.""".      
+00011850: 2020 2320 5265 6772 6573 7369 6f6e 2074    # Regression t
+00011860: 6573 7420 666f 7220 4275 6720 2339 3332  est for Bug #932
+00011870: 3438 3220 2868 7474 7073 3a2f 2f62 7567  482 (https://bug
+00011880: 732e 6c61 756e 6368 7061 642e 6e65 742f  s.launchpad.net/
+00011890: 6475 706c 6963 6974 792f 2b62 7567 2f39  duplicity/+bug/9
+000118a0: 3332 3438 3229 0a20 2020 2020 2020 2073  32482).        s
+000118b0: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+000118c0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+000118d0: 6c65 6374 2f31 222c 0a20 2020 2020 2020  lect/1",.       
+000118e0: 2020 2020 2020 2020 2020 2020 206f 7074               opt
+000118f0: 696f 6e73 3d5b 222d 2d69 6e63 6c75 6465  ions=["--include
+00011900: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00011910: 6c65 6374 2f31 2f32 2f31 2f22 2c0a 2020  lect/1/2/1/",.  
+00011920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011930: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00011940: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00011950: 6573 2f2a 2f31 2f32 2f22 2c0a 2020 2020  es/*/1/2/",.    
+00011960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011970: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00011980: 7564 6522 2c20 222a 2f73 656c 6563 742f  ude", "*/select/
+00011990: 312f 312f 222c 0a20 2020 2020 2020 2020  1/1/",.         
+000119a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000119b0: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+000119c0: 2022 2a2f 7365 6c65 6374 2f31 2f33 2f22   "*/select/1/3/"
+000119d0: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
+000119e0: 7265 7374 6f72 655f 616e 645f 6368 6563  restore_and_chec
+000119f0: 6b28 290a 0a0a 636c 6173 7320 5465 7374  k()...class Test
+00011a00: 5472 6169 6c69 6e67 536c 6173 6832 2849  TrailingSlash2(I
+00011a10: 6e63 6c75 6465 4578 636c 7564 6546 756e  ncludeExcludeFun
+00011a20: 6374 696f 6e61 6c54 6573 7429 3a0a 2020  ctionalTest):.  
+00011a30: 2020 2222 2220 5468 6973 2074 6573 7473    """ This tests
+00011a40: 2074 6865 2062 6568 6176 696f 7572 206f   the behaviour o
+00011a50: 6620 676c 6f62 6269 6e67 2073 7472 696e  f globbing strin
+00011a60: 6773 2077 6974 6820 6120 7472 6169 6c69  gs with a traili
+00011a70: 6e67 2073 6c61 7368 2222 220a 0a20 2020  ng slash"""..   
+00011a80: 2023 2053 6565 2042 7567 2023 3134 3739   # See Bug #1479
+00011a90: 3534 3520 2868 7474 7073 3a2f 2f62 7567  545 (https://bug
+00011aa0: 732e 6c61 756e 6368 7061 642e 6e65 742f  s.launchpad.net/
+00011ab0: 6475 706c 6963 6974 792f 2b62 7567 2f31  duplicity/+bug/1
+00011ac0: 3437 3935 3435 290a 0a20 2020 2064 6566  479545)..    def
+00011ad0: 2074 6573 745f 6e6f 5f74 7261 696c 696e   test_no_trailin
+00011ae0: 675f 736c 6173 6828 7365 6c66 293a 0a20  g_slash(self):. 
+00011af0: 2020 2020 2020 2022 2222 2054 6573 7420         """ Test 
+00011b00: 7468 6174 2069 6e63 6c75 6469 6e67 2031  that including 1
+00011b10: 2e70 7920 776f 726b 7320 6173 2065 7870  .py works as exp
+00011b20: 6563 7465 6422 2222 0a20 2020 2020 2020  ected""".       
+00011b30: 2073 656c 662e 6261 636b 7570 2822 6675   self.backup("fu
+00011b40: 6c6c 222c 2022 7465 7374 6669 6c65 732f  ll", "testfiles/
+00011b50: 7365 6c65 6374 3222 2c0a 2020 2020 2020  select2",.      
+00011b60: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+00011b70: 7469 6f6e 733d 5b22 2d2d 696e 636c 7564  tions=["--includ
+00011b80: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00011b90: 656c 6563 7432 2f31 2e70 7922 2c0a 2020  elect2/1.py",.  
+00011ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011bb0: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00011bc0: 636c 7564 6522 2c20 222a 2a22 5d29 0a20  clude", "**"]). 
+00011bd0: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
+00011be0: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
+00011bf0: 7374 6f72 655f 7061 7468 203d 2022 7465  store_path = "te
+00011c00: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
+00011c10: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
+00011c20: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
+00011c30: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
+00011c40: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
+00011c50: 746f 7265 5f70 6174 6829 0a20 2020 2020  tore_path).     
+00011c60: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
+00011c70: 7561 6c28 7265 7374 6f72 6564 2c20 5b5b  ual(restored, [[
+00011c80: 2231 2e70 7922 5d5d 290a 0a20 2020 2064  "1.py"]])..    d
+00011c90: 6566 2074 6573 745f 7472 6169 6c69 6e67  ef test_trailing
+00011ca0: 5f73 6c61 7368 2873 656c 6629 3a0a 2020  _slash(self):.  
+00011cb0: 2020 2020 2020 2222 2220 5465 7374 2074        """ Test t
+00011cc0: 6861 7420 676c 6f62 7320 7769 7468 2061  hat globs with a
+00011cd0: 2074 7261 696c 696e 6720 736c 6173 6820   trailing slash 
+00011ce0: 6f6e 6c79 206d 6174 6368 2064 6972 6563  only match direc
+00011cf0: 746f 7269 6573 2222 220a 2020 2020 2020  tories""".      
+00011d00: 2020 2320 5265 6772 6573 7369 6f6e 2074    # Regression t
+00011d10: 6573 7420 666f 7220 4275 6720 2331 3437  est for Bug #147
+00011d20: 3935 3435 0a20 2020 2020 2020 2023 2028  9545.        # (
+00011d30: 6874 7470 733a 2f2f 6275 6773 2e6c 6175  https://bugs.lau
+00011d40: 6e63 6870 6164 2e6e 6574 2f64 7570 6c69  nchpad.net/dupli
+00011d50: 6369 7479 2f2b 6275 672f 3134 3739 3534  city/+bug/147954
+00011d60: 3529 0a20 2020 2020 2020 2073 656c 662e  5).        self.
+00011d70: 6261 636b 7570 2822 6675 6c6c 222c 2022  backup("full", "
+00011d80: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00011d90: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
+00011da0: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
+00011db0: 5b22 2d2d 696e 636c 7564 6522 2c20 2274  ["--include", "t
+00011dc0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+00011dd0: 2f31 2e70 792f 222c 0a20 2020 2020 2020  /1.py/",.       
+00011de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011df0: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+00011e00: 222c 2022 2a2a 225d 290a 2020 2020 2020  ", "**"]).      
+00011e10: 2020 7365 6c66 2e72 6573 746f 7265 2829    self.restore()
+00011e20: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+00011e30: 5f70 6174 6820 3d20 2274 6573 7466 696c  _path = "testfil
+00011e40: 6573 2f72 6573 746f 7265 5f6f 7574 220a  es/restore_out".
+00011e50: 2020 2020 2020 2020 7265 7374 6f72 6564          restored
+00011e60: 203d 2073 656c 662e 6469 7265 6374 6f72   = self.director
+00011e70: 795f 7472 6565 5f74 6f5f 6c69 7374 5f6f  y_tree_to_list_o
+00011e80: 665f 6c69 7374 7328 7265 7374 6f72 655f  f_lists(restore_
+00011e90: 7061 7468 290a 2020 2020 2020 2020 7365  path).        se
+00011ea0: 6c66 2e61 7373 6572 7445 7175 616c 2872  lf.assertEqual(r
+00011eb0: 6573 746f 7265 642c 205b 5d29 0a0a 2020  estored, [])..  
+00011ec0: 2020 6465 6620 7465 7374 5f69 6e63 6c75    def test_inclu
+00011ed0: 6465 5f66 696c 6573 5f6e 6f74 5f73 7562  de_files_not_sub
+00011ee0: 6469 7265 6374 6f72 6965 7328 7365 6c66  directories(self
+00011ef0: 293a 0a20 2020 2020 2020 2022 2222 2054  ):.        """ T
+00011f00: 6573 7420 7468 6174 2061 2074 7261 696c  est that a trail
+00011f10: 696e 6720 736c 6173 6820 676c 6f62 2066  ing slash glob f
+00011f20: 6f6c 6c6f 7765 6420 6279 2061 202a 2067  ollowed by a * g
+00011f30: 6c6f 6220 6f6e 6c79 206d 6174 6368 6573  lob only matches
+00011f40: 0a20 2020 2020 2020 2066 696c 6573 2061  .        files a
+00011f50: 6e64 206e 6f74 2073 7562 6469 7265 6374  nd not subdirect
+00011f60: 6f72 6965 7322 2222 0a20 2020 2020 2020  ories""".       
+00011f70: 2073 656c 662e 6261 636b 7570 2822 6675   self.backup("fu
+00011f80: 6c6c 222c 2022 7465 7374 6669 6c65 732f  ll", "testfiles/
+00011f90: 7365 6c65 6374 3222 2c0a 2020 2020 2020  select2",.      
+00011fa0: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+00011fb0: 7469 6f6e 733d 5b22 2d2d 6578 636c 7564  tions=["--exclud
+00011fc0: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00011fd0: 656c 6563 7432 2f2a 2f22 2c0a 2020 2020  elect2/*/",.    
+00011fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011ff0: 2020 2020 2020 2020 2022 2d2d 696e 636c           "--incl
+00012000: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00012010: 2f73 656c 6563 7432 2f2a 222c 0a20 2020  /select2/*",.   
+00012020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012030: 2020 2020 2020 2020 2020 222d 2d65 7863            "--exc
+00012040: 6c75 6465 222c 2022 2a2a 225d 290a 2020  lude", "**"]).  
+00012050: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
+00012060: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
+00012070: 746f 7265 5f70 6174 6820 3d20 2274 6573  tore_path = "tes
+00012080: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
+00012090: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
+000120a0: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
+000120b0: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
+000120c0: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
+000120d0: 6f72 655f 7061 7468 290a 2020 2020 2020  ore_path).      
+000120e0: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
+000120f0: 616c 2872 6573 746f 7265 642c 205b 5b22  al(restored, [["
+00012100: 312e 646f 6322 2c20 2231 2e70 7922 5d5d  1.doc", "1.py"]]
+00012110: 290a 0a20 2020 2064 6566 2074 6573 745f  )..    def test_
+00012120: 696e 636c 7564 655f 7375 6264 6972 6563  include_subdirec
+00012130: 746f 7269 6573 5f6e 6f74 5f66 696c 6573  tories_not_files
+00012140: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00012150: 2222 2220 5465 7374 2074 6861 7420 6120  """ Test that a 
+00012160: 7472 6169 6c69 6e67 2073 6c61 7368 2067  trailing slash g
+00012170: 6c6f 6220 6f6e 6c79 206d 6174 6368 6573  lob only matches
+00012180: 2064 6972 6563 746f 7269 6573 2222 220a   directories""".
+00012190: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
+000121a0: 6b75 7028 2266 756c 6c22 2c20 2274 6573  kup("full", "tes
+000121b0: 7466 696c 6573 2f73 656c 6563 7432 222c  tfiles/select2",
+000121c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000121d0: 2020 2020 206f 7074 696f 6e73 3d5b 222d       options=["-
+000121e0: 2d69 6e63 6c75 6465 222c 2022 7465 7374  -include", "test
+000121f0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
+00012200: 3173 7562 312f 2a2a 2f22 2c0a 2020 2020  1sub1/**/",.    
+00012210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012220: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00012230: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00012240: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
+00012250: 2f2a 2a22 2c0a 2020 2020 2020 2020 2020  /**",.          
+00012260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012270: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00012280: 222a 2a22 5d29 0a20 2020 2020 2020 2073  "**"]).        s
+00012290: 656c 662e 7265 7374 6f72 6528 290a 2020  elf.restore().  
+000122a0: 2020 2020 2020 7265 7374 6f72 655f 7061        restore_pa
+000122b0: 7468 203d 2022 7465 7374 6669 6c65 732f  th = "testfiles/
+000122c0: 7265 7374 6f72 655f 6f75 7422 0a20 2020  restore_out".   
+000122d0: 2020 2020 2072 6573 746f 7265 6420 3d20       restored = 
+000122e0: 7365 6c66 2e64 6972 6563 746f 7279 5f74  self.directory_t
+000122f0: 7265 655f 746f 5f6c 6973 745f 6f66 5f6c  ree_to_list_of_l
+00012300: 6973 7473 2872 6573 746f 7265 5f70 6174  ists(restore_pat
+00012310: 6829 0a20 2020 2020 2020 2073 656c 662e  h).        self.
+00012320: 6173 7365 7274 4571 7561 6c28 7265 7374  assertEqual(rest
+00012330: 6f72 6564 2c20 5b5b 2231 225d 2c20 5b22  ored, [["1"], ["
+00012340: 3173 7562 3122 5d2c 0a20 2020 2020 2020  1sub1"],.       
 00012350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012360: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00012370: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00012380: 656c 6563 742f 312f 3122 2c0a 2020 2020  elect/1/1",.    
-00012390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000123a0: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-000123b0: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-000123c0: 6573 2f73 656c 6563 742f 312f 3322 5d29  es/select/1/3"])
-000123d0: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-000123e0: 7374 6f72 655f 616e 645f 6368 6563 6b28  store_and_check(
-000123f0: 290a 0a20 2020 2064 6566 2074 6573 745f  )..    def test_
-00012400: 696e 636c 7564 655f 676c 6f62 6269 6e67  include_globbing
-00012410: 5f66 696c 656c 6973 7428 7365 6c66 293a  _filelist(self):
-00012420: 0a20 2020 2020 2020 2075 2222 2274 6573  .        u"""tes
-00012430: 7420 616e 2065 7863 6c75 6465 6420 666f  t an excluded fo
-00012440: 6c64 6572 2069 7320 696e 636c 7564 6564  lder is included
-00012450: 2066 6f72 2069 6e63 6c75 6465 6420 636f   for included co
-00012460: 6e74 656e 7473 2077 6974 6820 616e 2069  ntents with an i
-00012470: 6e63 6c75 6465 2d67 6c6f 6262 696e 672d  nclude-globbing-
-00012480: 6669 6c65 6c69 7374 2022 2222 0a20 2020  filelist """.   
-00012490: 2020 2020 2023 2044 6570 7265 6361 7465       # Deprecate
-000124a0: 642c 2062 7574 2069 6e63 6c75 6465 2066  d, but include f
-000124b0: 6f72 206e 6f77 2074 6f20 656e 7375 7265  or now to ensure
-000124c0: 2069 7420 6b65 6570 7320 776f 726b 696e   it keeps workin
-000124d0: 6720 756e 7469 6c20 6974 2069 7320 6465  g until it is de
-000124e0: 6c69 6265 7261 7465 6c79 2072 656d 6f76  liberately remov
-000124f0: 6564 2e0a 2020 2020 2020 2020 7365 6c66  ed..        self
-00012500: 2e77 7269 7465 5f66 696c 656c 6973 7428  .write_filelist(
-00012510: 7522 7465 7374 6669 6c65 732f 696e 636c  u"testfiles/incl
-00012520: 7564 652e 7478 7422 290a 2020 2020 2020  ude.txt").      
-00012530: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-00012540: 6675 6c6c 222c 2075 2274 6573 7466 696c  full", u"testfil
-00012550: 6573 2f73 656c 6563 742f 3122 2c20 6f70  es/select/1", op
-00012560: 7469 6f6e 733d 5b75 222d 2d69 6e63 6c75  tions=[u"--inclu
-00012570: 6465 2d67 6c6f 6262 696e 672d 6669 6c65  de-globbing-file
-00012580: 6c69 7374 3d74 6573 7466 696c 6573 2f69  list=testfiles/i
-00012590: 6e63 6c75 6465 2e74 7874 225d 290a 2020  nclude.txt"]).  
-000125a0: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
-000125b0: 7265 5f61 6e64 5f63 6865 636b 2829 0a0a  re_and_check()..
-000125c0: 2020 2020 6465 6620 7465 7374 5f65 7863      def test_exc
-000125d0: 6c75 6465 5f67 6c6f 6262 696e 675f 6669  lude_globbing_fi
-000125e0: 6c65 6c69 7374 2873 656c 6629 3a0a 2020  lelist(self):.  
-000125f0: 2020 2020 2020 7522 2222 7465 7374 2061        u"""test a
-00012600: 6e20 6578 636c 7564 6564 2066 6f6c 6465  n excluded folde
-00012610: 7220 6973 2069 6e63 6c75 6465 6420 666f  r is included fo
-00012620: 7220 696e 636c 7564 6564 2063 6f6e 7465  r included conte
-00012630: 6e74 7320 7769 7468 2061 6e20 6578 636c  nts with an excl
-00012640: 7564 652d 676c 6f62 6269 6e67 2d66 696c  ude-globbing-fil
-00012650: 656c 6973 7420 2222 220a 2020 2020 2020  elist """.      
-00012660: 2020 2320 4465 7072 6563 6174 6564 2c20    # Deprecated, 
-00012670: 6275 7420 696e 636c 7564 6520 666f 7220  but include for 
-00012680: 6e6f 7720 746f 2065 6e73 7572 6520 6974  now to ensure it
-00012690: 206b 6565 7073 2077 6f72 6b69 6e67 2075   keeps working u
-000126a0: 6e74 696c 2069 7420 6973 2064 656c 6962  ntil it is delib
-000126b0: 6572 6174 656c 7920 7265 6d6f 7665 642e  erately removed.
-000126c0: 0a20 2020 2020 2020 2073 656c 662e 7772  .        self.wr
-000126d0: 6974 655f 6669 6c65 6c69 7374 2875 2274  ite_filelist(u"t
-000126e0: 6573 7466 696c 6573 2f65 7863 6c75 6465  estfiles/exclude
-000126f0: 2e74 7874 2229 0a20 2020 2020 2020 2073  .txt").        s
-00012700: 656c 662e 6261 636b 7570 2875 2266 756c  elf.backup(u"ful
-00012710: 6c22 2c20 7522 7465 7374 6669 6c65 732f  l", u"testfiles/
-00012720: 7365 6c65 6374 2f31 222c 206f 7074 696f  select/1", optio
-00012730: 6e73 3d5b 7522 2d2d 6578 636c 7564 652d  ns=[u"--exclude-
-00012740: 676c 6f62 6269 6e67 2d66 696c 656c 6973  globbing-filelis
-00012750: 743d 7465 7374 6669 6c65 732f 6578 636c  t=testfiles/excl
-00012760: 7564 652e 7478 7422 5d29 0a20 2020 2020  ude.txt"]).     
-00012770: 2020 2073 656c 662e 7265 7374 6f72 655f     self.restore_
-00012780: 616e 645f 6368 6563 6b28 290a 0a20 2020  and_check()..   
-00012790: 2064 6566 2074 6573 745f 696e 636c 7564   def test_includ
-000127a0: 655f 6669 6c65 6c69 7374 2873 656c 6629  e_filelist(self)
-000127b0: 3a0a 2020 2020 2020 2020 7522 2222 7465  :.        u"""te
-000127c0: 7374 2061 6e20 6578 636c 7564 6564 2066  st an excluded f
-000127d0: 6f6c 6465 7220 6973 2069 6e63 6c75 6465  older is include
-000127e0: 6420 666f 7220 696e 636c 7564 6564 2063  d for included c
-000127f0: 6f6e 7465 6e74 7320 7769 7468 2061 6e20  ontents with an 
-00012800: 696e 636c 7564 652d 6669 6c65 6c69 7374  include-filelist
-00012810: 2028 6e6f 6e2d 676c 6f62 6269 6e67 2920   (non-globbing) 
-00012820: 2222 220a 2020 2020 2020 2020 2320 5265  """.        # Re
-00012830: 6772 6573 7369 6f6e 2074 6573 7420 666f  gression test fo
-00012840: 7220 4275 6720 2331 3430 3834 3131 2028  r Bug #1408411 (
-00012850: 6874 7470 733a 2f2f 6275 6773 2e6c 6175  https://bugs.lau
-00012860: 6e63 6870 6164 2e6e 6574 2f64 7570 6c69  nchpad.net/dupli
-00012870: 6369 7479 2f2b 6275 672f 3134 3038 3431  city/+bug/140841
-00012880: 3129 0a20 2020 2020 2020 2073 656c 662e  1).        self.
-00012890: 7772 6974 655f 6669 6c65 6c69 7374 2875  write_filelist(u
-000128a0: 2274 6573 7466 696c 6573 2f69 6e63 6c75  "testfiles/inclu
-000128b0: 6465 2e74 7874 2229 0a20 2020 2020 2020  de.txt").       
-000128c0: 2073 656c 662e 6261 636b 7570 2875 2266   self.backup(u"f
-000128d0: 756c 6c22 2c20 7522 7465 7374 6669 6c65  ull", u"testfile
-000128e0: 732f 7365 6c65 6374 2f31 222c 206f 7074  s/select/1", opt
-000128f0: 696f 6e73 3d5b 7522 2d2d 696e 636c 7564  ions=[u"--includ
-00012900: 652d 6669 6c65 6c69 7374 3d74 6573 7466  e-filelist=testf
-00012910: 696c 6573 2f69 6e63 6c75 6465 2e74 7874  iles/include.txt
-00012920: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
-00012930: 2e72 6573 746f 7265 5f61 6e64 5f63 6865  .restore_and_che
-00012940: 636b 2829 0a0a 2020 2020 6465 6620 7465  ck()..    def te
-00012950: 7374 5f65 7863 6c75 6465 5f66 696c 656c  st_exclude_filel
-00012960: 6973 7428 7365 6c66 293a 0a20 2020 2020  ist(self):.     
-00012970: 2020 2075 2222 2274 6573 7420 616e 2065     u"""test an e
-00012980: 7863 6c75 6465 6420 666f 6c64 6572 2069  xcluded folder i
-00012990: 7320 696e 636c 7564 6564 2066 6f72 2069  s included for i
-000129a0: 6e63 6c75 6465 6420 636f 6e74 656e 7473  ncluded contents
-000129b0: 2077 6974 6820 616e 2065 7863 6c75 6465   with an exclude
-000129c0: 2d66 696c 656c 6973 7420 2028 6e6f 6e2d  -filelist  (non-
-000129d0: 676c 6f62 6269 6e67 2920 2222 220a 2020  globbing) """.  
-000129e0: 2020 2020 2020 2320 5265 6772 6573 7369        # Regressi
-000129f0: 6f6e 2074 6573 7420 666f 7220 4275 6720  on test for Bug 
-00012a00: 2331 3430 3834 3131 2028 6874 7470 733a  #1408411 (https:
-00012a10: 2f2f 6275 6773 2e6c 6175 6e63 6870 6164  //bugs.launchpad
-00012a20: 2e6e 6574 2f64 7570 6c69 6369 7479 2f2b  .net/duplicity/+
-00012a30: 6275 672f 3134 3038 3431 3129 0a20 2020  bug/1408411).   
-00012a40: 2020 2020 2073 656c 662e 7772 6974 655f       self.write_
-00012a50: 6669 6c65 6c69 7374 2875 2274 6573 7466  filelist(u"testf
-00012a60: 696c 6573 2f65 7863 6c75 6465 2e74 7874  iles/exclude.txt
-00012a70: 2229 0a20 2020 2020 2020 2073 656c 662e  ").        self.
-00012a80: 6261 636b 7570 2875 2266 756c 6c22 2c20  backup(u"full", 
-00012a90: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00012aa0: 6374 2f31 222c 206f 7074 696f 6e73 3d5b  ct/1", options=[
-00012ab0: 7522 2d2d 6578 636c 7564 652d 6669 6c65  u"--exclude-file
-00012ac0: 6c69 7374 3d74 6573 7466 696c 6573 2f65  list=testfiles/e
-00012ad0: 7863 6c75 6465 2e74 7874 225d 290a 2020  xclude.txt"]).  
-00012ae0: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
-00012af0: 7265 5f61 6e64 5f63 6865 636b 2829 0a0a  re_and_check()..
-00012b00: 0a63 6c61 7373 2054 6573 7441 7374 6572  .class TestAster
-00012b10: 6973 6b73 2849 6e63 6c75 6465 4578 636c  isks(IncludeExcl
-00012b20: 7564 6546 756e 6374 696f 6e61 6c54 6573  udeFunctionalTes
-00012b30: 7429 3a0a 2020 2020 7522 2222 2054 6573  t):.    u""" Tes
-00012b40: 7420 746f 2063 6865 636b 2074 6861 7420  t to check that 
-00012b50: 6173 7465 7269 736b 7320 776f 726b 2061  asterisks work a
-00012b60: 7320 6578 7065 6374 6564 0a20 2020 2020  s expected.     
-00012b70: 4578 6869 6269 7473 2074 6865 2069 7373  Exhibits the iss
-00012b80: 7565 2072 6570 6f72 7465 6420 696e 2042  ue reported in B
-00012b90: 7567 2023 3838 3433 3731 2028 6874 7470  ug #884371 (http
-00012ba0: 733a 2f2f 6275 6773 2e6c 6175 6e63 6870  s://bugs.launchp
-00012bb0: 6164 2e6e 6574 2f64 7570 6c69 6369 7479  ad.net/duplicity
-00012bc0: 2f2b 6275 672f 3838 3433 3731 292e 0a20  /+bug/884371).. 
-00012bd0: 2020 2020 5365 6520 7468 6520 756e 6974      See the unit
-00012be0: 2074 6573 7473 2066 6f72 206d 6f72 6520   tests for more 
-00012bf0: 6772 616e 756c 6172 6974 7920 6f6e 2074  granularity on t
-00012c00: 6865 2069 7373 7565 2e22 2222 0a0a 2020  he issue."""..  
-00012c10: 2020 6465 6620 7265 7374 6f72 655f 616e    def restore_an
-00012c20: 645f 6368 6563 6b28 7365 6c66 293a 0a20  d_check(self):. 
-00012c30: 2020 2020 2020 2075 2222 2252 6573 746f         u"""Resto
-00012c40: 7265 7320 7468 6520 6261 636b 7570 2061  res the backup a
-00012c50: 6e64 2063 6f6d 7061 7265 7320 746f 2077  nd compares to w
-00012c60: 6861 7420 6973 2065 7870 6563 7465 642e  hat is expected.
-00012c70: 2222 220a 2020 2020 2020 2020 7365 6c66  """.        self
-00012c80: 2e72 6573 746f 7265 2829 0a20 2020 2020  .restore().     
-00012c90: 2020 2072 6573 746f 7265 5f64 6972 203d     restore_dir =
-00012ca0: 2075 2274 6573 7466 696c 6573 2f72 6573   u"testfiles/res
-00012cb0: 746f 7265 5f6f 7574 220a 2020 2020 2020  tore_out".      
-00012cc0: 2020 7265 7374 6f72 6564 203d 2073 656c    restored = sel
-00012cd0: 662e 6469 7265 6374 6f72 795f 7472 6565  f.directory_tree
-00012ce0: 5f74 6f5f 6c69 7374 5f6f 665f 6c69 7374  _to_list_of_list
-00012cf0: 7328 7265 7374 6f72 655f 6469 7229 0a20  s(restore_dir). 
-00012d00: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
-00012d10: 7274 4571 7561 6c28 7265 7374 6f72 6564  rtEqual(restored
-00012d20: 2c20 5b5b 7522 3222 5d2c 205b 7522 3122  , [[u"2"], [u"1"
-00012d30: 5d5d 290a 0a20 2020 2064 6566 2074 6573  ]])..    def tes
-00012d40: 745f 6578 636c 7564 655f 6669 6c65 6c69  t_exclude_fileli
-00012d50: 7374 5f61 7374 6572 6973 6b73 5f6e 6f6e  st_asterisks_non
-00012d60: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
-00012d70: 2075 2222 2242 6173 6963 2065 7863 6c75   u"""Basic exclu
-00012d80: 6465 2066 696c 656c 6973 742e 2222 220a  de filelist.""".
-00012d90: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
-00012da0: 6f70 656e 2875 2274 6573 7466 696c 6573  open(u"testfiles
-00012db0: 2f66 696c 656c 6973 742e 7478 7422 2c20  /filelist.txt", 
-00012dc0: 7522 7722 2920 6173 2066 3a0a 2020 2020  u"w") as f:.    
-00012dd0: 2020 2020 2020 2020 662e 7772 6974 6528          f.write(
-00012de0: 7522 2b20 7465 7374 6669 6c65 732f 7365  u"+ testfiles/se
-00012df0: 6c65 6374 2f31 2f32 2f31 5c6e 220a 2020  lect/1/2/1\n".  
+00012360: 2020 2020 2020 2020 2020 2020 205b 2231               ["1
+00012370: 7375 6231 7375 6231 222c 2022 3173 7562  sub1sub1", "1sub
+00012380: 3173 7562 3222 2c20 2231 7375 6231 7375  1sub2", "1sub1su
+00012390: 6233 225d 5d29 0a0a 0a63 6c61 7373 2054  b3"]])...class T
+000123a0: 6573 7447 6c6f 6262 696e 6752 6570 6c61  estGlobbingRepla
+000123b0: 6365 6d65 6e74 2849 6e63 6c75 6465 4578  cement(IncludeEx
+000123c0: 636c 7564 6546 756e 6374 696f 6e61 6c54  cludeFunctionalT
+000123d0: 6573 7429 3a0a 2020 2020 2222 2220 5468  est):.    """ Th
+000123e0: 6973 2074 6573 7473 2074 6865 2062 6568  is tests the beh
+000123f0: 6176 696f 7572 206f 6620 7468 6520 6578  aviour of the ex
+00012400: 7465 6e64 6564 2073 6865 6c6c 2067 6c6f  tended shell glo
+00012410: 6262 696e 6720 7061 7474 6572 6e20 7265  bbing pattern re
+00012420: 706c 6163 656d 656e 7420 6675 6e63 7469  placement functi
+00012430: 6f6e 732e 2222 220a 0a20 2020 2023 2053  ons."""..    # S
+00012440: 6565 2074 6865 206d 616e 7561 6c20 666f  ee the manual fo
+00012450: 7220 6120 6465 7363 7269 7074 696f 6e20  r a description 
+00012460: 6f66 2062 6568 6176 696f 7572 732c 2062  of behaviours, b
+00012470: 7574 2069 6e20 7375 6d6d 6172 793a 0a20  ut in summary:. 
+00012480: 2020 2023 202a 2063 616e 2062 6520 6578     # * can be ex
+00012490: 7061 6e64 6564 2074 6f20 616e 7920 7374  panded to any st
+000124a0: 7269 6e67 206f 6620 6368 6172 6163 7465  ring of characte
+000124b0: 7273 206e 6f74 2063 6f6e 7461 696e 696e  rs not containin
+000124c0: 6720 222f 220a 2020 2020 2320 3f20 6578  g "/".    # ? ex
+000124d0: 7061 6e64 7320 746f 2061 6e79 2063 6861  pands to any cha
+000124e0: 7261 6374 6572 2065 7863 6570 7420 222f  racter except "/
+000124f0: 2220 616e 640a 2020 2020 2320 5b2e 2e2e  " and.    # [...
+00012500: 5d20 6578 7061 6e64 7320 746f 2061 2073  ] expands to a s
+00012510: 696e 676c 6520 6368 6172 6163 7465 7220  ingle character 
+00012520: 6f66 2074 686f 7365 2063 6861 7261 6374  of those charact
+00012530: 6572 7320 7370 6563 6966 6965 6420 2872  ers specified (r
+00012540: 616e 6765 7320 6172 6520 6163 6365 7074  anges are accept
+00012550: 6162 6c65 292e 0a20 2020 2023 2054 6865  able)..    # The
+00012560: 206e 6577 2073 7065 6369 616c 2070 6174   new special pat
+00012570: 7465 726e 2c20 2a2a 2c20 6578 7061 6e64  tern, **, expand
+00012580: 7320 746f 2061 6e79 2073 7472 696e 6720  s to any string 
+00012590: 6f66 2063 6861 7261 6374 6572 7320 7768  of characters wh
+000125a0: 6574 6865 7220 6f72 206e 6f74 2069 7420  ether or not it 
+000125b0: 636f 6e74 6169 6e73 2022 2f22 2e0a 2020  contains "/"..  
+000125c0: 2020 2320 4675 7274 6865 726d 6f72 652c    # Furthermore,
+000125d0: 2069 6620 7468 6520 7061 7474 6572 6e20   if the pattern 
+000125e0: 7374 6172 7473 2077 6974 6820 2269 676e  starts with "ign
+000125f0: 6f72 6563 6173 653a 2220 2863 6173 6520  orecase:" (case 
+00012600: 696e 7365 6e73 6974 6976 6529 2c20 7468  insensitive), th
+00012610: 656e 2074 6869 7320 7072 6566 6978 2077  en this prefix w
+00012620: 696c 6c20 6265 0a20 2020 2023 2072 656d  ill be.    # rem
+00012630: 6f76 6564 2061 6e64 2061 6e79 2063 6861  oved and any cha
+00012640: 7261 6374 6572 2069 6e20 7468 6520 7374  racter in the st
+00012650: 7269 6e67 2063 616e 2062 6520 7265 706c  ring can be repl
+00012660: 6163 6564 2077 6974 6820 616e 2075 7070  aced with an upp
+00012670: 6572 2d20 6f72 206c 6f77 6572 6361 7365  er- or lowercase
+00012680: 2076 6572 7369 6f6e 206f 6620 6974 7365   version of itse
+00012690: 6c66 2e0a 0a20 2020 2064 6566 2074 6573  lf...    def tes
+000126a0: 745f 676c 6f62 6269 6e67 5f72 6570 6c61  t_globbing_repla
+000126b0: 6365 6d65 6e74 5f69 6e5f 696e 636c 7564  cement_in_includ
+000126c0: 6573 2873 656c 6629 3a0a 2020 2020 2020  es(self):.      
+000126d0: 2020 2222 2220 5465 7374 2062 6568 6176    """ Test behav
+000126e0: 696f 7572 206f 6620 7468 6520 6578 7465  iour of the exte
+000126f0: 6e64 6564 2073 6865 6c6c 2067 6c6f 6262  nded shell globb
+00012700: 696e 6720 7061 7474 6572 6e20 7265 706c  ing pattern repl
+00012710: 6163 656d 656e 7420 6675 6e63 7469 6f6e  acement function
+00012720: 7320 696e 2062 6f74 6820 696e 636c 7564  s in both includ
+00012730: 6520 616e 6420 6578 636c 7564 6522 2222  e and exclude"""
+00012740: 0a20 2020 2020 2020 2023 2049 6465 6e74  .        # Ident
+00012750: 6963 616c 2074 6f20 7465 7374 5f69 6e63  ical to test_inc
+00012760: 6c75 6465 5f65 7863 6c75 6465 5f62 6173  lude_exclude_bas
+00012770: 6963 2077 6974 6820 676c 6f62 6269 6e67  ic with globbing
+00012780: 2063 6861 7261 6374 6572 7320 6164 6465   characters adde
+00012790: 6420 746f 2062 6f74 6820 696e 636c 7564  d to both includ
+000127a0: 6520 616e 6420 6578 636c 7564 6520 6c69  e and exclude li
+000127b0: 6e65 730a 2020 2020 2020 2020 2320 4578  nes.        # Ex
+000127c0: 6869 6269 7473 2074 6865 2069 7373 7565  hibits the issue
+000127d0: 2072 6570 6f72 7465 6420 696e 2042 7567   reported in Bug
+000127e0: 2023 3838 3433 3731 2028 6874 7470 733a   #884371 (https:
+000127f0: 2f2f 6275 6773 2e6c 6175 6e63 6870 6164  //bugs.launchpad
+00012800: 2e6e 6574 2f64 7570 6c69 6369 7479 2f2b  .net/duplicity/+
+00012810: 6275 672f 3838 3433 3731 292e 0a20 2020  bug/884371)..   
+00012820: 2020 2020 2023 2053 6565 2061 626f 7665       # See above
+00012830: 2061 6e64 2074 6865 2075 6e69 7420 7465   and the unit te
+00012840: 7374 7320 666f 7220 6d6f 7265 2067 7261  sts for more gra
+00012850: 6e75 6c61 7269 7479 206f 6e20 7468 6520  nularity on the 
+00012860: 6973 7375 652e 0a20 2020 2020 2020 2073  issue..        s
+00012870: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+00012880: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00012890: 6c65 6374 3222 2c0a 2020 2020 2020 2020  lect2",.        
+000128a0: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
+000128b0: 6f6e 733d 5b22 2d2d 696e 636c 7564 6522  ons=["--include"
+000128c0: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+000128d0: 6563 7432 2f2a 2a2f 3373 7562 3373 7562  ect2/**/3sub3sub
+000128e0: 322f 3373 7562 3373 753f 325f 6669 6c65  2/3sub3su?2_file
+000128f0: 2e74 7874 222c 2020 2320 4e6f 7465 202a  .txt",  # Note *
+00012900: 2a20 616e 6420 3f20 6164 6465 640a 2020  * and ? added.  
+00012910: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012920: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00012930: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00012940: 6573 2f73 656c 6563 7432 2f2a 2f33 732a  es/select2/*/3s*
+00012950: 3122 2c20 2023 204e 6f74 6520 2a20 6164  1",  # Note * ad
+00012960: 6465 6420 696e 2062 6f74 6820 6469 7265  ded in both dire
+00012970: 6374 6f72 7920 616e 6420 6669 6c65 6e61  ctory and filena
+00012980: 6d65 0a20 2020 2020 2020 2020 2020 2020  me.             
+00012990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000129a0: 222d 2d65 7863 6c75 6465 222c 2022 7465  "--exclude", "te
+000129b0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+000129c0: 2a2a 2f32 7375 6231 7375 6233 222c 2020  **/2sub1sub3",  
+000129d0: 2320 4e6f 7465 202a 2a20 6164 6465 640a  # Note ** added.
+000129e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000129f0: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00012a00: 6578 636c 7564 6522 2c20 2269 676e 6f72  exclude", "ignor
+00012a10: 6563 6173 653a 7465 7374 6669 6c65 732f  ecase:testfiles/
+00012a20: 7365 6c65 6374 322f 322f 3273 7562 312f  select2/2/2sub1/
+00012a30: 3253 7562 3153 7562 3222 2c20 2023 204e  2Sub1Sub2",  # N
+00012a40: 6f74 6520 6967 6e6f 7265 6361 7365 2061  ote ignorecase a
+00012a50: 6464 6564 0a20 2020 2020 2020 2020 2020  dded.           
+00012a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012a70: 2020 222d 2d69 6e63 6c75 6465 222c 2022    "--include", "
+00012a80: 6967 6e6f 7265 6361 7365 3a74 6573 7466  ignorecase:testf
+00012a90: 696c 6573 2f73 656c 5b77 2c75 2c65 2c71  iles/sel[w,u,e,q
+00012aa0: 5d63 7432 2f32 2f32 533f 6231 222c 2020  ]ct2/2/2S?b1",  
+00012ab0: 2320 4e6f 7465 2069 676e 6f72 6563 6173  # Note ignorecas
+00012ac0: 652c 205b 5d20 616e 640a 2020 2020 2020  e, [] and.      
+00012ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012ae0: 2020 2020 2020 2023 203f 2061 6464 6564         # ? added
+00012af0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012b00: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00012b10: 2d65 7863 6c75 6465 222c 2022 7465 7374  -exclude", "test
+00012b20: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
+00012b30: 3173 7562 332f 3173 5b77 2c75 2c70 2c71  1sub3/1s[w,u,p,q
+00012b40: 5d62 3373 7562 3222 2c20 2023 204e 6f74  ]b3sub2",  # Not
+00012b50: 6520 5b5d 2061 6464 6564 0a20 2020 2020  e [] added.     
+00012b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012b70: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+00012b80: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00012b90: 7365 6c65 6374 322f 312f 3173 7562 5b31  select2/1/1sub[1
+00012ba0: 2d34 5d2f 3173 7562 3373 7562 3122 2c20  -4]/1sub3sub1", 
+00012bb0: 2023 204e 6f74 6520 5b72 616e 6765 5d20   # Note [range] 
+00012bc0: 6164 6465 640a 2020 2020 2020 2020 2020  added.          
+00012bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012be0: 2020 2022 2d2d 696e 636c 7564 6522 2c20     "--include", 
+00012bf0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00012c00: 7432 2f2a 2f31 7375 6232 2f31 735b 772c  t2/*/1sub2/1s[w,
+00012c10: 752c 702c 715d 6232 7375 6231 222c 2020  u,p,q]b2sub1",  
+00012c20: 2320 4e6f 7465 202a 2061 6e64 205b 5d20  # Note * and [] 
+00012c30: 6164 6465 640a 2020 2020 2020 2020 2020  added.          
+00012c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012c50: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00012c60: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00012c70: 7432 2f31 2f31 7375 6231 2f31 7375 6231  t2/1/1sub1/1sub1
+00012c80: 7375 6233 2f31 7375 3f31 7375 6233 5f66  sub3/1su?1sub3_f
+00012c90: 696c 652e 7478 7422 2c20 2023 204e 6f74  ile.txt",  # Not
+00012ca0: 6520 3f20 6164 6465 640a 2020 2020 2020  e ? added.      
+00012cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012cc0: 2020 2020 2020 2022 2d2d 6578 636c 7564         "--exclud
+00012cd0: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00012ce0: 656c 6563 7432 2f31 2f31 2a31 2f31 7375  elect2/1/1*1/1su
+00012cf0: 6231 7375 6232 222c 2020 2320 4e6f 7465  b1sub2",  # Note
+00012d00: 202a 2061 6464 6564 0a20 2020 2020 2020   * added.       
+00012d10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012d20: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+00012d30: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00012d40: 6c65 6374 322f 312f 3173 7562 3222 2c0a  lect2/1/1sub2",.
+00012d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012d60: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00012d70: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+00012d80: 696c 6573 2f73 656c 6563 745b 322d 345d  iles/select[2-4]
+00012d90: 2f2a 2e70 7922 2c20 2023 204e 6f74 6520  /*.py",  # Note 
+00012da0: 2a20 616e 6420 5b72 616e 6765 5d20 6164  * and [range] ad
+00012db0: 6465 640a 2020 2020 2020 2020 2020 2020  ded.            
+00012dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012dd0: 2022 2d2d 696e 636c 7564 6522 2c20 2274   "--include", "t
+00012de0: 6573 7466 696c 6573 2f2a 322f 3322 2c20  estfiles/*2/3", 
+00012df0: 2023 204e 6f74 6520 2a20 6164 6465 640a   # Note * added.
 00012e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012e10: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-00012e20: 7365 6c65 6374 2f31 2f32 5c6e 220a 2020  select/1/2\n".  
-00012e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012e40: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-00012e50: 7365 6c65 6374 2f31 2f31 5c6e 220a 2020  select/1/1\n".  
-00012e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012e70: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-00012e80: 7365 6c65 6374 2f31 2f33 2229 0a20 2020  select/1/3").   
-00012e90: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
-00012ea0: 2875 2266 756c 6c22 2c20 7522 7465 7374  (u"full", u"test
-00012eb0: 6669 6c65 732f 7365 6c65 6374 2f31 222c  files/select/1",
-00012ec0: 206f 7074 696f 6e73 3d5b 7522 2d2d 6578   options=[u"--ex
-00012ed0: 636c 7564 652d 6669 6c65 6c69 7374 3d74  clude-filelist=t
-00012ee0: 6573 7466 696c 6573 2f66 696c 656c 6973  estfiles/filelis
-00012ef0: 742e 7478 7422 5d29 0a20 2020 2020 2020  t.txt"]).       
-00012f00: 2073 656c 662e 7265 7374 6f72 655f 616e   self.restore_an
-00012f10: 645f 6368 6563 6b28 290a 0a20 2020 2064  d_check()..    d
-00012f20: 6566 2074 6573 745f 6578 636c 7564 655f  ef test_exclude_
-00012f30: 6669 6c65 6c69 7374 5f61 7374 6572 6973  filelist_asteris
-00012f40: 6b73 5f73 696e 676c 6528 7365 6c66 293a  ks_single(self):
-00012f50: 0a20 2020 2020 2020 2075 2222 2245 7863  .        u"""Exc
-00012f60: 6c75 6465 2066 696c 656c 6973 7420 7769  lude filelist wi
-00012f70: 7468 2061 7374 6572 6973 6b73 2072 6570  th asterisks rep
-00012f80: 6c61 6369 6e67 2066 6f6c 6465 7273 2e22  lacing folders."
-00012f90: 2222 0a20 2020 2020 2020 2023 2052 6567  "".        # Reg
-00012fa0: 7265 7373 696f 6e20 7465 7374 2066 6f72  ression test for
-00012fb0: 2042 7567 2023 3838 3433 3731 2028 6874   Bug #884371 (ht
-00012fc0: 7470 733a 2f2f 6275 6773 2e6c 6175 6e63  tps://bugs.launc
-00012fd0: 6870 6164 2e6e 6574 2f64 7570 6c69 6369  hpad.net/duplici
-00012fe0: 7479 2f2b 6275 672f 3838 3433 3731 290a  ty/+bug/884371).
-00012ff0: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
-00013000: 6f70 656e 2875 2274 6573 7466 696c 6573  open(u"testfiles
-00013010: 2f66 696c 656c 6973 742e 7478 7422 2c20  /filelist.txt", 
-00013020: 7522 7722 2920 6173 2066 3a0a 2020 2020  u"w") as f:.    
-00013030: 2020 2020 2020 2020 662e 7772 6974 6528          f.write(
-00013040: 7522 2b20 2a2f 7365 6c65 6374 2f31 2f32  u"+ */select/1/2
-00013050: 2f31 5c6e 220a 2020 2020 2020 2020 2020  /1\n".          
-00013060: 2020 2020 2020 2020 2020 7522 2d20 2a2f            u"- */
-00013070: 7365 6c65 6374 2f31 2f32 5c6e 220a 2020  select/1/2\n".  
-00013080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013090: 2020 7522 2d20 7465 7374 6669 6c65 732f    u"- testfiles/
-000130a0: 2a2f 312f 315c 6e22 0a20 2020 2020 2020  */1/1\n".       
-000130b0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-000130c0: 202a 2f2a 2f31 2f33 2229 0a20 2020 2020   */*/1/3").     
-000130d0: 2020 2073 656c 662e 6261 636b 7570 2875     self.backup(u
-000130e0: 2266 756c 6c22 2c20 7522 7465 7374 6669  "full", u"testfi
-000130f0: 6c65 732f 7365 6c65 6374 2f31 222c 206f  les/select/1", o
-00013100: 7074 696f 6e73 3d5b 7522 2d2d 6578 636c  ptions=[u"--excl
-00013110: 7564 652d 6669 6c65 6c69 7374 3d74 6573  ude-filelist=tes
-00013120: 7466 696c 6573 2f66 696c 656c 6973 742e  tfiles/filelist.
-00013130: 7478 7422 5d29 0a20 2020 2020 2020 2073  txt"]).        s
-00013140: 656c 662e 7265 7374 6f72 655f 616e 645f  elf.restore_and_
-00013150: 6368 6563 6b28 290a 0a20 2020 2064 6566  check()..    def
-00013160: 2074 6573 745f 6578 636c 7564 655f 6669   test_exclude_fi
-00013170: 6c65 6c69 7374 5f61 7374 6572 6973 6b73  lelist_asterisks
-00013180: 5f64 6f75 626c 655f 6173 7465 7269 736b  _double_asterisk
-00013190: 7328 7365 6c66 293a 0a20 2020 2020 2020  s(self):.       
-000131a0: 2075 2222 2245 7863 6c75 6465 2066 696c   u"""Exclude fil
-000131b0: 656c 6973 7420 7769 7468 2064 6f75 626c  elist with doubl
-000131c0: 6520 6173 7465 7269 736b 7320 7265 706c  e asterisks repl
-000131d0: 6163 696e 6720 666f 6c64 6572 732e 2222  acing folders.""
-000131e0: 220a 2020 2020 2020 2020 2320 5265 6772  ".        # Regr
-000131f0: 6573 7369 6f6e 2074 6573 7420 666f 7220  ession test for 
-00013200: 4275 6720 2338 3834 3337 3120 2868 7474  Bug #884371 (htt
-00013210: 7073 3a2f 2f62 7567 732e 6c61 756e 6368  ps://bugs.launch
-00013220: 7061 642e 6e65 742f 6475 706c 6963 6974  pad.net/duplicit
-00013230: 792f 2b62 7567 2f38 3834 3337 3129 0a20  y/+bug/884371). 
-00013240: 2020 2020 2020 2077 6974 6820 696f 2e6f         with io.o
-00013250: 7065 6e28 7522 7465 7374 6669 6c65 732f  pen(u"testfiles/
-00013260: 6669 6c65 6c69 7374 2e74 7874 222c 2075  filelist.txt", u
-00013270: 2277 2229 2061 7320 663a 0a20 2020 2020  "w") as f:.     
-00013280: 2020 2020 2020 2066 2e77 7269 7465 2875         f.write(u
-00013290: 222b 202a 2a2f 312f 322f 315c 6e22 0a20  "+ **/1/2/1\n". 
-000132a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000132b0: 2020 2075 222d 202a 2a2f 312f 325c 6e22     u"- **/1/2\n"
-000132c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000132d0: 2020 2020 2075 222d 202a 2a2f 7365 6c65       u"- **/sele
-000132e0: 6374 2f31 2f31 5c6e 220a 2020 2020 2020  ct/1/1\n".      
-000132f0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00013300: 2d20 7465 7374 6669 6c65 732f 7365 6c65  - testfiles/sele
-00013310: 6374 2f31 2f33 2229 0a20 2020 2020 2020  ct/1/3").       
-00013320: 2073 656c 662e 6261 636b 7570 2875 2266   self.backup(u"f
-00013330: 756c 6c22 2c20 7522 7465 7374 6669 6c65  ull", u"testfile
-00013340: 732f 7365 6c65 6374 2f31 222c 206f 7074  s/select/1", opt
-00013350: 696f 6e73 3d5b 7522 2d2d 6578 636c 7564  ions=[u"--exclud
-00013360: 652d 6669 6c65 6c69 7374 3d74 6573 7466  e-filelist=testf
-00013370: 696c 6573 2f66 696c 656c 6973 742e 7478  iles/filelist.tx
-00013380: 7422 5d29 0a20 2020 2020 2020 2073 656c  t"]).        sel
-00013390: 662e 7265 7374 6f72 655f 616e 645f 6368  f.restore_and_ch
-000133a0: 6563 6b28 290a 0a20 2020 2064 6566 2074  eck()..    def t
-000133b0: 6573 745f 636f 6d6d 616e 646c 696e 655f  est_commandline_
-000133c0: 6173 7465 7269 736b 735f 7369 6e67 6c65  asterisks_single
-000133d0: 5f65 7863 6c75 6465 735f 6f6e 6c79 2873  _excludes_only(s
-000133e0: 656c 6629 3a0a 2020 2020 2020 2020 7522  elf):.        u"
-000133f0: 2222 7465 7374 5f63 6f6d 6d61 6e64 6c69  ""test_commandli
-00013400: 6e65 5f69 6e63 6c75 6465 5f65 7863 6c75  ne_include_exclu
-00013410: 6465 2077 6974 6820 7369 6e67 6c65 2061  de with single a
-00013420: 7374 6572 6973 6b73 206f 6e20 6578 636c  sterisks on excl
-00013430: 7564 6520 6c69 6e65 732e 2222 220a 2020  ude lines.""".  
-00013440: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-00013450: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-00013460: 7466 696c 6573 2f73 656c 6563 742f 3122  tfiles/select/1"
-00013470: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00013480: 2020 2020 2020 6f70 7469 6f6e 733d 5b75        options=[u
-00013490: 222d 2d69 6e63 6c75 6465 222c 2075 2274  "--include", u"t
-000134a0: 6573 7466 696c 6573 2f73 656c 6563 742f  estfiles/select/
-000134b0: 312f 322f 3122 2c0a 2020 2020 2020 2020  1/2/1",.        
-000134c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000134d0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-000134e0: 222c 2075 2274 6573 7466 696c 6573 2f2a  ", u"testfiles/*
-000134f0: 2f31 2f32 222c 0a20 2020 2020 2020 2020  /1/2",.         
+00012e10: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00012e20: 696e 636c 7564 6522 2c20 222a 2a2f 7365  include", "**/se
+00012e30: 6c65 6374 322f 3122 2c20 2023 204e 6f74  lect2/1",  # Not
+00012e40: 6520 2a2a 2061 6464 6564 0a20 2020 2020  e ** added.     
+00012e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012e60: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+00012e70: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00012e80: 7365 6c65 6374 322f 2a2a 225d 290a 2020  select2/**"]).  
+00012e90: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
+00012ea0: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
+00012eb0: 746f 7265 5f70 6174 6820 3d20 2274 6573  tore_path = "tes
+00012ec0: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
+00012ed0: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
+00012ee0: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
+00012ef0: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
+00012f00: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
+00012f10: 6f72 655f 7061 7468 290a 2020 2020 2020  ore_path).      
+00012f20: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
+00012f30: 616c 2872 6573 746f 7265 642c 2073 656c  al(restored, sel
+00012f40: 662e 6578 7065 6374 6564 5f72 6573 746f  f.expected_resto
+00012f50: 7265 645f 7472 6565 290a 0a20 2020 2064  red_tree)..    d
+00012f60: 6566 2074 6573 745f 676c 6f62 6269 6e67  ef test_globbing
+00012f70: 5f72 6570 6c61 6365 6d65 6e74 5f69 6e5f  _replacement_in_
+00012f80: 696e 636c 7564 6573 5f75 7369 6e67 5f66  includes_using_f
+00012f90: 696c 7465 725f 6967 6e6f 7265 6361 7365  ilter_ignorecase
+00012fa0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00012fb0: 2222 2220 5465 7374 2062 6568 6176 696f  """ Test behavio
+00012fc0: 7572 206f 6620 7468 6520 6578 7465 6e64  ur of the extend
+00012fd0: 6564 2073 6865 6c6c 2067 6c6f 6262 696e  ed shell globbin
+00012fe0: 6720 7061 7474 6572 6e20 7265 706c 6163  g pattern replac
+00012ff0: 656d 656e 7420 6675 6e63 7469 6f6e 7320  ement functions 
+00013000: 696e 2062 6f74 6820 696e 636c 7564 6520  in both include 
+00013010: 616e 6420 6578 636c 7564 652e 0a20 2020  and exclude..   
+00013020: 2020 2020 2073 616d 6520 7465 7374 2061       same test a
+00013030: 7320 6162 6f76 652c 2062 7574 2069 6d70  s above, but imp
+00013040: 6c65 6d65 6e74 6564 2075 7369 6e67 202d  lemented using -
+00013050: 2d66 696c 7465 722d 2a63 6173 6520 696e  -filter-*case in
+00013060: 7374 6561 6420 6f66 2074 6865 2069 676e  stead of the ign
+00013070: 6f72 6563 6173 6520 7072 6566 6978 2e0a  orecase prefix..
+00013080: 2020 2020 2020 2020 2222 220a 2020 2020          """.    
+00013090: 2020 2020 2320 4964 656e 7469 6361 6c20      # Identical 
+000130a0: 746f 2074 6573 745f 696e 636c 7564 655f  to test_include_
+000130b0: 6578 636c 7564 655f 6261 7369 6320 7769  exclude_basic wi
+000130c0: 7468 2067 6c6f 6262 696e 6720 6368 6172  th globbing char
+000130d0: 6163 7465 7273 2061 6464 6564 2074 6f20  acters added to 
+000130e0: 626f 7468 2069 6e63 6c75 6465 2061 6e64  both include and
+000130f0: 2065 7863 6c75 6465 206c 696e 6573 0a20   exclude lines. 
+00013100: 2020 2020 2020 2023 2045 7868 6962 6974         # Exhibit
+00013110: 7320 7468 6520 6973 7375 6520 7265 706f  s the issue repo
+00013120: 7274 6564 2069 6e20 4275 6720 2338 3834  rted in Bug #884
+00013130: 3337 3120 2868 7474 7073 3a2f 2f62 7567  371 (https://bug
+00013140: 732e 6c61 756e 6368 7061 642e 6e65 742f  s.launchpad.net/
+00013150: 6475 706c 6963 6974 792f 2b62 7567 2f38  duplicity/+bug/8
+00013160: 3834 3337 3129 2e0a 2020 2020 2020 2020  84371)..        
+00013170: 2320 5365 6520 6162 6f76 6520 616e 6420  # See above and 
+00013180: 7468 6520 756e 6974 2074 6573 7473 2066  the unit tests f
+00013190: 6f72 206d 6f72 6520 6772 616e 756c 6172  or more granular
+000131a0: 6974 7920 6f6e 2074 6865 2069 7373 7565  ity on the issue
+000131b0: 2e0a 2020 2020 2020 2020 7365 6c66 2e62  ..        self.b
+000131c0: 6163 6b75 7028 2266 756c 6c22 2c20 2274  ackup("full", "t
+000131d0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+000131e0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
+000131f0: 2020 2020 2020 206f 7074 696f 6e73 3d5b         options=[
+00013200: 222d 2d69 6e63 6c75 6465 222c 2022 7465  "--include", "te
+00013210: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+00013220: 2a2a 2f33 7375 6233 7375 6232 2f33 7375  **/3sub3sub2/3su
+00013230: 6233 7375 3f32 5f66 696c 652e 7478 7422  b3su?2_file.txt"
+00013240: 2c20 2023 204e 6f74 6520 2a2a 2061 6e64  ,  # Note ** and
+00013250: 203f 2061 6464 6564 0a20 2020 2020 2020   ? added.       
+00013260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013270: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+00013280: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00013290: 6c65 6374 322f 2a2f 3373 2a31 222c 2020  lect2/*/3s*1",  
+000132a0: 2320 4e6f 7465 202a 2061 6464 6564 2069  # Note * added i
+000132b0: 6e20 626f 7468 2064 6972 6563 746f 7279  n both directory
+000132c0: 2061 6e64 2066 696c 656e 616d 650a 2020   and filename.  
+000132d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000132e0: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+000132f0: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00013300: 6573 2f73 656c 6563 7432 2f2a 2a2f 3273  es/select2/**/2s
+00013310: 7562 3173 7562 3322 2c20 2023 204e 6f74  ub1sub3",  # Not
+00013320: 6520 2a2a 2061 6464 6564 0a20 2020 2020  e ** added.     
+00013330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013340: 2020 2020 2020 2020 222d 2d66 696c 7465          "--filte
+00013350: 722d 6967 6e6f 7265 6361 7365 222c 0a20  r-ignorecase",. 
+00013360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013370: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00013380: 7863 6c75 6465 222c 2022 7465 7374 6669  xclude", "testfi
+00013390: 6c65 732f 7365 6c65 6374 322f 322f 3273  les/select2/2/2s
+000133a0: 7562 312f 3253 7562 3153 7562 3222 2c20  ub1/2Sub1Sub2", 
+000133b0: 2023 204e 6f74 6520 6967 6e6f 7265 6361   # Note ignoreca
+000133c0: 7365 2061 6464 6564 0a20 2020 2020 2020  se added.       
+000133d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000133e0: 2020 2020 2020 222d 2d69 6e63 6c75 6465        "--include
+000133f0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00013400: 6c5b 772c 752c 652c 715d 6374 322f 322f  l[w,u,e,q]ct2/2/
+00013410: 3253 3f62 3122 2c20 2023 204e 6f74 6520  2S?b1",  # Note 
+00013420: 6967 6e6f 7265 6361 7365 2c20 5b5d 2061  ignorecase, [] a
+00013430: 6e64 0a20 2020 2020 2020 2020 2020 2020  nd.             
+00013440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013450: 222d 2d66 696c 7465 722d 7374 7269 6374  "--filter-strict
+00013460: 6361 7365 222c 0a20 2020 2020 2020 2020  case",.         
+00013470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013480: 2020 2020 2320 3f20 6164 6465 640a 2020      # ? added.  
+00013490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000134a0: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+000134b0: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+000134c0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+000134d0: 6233 2f31 735b 772c 752c 702c 715d 6233  b3/1s[w,u,p,q]b3
+000134e0: 7375 6232 222c 2020 2320 4e6f 7465 205b  sub2",  # Note [
+000134f0: 5d20 6164 6465 640a 2020 2020 2020 2020  ] added.        
 00013500: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013510: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-00013520: 2c20 7522 2a2f 7365 6c65 6374 2f31 2f31  , u"*/select/1/1
-00013530: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00013540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013550: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00013560: 2a2f 7365 6c65 6374 2f31 2f33 225d 290a  */select/1/3"]).
-00013570: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-00013580: 746f 7265 5f61 6e64 5f63 6865 636b 2829  tore_and_check()
-00013590: 0a0a 2020 2020 6465 6620 7465 7374 5f63  ..    def test_c
-000135a0: 6f6d 6d61 6e64 6c69 6e65 5f61 7374 6572  ommandline_aster
-000135b0: 6973 6b73 5f73 696e 676c 655f 626f 7468  isks_single_both
-000135c0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-000135d0: 7522 2222 7465 7374 5f63 6f6d 6d61 6e64  u"""test_command
-000135e0: 6c69 6e65 5f69 6e63 6c75 6465 5f65 7863  line_include_exc
-000135f0: 6c75 6465 2077 6974 6820 7369 6e67 6c65  lude with single
-00013600: 2061 7374 6572 6973 6b73 206f 6e20 626f   asterisks on bo
-00013610: 7468 2065 7863 6c75 6465 2061 6e64 2069  th exclude and i
-00013620: 6e63 6c75 6465 206c 696e 6573 2e22 2222  nclude lines."""
-00013630: 0a20 2020 2020 2020 2023 2052 6567 7265  .        # Regre
-00013640: 7373 696f 6e20 7465 7374 2066 6f72 2042  ssion test for B
-00013650: 7567 2023 3838 3433 3731 2028 6874 7470  ug #884371 (http
-00013660: 733a 2f2f 6275 6773 2e6c 6175 6e63 6870  s://bugs.launchp
-00013670: 6164 2e6e 6574 2f64 7570 6c69 6369 7479  ad.net/duplicity
-00013680: 2f2b 6275 672f 3838 3433 3731 290a 2020  /+bug/884371).  
-00013690: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-000136a0: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-000136b0: 7466 696c 6573 2f73 656c 6563 742f 3122  tfiles/select/1"
-000136c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000136d0: 2020 2020 2020 6f70 7469 6f6e 733d 5b75        options=[u
-000136e0: 222d 2d69 6e63 6c75 6465 222c 2075 222a  "--include", u"*
-000136f0: 2f73 656c 6563 742f 312f 322f 3122 2c0a  /select/1/2/1",.
-00013700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013710: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00013720: 2d65 7863 6c75 6465 222c 2075 2274 6573  -exclude", u"tes
-00013730: 7466 696c 6573 2f2a 2f31 2f32 222c 0a20  tfiles/*/1/2",. 
-00013740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013750: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00013760: 6578 636c 7564 6522 2c20 7522 2a2f 7365  exclude", u"*/se
-00013770: 6c65 6374 2f31 2f31 222c 0a20 2020 2020  lect/1/1",.     
-00013780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013790: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-000137a0: 7564 6522 2c20 7522 2a2f 7365 6c65 6374  ude", u"*/select
-000137b0: 2f31 2f33 225d 290a 2020 2020 2020 2020  /1/3"]).        
-000137c0: 7365 6c66 2e72 6573 746f 7265 5f61 6e64  self.restore_and
-000137d0: 5f63 6865 636b 2829 0a0a 2020 2020 6465  _check()..    de
-000137e0: 6620 7465 7374 5f63 6f6d 6d61 6e64 6c69  f test_commandli
-000137f0: 6e65 5f61 7374 6572 6973 6b73 5f64 6f75  ne_asterisks_dou
-00013800: 626c 655f 6578 636c 7564 655f 6f6e 6c79  ble_exclude_only
-00013810: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00013820: 7522 2222 7465 7374 5f63 6f6d 6d61 6e64  u"""test_command
-00013830: 6c69 6e65 5f69 6e63 6c75 6465 5f65 7863  line_include_exc
-00013840: 6c75 6465 2077 6974 6820 646f 7562 6c65  lude with double
-00013850: 2061 7374 6572 6973 6b73 206f 6e20 6578   asterisks on ex
-00013860: 636c 7564 6520 6c69 6e65 732e 2222 220a  clude lines.""".
-00013870: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
-00013880: 6b75 7028 7522 6675 6c6c 222c 2075 2274  kup(u"full", u"t
-00013890: 6573 7466 696c 6573 2f73 656c 6563 742f  estfiles/select/
-000138a0: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
-000138b0: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-000138c0: 5b75 222d 2d69 6e63 6c75 6465 222c 2075  [u"--include", u
-000138d0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-000138e0: 742f 312f 322f 3122 2c0a 2020 2020 2020  t/1/2/1",.      
-000138f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013900: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-00013910: 6465 222c 2075 222a 2a2f 312f 3222 2c0a  de", u"**/1/2",.
-00013920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013930: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00013940: 2d65 7863 6c75 6465 222c 2075 222a 2a2f  -exclude", u"**/
-00013950: 312f 3122 2c0a 2020 2020 2020 2020 2020  1/1",.          
-00013960: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013970: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-00013980: 2075 222a 2a2f 312f 3322 5d29 0a20 2020   u"**/1/3"]).   
-00013990: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
-000139a0: 655f 616e 645f 6368 6563 6b28 290a 0a20  e_and_check().. 
-000139b0: 2020 2064 6566 2074 6573 745f 636f 6d6d     def test_comm
-000139c0: 616e 646c 696e 655f 6173 7465 7269 736b  andline_asterisk
-000139d0: 735f 646f 7562 6c65 5f62 6f74 6828 7365  s_double_both(se
-000139e0: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-000139f0: 2274 6573 745f 636f 6d6d 616e 646c 696e  "test_commandlin
-00013a00: 655f 696e 636c 7564 655f 6578 636c 7564  e_include_exclud
-00013a10: 6520 7769 7468 2064 6f75 626c 6520 6173  e with double as
-00013a20: 7465 7269 736b 7320 6f6e 2062 6f74 6820  terisks on both 
-00013a30: 6578 636c 7564 6520 616e 6420 696e 636c  exclude and incl
-00013a40: 7564 6520 6c69 6e65 732e 2222 220a 2020  ude lines.""".  
-00013a50: 2020 2020 2020 2320 5265 6772 6573 7369        # Regressi
-00013a60: 6f6e 2074 6573 7420 666f 7220 4275 6720  on test for Bug 
-00013a70: 2338 3834 3337 3120 2868 7474 7073 3a2f  #884371 (https:/
-00013a80: 2f62 7567 732e 6c61 756e 6368 7061 642e  /bugs.launchpad.
-00013a90: 6e65 742f 6475 706c 6963 6974 792f 2b62  net/duplicity/+b
-00013aa0: 7567 2f38 3834 3337 3129 0a20 2020 2020  ug/884371).     
-00013ab0: 2020 2073 656c 662e 6261 636b 7570 2875     self.backup(u
-00013ac0: 2266 756c 6c22 2c20 7522 7465 7374 6669  "full", u"testfi
-00013ad0: 6c65 732f 7365 6c65 6374 2f31 222c 0a20  les/select/1",. 
-00013ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013af0: 2020 206f 7074 696f 6e73 3d5b 7522 2d2d     options=[u"--
-00013b00: 696e 636c 7564 6522 2c20 7522 2a2a 2f31  include", u"**/1
-00013b10: 2f32 2f31 222c 0a20 2020 2020 2020 2020  /2/1",.         
+00013510: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+00013520: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00013530: 6563 7432 2f31 2f31 7375 625b 312d 345d  ect2/1/1sub[1-4]
+00013540: 2f31 7375 6233 7375 6231 222c 2020 2320  /1sub3sub1",  # 
+00013550: 4e6f 7465 205b 7261 6e67 655d 2061 6464  Note [range] add
+00013560: 6564 0a20 2020 2020 2020 2020 2020 2020  ed.             
+00013570: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013580: 222d 2d69 6e63 6c75 6465 222c 2022 7465  "--include", "te
+00013590: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+000135a0: 2a2f 3173 7562 322f 3173 5b77 2c75 2c70  */1sub2/1s[w,u,p
+000135b0: 2c71 5d62 3273 7562 3122 2c20 2023 204e  ,q]b2sub1",  # N
+000135c0: 6f74 6520 2a20 616e 6420 5b5d 2061 6464  ote * and [] add
+000135d0: 6564 0a20 2020 2020 2020 2020 2020 2020  ed.             
+000135e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000135f0: 222d 2d65 7863 6c75 6465 222c 2022 7465  "--exclude", "te
+00013600: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+00013610: 312f 3173 7562 312f 3173 7562 3173 7562  1/1sub1/1sub1sub
+00013620: 332f 3173 753f 3173 7562 335f 6669 6c65  3/1su?1sub3_file
+00013630: 2e74 7874 222c 2020 2320 4e6f 7465 203f  .txt",  # Note ?
+00013640: 2061 6464 6564 0a20 2020 2020 2020 2020   added.         
+00013650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013660: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00013670: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00013680: 6374 322f 312f 312a 312f 3173 7562 3173  ct2/1/1*1/1sub1s
+00013690: 7562 3222 2c20 2023 204e 6f74 6520 2a20  ub2",  # Note * 
+000136a0: 6164 6465 640a 2020 2020 2020 2020 2020  added.          
+000136b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000136c0: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+000136d0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+000136e0: 7432 2f31 2f31 7375 6232 222c 0a20 2020  t2/1/1sub2",.   
+000136f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013700: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+00013710: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00013720: 732f 7365 6c65 6374 5b32 2d34 5d2f 2a2e  s/select[2-4]/*.
+00013730: 7079 222c 2020 2320 4e6f 7465 202a 2061  py",  # Note * a
+00013740: 6e64 205b 7261 6e67 655d 2061 6464 6564  nd [range] added
+00013750: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00013760: 2020 2020 2020 2020 2020 2020 2020 222d                "-
+00013770: 2d69 6e63 6c75 6465 222c 2022 7465 7374  -include", "test
+00013780: 6669 6c65 732f 2a32 2f33 222c 2020 2320  files/*2/3",  # 
+00013790: 4e6f 7465 202a 2061 6464 6564 0a20 2020  Note * added.   
+000137a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000137b0: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+000137c0: 6c75 6465 222c 2022 2a2a 2f73 656c 6563  lude", "**/selec
+000137d0: 7432 2f31 222c 2020 2320 4e6f 7465 202a  t2/1",  # Note *
+000137e0: 2a20 6164 6465 640a 2020 2020 2020 2020  * added.        
+000137f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013800: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+00013810: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00013820: 6563 7432 2f2a 2a22 5d29 0a20 2020 2020  ect2/**"]).     
+00013830: 2020 2073 656c 662e 7265 7374 6f72 6528     self.restore(
+00013840: 290a 2020 2020 2020 2020 7265 7374 6f72  ).        restor
+00013850: 655f 7061 7468 203d 2022 7465 7374 6669  e_path = "testfi
+00013860: 6c65 732f 7265 7374 6f72 655f 6f75 7422  les/restore_out"
+00013870: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+00013880: 6420 3d20 7365 6c66 2e64 6972 6563 746f  d = self.directo
+00013890: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
+000138a0: 6f66 5f6c 6973 7473 2872 6573 746f 7265  of_lists(restore
+000138b0: 5f70 6174 6829 0a20 2020 2020 2020 2073  _path).        s
+000138c0: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
+000138d0: 7265 7374 6f72 6564 2c20 7365 6c66 2e65  restored, self.e
+000138e0: 7870 6563 7465 645f 7265 7374 6f72 6564  xpected_restored
+000138f0: 5f74 7265 6529 0a0a 0a63 6c61 7373 2054  _tree)...class T
+00013900: 6573 7445 7863 6c75 6465 4966 5072 6573  estExcludeIfPres
+00013910: 656e 7428 496e 636c 7564 6545 7863 6c75  ent(IncludeExclu
+00013920: 6465 4675 6e63 7469 6f6e 616c 5465 7374  deFunctionalTest
+00013930: 293a 0a20 2020 2022 2222 2054 6869 7320  ):.    """ This 
+00013940: 7465 7374 7320 7468 6520 6265 6861 7669  tests the behavi
+00013950: 6f75 7220 6f66 2064 7570 6c69 6369 7479  our of duplicity
+00013960: 2773 202d 2d65 7863 6c75 6465 2d69 662d  's --exclude-if-
+00013970: 7072 6573 656e 7420 6f70 7469 6f6e 2222  present option""
+00013980: 220a 0a20 2020 2064 6566 2074 6573 745f  "..    def test_
+00013990: 6578 636c 7564 655f 6966 5f70 7265 7365  exclude_if_prese
+000139a0: 6e74 5f62 6173 656c 696e 6528 7365 6c66  nt_baseline(self
+000139b0: 293a 0a20 2020 2020 2020 2022 2222 2054  ):.        """ T
+000139c0: 6573 7420 7468 6174 2064 7570 6c69 6369  est that duplici
+000139d0: 7479 206e 6f72 6d61 6c6c 7920 6261 636b  ty normally back
+000139e0: 7320 7570 2066 696c 6573 2222 220a 2020  s up files""".  
+000139f0: 2020 2020 2020 7769 7468 2069 6f2e 6f70        with io.op
+00013a00: 656e 2822 7465 7374 6669 6c65 732f 7365  en("testfiles/se
+00013a10: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
+00013a20: 7562 3173 7562 312f 2e6e 6f62 6163 6b75  ub1sub1/.nobacku
+00013a30: 7022 2c20 2277 2229 2061 7320 7461 673a  p", "w") as tag:
+00013a40: 0a20 2020 2020 2020 2020 2020 2074 6167  .            tag
+00013a50: 2e77 7269 7465 2822 4669 6c65 7320 696e  .write("Files in
+00013a60: 2074 6869 7320 666f 6c64 6572 2073 686f   this folder sho
+00013a70: 756c 6420 6e6f 7420 6265 2062 6163 6b65  uld not be backe
+00013a80: 6420 7570 2e22 290a 2020 2020 2020 2020  d up.").        
+00013a90: 7365 6c66 2e62 6163 6b75 7028 2266 756c  self.backup("ful
+00013aa0: 6c22 2c20 2274 6573 7466 696c 6573 2f73  l", "testfiles/s
+00013ab0: 656c 6563 7432 2f31 2f31 7375 6231 222c  elect2/1/1sub1",
+00013ac0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00013ad0: 2020 2020 206f 7074 696f 6e73 3d5b 222d       options=["-
+00013ae0: 2d69 6e63 6c75 6465 222c 2022 7465 7374  -include", "test
+00013af0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
+00013b00: 3173 7562 312f 3173 7562 3173 7562 312f  1sub1/1sub1sub1/
+00013b10: 2a22 2c0a 2020 2020 2020 2020 2020 2020  *",.            
 00013b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013b30: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-00013b40: 2c20 7522 2a2a 2f31 2f32 222c 0a20 2020  , u"**/1/2",.   
-00013b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013b60: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-00013b70: 636c 7564 6522 2c20 7522 2a2a 2f31 2f31  clude", u"**/1/1
-00013b80: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00013b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013ba0: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00013bb0: 2a2a 2f31 2f33 225d 290a 2020 2020 2020  **/1/3"]).      
-00013bc0: 2020 7365 6c66 2e72 6573 746f 7265 5f61    self.restore_a
-00013bd0: 6e64 5f63 6865 636b 2829 0a0a 2020 2020  nd_check()..    
-00013be0: 6465 6620 7465 7374 5f73 696e 676c 655f  def test_single_
-00013bf0: 616e 645f 646f 7562 6c65 5f61 7374 6572  and_double_aster
-00013c00: 6973 6b73 2873 656c 6629 3a0a 2020 2020  isks(self):.    
-00013c10: 2020 2020 7522 2222 5468 6973 2063 6f6d      u"""This com
-00013c20: 7061 7265 7320 6120 6261 636b 7570 2075  pares a backup u
-00013c30: 7369 6e67 202d 2d69 6e63 6c75 6465 2d67  sing --include-g
-00013c40: 6c6f 6262 696e 672d 6669 6c65 6c69 7374  lobbing-filelist
-00013c50: 2077 6974 6820 6120 7369 6e67 6c65 2061   with a single a
-00013c60: 6e64 2064 6f75 626c 6520 2a2e 2222 220a  nd double *.""".
-00013c70: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
-00013c80: 6f70 656e 2875 2274 6573 7466 696c 6573  open(u"testfiles
-00013c90: 2f66 696c 656c 6973 742e 7478 7422 2c20  /filelist.txt", 
-00013ca0: 7522 7722 2920 6173 2066 3a0a 2020 2020  u"w") as f:.    
-00013cb0: 2020 2020 2020 2020 662e 7772 6974 6528          f.write(
-00013cc0: 7522 2b20 7465 7374 6669 6c65 732f 7365  u"+ testfiles/se
-00013cd0: 6c65 6374 322f 2a5c 6e22 0a20 2020 2020  lect2/*\n".     
-00013ce0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00013cf0: 222d 2074 6573 7466 696c 6573 2f73 656c  "- testfiles/sel
-00013d00: 6563 7422 290a 2020 2020 2020 2020 7365  ect").        se
-00013d10: 6c66 2e62 6163 6b75 7028 7522 6675 6c6c  lf.backup(u"full
-00013d20: 222c 2075 2274 6573 7466 696c 6573 2f22  ", u"testfiles/"
-00013d30: 2c20 6f70 7469 6f6e 733d 5b75 222d 2d69  , options=[u"--i
-00013d40: 6e63 6c75 6465 2d67 6c6f 6262 696e 672d  nclude-globbing-
-00013d50: 6669 6c65 6c69 7374 3d74 6573 7466 696c  filelist=testfil
-00013d60: 6573 2f66 696c 656c 6973 742e 7478 7422  es/filelist.txt"
-00013d70: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
-00013d80: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
-00013d90: 2020 7265 7374 6f72 655f 6469 7220 3d20    restore_dir = 
-00013da0: 7522 7465 7374 6669 6c65 732f 7265 7374  u"testfiles/rest
-00013db0: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
-00013dc0: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
-00013dd0: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
-00013de0: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-00013df0: 2872 6573 746f 7265 5f64 6972 202b 2075  (restore_dir + u
-00013e00: 222f 7365 6c65 6374 3222 290a 2020 2020  "/select2").    
-00013e10: 2020 2020 7769 7468 2069 6f2e 6f70 656e      with io.open
-00013e20: 2875 2274 6573 7466 696c 6573 2f66 696c  (u"testfiles/fil
-00013e30: 656c 6973 7432 2e74 7874 222c 2075 2277  elist2.txt", u"w
-00013e40: 2229 2061 7320 663a 0a20 2020 2020 2020  ") as f:.       
-00013e50: 2020 2020 2066 2e77 7269 7465 2875 222b       f.write(u"+
-00013e60: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-00013e70: 7432 2f2a 2a5c 6e22 0a20 2020 2020 2020  t2/**\n".       
-00013e80: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00013e90: 2074 6573 7466 696c 6573 2f73 656c 6563   testfiles/selec
-00013ea0: 7422 290a 2020 2020 2020 2020 7365 6c66  t").        self
-00013eb0: 2e62 6163 6b75 7028 7522 6675 6c6c 222c  .backup(u"full",
-00013ec0: 2075 2274 6573 7466 696c 6573 2f22 2c20   u"testfiles/", 
-00013ed0: 6f70 7469 6f6e 733d 5b75 222d 2d69 6e63  options=[u"--inc
-00013ee0: 6c75 6465 2d67 6c6f 6262 696e 672d 6669  lude-globbing-fi
-00013ef0: 6c65 6c69 7374 3d74 6573 7466 696c 6573  lelist=testfiles
-00013f00: 2f66 696c 656c 6973 7432 2e74 7874 225d  /filelist2.txt"]
-00013f10: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
-00013f20: 6573 746f 7265 2829 0a20 2020 2020 2020  estore().       
-00013f30: 2072 6573 746f 7265 5f64 6972 203d 2075   restore_dir = u
-00013f40: 2274 6573 7466 696c 6573 2f72 6573 746f  "testfiles/resto
-00013f50: 7265 5f6f 7574 220a 2020 2020 2020 2020  re_out".        
-00013f60: 7265 7374 6f72 6564 3220 3d20 7365 6c66  restored2 = self
-00013f70: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
-00013f80: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-00013f90: 2872 6573 746f 7265 5f64 6972 202b 2075  (restore_dir + u
-00013fa0: 222f 7365 6c65 6374 3222 290a 2020 2020  "/select2").    
-00013fb0: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
-00013fc0: 7175 616c 2872 6573 746f 7265 642c 2072  qual(restored, r
-00013fd0: 6573 746f 7265 6432 290a 0a20 2020 2064  estored2)..    d
-00013fe0: 6566 2074 6573 745f 7369 6e67 6c65 5f61  ef test_single_a
-00013ff0: 6e64 5f64 6f75 626c 655f 6173 7465 7269  nd_double_asteri
-00014000: 736b 735f 696e 636c 7564 6573 5f65 7863  sks_includes_exc
-00014010: 6c75 6465 7328 7365 6c66 293a 0a20 2020  ludes(self):.   
-00014020: 2020 2020 2075 2222 2254 6869 7320 636f       u"""This co
-00014030: 6d70 6172 6573 2061 2062 6163 6b75 7020  mpares a backup 
-00014040: 7573 696e 6720 2d2d 696e 636c 7564 6573  using --includes
-00014050: 2f2d 2d65 7863 6c75 6465 7320 7769 7468  /--excludes with
-00014060: 2061 2073 696e 676c 6520 616e 6420 646f   a single and do
-00014070: 7562 6c65 202a 2e22 2222 0a20 2020 2020  uble *.""".     
-00014080: 2020 2073 656c 662e 6261 636b 7570 2875     self.backup(u
-00014090: 2266 756c 6c22 2c20 7522 7465 7374 6669  "full", u"testfi
-000140a0: 6c65 732f 222c 0a20 2020 2020 2020 2020  les/",.         
-000140b0: 2020 2020 2020 2020 2020 206f 7074 696f             optio
-000140c0: 6e73 3d5b 7522 2d2d 696e 636c 7564 6522  ns=[u"--include"
-000140d0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-000140e0: 6c65 6374 322f 2a22 2c0a 2020 2020 2020  lect2/*",.      
-000140f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014100: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-00014110: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00014120: 2f73 656c 6563 7422 5d29 0a20 2020 2020  /select"]).     
-00014130: 2020 2073 656c 662e 7265 7374 6f72 6528     self.restore(
-00014140: 290a 2020 2020 2020 2020 7265 7374 6f72  ).        restor
-00014150: 655f 6469 7220 3d20 7522 7465 7374 6669  e_dir = u"testfi
-00014160: 6c65 732f 7265 7374 6f72 655f 6f75 7422  les/restore_out"
-00014170: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
-00014180: 6420 3d20 7365 6c66 2e64 6972 6563 746f  d = self.directo
-00014190: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
-000141a0: 6f66 5f6c 6973 7473 2872 6573 746f 7265  of_lists(restore
-000141b0: 5f64 6972 202b 2075 222f 7365 6c65 6374  _dir + u"/select
-000141c0: 3222 290a 2020 2020 2020 2020 7365 6c66  2").        self
-000141d0: 2e62 6163 6b75 7028 7522 6675 6c6c 222c  .backup(u"full",
-000141e0: 2075 2274 6573 7466 696c 6573 2f22 2c0a   u"testfiles/",.
-000141f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014200: 2020 2020 6f70 7469 6f6e 733d 5b75 222d      options=[u"-
-00014210: 2d69 6e63 6c75 6465 222c 2075 2274 6573  -include", u"tes
-00014220: 7466 696c 6573 2f73 656c 6563 7432 2f2a  tfiles/select2/*
-00014230: 2a22 2c0a 2020 2020 2020 2020 2020 2020  *",.            
-00014240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014250: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00014260: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00014270: 7422 5d29 0a20 2020 2020 2020 2073 656c  t"]).        sel
-00014280: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
-00014290: 2020 2020 7265 7374 6f72 655f 6469 7220      restore_dir 
-000142a0: 3d20 7522 7465 7374 6669 6c65 732f 7265  = u"testfiles/re
-000142b0: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
-000142c0: 2020 2072 6573 746f 7265 6432 203d 2073     restored2 = s
-000142d0: 656c 662e 6469 7265 6374 6f72 795f 7472  elf.directory_tr
-000142e0: 6565 5f74 6f5f 6c69 7374 5f6f 665f 6c69  ee_to_list_of_li
-000142f0: 7374 7328 7265 7374 6f72 655f 6469 7220  sts(restore_dir 
-00014300: 2b20 7522 2f73 656c 6563 7432 2229 0a20  + u"/select2"). 
-00014310: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
-00014320: 7274 4571 7561 6c28 7265 7374 6f72 6564  rtEqual(restored
-00014330: 2c20 7265 7374 6f72 6564 3229 0a0a 0a63  , restored2)...c
-00014340: 6c61 7373 2054 6573 7454 7261 696c 696e  lass TestTrailin
-00014350: 6753 6c61 7368 2849 6e63 6c75 6465 4578  gSlash(IncludeEx
-00014360: 636c 7564 6546 756e 6374 696f 6e61 6c54  cludeFunctionalT
-00014370: 6573 7429 3a0a 2020 2020 7522 2222 2054  est):.    u""" T
-00014380: 6573 7420 746f 2063 6865 636b 2074 6861  est to check tha
-00014390: 7420 6120 7472 6169 6c69 6e67 2073 6c61  t a trailing sla
-000143a0: 7368 2077 6f72 6b73 2061 7320 6578 7065  sh works as expe
-000143b0: 6374 6564 0a20 2020 2020 4578 6869 6269  cted.     Exhibi
-000143c0: 7473 2074 6865 2069 7373 7565 2072 6570  ts the issue rep
-000143d0: 6f72 7465 6420 696e 2042 7567 2023 3933  orted in Bug #93
-000143e0: 3234 3832 2028 6874 7470 733a 2f2f 6275  2482 (https://bu
-000143f0: 6773 2e6c 6175 6e63 6870 6164 2e6e 6574  gs.launchpad.net
-00014400: 2f64 7570 6c69 6369 7479 2f2b 6275 672f  /duplicity/+bug/
-00014410: 3933 3234 3832 292e 2222 220a 0a20 2020  932482)."""..   
-00014420: 2064 6566 2072 6573 746f 7265 5f61 6e64   def restore_and
-00014430: 5f63 6865 636b 2873 656c 6629 3a0a 2020  _check(self):.  
-00014440: 2020 2020 2020 7522 2222 5265 7374 6f72        u"""Restor
-00014450: 6573 2074 6865 2062 6163 6b75 7020 616e  es the backup an
-00014460: 6420 636f 6d70 6172 6573 2074 6f20 7768  d compares to wh
-00014470: 6174 2069 7320 6578 7065 6374 6564 2e22  at is expected."
-00014480: 2222 0a20 2020 2020 2020 2073 656c 662e  "".        self.
-00014490: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
-000144a0: 2020 7265 7374 6f72 655f 6469 7220 3d20    restore_dir = 
-000144b0: 7522 7465 7374 6669 6c65 732f 7265 7374  u"testfiles/rest
-000144c0: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
-000144d0: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
-000144e0: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
-000144f0: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-00014500: 2872 6573 746f 7265 5f64 6972 290a 2020  (restore_dir).  
-00014510: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
-00014520: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
-00014530: 205b 5b75 2232 225d 2c20 5b75 2231 225d   [[u"2"], [u"1"]
-00014540: 5d29 0a0a 2020 2020 6465 6620 7465 7374  ])..    def test
-00014550: 5f65 7863 6c75 6465 5f66 696c 656c 6973  _exclude_filelis
-00014560: 745f 7472 6169 6c69 6e67 5f73 6c61 7368  t_trailing_slash
-00014570: 6573 2873 656c 6629 3a0a 2020 2020 2020  es(self):.      
-00014580: 2020 7522 2222 7465 7374 5f65 7863 6c75    u"""test_exclu
-00014590: 6465 5f66 696c 656c 6973 745f 6173 7465  de_filelist_aste
-000145a0: 7269 736b 735f 6e6f 6e65 2077 6974 6820  risks_none with 
-000145b0: 7472 6169 6c69 6e67 2073 6c61 7368 6573  trailing slashes
-000145c0: 2e22 2222 0a20 2020 2020 2020 2077 6974  .""".        wit
-000145d0: 6820 696f 2e6f 7065 6e28 7522 7465 7374  h io.open(u"test
-000145e0: 6669 6c65 732f 6669 6c65 6c69 7374 2e74  files/filelist.t
-000145f0: 7874 222c 2075 2277 2229 2061 7320 663a  xt", u"w") as f:
-00014600: 0a20 2020 2020 2020 2020 2020 2066 2e77  .            f.w
-00014610: 7269 7465 2875 222b 2074 6573 7466 696c  rite(u"+ testfil
-00014620: 6573 2f73 656c 6563 742f 312f 322f 312f  es/select/1/2/1/
-00014630: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-00014640: 2020 2020 2020 2020 7522 2d20 7465 7374          u"- test
-00014650: 6669 6c65 732f 7365 6c65 6374 2f31 2f32  files/select/1/2
-00014660: 2f5c 6e22 0a20 2020 2020 2020 2020 2020  /\n".           
-00014670: 2020 2020 2020 2020 2075 222d 2074 6573           u"- tes
-00014680: 7466 696c 6573 2f73 656c 6563 742f 312f  tfiles/select/1/
-00014690: 312f 5c6e 220a 2020 2020 2020 2020 2020  1/\n".          
-000146a0: 2020 2020 2020 2020 2020 7522 2d20 7465            u"- te
-000146b0: 7374 6669 6c65 732f 7365 6c65 6374 2f31  stfiles/select/1
-000146c0: 2f33 2f22 290a 2020 2020 2020 2020 7365  /3/").        se
-000146d0: 6c66 2e62 6163 6b75 7028 7522 6675 6c6c  lf.backup(u"full
-000146e0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-000146f0: 656c 6563 742f 3122 2c20 6f70 7469 6f6e  elect/1", option
-00014700: 733d 5b75 222d 2d65 7863 6c75 6465 2d66  s=[u"--exclude-f
-00014710: 696c 656c 6973 743d 7465 7374 6669 6c65  ilelist=testfile
-00014720: 732f 6669 6c65 6c69 7374 2e74 7874 225d  s/filelist.txt"]
-00014730: 290a 2020 2020 2020 2020 7365 6c66 2e72  ).        self.r
-00014740: 6573 746f 7265 5f61 6e64 5f63 6865 636b  estore_and_check
-00014750: 2829 0a0a 2020 2020 6465 6620 7465 7374  ()..    def test
-00014760: 5f65 7863 6c75 6465 5f66 696c 656c 6973  _exclude_filelis
-00014770: 745f 7472 6169 6c69 6e67 5f73 6c61 7368  t_trailing_slash
-00014780: 6573 5f73 696e 676c 655f 7769 6c64 6361  es_single_wildca
-00014790: 7264 735f 6578 636c 7564 6573 2873 656c  rds_excludes(sel
-000147a0: 6629 3a0a 2020 2020 2020 2020 7522 2222  f):.        u"""
-000147b0: 7465 7374 5f65 7863 6c75 6465 5f66 696c  test_exclude_fil
-000147c0: 656c 6973 745f 7472 6169 6c69 6e67 5f73  elist_trailing_s
-000147d0: 6c61 7368 6573 2077 6974 6820 7369 6e67  lashes with sing
-000147e0: 6c65 2077 696c 6463 6172 6473 2069 6e20  le wildcards in 
-000147f0: 6578 636c 7564 6573 2e22 2222 0a20 2020  excludes.""".   
-00014800: 2020 2020 2023 2052 6567 7265 7373 696f       # Regressio
-00014810: 6e20 7465 7374 2066 6f72 2042 7567 2023  n test for Bug #
-00014820: 3933 3234 3832 2028 6874 7470 733a 2f2f  932482 (https://
-00014830: 6275 6773 2e6c 6175 6e63 6870 6164 2e6e  bugs.launchpad.n
-00014840: 6574 2f64 7570 6c69 6369 7479 2f2b 6275  et/duplicity/+bu
-00014850: 672f 3933 3234 3832 290a 2020 2020 2020  g/932482).      
-00014860: 2020 7769 7468 2069 6f2e 6f70 656e 2875    with io.open(u
-00014870: 2274 6573 7466 696c 6573 2f66 696c 656c  "testfiles/filel
-00014880: 6973 742e 7478 7422 2c20 7522 7722 2920  ist.txt", u"w") 
-00014890: 6173 2066 3a0a 2020 2020 2020 2020 2020  as f:.          
-000148a0: 2020 662e 7772 6974 6528 7522 2b20 7465    f.write(u"+ te
-000148b0: 7374 6669 6c65 732f 7365 6c65 6374 2f31  stfiles/select/1
-000148c0: 2f32 2f31 2f5c 6e22 0a20 2020 2020 2020  /2/1/\n".       
-000148d0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-000148e0: 202a 2f73 656c 6563 742f 312f 322f 5c6e   */select/1/2/\n
-000148f0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00014900: 2020 2020 2020 7522 2d20 7465 7374 6669        u"- testfi
-00014910: 6c65 732f 2a2f 312f 312f 5c6e 220a 2020  les/*/1/1/\n".  
-00014920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014930: 2020 7522 2d20 2a2f 2a2f 312f 332f 2229    u"- */*/1/3/")
-00014940: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
-00014950: 636b 7570 2875 2266 756c 6c22 2c20 7522  ckup(u"full", u"
-00014960: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00014970: 2f31 222c 206f 7074 696f 6e73 3d5b 7522  /1", options=[u"
-00014980: 2d2d 6578 636c 7564 652d 6669 6c65 6c69  --exclude-fileli
-00014990: 7374 3d74 6573 7466 696c 6573 2f66 696c  st=testfiles/fil
-000149a0: 656c 6973 742e 7478 7422 5d29 0a20 2020  elist.txt"]).   
-000149b0: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
-000149c0: 655f 616e 645f 6368 6563 6b28 290a 0a20  e_and_check().. 
-000149d0: 2020 2064 6566 2074 6573 745f 6578 636c     def test_excl
-000149e0: 7564 655f 6669 6c65 6c69 7374 5f74 7261  ude_filelist_tra
-000149f0: 696c 696e 675f 736c 6173 6865 735f 646f  iling_slashes_do
-00014a00: 7562 6c65 5f77 696c 6463 6172 6473 5f65  uble_wildcards_e
-00014a10: 7863 6c75 6465 7328 7365 6c66 293a 0a20  xcludes(self):. 
-00014a20: 2020 2020 2020 2075 2222 2274 6573 745f         u"""test_
-00014a30: 6578 636c 7564 655f 6669 6c65 6c69 7374  exclude_filelist
-00014a40: 5f74 7261 696c 696e 675f 736c 6173 6865  _trailing_slashe
-00014a50: 7320 7769 7468 2064 6f75 626c 6520 7769  s with double wi
-00014a60: 6c64 6361 7264 7320 696e 2065 7863 6c75  ldcards in exclu
-00014a70: 6465 732e 2222 220a 2020 2020 2020 2020  des.""".        
-00014a80: 2320 5265 6772 6573 7369 6f6e 2074 6573  # Regression tes
-00014a90: 7420 666f 7220 4275 6720 2339 3332 3438  t for Bug #93248
-00014aa0: 3220 2868 7474 7073 3a2f 2f62 7567 732e  2 (https://bugs.
-00014ab0: 6c61 756e 6368 7061 642e 6e65 742f 6475  launchpad.net/du
-00014ac0: 706c 6963 6974 792f 2b62 7567 2f39 3332  plicity/+bug/932
-00014ad0: 3438 3229 0a20 2020 2020 2020 2077 6974  482).        wit
-00014ae0: 6820 696f 2e6f 7065 6e28 7522 7465 7374  h io.open(u"test
-00014af0: 6669 6c65 732f 6669 6c65 6c69 7374 2e74  files/filelist.t
-00014b00: 7874 222c 2075 2277 2229 2061 7320 663a  xt", u"w") as f:
-00014b10: 0a20 2020 2020 2020 2020 2020 2066 2e77  .            f.w
-00014b20: 7269 7465 2875 222b 2074 6573 7466 696c  rite(u"+ testfil
-00014b30: 6573 2f73 656c 6563 742f 312f 322f 312f  es/select/1/2/1/
-00014b40: 5c6e 220a 2020 2020 2020 2020 2020 2020  \n".            
-00014b50: 2020 2020 2020 2020 7522 2d20 2a2a 2f31          u"- **/1
-00014b60: 2f32 2f5c 6e22 0a20 2020 2020 2020 2020  /2/\n".         
-00014b70: 2020 2020 2020 2020 2020 2075 222d 202a             u"- *
-00014b80: 2a2f 312f 312f 5c6e 220a 2020 2020 2020  */1/1/\n".      
-00014b90: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00014ba0: 2d20 2a2a 2f31 2f33 2f22 290a 2020 2020  - **/1/3/").    
-00014bb0: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
-00014bc0: 7522 6675 6c6c 222c 2075 2274 6573 7466  u"full", u"testf
-00014bd0: 696c 6573 2f73 656c 6563 742f 3122 2c20  iles/select/1", 
-00014be0: 6f70 7469 6f6e 733d 5b75 222d 2d65 7863  options=[u"--exc
-00014bf0: 6c75 6465 2d66 696c 656c 6973 743d 7465  lude-filelist=te
-00014c00: 7374 6669 6c65 732f 6669 6c65 6c69 7374  stfiles/filelist
-00014c10: 2e74 7874 225d 290a 2020 2020 2020 2020  .txt"]).        
-00014c20: 7365 6c66 2e72 6573 746f 7265 5f61 6e64  self.restore_and
-00014c30: 5f63 6865 636b 2829 0a0a 2020 2020 6465  _check()..    de
-00014c40: 6620 7465 7374 5f65 7863 6c75 6465 5f66  f test_exclude_f
-00014c50: 696c 656c 6973 745f 7472 6169 6c69 6e67  ilelist_trailing
-00014c60: 5f73 6c61 7368 6573 5f64 6f75 626c 655f  _slashes_double_
-00014c70: 7769 6c64 6361 7264 735f 6578 636c 7564  wildcards_exclud
-00014c80: 6573 5f32 2873 656c 6629 3a0a 2020 2020  es_2(self):.    
-00014c90: 2020 2020 7522 2222 7365 636f 6e64 2074      u"""second t
-00014ca0: 6573 745f 6578 636c 7564 655f 6669 6c65  est_exclude_file
-00014cb0: 6c69 7374 5f74 7261 696c 696e 675f 736c  list_trailing_sl
-00014cc0: 6173 6865 7320 7769 7468 2064 6f75 626c  ashes with doubl
-00014cd0: 6520 7769 6c64 6361 7264 7320 696e 2065  e wildcards in e
-00014ce0: 7863 6c75 6465 732e 2222 220a 2020 2020  xcludes.""".    
-00014cf0: 2020 2020 2320 5265 6772 6573 7369 6f6e      # Regression
-00014d00: 2074 6573 7420 666f 7220 4275 6720 2339   test for Bug #9
-00014d10: 3332 3438 3220 2868 7474 7073 3a2f 2f62  32482 (https://b
-00014d20: 7567 732e 6c61 756e 6368 7061 642e 6e65  ugs.launchpad.ne
-00014d30: 742f 6475 706c 6963 6974 792f 2b62 7567  t/duplicity/+bug
-00014d40: 2f39 3332 3438 3229 2061 6e64 0a20 2020  /932482) and.   
-00014d50: 2020 2020 2023 2052 6567 7265 7373 696f       # Regressio
-00014d60: 6e20 7465 7374 2066 6f72 2042 7567 2023  n test for Bug #
-00014d70: 3838 3433 3731 2028 6874 7470 733a 2f2f  884371 (https://
-00014d80: 6275 6773 2e6c 6175 6e63 6870 6164 2e6e  bugs.launchpad.n
-00014d90: 6574 2f64 7570 6c69 6369 7479 2f2b 6275  et/duplicity/+bu
-00014da0: 672f 3838 3433 3731 290a 2020 2020 2020  g/884371).      
-00014db0: 2020 7769 7468 2069 6f2e 6f70 656e 2875    with io.open(u
-00014dc0: 2274 6573 7466 696c 6573 2f66 696c 656c  "testfiles/filel
-00014dd0: 6973 742e 7478 7422 2c20 7522 7722 2920  ist.txt", u"w") 
-00014de0: 6173 2066 3a0a 2020 2020 2020 2020 2020  as f:.          
-00014df0: 2020 662e 7772 6974 6528 7522 2b20 2a2a    f.write(u"+ **
-00014e00: 2f31 2f32 2f31 2f5c 6e22 0a20 2020 2020  /1/2/1/\n".     
-00014e10: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00014e20: 222d 202a 2a2f 312f 322f 5c6e 220a 2020  "- **/1/2/\n".  
-00014e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014e40: 2020 7522 2d20 2a2a 2f31 2f31 2f5c 6e22    u"- **/1/1/\n"
-00014e50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014e60: 2020 2020 2075 222d 202a 2a2f 312f 332f       u"- **/1/3/
-00014e70: 2229 0a20 2020 2020 2020 2073 656c 662e  ").        self.
-00014e80: 6261 636b 7570 2875 2266 756c 6c22 2c20  backup(u"full", 
-00014e90: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00014ea0: 6374 2f31 222c 206f 7074 696f 6e73 3d5b  ct/1", options=[
-00014eb0: 7522 2d2d 6578 636c 7564 652d 6669 6c65  u"--exclude-file
-00014ec0: 6c69 7374 3d74 6573 7466 696c 6573 2f66  list=testfiles/f
-00014ed0: 696c 656c 6973 742e 7478 7422 5d29 0a20  ilelist.txt"]). 
-00014ee0: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
-00014ef0: 6f72 655f 616e 645f 6368 6563 6b28 290a  ore_and_check().
-00014f00: 0a20 2020 2064 6566 2074 6573 745f 6578  .    def test_ex
-00014f10: 636c 7564 655f 6669 6c65 6c69 7374 5f74  clude_filelist_t
-00014f20: 7261 696c 696e 675f 736c 6173 6865 735f  railing_slashes_
-00014f30: 7769 6c64 6361 7264 7328 7365 6c66 293a  wildcards(self):
-00014f40: 0a20 2020 2020 2020 2075 2222 2274 6573  .        u"""tes
-00014f50: 745f 636f 6d6d 616e 646c 696e 655f 6173  t_commandline_as
-00014f60: 7465 7269 736b 735f 7369 6e67 6c65 5f65  terisks_single_e
-00014f70: 7863 6c75 6465 735f 6f6e 6c79 2077 6974  xcludes_only wit
-00014f80: 6820 7472 6169 6c69 6e67 2073 6c61 7368  h trailing slash
-00014f90: 6573 2e22 2222 0a20 2020 2020 2020 2023  es.""".        #
-00014fa0: 2052 6567 7265 7373 696f 6e20 7465 7374   Regression test
-00014fb0: 2066 6f72 2042 7567 2023 3933 3234 3832   for Bug #932482
-00014fc0: 2028 6874 7470 733a 2f2f 6275 6773 2e6c   (https://bugs.l
-00014fd0: 6175 6e63 6870 6164 2e6e 6574 2f64 7570  aunchpad.net/dup
-00014fe0: 6c69 6369 7479 2f2b 6275 672f 3933 3234  licity/+bug/9324
-00014ff0: 3832 290a 2020 2020 2020 2020 7365 6c66  82).        self
-00015000: 2e62 6163 6b75 7028 7522 6675 6c6c 222c  .backup(u"full",
-00015010: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00015020: 6563 742f 3122 2c0a 2020 2020 2020 2020  ect/1",.        
-00015030: 2020 2020 2020 2020 2020 2020 6f70 7469              opti
-00015040: 6f6e 733d 5b75 222d 2d69 6e63 6c75 6465  ons=[u"--include
-00015050: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00015060: 656c 6563 742f 312f 322f 312f 222c 0a20  elect/1/2/1/",. 
-00015070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015080: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00015090: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-000150a0: 6669 6c65 732f 2a2f 312f 322f 222c 0a20  files/*/1/2/",. 
-000150b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000150c0: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-000150d0: 6578 636c 7564 6522 2c20 7522 2a2f 7365  exclude", u"*/se
-000150e0: 6c65 6374 2f31 2f31 2f22 2c0a 2020 2020  lect/1/1/",.    
-000150f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015100: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00015110: 6c75 6465 222c 2075 222a 2f73 656c 6563  lude", u"*/selec
-00015120: 742f 312f 332f 225d 290a 2020 2020 2020  t/1/3/"]).      
-00015130: 2020 7365 6c66 2e72 6573 746f 7265 5f61    self.restore_a
-00015140: 6e64 5f63 6865 636b 2829 0a0a 0a63 6c61  nd_check()...cla
-00015150: 7373 2054 6573 7454 7261 696c 696e 6753  ss TestTrailingS
-00015160: 6c61 7368 3228 496e 636c 7564 6545 7863  lash2(IncludeExc
-00015170: 6c75 6465 4675 6e63 7469 6f6e 616c 5465  ludeFunctionalTe
-00015180: 7374 293a 0a20 2020 2075 2222 2220 5468  st):.    u""" Th
-00015190: 6973 2074 6573 7473 2074 6865 2062 6568  is tests the beh
-000151a0: 6176 696f 7572 206f 6620 676c 6f62 6269  aviour of globbi
-000151b0: 6e67 2073 7472 696e 6773 2077 6974 6820  ng strings with 
-000151c0: 6120 7472 6169 6c69 6e67 2073 6c61 7368  a trailing slash
-000151d0: 2222 220a 2020 2020 2320 5365 6520 4275  """.    # See Bu
-000151e0: 6720 2331 3437 3935 3435 2028 6874 7470  g #1479545 (http
-000151f0: 733a 2f2f 6275 6773 2e6c 6175 6e63 6870  s://bugs.launchp
-00015200: 6164 2e6e 6574 2f64 7570 6c69 6369 7479  ad.net/duplicity
-00015210: 2f2b 6275 672f 3134 3739 3534 3529 0a0a  /+bug/1479545)..
-00015220: 2020 2020 6465 6620 7465 7374 5f6e 6f5f      def test_no_
-00015230: 7472 6169 6c69 6e67 5f73 6c61 7368 2873  trailing_slash(s
-00015240: 656c 6629 3a0a 2020 2020 2020 2020 7522  elf):.        u"
-00015250: 2222 2054 6573 7420 7468 6174 2069 6e63  "" Test that inc
-00015260: 6c75 6469 6e67 2031 2e70 7920 776f 726b  luding 1.py work
-00015270: 7320 6173 2065 7870 6563 7465 6422 2222  s as expected"""
-00015280: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
-00015290: 636b 7570 2875 2266 756c 6c22 2c20 7522  ckup(u"full", u"
-000152a0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-000152b0: 3222 2c0a 2020 2020 2020 2020 2020 2020  2",.            
-000152c0: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-000152d0: 5b75 222d 2d69 6e63 6c75 6465 222c 2075  [u"--include", u
-000152e0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-000152f0: 7432 2f31 2e70 7922 2c0a 2020 2020 2020  t2/1.py",.      
-00015300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015310: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-00015320: 6465 222c 2075 222a 2a22 5d29 0a20 2020  de", u"**"]).   
-00015330: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
-00015340: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
-00015350: 6f72 655f 6469 7220 3d20 7522 7465 7374  ore_dir = u"test
-00015360: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
-00015370: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
-00015380: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
-00015390: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
-000153a0: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
-000153b0: 7265 5f64 6972 290a 2020 2020 2020 2020  re_dir).        
-000153c0: 7365 6c66 2e61 7373 6572 7445 7175 616c  self.assertEqual
-000153d0: 2872 6573 746f 7265 642c 205b 5b75 2231  (restored, [[u"1
-000153e0: 2e70 7922 5d5d 290a 0a20 2020 2064 6566  .py"]])..    def
-000153f0: 2074 6573 745f 7472 6169 6c69 6e67 5f73   test_trailing_s
-00015400: 6c61 7368 2873 656c 6629 3a0a 2020 2020  lash(self):.    
-00015410: 2020 2020 7522 2222 2054 6573 7420 7468      u""" Test th
-00015420: 6174 2067 6c6f 6273 2077 6974 6820 6120  at globs with a 
-00015430: 7472 6169 6c69 6e67 2073 6c61 7368 206f  trailing slash o
-00015440: 6e6c 7920 6d61 7463 6820 6469 7265 6374  nly match direct
-00015450: 6f72 6965 7322 2222 0a20 2020 2020 2020  ories""".       
-00015460: 2023 2052 6567 7265 7373 696f 6e20 7465   # Regression te
-00015470: 7374 2066 6f72 2042 7567 2023 3134 3739  st for Bug #1479
-00015480: 3534 350a 2020 2020 2020 2020 2320 2868  545.        # (h
-00015490: 7474 7073 3a2f 2f62 7567 732e 6c61 756e  ttps://bugs.laun
-000154a0: 6368 7061 642e 6e65 742f 6475 706c 6963  chpad.net/duplic
-000154b0: 6974 792f 2b62 7567 2f31 3437 3935 3435  ity/+bug/1479545
-000154c0: 290a 2020 2020 2020 2020 7365 6c66 2e62  ).        self.b
-000154d0: 6163 6b75 7028 7522 6675 6c6c 222c 2075  ackup(u"full", u
-000154e0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-000154f0: 7432 222c 0a20 2020 2020 2020 2020 2020  t2",.           
-00015500: 2020 2020 2020 2020 206f 7074 696f 6e73           options
-00015510: 3d5b 7522 2d2d 696e 636c 7564 6522 2c20  =[u"--include", 
-00015520: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00015530: 6374 322f 312e 7079 2f22 2c0a 2020 2020  ct2/1.py/",.    
-00015540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015550: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00015560: 6c75 6465 222c 2075 222a 2a22 5d29 0a20  lude", u"**"]). 
-00015570: 2020 2020 2020 2073 656c 662e 7265 7374         self.rest
-00015580: 6f72 6528 290a 2020 2020 2020 2020 7265  ore().        re
-00015590: 7374 6f72 655f 6469 7220 3d20 7522 7465  store_dir = u"te
-000155a0: 7374 6669 6c65 732f 7265 7374 6f72 655f  stfiles/restore_
-000155b0: 6f75 7422 0a20 2020 2020 2020 2072 6573  out".        res
-000155c0: 746f 7265 6420 3d20 7365 6c66 2e64 6972  tored = self.dir
-000155d0: 6563 746f 7279 5f74 7265 655f 746f 5f6c  ectory_tree_to_l
-000155e0: 6973 745f 6f66 5f6c 6973 7473 2872 6573  ist_of_lists(res
-000155f0: 746f 7265 5f64 6972 290a 2020 2020 2020  tore_dir).      
-00015600: 2020 7365 6c66 2e61 7373 6572 7445 7175    self.assertEqu
-00015610: 616c 2872 6573 746f 7265 642c 205b 5d29  al(restored, [])
-00015620: 0a0a 2020 2020 6465 6620 7465 7374 5f69  ..    def test_i
-00015630: 6e63 6c75 6465 5f66 696c 6573 5f6e 6f74  nclude_files_not
-00015640: 5f73 7562 6469 7265 6374 6f72 6965 7328  _subdirectories(
-00015650: 7365 6c66 293a 0a20 2020 2020 2020 2075  self):.        u
-00015660: 2222 2220 5465 7374 2074 6861 7420 6120  """ Test that a 
-00015670: 7472 6169 6c69 6e67 2073 6c61 7368 2067  trailing slash g
-00015680: 6c6f 6220 666f 6c6c 6f77 6564 2062 7920  lob followed by 
-00015690: 6120 2a20 676c 6f62 206f 6e6c 7920 6d61  a * glob only ma
-000156a0: 7463 6865 730a 2020 2020 2020 2020 6669  tches.        fi
-000156b0: 6c65 7320 616e 6420 6e6f 7420 7375 6264  les and not subd
-000156c0: 6972 6563 746f 7269 6573 2222 220a 2020  irectories""".  
-000156d0: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-000156e0: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-000156f0: 7466 696c 6573 2f73 656c 6563 7432 222c  tfiles/select2",
-00015700: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015710: 2020 2020 206f 7074 696f 6e73 3d5b 7522       options=[u"
-00015720: 2d2d 6578 636c 7564 6522 2c20 7522 7465  --exclude", u"te
-00015730: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00015740: 2a2f 222c 0a20 2020 2020 2020 2020 2020  */",.           
-00015750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015760: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-00015770: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00015780: 6374 322f 2a22 2c0a 2020 2020 2020 2020  ct2/*",.        
-00015790: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000157a0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-000157b0: 222c 2075 222a 2a22 5d29 0a20 2020 2020  ", u"**"]).     
-000157c0: 2020 2073 656c 662e 7265 7374 6f72 6528     self.restore(
-000157d0: 290a 2020 2020 2020 2020 7265 7374 6f72  ).        restor
-000157e0: 655f 6469 7220 3d20 7522 7465 7374 6669  e_dir = u"testfi
-000157f0: 6c65 732f 7265 7374 6f72 655f 6f75 7422  les/restore_out"
-00015800: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
-00015810: 6420 3d20 7365 6c66 2e64 6972 6563 746f  d = self.directo
-00015820: 7279 5f74 7265 655f 746f 5f6c 6973 745f  ry_tree_to_list_
-00015830: 6f66 5f6c 6973 7473 2872 6573 746f 7265  of_lists(restore
-00015840: 5f64 6972 290a 2020 2020 2020 2020 7365  _dir).        se
-00015850: 6c66 2e61 7373 6572 7445 7175 616c 2872  lf.assertEqual(r
-00015860: 6573 746f 7265 642c 205b 5b75 2231 2e64  estored, [[u"1.d
-00015870: 6f63 222c 2075 2231 2e70 7922 5d5d 290a  oc", u"1.py"]]).
-00015880: 0a20 2020 2064 6566 2074 6573 745f 696e  .    def test_in
-00015890: 636c 7564 655f 7375 6264 6972 6563 746f  clude_subdirecto
-000158a0: 7269 6573 5f6e 6f74 5f66 696c 6573 2873  ries_not_files(s
-000158b0: 656c 6629 3a0a 2020 2020 2020 2020 7522  elf):.        u"
-000158c0: 2222 2054 6573 7420 7468 6174 2061 2074  "" Test that a t
-000158d0: 7261 696c 696e 6720 736c 6173 6820 676c  railing slash gl
-000158e0: 6f62 206f 6e6c 7920 6d61 7463 6865 7320  ob only matches 
-000158f0: 6469 7265 6374 6f72 6965 7322 2222 0a20  directories""". 
-00015900: 2020 2020 2020 2073 656c 662e 6261 636b         self.back
-00015910: 7570 2875 2266 756c 6c22 2c20 7522 7465  up(u"full", u"te
-00015920: 7374 6669 6c65 732f 7365 6c65 6374 3222  stfiles/select2"
-00015930: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00015940: 2020 2020 2020 6f70 7469 6f6e 733d 5b75        options=[u
-00015950: 222d 2d69 6e63 6c75 6465 222c 2075 2274  "--include", u"t
-00015960: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00015970: 2f31 2f31 7375 6231 2f2a 2a2f 222c 0a20  /1/1sub1/**/",. 
-00015980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015990: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-000159a0: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-000159b0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-000159c0: 3173 7562 312f 2a2a 222c 0a20 2020 2020  1sub1/**",.     
-000159d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000159e0: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-000159f0: 7564 6522 2c20 7522 2a2a 225d 290a 2020  ude", u"**"]).  
-00015a00: 2020 2020 2020 7365 6c66 2e72 6573 746f        self.resto
-00015a10: 7265 2829 0a20 2020 2020 2020 2072 6573  re().        res
-00015a20: 746f 7265 5f64 6972 203d 2075 2274 6573  tore_dir = u"tes
-00015a30: 7466 696c 6573 2f72 6573 746f 7265 5f6f  tfiles/restore_o
-00015a40: 7574 220a 2020 2020 2020 2020 7265 7374  ut".        rest
-00015a50: 6f72 6564 203d 2073 656c 662e 6469 7265  ored = self.dire
-00015a60: 6374 6f72 795f 7472 6565 5f74 6f5f 6c69  ctory_tree_to_li
-00015a70: 7374 5f6f 665f 6c69 7374 7328 7265 7374  st_of_lists(rest
-00015a80: 6f72 655f 6469 7229 0a20 2020 2020 2020  ore_dir).       
-00015a90: 2073 656c 662e 6173 7365 7274 4571 7561   self.assertEqua
-00015aa0: 6c28 7265 7374 6f72 6564 2c20 5b5b 7522  l(restored, [[u"
-00015ab0: 3122 5d2c 205b 7522 3173 7562 3122 5d2c  1"], [u"1sub1"],
-00015ac0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00015ad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015ae0: 2020 2020 205b 7522 3173 7562 3173 7562       [u"1sub1sub
-00015af0: 3122 2c20 7522 3173 7562 3173 7562 3222  1", u"1sub1sub2"
-00015b00: 2c20 7522 3173 7562 3173 7562 3322 5d5d  , u"1sub1sub3"]]
-00015b10: 290a 0a0a 636c 6173 7320 5465 7374 476c  )...class TestGl
-00015b20: 6f62 6269 6e67 5265 706c 6163 656d 656e  obbingReplacemen
-00015b30: 7428 496e 636c 7564 6545 7863 6c75 6465  t(IncludeExclude
-00015b40: 4675 6e63 7469 6f6e 616c 5465 7374 293a  FunctionalTest):
-00015b50: 0a20 2020 2075 2222 2220 5468 6973 2074  .    u""" This t
-00015b60: 6573 7473 2074 6865 2062 6568 6176 696f  ests the behavio
-00015b70: 7572 206f 6620 7468 6520 6578 7465 6e64  ur of the extend
-00015b80: 6564 2073 6865 6c6c 2067 6c6f 6262 696e  ed shell globbin
-00015b90: 6720 7061 7474 6572 6e20 7265 706c 6163  g pattern replac
-00015ba0: 656d 656e 7420 6675 6e63 7469 6f6e 732e  ement functions.
-00015bb0: 2222 220a 2020 2020 2320 5365 6520 7468  """.    # See th
-00015bc0: 6520 6d61 6e75 616c 2066 6f72 2061 2064  e manual for a d
-00015bd0: 6573 6372 6970 7469 6f6e 206f 6620 6265  escription of be
-00015be0: 6861 7669 6f75 7273 2c20 6275 7420 696e  haviours, but in
-00015bf0: 2073 756d 6d61 7279 3a0a 2020 2020 2320   summary:.    # 
-00015c00: 2a20 6361 6e20 6265 2065 7870 616e 6465  * can be expande
-00015c10: 6420 746f 2061 6e79 2073 7472 696e 6720  d to any string 
-00015c20: 6f66 2063 6861 7261 6374 6572 7320 6e6f  of characters no
-00015c30: 7420 636f 6e74 6169 6e69 6e67 2022 2f22  t containing "/"
-00015c40: 0a20 2020 2023 203f 2065 7870 616e 6473  .    # ? expands
-00015c50: 2074 6f20 616e 7920 6368 6172 6163 7465   to any characte
-00015c60: 7220 6578 6365 7074 2022 2f22 2061 6e64  r except "/" and
-00015c70: 0a20 2020 2023 205b 2e2e 2e5d 2065 7870  .    # [...] exp
-00015c80: 616e 6473 2074 6f20 6120 7369 6e67 6c65  ands to a single
-00015c90: 2063 6861 7261 6374 6572 206f 6620 7468   character of th
-00015ca0: 6f73 6520 6368 6172 6163 7465 7273 2073  ose characters s
-00015cb0: 7065 6369 6669 6564 2028 7261 6e67 6573  pecified (ranges
-00015cc0: 2061 7265 2061 6363 6570 7461 626c 6529   are acceptable)
-00015cd0: 2e0a 2020 2020 2320 5468 6520 6e65 7720  ..    # The new 
-00015ce0: 7370 6563 6961 6c20 7061 7474 6572 6e2c  special pattern,
-00015cf0: 202a 2a2c 2065 7870 616e 6473 2074 6f20   **, expands to 
-00015d00: 616e 7920 7374 7269 6e67 206f 6620 6368  any string of ch
-00015d10: 6172 6163 7465 7273 2077 6865 7468 6572  aracters whether
-00015d20: 206f 7220 6e6f 7420 6974 2063 6f6e 7461   or not it conta
-00015d30: 696e 7320 222f 222e 0a20 2020 2023 2046  ins "/"..    # F
-00015d40: 7572 7468 6572 6d6f 7265 2c20 6966 2074  urthermore, if t
-00015d50: 6865 2070 6174 7465 726e 2073 7461 7274  he pattern start
-00015d60: 7320 7769 7468 2022 6967 6e6f 7265 6361  s with "ignoreca
-00015d70: 7365 3a22 2028 6361 7365 2069 6e73 656e  se:" (case insen
-00015d80: 7369 7469 7665 292c 2074 6865 6e20 7468  sitive), then th
-00015d90: 6973 2070 7265 6669 7820 7769 6c6c 2062  is prefix will b
-00015da0: 650a 2020 2020 2320 7265 6d6f 7665 6420  e.    # removed 
-00015db0: 616e 6420 616e 7920 6368 6172 6163 7465  and any characte
-00015dc0: 7220 696e 2074 6865 2073 7472 696e 6720  r in the string 
-00015dd0: 6361 6e20 6265 2072 6570 6c61 6365 6420  can be replaced 
-00015de0: 7769 7468 2061 6e20 7570 7065 722d 206f  with an upper- o
-00015df0: 7220 6c6f 7765 7263 6173 6520 7665 7273  r lowercase vers
-00015e00: 696f 6e20 6f66 2069 7473 656c 662e 0a0a  ion of itself...
-00015e10: 2020 2020 6465 6620 7465 7374 5f67 6c6f      def test_glo
-00015e20: 6262 696e 675f 7265 706c 6163 656d 656e  bbing_replacemen
-00015e30: 745f 696e 5f69 6e63 6c75 6465 7328 7365  t_in_includes(se
-00015e40: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00015e50: 2220 5465 7374 2062 6568 6176 696f 7572  " Test behaviour
-00015e60: 206f 6620 7468 6520 6578 7465 6e64 6564   of the extended
-00015e70: 2073 6865 6c6c 2067 6c6f 6262 696e 6720   shell globbing 
-00015e80: 7061 7474 6572 6e20 7265 706c 6163 656d  pattern replacem
-00015e90: 656e 7420 6675 6e63 7469 6f6e 7320 696e  ent functions in
-00015ea0: 2062 6f74 6820 696e 636c 7564 6520 616e   both include an
-00015eb0: 6420 6578 636c 7564 6522 2222 0a20 2020  d exclude""".   
-00015ec0: 2020 2020 2023 2049 6465 6e74 6963 616c       # Identical
-00015ed0: 2074 6f20 7465 7374 5f69 6e63 6c75 6465   to test_include
-00015ee0: 5f65 7863 6c75 6465 5f62 6173 6963 2077  _exclude_basic w
-00015ef0: 6974 6820 676c 6f62 6269 6e67 2063 6861  ith globbing cha
-00015f00: 7261 6374 6572 7320 6164 6465 6420 746f  racters added to
-00015f10: 2062 6f74 6820 696e 636c 7564 6520 616e   both include an
-00015f20: 6420 6578 636c 7564 6520 6c69 6e65 730a  d exclude lines.
-00015f30: 2020 2020 2020 2020 2320 4578 6869 6269          # Exhibi
-00015f40: 7473 2074 6865 2069 7373 7565 2072 6570  ts the issue rep
-00015f50: 6f72 7465 6420 696e 2042 7567 2023 3838  orted in Bug #88
-00015f60: 3433 3731 2028 6874 7470 733a 2f2f 6275  4371 (https://bu
-00015f70: 6773 2e6c 6175 6e63 6870 6164 2e6e 6574  gs.launchpad.net
-00015f80: 2f64 7570 6c69 6369 7479 2f2b 6275 672f  /duplicity/+bug/
-00015f90: 3838 3433 3731 292e 0a20 2020 2020 2020  884371)..       
-00015fa0: 2023 2053 6565 2061 626f 7665 2061 6e64   # See above and
-00015fb0: 2074 6865 2075 6e69 7420 7465 7374 7320   the unit tests 
-00015fc0: 666f 7220 6d6f 7265 2067 7261 6e75 6c61  for more granula
-00015fd0: 7269 7479 206f 6e20 7468 6520 6973 7375  rity on the issu
-00015fe0: 652e 0a20 2020 2020 2020 2073 656c 662e  e..        self.
-00015ff0: 6261 636b 7570 2875 2266 756c 6c22 2c20  backup(u"full", 
-00016000: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00016010: 6374 3222 2c0a 2020 2020 2020 2020 2020  ct2",.          
-00016020: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
-00016030: 733d 5b75 222d 2d69 6e63 6c75 6465 222c  s=[u"--include",
-00016040: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00016050: 6563 7432 2f2a 2a2f 3373 7562 3373 7562  ect2/**/3sub3sub
-00016060: 322f 3373 7562 3373 753f 325f 6669 6c65  2/3sub3su?2_file
-00016070: 2e74 7874 222c 2020 2320 4e6f 7465 202a  .txt",  # Note *
-00016080: 2a20 616e 6420 3f20 6164 6465 640a 2020  * and ? added.  
+00013b30: 2022 2d2d 6578 636c 7564 6522 2c20 222a   "--exclude", "*
+00013b40: 2a22 5d29 0a20 2020 2020 2020 2073 656c  *"]).        sel
+00013b50: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
+00013b60: 2020 2020 7265 7374 6f72 655f 7061 7468      restore_path
+00013b70: 203d 2022 7465 7374 6669 6c65 732f 7265   = "testfiles/re
+00013b80: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
+00013b90: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
+00013ba0: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
+00013bb0: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
+00013bc0: 7473 2872 6573 746f 7265 5f70 6174 6829  ts(restore_path)
+00013bd0: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
+00013be0: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
+00013bf0: 6564 2c20 5b5b 2231 7375 6231 7375 6231  ed, [["1sub1sub1
+00013c00: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00013c10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013c20: 2020 2020 2020 2020 5b22 2e6e 6f62 6163          [".nobac
+00013c30: 6b75 7022 2c20 2231 7375 6231 7375 6231  kup", "1sub1sub1
+00013c40: 5f66 696c 652e 7478 7422 5d5d 290a 0a20  _file.txt"]]).. 
+00013c50: 2020 2064 6566 2074 6573 745f 6578 636c     def test_excl
+00013c60: 7564 655f 6966 5f70 7265 7365 6e74 5f65  ude_if_present_e
+00013c70: 7863 6c75 6465 7328 7365 6c66 293a 0a20  xcludes(self):. 
+00013c80: 2020 2020 2020 2022 2222 2054 6573 7420         """ Test 
+00013c90: 7468 6174 2064 7570 6c69 6369 7479 2065  that duplicity e
+00013ca0: 7863 6c75 6465 7320 6669 6c65 7320 7769  xcludes files wi
+00013cb0: 7468 2072 656c 6576 616e 7420 7461 6722  th relevant tag"
+00013cc0: 2222 0a20 2020 2020 2020 2077 6974 6820  "".        with 
+00013cd0: 696f 2e6f 7065 6e28 2274 6573 7466 696c  io.open("testfil
+00013ce0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+00013cf0: 6231 2f31 7375 6231 7375 6231 2f2e 6e6f  b1/1sub1sub1/.no
+00013d00: 6261 636b 7570 222c 2022 7722 2920 6173  backup", "w") as
+00013d10: 2074 6167 3a0a 2020 2020 2020 2020 2020   tag:.          
+00013d20: 2020 7461 672e 7772 6974 6528 2246 696c    tag.write("Fil
+00013d30: 6573 2069 6e20 7468 6973 2066 6f6c 6465  es in this folde
+00013d40: 7220 7368 6f75 6c64 206e 6f74 2062 6520  r should not be 
+00013d50: 6261 636b 6564 2075 702e 2229 0a20 2020  backed up.").   
+00013d60: 2020 2020 2073 656c 662e 6261 636b 7570       self.backup
+00013d70: 2822 6675 6c6c 222c 2022 7465 7374 6669  ("full", "testfi
+00013d80: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+00013d90: 7562 3122 2c0a 2020 2020 2020 2020 2020  ub1",.          
+00013da0: 2020 2020 2020 2020 2020 6f70 7469 6f6e            option
+00013db0: 733d 5b22 2d2d 6578 636c 7564 652d 6966  s=["--exclude-if
+00013dc0: 2d70 7265 7365 6e74 222c 2022 2e6e 6f62  -present", ".nob
+00013dd0: 6163 6b75 7022 2c0a 2020 2020 2020 2020  ackup",.        
+00013de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013df0: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+00013e00: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00013e10: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
+00013e20: 6231 7375 6231 2f2a 222c 0a20 2020 2020  b1sub1/*",.     
+00013e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013e40: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+00013e50: 6465 222c 2022 2a2a 225d 290a 2020 2020  de", "**"]).    
+00013e60: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
+00013e70: 2829 0a20 2020 2020 2020 2072 6573 746f  ().        resto
+00013e80: 7265 5f70 6174 6820 3d20 2274 6573 7466  re_path = "testf
+00013e90: 696c 6573 2f72 6573 746f 7265 5f6f 7574  iles/restore_out
+00013ea0: 220a 2020 2020 2020 2020 7265 7374 6f72  ".        restor
+00013eb0: 6564 203d 2073 656c 662e 6469 7265 6374  ed = self.direct
+00013ec0: 6f72 795f 7472 6565 5f74 6f5f 6c69 7374  ory_tree_to_list
+00013ed0: 5f6f 665f 6c69 7374 7328 7265 7374 6f72  _of_lists(restor
+00013ee0: 655f 7061 7468 290a 2020 2020 2020 2020  e_path).        
+00013ef0: 7365 6c66 2e61 7373 6572 7445 7175 616c  self.assertEqual
+00013f00: 2872 6573 746f 7265 642c 205b 5d29 0a0a  (restored, [])..
+00013f10: 2020 2020 6465 6620 7465 7374 5f65 7863      def test_exc
+00013f20: 6c75 6465 5f69 665f 7072 6573 656e 745f  lude_if_present_
+00013f30: 6578 636c 7564 6573 5f32 2873 656c 6629  excludes_2(self)
+00013f40: 3a0a 2020 2020 2020 2020 2222 2220 5465  :.        """ Te
+00013f50: 7374 2074 6861 7420 6475 706c 6963 6974  st that duplicit
+00013f60: 7920 6578 636c 7564 6573 2066 696c 6573  y excludes files
+00013f70: 2077 6974 6820 7265 6c65 7661 6e74 2074   with relevant t
+00013f80: 6167 2222 220a 2020 2020 2020 2020 7769  ag""".        wi
+00013f90: 7468 2069 6f2e 6f70 656e 2822 7465 7374  th io.open("test
+00013fa0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
+00013fb0: 3173 7562 312f 3173 7562 3173 7562 312f  1sub1/1sub1sub1/
+00013fc0: 4558 434c 5544 452e 7461 6722 2c20 2277  EXCLUDE.tag", "w
+00013fd0: 2229 2061 7320 7461 673a 0a20 2020 2020  ") as tag:.     
+00013fe0: 2020 2020 2020 2074 6167 2e77 7269 7465         tag.write
+00013ff0: 2822 4669 6c65 7320 696e 2074 6869 7320  ("Files in this 
+00014000: 666f 6c64 6572 2073 686f 756c 6420 616c  folder should al
+00014010: 736f 206e 6f74 2062 6520 6261 636b 6564  so not be backed
+00014020: 2075 702e 2229 0a20 2020 2020 2020 2073   up.").        s
+00014030: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+00014040: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00014050: 6c65 6374 322f 312f 3173 7562 3122 2c0a  lect2/1/1sub1",.
+00014060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014070: 2020 2020 6f70 7469 6f6e 733d 5b22 2d2d      options=["--
+00014080: 6578 636c 7564 652d 6966 2d70 7265 7365  exclude-if-prese
+00014090: 6e74 222c 2022 4558 434c 5544 452e 7461  nt", "EXCLUDE.ta
+000140a0: 6722 2c0a 2020 2020 2020 2020 2020 2020  g",.            
+000140b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000140c0: 2022 2d2d 696e 636c 7564 6522 2c20 2274   "--include", "t
+000140d0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+000140e0: 2f31 2f31 7375 6231 2f31 7375 6231 7375  /1/1sub1/1sub1su
+000140f0: 6231 2f2a 222c 0a20 2020 2020 2020 2020  b1/*",.         
+00014100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014110: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00014120: 2022 2a2a 225d 290a 2020 2020 2020 2020   "**"]).        
+00014130: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
+00014140: 2020 2020 2020 2072 6573 746f 7265 5f70         restore_p
+00014150: 6174 6820 3d20 2274 6573 7466 696c 6573  ath = "testfiles
+00014160: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
+00014170: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
+00014180: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
+00014190: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
+000141a0: 6c69 7374 7328 7265 7374 6f72 655f 7061  lists(restore_pa
+000141b0: 7468 290a 2020 2020 2020 2020 7365 6c66  th).        self
+000141c0: 2e61 7373 6572 7445 7175 616c 2872 6573  .assertEqual(res
+000141d0: 746f 7265 642c 205b 5d29 0a0a 0a63 6c61  tored, [])...cla
+000141e0: 7373 2054 6573 744c 6f63 6b65 6446 6f6c  ss TestLockedFol
+000141f0: 6465 7273 4e6f 4572 726f 7228 496e 636c  dersNoError(Incl
+00014200: 7564 6545 7863 6c75 6465 4675 6e63 7469  udeExcludeFuncti
+00014210: 6f6e 616c 5465 7374 293a 0a20 2020 2022  onalTest):.    "
+00014220: 2222 2054 6869 7320 7465 7374 7320 7468  "" This tests th
+00014230: 6174 2069 6e61 6363 6573 7369 626c 6520  at inaccessible 
+00014240: 666f 6c64 6572 7320 646f 206e 6f74 2063  folders do not c
+00014250: 6175 7365 2061 6e20 6572 726f 7222 2222  ause an error"""
+00014260: 0a0a 2020 2020 4075 6e69 7474 6573 742e  ..    @unittest.
+00014270: 736b 6970 556e 6c65 7373 2870 6c61 7466  skipUnless(platf
+00014280: 6f72 6d2e 706c 6174 666f 726d 2829 2e73  orm.platform().s
+00014290: 7461 7274 7377 6974 6828 224c 696e 7578  tartswith("Linux
+000142a0: 2229 2c0a 2020 2020 2020 2020 2020 2020  "),.            
+000142b0: 2020 2020 2020 2020 2020 2020 2022 536b               "Sk
+000142c0: 6970 206f 6e20 6e6f 6e2d 4c69 6e75 7820  ip on non-Linux 
+000142d0: 7379 7374 656d 7322 290a 2020 2020 6465  systems").    de
+000142e0: 6620 7465 7374 5f6c 6f63 6b65 645f 6261  f test_locked_ba
+000142f0: 7365 6c69 6e65 2873 656c 6629 3a0a 2020  seline(self):.  
+00014300: 2020 2020 2020 2222 2220 5465 7374 206e        """ Test n
+00014310: 6f20 6572 726f 7220 6966 206c 6f63 6b65  o error if locke
+00014320: 6420 696e 2070 6174 6820 6275 7420 6578  d in path but ex
+00014330: 636c 7564 6564 2222 220a 2020 2020 2020  cluded""".      
+00014340: 2020 666f 6c64 6572 5f74 6f5f 6c6f 636b    folder_to_lock
+00014350: 203d 2022 7465 7374 6669 6c65 732f 7365   = "testfiles/se
+00014360: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
+00014370: 7562 3173 7562 3322 0a20 2020 2020 2020  ub1sub3".       
+00014380: 2069 6e69 7469 616c 5f6d 6f64 6520 3d20   initial_mode = 
+00014390: 6f73 2e73 7461 7428 666f 6c64 6572 5f74  os.stat(folder_t
+000143a0: 6f5f 6c6f 636b 292e 7374 5f6d 6f64 650a  o_lock).st_mode.
+000143b0: 2020 2020 2020 2020 6f73 2e63 686d 6f64          os.chmod
+000143c0: 2866 6f6c 6465 725f 746f 5f6c 6f63 6b2c  (folder_to_lock,
+000143d0: 2030 6f30 3030 3029 0a20 2020 2020 2020   0o0000).       
+000143e0: 2073 656c 662e 6261 636b 7570 2822 6675   self.backup("fu
+000143f0: 6c6c 222c 2022 7465 7374 6669 6c65 732f  ll", "testfiles/
+00014400: 7365 6c65 6374 322f 312f 3173 7562 3122  select2/1/1sub1"
+00014410: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00014420: 2020 2020 2020 6f70 7469 6f6e 733d 5b22        options=["
+00014430: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+00014440: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+00014450: 2f31 7375 6231 2f31 7375 6231 7375 6231  /1sub1/1sub1sub1
+00014460: 2f2a 222c 0a20 2020 2020 2020 2020 2020  /*",.           
+00014470: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014480: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+00014490: 2a2a 225d 290a 2020 2020 2020 2020 6f73  **"]).        os
+000144a0: 2e63 686d 6f64 2866 6f6c 6465 725f 746f  .chmod(folder_to
+000144b0: 5f6c 6f63 6b2c 2069 6e69 7469 616c 5f6d  _lock, initial_m
+000144c0: 6f64 6529 0a20 2020 2020 2020 2073 656c  ode).        sel
+000144d0: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
+000144e0: 2020 2020 7265 7374 6f72 655f 7061 7468      restore_path
+000144f0: 203d 2022 7465 7374 6669 6c65 732f 7265   = "testfiles/re
+00014500: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
+00014510: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
+00014520: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
+00014530: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
+00014540: 7473 2872 6573 746f 7265 5f70 6174 6829  ts(restore_path)
+00014550: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
+00014560: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
+00014570: 6564 2c20 5b5b 2231 7375 6231 7375 6231  ed, [["1sub1sub1
+00014580: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+00014590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000145a0: 2020 2020 2020 2020 5b22 3173 7562 3173          ["1sub1s
+000145b0: 7562 315f 6669 6c65 2e74 7874 225d 5d29  ub1_file.txt"]])
+000145c0: 0a0a 2020 2020 4075 6e69 7474 6573 742e  ..    @unittest.
+000145d0: 736b 6970 556e 6c65 7373 2870 6c61 7466  skipUnless(platf
+000145e0: 6f72 6d2e 706c 6174 666f 726d 2829 2e73  orm.platform().s
+000145f0: 7461 7274 7377 6974 6828 224c 696e 7578  tartswith("Linux
+00014600: 2229 2c0a 2020 2020 2020 2020 2020 2020  "),.            
+00014610: 2020 2020 2020 2020 2020 2020 2022 536b               "Sk
+00014620: 6970 206f 6e20 6e6f 6e2d 4c69 6e75 7820  ip on non-Linux 
+00014630: 7379 7374 656d 7322 290a 2020 2020 6465  systems").    de
+00014640: 6620 7465 7374 5f6c 6f63 6b65 645f 6578  f test_locked_ex
+00014650: 636c 5f69 665f 7072 6573 656e 7428 7365  cl_if_present(se
+00014660: 6c66 293a 0a20 2020 2020 2020 2022 2222  lf):.        """
+00014670: 2054 6573 7420 6e6f 2065 7272 6f72 2069   Test no error i
+00014680: 6620 6578 636c 7564 6564 206c 6f63 6b65  f excluded locke
+00014690: 6420 7769 7468 202d 2d65 7863 6c75 6465  d with --exclude
+000146a0: 2d69 662d 7072 6573 656e 7422 2222 0a20  -if-present""". 
+000146b0: 2020 2020 2020 2023 2052 6567 7265 7373         # Regress
+000146c0: 696f 6e20 7465 7374 2066 6f72 2042 7567  ion test for Bug
+000146d0: 2023 3136 3230 3038 350a 2020 2020 2020   #1620085.      
+000146e0: 2020 2320 6874 7470 733a 2f2f 6275 6773    # https://bugs
+000146f0: 2e6c 6175 6e63 6870 6164 2e6e 6574 2f64  .launchpad.net/d
+00014700: 7570 6c69 6369 7479 2f2b 6275 672f 3136  uplicity/+bug/16
+00014710: 3230 3038 350a 2020 2020 2020 2020 666f  20085.        fo
+00014720: 6c64 6572 5f74 6f5f 6c6f 636b 203d 2022  lder_to_lock = "
+00014730: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00014740: 322f 312f 3173 7562 312f 3173 7562 3173  2/1/1sub1/1sub1s
+00014750: 7562 3322 0a20 2020 2020 2020 2069 6e69  ub3".        ini
+00014760: 7469 616c 5f6d 6f64 6520 3d20 6f73 2e73  tial_mode = os.s
+00014770: 7461 7428 666f 6c64 6572 5f74 6f5f 6c6f  tat(folder_to_lo
+00014780: 636b 292e 7374 5f6d 6f64 650a 2020 2020  ck).st_mode.    
+00014790: 2020 2020 6f73 2e63 686d 6f64 2866 6f6c      os.chmod(fol
+000147a0: 6465 725f 746f 5f6c 6f63 6b2c 2030 6f30  der_to_lock, 0o0
+000147b0: 3030 3029 0a20 2020 2020 2020 2073 656c  000).        sel
+000147c0: 662e 6261 636b 7570 2822 6675 6c6c 222c  f.backup("full",
+000147d0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+000147e0: 6374 322f 312f 3173 7562 3122 2c0a 2020  ct2/1/1sub1",.  
+000147f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014800: 2020 6f70 7469 6f6e 733d 5b22 2d2d 6578    options=["--ex
+00014810: 636c 7564 652d 6966 2d70 7265 7365 6e74  clude-if-present
+00014820: 222c 2022 4558 434c 5544 452e 7461 6722  ", "EXCLUDE.tag"
+00014830: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00014840: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00014850: 2d2d 696e 636c 7564 6522 2c20 2274 6573  --include", "tes
+00014860: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+00014870: 2f31 7375 6231 2f31 7375 6231 7375 6231  /1sub1/1sub1sub1
+00014880: 2f2a 222c 0a20 2020 2020 2020 2020 2020  /*",.           
+00014890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000148a0: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+000148b0: 2a2a 225d 290a 2020 2020 2020 2020 6f73  **"]).        os
+000148c0: 2e63 686d 6f64 2866 6f6c 6465 725f 746f  .chmod(folder_to
+000148d0: 5f6c 6f63 6b2c 2069 6e69 7469 616c 5f6d  _lock, initial_m
+000148e0: 6f64 6529 0a20 2020 2020 2020 2073 656c  ode).        sel
+000148f0: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
+00014900: 2020 2020 7265 7374 6f72 655f 7061 7468      restore_path
+00014910: 203d 2022 7465 7374 6669 6c65 732f 7265   = "testfiles/re
+00014920: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
+00014930: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
+00014940: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
+00014950: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
+00014960: 7473 2872 6573 746f 7265 5f70 6174 6829  ts(restore_path)
+00014970: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
+00014980: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
+00014990: 6564 2c20 5b5b 2231 7375 6231 7375 6231  ed, [["1sub1sub1
+000149a0: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
+000149b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000149c0: 2020 2020 2020 2020 5b22 3173 7562 3173          ["1sub1s
+000149d0: 7562 315f 6669 6c65 2e74 7874 225d 5d29  ub1_file.txt"]])
+000149e0: 0a0a 0a63 6c61 7373 2054 6573 7446 6f6c  ...class TestFol
+000149f0: 6465 7249 6e63 6c75 6465 7346 696c 6573  derIncludesFiles
+00014a00: 2849 6e63 6c75 6465 4578 636c 7564 6546  (IncludeExcludeF
+00014a10: 756e 6374 696f 6e61 6c54 6573 7429 3a0a  unctionalTest):.
+00014a20: 2020 2020 2222 2220 5468 6973 2074 6573      """ This tes
+00014a30: 7473 2074 6861 7420 696e 636c 7564 696e  ts that includin
+00014a40: 6720 6120 666f 6c64 6572 2069 6e63 6c75  g a folder inclu
+00014a50: 6465 7320 7468 6520 6669 6c65 7320 7769  des the files wi
+00014a60: 7468 696e 2069 7422 2222 0a0a 2020 2020  thin it"""..    
+00014a70: 2320 6874 7470 733a 2f2f 6275 6773 2e6c  # https://bugs.l
+00014a80: 6175 6e63 6870 6164 2e6e 6574 2f64 7570  aunchpad.net/dup
+00014a90: 6c69 6369 7479 2f2b 6275 672f 3136 3234  licity/+bug/1624
+00014aa0: 3732 350a 0a20 2020 2064 6566 2074 6573  725..    def tes
+00014ab0: 745f 696e 636c 7564 6573 5f66 696c 6573  t_includes_files
+00014ac0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00014ad0: 2222 2254 6869 7320 7465 7374 7320 7468  """This tests th
+00014ae0: 6174 2069 6e63 6c75 6469 6e67 2061 2066  at including a f
+00014af0: 6f6c 6465 7220 696e 636c 7564 6573 2074  older includes t
+00014b00: 6865 2066 696c 6573 2077 6974 6869 6e20  he files within 
+00014b10: 6974 2222 220a 2020 2020 2020 2020 7365  it""".        se
+00014b20: 6c66 2e62 6163 6b75 7028 2266 756c 6c22  lf.backup("full"
+00014b30: 2c20 2274 6573 7466 696c 6573 2f73 656c  , "testfiles/sel
+00014b40: 6563 7432 2f31 2f31 7375 6231 222c 0a20  ect2/1/1sub1",. 
+00014b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014b60: 2020 206f 7074 696f 6e73 3d5b 222d 2d69     options=["--i
+00014b70: 6e63 6c75 6465 222c 2022 7465 7374 6669  nclude", "testfi
+00014b80: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+00014b90: 7562 312f 3173 7562 3173 7562 3122 2c0a  ub1/1sub1sub1",.
+00014ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014bb0: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00014bc0: 6578 636c 7564 6522 2c20 222a 2a22 5d29  exclude", "**"])
+00014bd0: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+00014be0: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
+00014bf0: 7265 7374 6f72 655f 7061 7468 203d 2022  restore_path = "
+00014c00: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
+00014c10: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
+00014c20: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
+00014c30: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
+00014c40: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
+00014c50: 6573 746f 7265 5f70 6174 6829 0a20 2020  estore_path).   
+00014c60: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
+00014c70: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
+00014c80: 5b5b 2231 7375 6231 7375 6231 225d 2c0a  [["1sub1sub1"],.
+00014c90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014cb0: 2020 2020 5b22 3173 7562 3173 7562 315f      ["1sub1sub1_
+00014cc0: 6669 6c65 2e74 7874 225d 5d29 0a0a 2020  file.txt"]])..  
+00014cd0: 2020 6465 6620 7465 7374 5f69 6e63 6c75    def test_inclu
+00014ce0: 6465 735f 6669 6c65 735f 7472 6169 6c69  des_files_traili
+00014cf0: 6e67 5f73 6c61 7368 2873 656c 6629 3a0a  ng_slash(self):.
+00014d00: 2020 2020 2020 2020 2222 2254 6869 7320          """This 
+00014d10: 7465 7374 7320 7468 6174 2069 6e63 6c75  tests that inclu
+00014d20: 6469 6e67 2061 2066 6f6c 6465 7220 696e  ding a folder in
+00014d30: 636c 7564 6573 2074 6865 2066 696c 6573  cludes the files
+00014d40: 2077 6974 6869 6e20 6974 2222 220a 2020   within it""".  
+00014d50: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
+00014d60: 7028 2266 756c 6c22 2c20 2274 6573 7466  p("full", "testf
+00014d70: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+00014d80: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
+00014d90: 2020 2020 2020 2020 2020 206f 7074 696f             optio
+00014da0: 6e73 3d5b 222d 2d69 6e63 6c75 6465 222c  ns=["--include",
+00014db0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00014dc0: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
+00014dd0: 3173 7562 312f 222c 0a20 2020 2020 2020  1sub1/",.       
+00014de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014df0: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+00014e00: 222c 2022 2a2a 225d 290a 2020 2020 2020  ", "**"]).      
+00014e10: 2020 7365 6c66 2e72 6573 746f 7265 2829    self.restore()
+00014e20: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
+00014e30: 5f70 6174 6820 3d20 2274 6573 7466 696c  _path = "testfil
+00014e40: 6573 2f72 6573 746f 7265 5f6f 7574 220a  es/restore_out".
+00014e50: 2020 2020 2020 2020 7265 7374 6f72 6564          restored
+00014e60: 203d 2073 656c 662e 6469 7265 6374 6f72   = self.director
+00014e70: 795f 7472 6565 5f74 6f5f 6c69 7374 5f6f  y_tree_to_list_o
+00014e80: 665f 6c69 7374 7328 7265 7374 6f72 655f  f_lists(restore_
+00014e90: 7061 7468 290a 2020 2020 2020 2020 7365  path).        se
+00014ea0: 6c66 2e61 7373 6572 7445 7175 616c 2872  lf.assertEqual(r
+00014eb0: 6573 746f 7265 642c 205b 5b22 3173 7562  estored, [["1sub
+00014ec0: 3173 7562 3122 5d2c 0a20 2020 2020 2020  1sub1"],.       
+00014ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014ee0: 2020 2020 2020 2020 2020 2020 205b 2231               ["1
+00014ef0: 7375 6231 7375 6231 5f66 696c 652e 7478  sub1sub1_file.tx
+00014f00: 7422 5d5d 290a 0a20 2020 2064 6566 2074  t"]])..    def t
+00014f10: 6573 745f 696e 636c 7564 6573 5f66 696c  est_includes_fil
+00014f20: 6573 5f74 7261 696c 696e 675f 736c 6173  es_trailing_slas
+00014f30: 685f 676c 6f62 6269 6e67 5f63 6861 7273  h_globbing_chars
+00014f40: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00014f50: 2222 2254 6573 7473 2066 6f6c 6465 7220  """Tests folder 
+00014f60: 696e 636c 7564 6573 2077 6974 6820 676c  includes with gl
+00014f70: 6f62 6269 6e67 2063 6861 7220 616e 6420  obbing char and 
+00014f80: 2f22 2222 0a20 2020 2020 2020 2073 656c  /""".        sel
+00014f90: 662e 6261 636b 7570 2822 6675 6c6c 222c  f.backup("full",
+00014fa0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+00014fb0: 6374 322f 312f 3173 7562 3122 2c0a 2020  ct2/1/1sub1",.  
+00014fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014fd0: 2020 6f70 7469 6f6e 733d 5b22 2d2d 696e    options=["--in
+00014fe0: 636c 7564 6522 2c20 2274 6573 7466 696c  clude", "testfil
+00014ff0: 6573 2f73 3f6c 6563 7432 2f31 2f31 7375  es/s?lect2/1/1su
+00015000: 6231 2f31 7375 6231 7375 6231 2f22 2c0a  b1/1sub1sub1/",.
+00015010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015020: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00015030: 6578 636c 7564 6522 2c20 222a 2a22 5d29  exclude", "**"])
+00015040: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+00015050: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
+00015060: 7265 7374 6f72 655f 7061 7468 203d 2022  restore_path = "
+00015070: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
+00015080: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
+00015090: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
+000150a0: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
+000150b0: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
+000150c0: 6573 746f 7265 5f70 6174 6829 0a20 2020  estore_path).   
+000150d0: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
+000150e0: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
+000150f0: 5b5b 2231 7375 6231 7375 6231 225d 2c0a  [["1sub1sub1"],.
+00015100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015120: 2020 2020 5b22 3173 7562 3173 7562 315f      ["1sub1sub1_
+00015130: 6669 6c65 2e74 7874 225d 5d29 0a0a 2020  file.txt"]])..  
+00015140: 2020 6465 6620 7465 7374 5f65 7863 6c75    def test_exclu
+00015150: 6465 735f 6669 6c65 735f 6e6f 5f74 7261  des_files_no_tra
+00015160: 696c 696e 675f 736c 6173 6828 7365 6c66  iling_slash(self
+00015170: 293a 0a20 2020 2020 2020 2022 2222 5468  ):.        """Th
+00015180: 6973 2074 6573 7473 2074 6861 7420 6578  is tests that ex
+00015190: 636c 7564 696e 6720 6120 666f 6c64 6572  cluding a folder
+000151a0: 2065 7863 6c75 6465 7320 7468 6520 6669   excludes the fi
+000151b0: 6c65 7320 7769 7468 696e 2069 7422 2222  les within it"""
+000151c0: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
+000151d0: 636b 7570 2822 6675 6c6c 222c 2022 7465  ckup("full", "te
+000151e0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+000151f0: 312f 3173 7562 3122 2c0a 2020 2020 2020  1/1sub1",.      
+00015200: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+00015210: 7469 6f6e 733d 5b22 2d2d 6578 636c 7564  tions=["--exclud
+00015220: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00015230: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
+00015240: 7375 6231 7375 6231 222c 0a20 2020 2020  sub1sub1",.     
+00015250: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015260: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+00015270: 6465 222c 2022 7465 7374 6669 6c65 732f  de", "testfiles/
+00015280: 7365 6c65 6374 322f 312f 3173 7562 312f  select2/1/1sub1/
+00015290: 3173 7562 3173 7562 3222 2c0a 2020 2020  1sub1sub2",.    
+000152a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000152b0: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+000152c0: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+000152d0: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
+000152e0: 2f31 7375 6231 7375 6233 222c 0a20 2020  /1sub1sub3",.   
+000152f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015300: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+00015310: 6c75 6465 222c 2022 7465 7374 6669 6c65  lude", "testfile
+00015320: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
+00015330: 312f 3173 7562 312a 2a22 2c0a 2020 2020  1/1sub1**",.    
+00015340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015350: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00015360: 7564 6522 2c20 2274 6573 7466 696c 6573  ude", "testfiles
+00015370: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
+00015380: 2f69 7272 656c 6576 616e 742e 7478 7422  /irrelevant.txt"
+00015390: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
+000153a0: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
+000153b0: 2020 7265 7374 6f72 655f 7061 7468 203d    restore_path =
+000153c0: 2022 7465 7374 6669 6c65 732f 7265 7374   "testfiles/rest
+000153d0: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
+000153e0: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
+000153f0: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
+00015400: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
+00015410: 2872 6573 746f 7265 5f70 6174 6829 0a20  (restore_path). 
+00015420: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
+00015430: 7274 4571 7561 6c28 7265 7374 6f72 6564  rtEqual(restored
+00015440: 2c20 5b5d 290a 0a20 2020 2064 6566 2074  , [])..    def t
+00015450: 6573 745f 6578 636c 7564 6573 5f66 696c  est_excludes_fil
+00015460: 6573 5f74 7261 696c 696e 675f 736c 6173  es_trailing_slas
+00015470: 6828 7365 6c66 293a 0a20 2020 2020 2020  h(self):.       
+00015480: 2022 2222 4578 636c 7564 696e 6720 6120   """Excluding a 
+00015490: 666f 6c64 6572 2065 7863 6c75 6465 7320  folder excludes 
+000154a0: 7468 6520 6669 6c65 7320 7769 7468 696e  the files within
+000154b0: 2069 742c 2069 6620 656e 6473 2077 6974   it, if ends wit
+000154c0: 6820 2f22 2222 0a20 2020 2020 2020 2073  h /""".        s
+000154d0: 656c 662e 6261 636b 7570 2822 6675 6c6c  elf.backup("full
+000154e0: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+000154f0: 6c65 6374 322f 312f 3173 7562 3122 2c0a  lect2/1/1sub1",.
+00015500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015510: 2020 2020 6f70 7469 6f6e 733d 5b22 2d2d      options=["--
+00015520: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+00015530: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+00015540: 7375 6231 2f31 7375 6231 7375 6231 2f22  sub1/1sub1sub1/"
+00015550: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00015560: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00015570: 2d2d 6578 636c 7564 6522 2c20 2274 6573  --exclude", "tes
+00015580: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+00015590: 2f31 7375 6231 2f31 7375 6231 7375 6232  /1sub1/1sub1sub2
+000155a0: 2f22 2c0a 2020 2020 2020 2020 2020 2020  /",.            
+000155b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000155c0: 2022 2d2d 6578 636c 7564 6522 2c20 2274   "--exclude", "t
+000155d0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+000155e0: 2f31 2f31 7375 6231 2f31 7375 6231 7375  /1/1sub1/1sub1su
+000155f0: 6233 2f22 2c0a 2020 2020 2020 2020 2020  b3/",.          
+00015600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015610: 2020 2022 2d2d 696e 636c 7564 6522 2c20     "--include", 
+00015620: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00015630: 7432 2f31 2f31 7375 6231 2f31 7375 6231  t2/1/1sub1/1sub1
+00015640: 2a2a 222c 0a20 2020 2020 2020 2020 2020  **",.           
+00015650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015660: 2020 222d 2d65 7863 6c75 6465 222c 2022    "--exclude", "
+00015670: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
+00015680: 322f 312f 3173 7562 312f 6972 7265 6c65  2/1/1sub1/irrele
+00015690: 7661 6e74 2e74 7874 225d 290a 2020 2020  vant.txt"]).    
+000156a0: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
+000156b0: 2829 0a20 2020 2020 2020 2072 6573 746f  ().        resto
+000156c0: 7265 5f70 6174 6820 3d20 2274 6573 7466  re_path = "testf
+000156d0: 696c 6573 2f72 6573 746f 7265 5f6f 7574  iles/restore_out
+000156e0: 220a 2020 2020 2020 2020 7265 7374 6f72  ".        restor
+000156f0: 6564 203d 2073 656c 662e 6469 7265 6374  ed = self.direct
+00015700: 6f72 795f 7472 6565 5f74 6f5f 6c69 7374  ory_tree_to_list
+00015710: 5f6f 665f 6c69 7374 7328 7265 7374 6f72  _of_lists(restor
+00015720: 655f 7061 7468 290a 2020 2020 2020 2020  e_path).        
+00015730: 7365 6c66 2e61 7373 6572 7445 7175 616c  self.assertEqual
+00015740: 2872 6573 746f 7265 642c 205b 5d29 0a0a  (restored, [])..
+00015750: 2020 2020 6465 6620 7465 7374 5f65 7863      def test_exc
+00015760: 6c75 6465 735f 6669 6c65 735f 7472 6169  ludes_files_trai
+00015770: 6c69 6e67 5f73 6c61 7368 5f67 6c6f 6262  ling_slash_globb
+00015780: 696e 675f 6368 6172 7328 7365 6c66 293a  ing_chars(self):
+00015790: 0a20 2020 2020 2020 2022 2222 5465 7374  .        """Test
+000157a0: 7320 666f 6c64 6572 2065 7863 6c75 6465  s folder exclude
+000157b0: 7320 7769 7468 2067 6c6f 6262 696e 6720  s with globbing 
+000157c0: 6368 6172 2061 6e64 202f 2222 220a 2020  char and /""".  
+000157d0: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
+000157e0: 7028 2266 756c 6c22 2c20 2274 6573 7466  p("full", "testf
+000157f0: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+00015800: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
+00015810: 2020 2020 2020 2020 2020 206f 7074 696f             optio
+00015820: 6e73 3d5b 222d 2d65 7863 6c75 6465 222c  ns=["--exclude",
+00015830: 2022 7465 7374 6669 6c65 732f 7365 6c3f   "testfiles/sel?
+00015840: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
+00015850: 3173 7562 312f 222c 0a20 2020 2020 2020  1sub1/",.       
+00015860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015870: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+00015880: 222c 2022 7465 7374 6669 6c65 732f 7365  ", "testfiles/se
+00015890: 6c5b 652c 665d 6374 322f 312f 3173 7562  l[e,f]ct2/1/1sub
+000158a0: 312f 3173 7562 3173 7562 322f 222c 0a20  1/1sub1sub2/",. 
+000158b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000158c0: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+000158d0: 7863 6c75 6465 222c 2022 7465 7374 6669  xclude", "testfi
+000158e0: 6c65 732f 7365 6c2a 7432 2f31 2f31 7375  les/sel*t2/1/1su
+000158f0: 6231 2f31 7375 6231 7375 6233 2f22 2c0a  b1/1sub1sub3/",.
+00015900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015910: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00015920: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+00015930: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+00015940: 7375 6231 2f31 7375 6231 2a2a 222c 0a20  sub1/1sub1**",. 
+00015950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015960: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00015970: 7863 6c75 6465 222c 2022 7465 7374 6669  xclude", "testfi
+00015980: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
+00015990: 7562 312f 6972 7265 6c65 7661 6e74 2e74  ub1/irrelevant.t
+000159a0: 7874 225d 290a 2020 2020 2020 2020 7365  xt"]).        se
+000159b0: 6c66 2e72 6573 746f 7265 2829 0a20 2020  lf.restore().   
+000159c0: 2020 2020 2072 6573 746f 7265 5f70 6174       restore_pat
+000159d0: 6820 3d20 2274 6573 7466 696c 6573 2f72  h = "testfiles/r
+000159e0: 6573 746f 7265 5f6f 7574 220a 2020 2020  estore_out".    
+000159f0: 2020 2020 7265 7374 6f72 6564 203d 2073      restored = s
+00015a00: 656c 662e 6469 7265 6374 6f72 795f 7472  elf.directory_tr
+00015a10: 6565 5f74 6f5f 6c69 7374 5f6f 665f 6c69  ee_to_list_of_li
+00015a20: 7374 7328 7265 7374 6f72 655f 7061 7468  sts(restore_path
+00015a30: 290a 2020 2020 2020 2020 7365 6c66 2e61  ).        self.a
+00015a40: 7373 6572 7445 7175 616c 2872 6573 746f  ssertEqual(resto
+00015a50: 7265 642c 205b 5d29 0a0a 0a63 6c61 7373  red, [])...class
+00015a60: 2054 6573 7441 6273 6f6c 7574 6550 6174   TestAbsolutePat
+00015a70: 6873 2849 6e63 6c75 6465 4578 636c 7564  hs(IncludeExclud
+00015a80: 6546 756e 6374 696f 6e61 6c54 6573 7429  eFunctionalTest)
+00015a90: 3a0a 2020 2020 2222 2220 5465 7374 7320  :.    """ Tests 
+00015aa0: 696e 636c 7564 652f 6578 636c 7564 6520  include/exclude 
+00015ab0: 6f70 7469 6f6e 7320 7769 7468 2061 6273  options with abs
+00015ac0: 6f6c 7574 6520 7061 7468 7322 2222 0a0a  olute paths"""..
+00015ad0: 2020 2020 6465 6620 7465 7374 5f61 6273      def test_abs
+00015ae0: 6f6c 7574 655f 7061 7468 735f 6e6f 6e5f  olute_paths_non_
+00015af0: 676c 6f62 6269 6e67 2873 656c 6629 3a0a  globbing(self):.
+00015b00: 2020 2020 2020 2020 2222 2220 5465 7374          """ Test
+00015b10: 202d 2d69 6e63 6c75 6465 2061 6e64 202d   --include and -
+00015b20: 2d65 7863 6c75 6465 2077 6f72 6b20 7769  -exclude work wi
+00015b30: 7468 2061 6273 6f6c 7574 6520 7061 7468  th absolute path
+00015b40: 7322 2222 0a20 2020 2020 2020 2073 656c  s""".        sel
+00015b50: 662e 6261 636b 7570 2822 6675 6c6c 222c  f.backup("full",
+00015b60: 206f 732e 7061 7468 2e61 6273 7061 7468   os.path.abspath
+00015b70: 2822 7465 7374 6669 6c65 732f 7365 6c65  ("testfiles/sele
+00015b80: 6374 3222 292c 0a20 2020 2020 2020 2020  ct2"),.         
+00015b90: 2020 2020 2020 2020 2020 206f 7074 696f             optio
+00015ba0: 6e73 3d5b 222d 2d69 6e63 6c75 6465 222c  ns=["--include",
+00015bb0: 206f 732e 7061 7468 2e61 6273 7061 7468   os.path.abspath
+00015bc0: 2822 7465 7374 6669 6c65 732f 7365 6c65  ("testfiles/sele
+00015bd0: 6374 322f 332f 3373 7562 332f 3373 7562  ct2/3/3sub3/3sub
+00015be0: 3373 7562 322f 3373 7562 3373 7562 325f  3sub2/3sub3sub2_
+00015bf0: 6669 6c65 2e74 7874 2229 2c0a 2020 2020  file.txt"),.    
+00015c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015c10: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00015c20: 7564 6522 2c20 6f73 2e70 6174 682e 6162  ude", os.path.ab
+00015c30: 7370 6174 6828 2274 6573 7466 696c 6573  spath("testfiles
+00015c40: 2f73 656c 6563 7432 2f33 2f33 7375 6233  /select2/3/3sub3
+00015c50: 2f33 7375 6233 7375 6232 2229 2c0a 2020  /3sub3sub2"),.  
+00015c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015c70: 2020 2020 2020 2020 2020 2022 2d2d 696e             "--in
+00015c80: 636c 7564 6522 2c20 6f73 2e70 6174 682e  clude", os.path.
+00015c90: 6162 7370 6174 6828 2274 6573 7466 696c  abspath("testfil
+00015ca0: 6573 2f73 656c 6563 7432 2f33 2f33 7375  es/select2/3/3su
+00015cb0: 6232 2f33 7375 6232 7375 6232 2229 2c0a  b2/3sub2sub2"),.
+00015cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015cd0: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00015ce0: 696e 636c 7564 6522 2c20 6f73 2e70 6174  include", os.pat
+00015cf0: 682e 6162 7370 6174 6828 2274 6573 7466  h.abspath("testf
+00015d00: 696c 6573 2f73 656c 6563 7432 2f33 2f33  iles/select2/3/3
+00015d10: 7375 6233 2229 2c0a 2020 2020 2020 2020  sub3"),.        
+00015d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015d30: 2020 2020 2022 2d2d 6578 636c 7564 6522       "--exclude"
+00015d40: 2c20 6f73 2e70 6174 682e 6162 7370 6174  , os.path.abspat
+00015d50: 6828 2274 6573 7466 696c 6573 2f73 656c  h("testfiles/sel
+00015d60: 6563 7432 2f33 2f33 7375 6231 2229 2c0a  ect2/3/3sub1"),.
+00015d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015d80: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00015d90: 6578 636c 7564 6522 2c20 6f73 2e70 6174  exclude", os.pat
+00015da0: 682e 6162 7370 6174 6828 2274 6573 7466  h.abspath("testf
+00015db0: 696c 6573 2f73 656c 6563 7432 2f32 2f32  iles/select2/2/2
+00015dc0: 7375 6231 2f32 7375 6231 7375 6233 2229  sub1/2sub1sub3")
+00015dd0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00015de0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00015df0: 2d2d 6578 636c 7564 6522 2c20 6f73 2e70  --exclude", os.p
+00015e00: 6174 682e 6162 7370 6174 6828 2274 6573  ath.abspath("tes
+00015e10: 7466 696c 6573 2f73 656c 6563 7432 2f32  tfiles/select2/2
+00015e20: 2f32 7375 6231 2f32 7375 6231 7375 6232  /2sub1/2sub1sub2
+00015e30: 2229 2c0a 2020 2020 2020 2020 2020 2020  "),.            
+00015e40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015e50: 2022 2d2d 696e 636c 7564 6522 2c20 6f73   "--include", os
+00015e60: 2e70 6174 682e 6162 7370 6174 6828 2274  .path.abspath("t
+00015e70: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+00015e80: 2f32 2f32 7375 6231 2229 2c0a 2020 2020  /2/2sub1"),.    
+00015e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015ea0: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00015eb0: 7564 6522 2c20 6f73 2e70 6174 682e 6162  ude", os.path.ab
+00015ec0: 7370 6174 6828 2274 6573 7466 696c 6573  spath("testfiles
+00015ed0: 2f73 656c 6563 7432 2f31 2f31 7375 6233  /select2/1/1sub3
+00015ee0: 2f31 7375 6233 7375 6232 2229 2c0a 2020  /1sub3sub2"),.  
+00015ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015f00: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00015f10: 636c 7564 6522 2c20 6f73 2e70 6174 682e  clude", os.path.
+00015f20: 6162 7370 6174 6828 2274 6573 7466 696c  abspath("testfil
+00015f30: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
+00015f40: 6233 2f31 7375 6233 7375 6231 2229 2c0a  b3/1sub3sub1"),.
+00015f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015f60: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00015f70: 6578 636c 7564 6522 2c20 6f73 2e70 6174  exclude", os.pat
+00015f80: 682e 6162 7370 6174 6828 2274 6573 7466  h.abspath("testf
+00015f90: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
+00015fa0: 7375 6232 2f31 7375 6232 7375 6233 2229  sub2/1sub2sub3")
+00015fb0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00015fc0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00015fd0: 2d2d 696e 636c 7564 6522 2c20 6f73 2e70  --include", os.p
+00015fe0: 6174 682e 6162 7370 6174 6828 2274 6573  ath.abspath("tes
+00015ff0: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
+00016000: 2f31 7375 6232 2f31 7375 6232 7375 6231  /1sub2/1sub2sub1
+00016010: 2229 2c0a 2020 2020 2020 2020 2020 2020  "),.            
+00016020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016030: 2022 2d2d 6578 636c 7564 6522 2c20 6f73   "--exclude", os
+00016040: 2e70 6174 682e 6162 7370 6174 6828 2274  .path.abspath("t
+00016050: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
+00016060: 2f31 2f31 7375 6231 2f31 7375 6231 7375  /1/1sub1/1sub1su
+00016070: 6233 2f31 7375 6231 7375 6233 5f66 696c  b3/1sub1sub3_fil
+00016080: 652e 7478 7422 292c 0a20 2020 2020 2020  e.txt"),.       
 00016090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000160a0: 2020 2020 2020 2020 2020 2075 222d 2d65             u"--e
-000160b0: 7863 6c75 6465 222c 2075 2274 6573 7466  xclude", u"testf
-000160c0: 696c 6573 2f73 656c 6563 7432 2f2a 2f33  iles/select2/*/3
-000160d0: 732a 3122 2c20 2023 204e 6f74 6520 2a20  s*1",  # Note * 
-000160e0: 6164 6465 6420 696e 2062 6f74 6820 6469  added in both di
-000160f0: 7265 6374 6f72 7920 616e 6420 6669 6c65  rectory and file
-00016100: 6e61 6d65 0a20 2020 2020 2020 2020 2020  name.           
-00016110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016120: 2020 7522 2d2d 6578 636c 7564 6522 2c20    u"--exclude", 
-00016130: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00016140: 6374 322f 2a2a 2f32 7375 6231 7375 6233  ct2/**/2sub1sub3
-00016150: 222c 2020 2320 4e6f 7465 202a 2a20 6164  ",  # Note ** ad
-00016160: 6465 640a 2020 2020 2020 2020 2020 2020  ded.            
-00016170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016180: 2075 222d 2d65 7863 6c75 6465 222c 2075   u"--exclude", u
-00016190: 2269 676e 6f72 6563 6173 653a 7465 7374  "ignorecase:test
-000161a0: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-000161b0: 3273 7562 312f 3253 7562 3153 7562 3222  2sub1/2Sub1Sub2"
-000161c0: 2c20 2023 204e 6f74 6520 6967 6e6f 7265  ,  # Note ignore
-000161d0: 6361 7365 2061 6464 6564 0a20 2020 2020  case added.     
-000161e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000161f0: 2020 2020 2020 2020 7522 2d2d 696e 636c          u"--incl
-00016200: 7564 6522 2c20 7522 6967 6e6f 7265 6361  ude", u"ignoreca
-00016210: 7365 3a74 6573 7466 696c 6573 2f73 656c  se:testfiles/sel
-00016220: 5b77 2c75 2c65 2c71 5d63 7432 2f32 2f32  [w,u,e,q]ct2/2/2
-00016230: 533f 6231 222c 2020 2020 2320 4e6f 7465  S?b1",    # Note
-00016240: 2069 676e 6f72 6563 6173 652c 205b 5d20   ignorecase, [] 
-00016250: 616e 640a 2020 2020 2020 2020 2020 2020  and.            
-00016260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016270: 2023 203f 2061 6464 6564 0a20 2020 2020   # ? added.     
-00016280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016290: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-000162a0: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-000162b0: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-000162c0: 332f 3173 5b77 2c75 2c70 2c71 5d62 3373  3/1s[w,u,p,q]b3s
-000162d0: 7562 3222 2c20 2023 204e 6f74 6520 5b5d  ub2",  # Note []
-000162e0: 2061 6464 6564 0a20 2020 2020 2020 2020   added.         
-000162f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016300: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-00016310: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00016320: 6c65 6374 322f 312f 3173 7562 5b31 2d34  lect2/1/1sub[1-4
-00016330: 5d2f 3173 7562 3373 7562 3122 2c20 2023  ]/1sub3sub1",  #
-00016340: 204e 6f74 6520 5b72 616e 6765 5d20 6164   Note [range] ad
-00016350: 6465 640a 2020 2020 2020 2020 2020 2020  ded.            
-00016360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016370: 2075 222d 2d69 6e63 6c75 6465 222c 2075   u"--include", u
-00016380: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00016390: 7432 2f2a 2f31 7375 6232 2f31 735b 772c  t2/*/1sub2/1s[w,
-000163a0: 752c 702c 715d 6232 7375 6231 222c 2020  u,p,q]b2sub1",  
-000163b0: 2320 4e6f 7465 202a 2061 6e64 205b 5d20  # Note * and [] 
-000163c0: 6164 6465 640a 2020 2020 2020 2020 2020  added.          
-000163d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000163e0: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-000163f0: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00016400: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
-00016410: 6231 7375 6233 2f31 7375 3f31 7375 6233  b1sub3/1su?1sub3
-00016420: 5f66 696c 652e 7478 7422 2c20 2023 204e  _file.txt",  # N
-00016430: 6f74 6520 3f20 6164 6465 640a 2020 2020  ote ? added.    
-00016440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016450: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00016460: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00016470: 6573 2f73 656c 6563 7432 2f31 2f31 2a31  es/select2/1/1*1
-00016480: 2f31 7375 6231 7375 6232 222c 2020 2320  /1sub1sub2",  # 
-00016490: 4e6f 7465 202a 2061 6464 6564 0a20 2020  Note * added.   
-000164a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000164b0: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-000164c0: 636c 7564 6522 2c20 7522 7465 7374 6669  clude", u"testfi
-000164d0: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-000164e0: 7562 3222 2c0a 2020 2020 2020 2020 2020  ub2",.          
-000164f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016500: 2020 2075 222d 2d69 6e63 6c75 6465 222c     u"--include",
-00016510: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00016520: 6563 745b 322d 345d 2f2a 2e70 7922 2c20  ect[2-4]/*.py", 
-00016530: 2023 204e 6f74 6520 2a20 616e 6420 5b72   # Note * and [r
-00016540: 616e 6765 5d20 6164 6465 640a 2020 2020  ange] added.    
-00016550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016560: 2020 2020 2020 2020 2075 222d 2d69 6e63           u"--inc
-00016570: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00016580: 6573 2f2a 322f 3322 2c20 2023 204e 6f74  es/*2/3",  # Not
-00016590: 6520 2a20 6164 6465 640a 2020 2020 2020  e * added.      
-000165a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000165b0: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-000165c0: 6465 222c 2075 222a 2a2f 7365 6c65 6374  de", u"**/select
-000165d0: 322f 3122 2c20 2023 204e 6f74 6520 2a2a  2/1",  # Note **
-000165e0: 2061 6464 6564 0a20 2020 2020 2020 2020   added.         
-000165f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016600: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-00016610: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00016620: 6c65 6374 322f 2a2a 225d 290a 2020 2020  lect2/**"]).    
-00016630: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
-00016640: 2829 0a20 2020 2020 2020 2072 6573 746f  ().        resto
-00016650: 7265 5f64 6972 203d 2075 2274 6573 7466  re_dir = u"testf
-00016660: 696c 6573 2f72 6573 746f 7265 5f6f 7574  iles/restore_out
-00016670: 220a 2020 2020 2020 2020 7265 7374 6f72  ".        restor
-00016680: 6564 203d 2073 656c 662e 6469 7265 6374  ed = self.direct
-00016690: 6f72 795f 7472 6565 5f74 6f5f 6c69 7374  ory_tree_to_list
-000166a0: 5f6f 665f 6c69 7374 7328 7265 7374 6f72  _of_lists(restor
-000166b0: 655f 6469 7229 0a20 2020 2020 2020 2073  e_dir).        s
-000166c0: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
-000166d0: 7265 7374 6f72 6564 2c20 7365 6c66 2e65  restored, self.e
-000166e0: 7870 6563 7465 645f 7265 7374 6f72 6564  xpected_restored
-000166f0: 5f74 7265 6529 0a0a 2020 2020 6465 6620  _tree)..    def 
-00016700: 7465 7374 5f67 6c6f 6262 696e 675f 7265  test_globbing_re
-00016710: 706c 6163 656d 656e 745f 696e 5f69 6e63  placement_in_inc
-00016720: 6c75 6465 735f 7573 696e 675f 6669 6c74  ludes_using_filt
-00016730: 6572 5f69 676e 6f72 6563 6173 6528 7365  er_ignorecase(se
-00016740: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00016750: 2220 5465 7374 2062 6568 6176 696f 7572  " Test behaviour
-00016760: 206f 6620 7468 6520 6578 7465 6e64 6564   of the extended
-00016770: 2073 6865 6c6c 2067 6c6f 6262 696e 6720   shell globbing 
-00016780: 7061 7474 6572 6e20 7265 706c 6163 656d  pattern replacem
-00016790: 656e 7420 6675 6e63 7469 6f6e 7320 696e  ent functions in
-000167a0: 2062 6f74 6820 696e 636c 7564 6520 616e   both include an
-000167b0: 6420 6578 636c 7564 652e 0a20 2020 2020  d exclude..     
-000167c0: 2020 2073 616d 6520 7465 7374 2061 7320     same test as 
-000167d0: 6162 6f76 652c 2062 7574 2069 6d70 6c65  above, but imple
-000167e0: 6d65 6e74 6564 2075 7369 6e67 202d 2d66  mented using --f
-000167f0: 696c 7465 722d 2a63 6173 6520 696e 7374  ilter-*case inst
-00016800: 6561 6420 6f66 2074 6865 2069 676e 6f72  ead of the ignor
-00016810: 6563 6173 6520 7072 6566 6978 2e0a 2020  ecase prefix..  
-00016820: 2020 2020 2020 2222 220a 2020 2020 2020        """.      
-00016830: 2020 2320 4964 656e 7469 6361 6c20 746f    # Identical to
-00016840: 2074 6573 745f 696e 636c 7564 655f 6578   test_include_ex
-00016850: 636c 7564 655f 6261 7369 6320 7769 7468  clude_basic with
-00016860: 2067 6c6f 6262 696e 6720 6368 6172 6163   globbing charac
-00016870: 7465 7273 2061 6464 6564 2074 6f20 626f  ters added to bo
-00016880: 7468 2069 6e63 6c75 6465 2061 6e64 2065  th include and e
-00016890: 7863 6c75 6465 206c 696e 6573 0a20 2020  xclude lines.   
-000168a0: 2020 2020 2023 2045 7868 6962 6974 7320       # Exhibits 
-000168b0: 7468 6520 6973 7375 6520 7265 706f 7274  the issue report
-000168c0: 6564 2069 6e20 4275 6720 2338 3834 3337  ed in Bug #88437
-000168d0: 3120 2868 7474 7073 3a2f 2f62 7567 732e  1 (https://bugs.
-000168e0: 6c61 756e 6368 7061 642e 6e65 742f 6475  launchpad.net/du
-000168f0: 706c 6963 6974 792f 2b62 7567 2f38 3834  plicity/+bug/884
-00016900: 3337 3129 2e0a 2020 2020 2020 2020 2320  371)..        # 
-00016910: 5365 6520 6162 6f76 6520 616e 6420 7468  See above and th
-00016920: 6520 756e 6974 2074 6573 7473 2066 6f72  e unit tests for
-00016930: 206d 6f72 6520 6772 616e 756c 6172 6974   more granularit
-00016940: 7920 6f6e 2074 6865 2069 7373 7565 2e0a  y on the issue..
-00016950: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
-00016960: 6b75 7028 7522 6675 6c6c 222c 2075 2274  kup(u"full", u"t
-00016970: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00016980: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00016990: 2020 2020 2020 206f 7074 696f 6e73 3d5b         options=[
-000169a0: 7522 2d2d 696e 636c 7564 6522 2c20 7522  u"--include", u"
-000169b0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-000169c0: 322f 2a2a 2f33 7375 6233 7375 6232 2f33  2/**/3sub3sub2/3
-000169d0: 7375 6233 7375 3f32 5f66 696c 652e 7478  sub3su?2_file.tx
-000169e0: 7422 2c20 2023 204e 6f74 6520 2a2a 2061  t",  # Note ** a
-000169f0: 6e64 203f 2061 6464 6564 0a20 2020 2020  nd ? added.     
-00016a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016a10: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-00016a20: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-00016a30: 732f 7365 6c65 6374 322f 2a2f 3373 2a31  s/select2/*/3s*1
-00016a40: 222c 2020 2320 4e6f 7465 202a 2061 6464  ",  # Note * add
-00016a50: 6564 2069 6e20 626f 7468 2064 6972 6563  ed in both direc
-00016a60: 746f 7279 2061 6e64 2066 696c 656e 616d  tory and filenam
-00016a70: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
-00016a80: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00016a90: 222d 2d65 7863 6c75 6465 222c 2075 2274  "--exclude", u"t
-00016aa0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00016ab0: 2f2a 2a2f 3273 7562 3173 7562 3322 2c20  /**/2sub1sub3", 
-00016ac0: 2023 204e 6f74 6520 2a2a 2061 6464 6564   # Note ** added
-00016ad0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00016ae0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00016af0: 2d2d 6669 6c74 6572 2d69 676e 6f72 6563  --filter-ignorec
-00016b00: 6173 6522 2c0a 2020 2020 2020 2020 2020  ase",.          
-00016b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016b20: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-00016b30: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00016b40: 6563 7432 2f32 2f32 7375 6231 2f32 5375  ect2/2/2sub1/2Su
-00016b50: 6231 5375 6232 222c 2020 2320 4e6f 7465  b1Sub2",  # Note
-00016b60: 2069 676e 6f72 6563 6173 6520 6164 6465   ignorecase adde
-00016b70: 640a 2020 2020 2020 2020 2020 2020 2020  d.              
-00016b80: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00016b90: 222d 2d69 6e63 6c75 6465 222c 2075 2274  "--include", u"t
-00016ba0: 6573 7466 696c 6573 2f73 656c 5b77 2c75  estfiles/sel[w,u
-00016bb0: 2c65 2c71 5d63 7432 2f32 2f32 533f 6231  ,e,q]ct2/2/2S?b1
-00016bc0: 222c 2020 2020 2320 4e6f 7465 2069 676e  ",    # Note ign
-00016bd0: 6f72 6563 6173 652c 205b 5d20 616e 640a  orecase, [] and.
-00016be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016bf0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00016c00: 2d66 696c 7465 722d 7374 7269 6374 6361  -filter-strictca
-00016c10: 7365 222c 0a20 2020 2020 2020 2020 2020  se",.           
-00016c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016c30: 2020 2320 3f20 6164 6465 640a 2020 2020    # ? added.    
-00016c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016c50: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00016c60: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00016c70: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-00016c80: 6233 2f31 735b 772c 752c 702c 715d 6233  b3/1s[w,u,p,q]b3
-00016c90: 7375 6232 222c 2020 2320 4e6f 7465 205b  sub2",  # Note [
-00016ca0: 5d20 6164 6465 640a 2020 2020 2020 2020  ] added.        
-00016cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016cc0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00016cd0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00016ce0: 656c 6563 7432 2f31 2f31 7375 625b 312d  elect2/1/1sub[1-
-00016cf0: 345d 2f31 7375 6233 7375 6231 222c 2020  4]/1sub3sub1",  
-00016d00: 2320 4e6f 7465 205b 7261 6e67 655d 2061  # Note [range] a
-00016d10: 6464 6564 0a20 2020 2020 2020 2020 2020  dded.           
-00016d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016d30: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-00016d40: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00016d50: 6374 322f 2a2f 3173 7562 322f 3173 5b77  ct2/*/1sub2/1s[w
-00016d60: 2c75 2c70 2c71 5d62 3273 7562 3122 2c20  ,u,p,q]b2sub1", 
-00016d70: 2023 204e 6f74 6520 2a20 616e 6420 5b5d   # Note * and []
-00016d80: 2061 6464 6564 0a20 2020 2020 2020 2020   added.         
-00016d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016da0: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-00016db0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00016dc0: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
-00016dd0: 7562 3173 7562 332f 3173 753f 3173 7562  ub1sub3/1su?1sub
-00016de0: 335f 6669 6c65 2e74 7874 222c 2020 2320  3_file.txt",  # 
-00016df0: 4e6f 7465 203f 2061 6464 6564 0a20 2020  Note ? added.   
-00016e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016e10: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-00016e20: 636c 7564 6522 2c20 7522 7465 7374 6669  clude", u"testfi
-00016e30: 6c65 732f 7365 6c65 6374 322f 312f 312a  les/select2/1/1*
-00016e40: 312f 3173 7562 3173 7562 3222 2c20 2023  1/1sub1sub2",  #
-00016e50: 204e 6f74 6520 2a20 6164 6465 640a 2020   Note * added.  
-00016e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016e70: 2020 2020 2020 2020 2020 2075 222d 2d65             u"--e
-00016e80: 7863 6c75 6465 222c 2075 2274 6573 7466  xclude", u"testf
-00016e90: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00016ea0: 7375 6232 222c 0a20 2020 2020 2020 2020  sub2",.         
-00016eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ec0: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-00016ed0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00016ee0: 6c65 6374 5b32 2d34 5d2f 2a2e 7079 222c  lect[2-4]/*.py",
-00016ef0: 2020 2320 4e6f 7465 202a 2061 6e64 205b    # Note * and [
-00016f00: 7261 6e67 655d 2061 6464 6564 0a20 2020  range] added.   
-00016f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016f20: 2020 2020 2020 2020 2020 7522 2d2d 696e            u"--in
-00016f30: 636c 7564 6522 2c20 7522 7465 7374 6669  clude", u"testfi
-00016f40: 6c65 732f 2a32 2f33 222c 2020 2320 4e6f  les/*2/3",  # No
-00016f50: 7465 202a 2061 6464 6564 0a20 2020 2020  te * added.     
-00016f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016f70: 2020 2020 2020 2020 7522 2d2d 696e 636c          u"--incl
-00016f80: 7564 6522 2c20 7522 2a2a 2f73 656c 6563  ude", u"**/selec
-00016f90: 7432 2f31 222c 2020 2320 4e6f 7465 202a  t2/1",  # Note *
-00016fa0: 2a20 6164 6465 640a 2020 2020 2020 2020  * added.        
-00016fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016fc0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00016fd0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00016fe0: 656c 6563 7432 2f2a 2a22 5d29 0a20 2020  elect2/**"]).   
-00016ff0: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
-00017000: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
-00017010: 6f72 655f 6469 7220 3d20 7522 7465 7374  ore_dir = u"test
-00017020: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
-00017030: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
-00017040: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
-00017050: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
-00017060: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
-00017070: 7265 5f64 6972 290a 2020 2020 2020 2020  re_dir).        
-00017080: 7365 6c66 2e61 7373 6572 7445 7175 616c  self.assertEqual
-00017090: 2872 6573 746f 7265 642c 2073 656c 662e  (restored, self.
-000170a0: 6578 7065 6374 6564 5f72 6573 746f 7265  expected_restore
-000170b0: 645f 7472 6565 290a 0a0a 636c 6173 7320  d_tree)...class 
-000170c0: 5465 7374 4578 636c 7564 6549 6650 7265  TestExcludeIfPre
-000170d0: 7365 6e74 2849 6e63 6c75 6465 4578 636c  sent(IncludeExcl
-000170e0: 7564 6546 756e 6374 696f 6e61 6c54 6573  udeFunctionalTes
-000170f0: 7429 3a0a 2020 2020 7522 2222 2054 6869  t):.    u""" Thi
-00017100: 7320 7465 7374 7320 7468 6520 6265 6861  s tests the beha
-00017110: 7669 6f75 7220 6f66 2064 7570 6c69 6369  viour of duplici
-00017120: 7479 2773 202d 2d65 7863 6c75 6465 2d69  ty's --exclude-i
-00017130: 662d 7072 6573 656e 7420 6f70 7469 6f6e  f-present option
-00017140: 2222 220a 0a20 2020 2064 6566 2074 6573  """..    def tes
-00017150: 745f 6578 636c 7564 655f 6966 5f70 7265  t_exclude_if_pre
-00017160: 7365 6e74 5f62 6173 656c 696e 6528 7365  sent_baseline(se
-00017170: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00017180: 2220 5465 7374 2074 6861 7420 6475 706c  " Test that dupl
-00017190: 6963 6974 7920 6e6f 726d 616c 6c79 2062  icity normally b
-000171a0: 6163 6b73 2075 7020 6669 6c65 7322 2222  acks up files"""
-000171b0: 0a20 2020 2020 2020 2077 6974 6820 696f  .        with io
-000171c0: 2e6f 7065 6e28 7522 7465 7374 6669 6c65  .open(u"testfile
-000171d0: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-000171e0: 312f 3173 7562 3173 7562 312f 2e6e 6f62  1/1sub1sub1/.nob
-000171f0: 6163 6b75 7022 2c20 7522 7722 2920 6173  ackup", u"w") as
-00017200: 2074 6167 3a0a 2020 2020 2020 2020 2020   tag:.          
-00017210: 2020 7461 672e 7772 6974 6528 7522 4669    tag.write(u"Fi
-00017220: 6c65 7320 696e 2074 6869 7320 666f 6c64  les in this fold
-00017230: 6572 2073 686f 756c 6420 6e6f 7420 6265  er should not be
-00017240: 2062 6163 6b65 6420 7570 2e22 290a 2020   backed up.").  
-00017250: 2020 2020 2020 7365 6c66 2e62 6163 6b75        self.backu
-00017260: 7028 7522 6675 6c6c 222c 2075 2274 6573  p(u"full", u"tes
-00017270: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-00017280: 2f31 7375 6231 222c 0a20 2020 2020 2020  /1sub1",.       
-00017290: 2020 2020 2020 2020 2020 2020 206f 7074               opt
-000172a0: 696f 6e73 3d5b 7522 2d2d 696e 636c 7564  ions=[u"--includ
-000172b0: 6522 2c20 7522 7465 7374 6669 6c65 732f  e", u"testfiles/
-000172c0: 7365 6c65 6374 322f 312f 3173 7562 312f  select2/1/1sub1/
-000172d0: 3173 7562 3173 7562 312f 2a22 2c0a 2020  1sub1sub1/*",.  
-000172e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000172f0: 2020 2020 2020 2020 2020 2075 222d 2d65             u"--e
-00017300: 7863 6c75 6465 222c 2075 222a 2a22 5d29  xclude", u"**"])
-00017310: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-00017320: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
-00017330: 7265 7374 6f72 655f 6469 7220 3d20 7522  restore_dir = u"
-00017340: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
-00017350: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
-00017360: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
-00017370: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
-00017380: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
-00017390: 6573 746f 7265 5f64 6972 290a 2020 2020  estore_dir).    
-000173a0: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
-000173b0: 7175 616c 2872 6573 746f 7265 642c 205b  qual(restored, [
-000173c0: 5b75 2231 7375 6231 7375 6231 225d 2c0a  [u"1sub1sub1"],.
-000173d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000173e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000173f0: 2020 2020 5b75 222e 6e6f 6261 636b 7570      [u".nobackup
-00017400: 222c 2075 2231 7375 6231 7375 6231 5f66  ", u"1sub1sub1_f
-00017410: 696c 652e 7478 7422 5d5d 290a 0a20 2020  ile.txt"]])..   
-00017420: 2064 6566 2074 6573 745f 6578 636c 7564   def test_exclud
-00017430: 655f 6966 5f70 7265 7365 6e74 5f65 7863  e_if_present_exc
-00017440: 6c75 6465 7328 7365 6c66 293a 0a20 2020  ludes(self):.   
-00017450: 2020 2020 2075 2222 2220 5465 7374 2074       u""" Test t
-00017460: 6861 7420 6475 706c 6963 6974 7920 6578  hat duplicity ex
-00017470: 636c 7564 6573 2066 696c 6573 2077 6974  cludes files wit
-00017480: 6820 7265 6c65 7661 6e74 2074 6167 2222  h relevant tag""
-00017490: 220a 2020 2020 2020 2020 7769 7468 2069  ".        with i
-000174a0: 6f2e 6f70 656e 2875 2274 6573 7466 696c  o.open(u"testfil
-000174b0: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-000174c0: 6231 2f31 7375 6231 7375 6231 2f2e 6e6f  b1/1sub1sub1/.no
-000174d0: 6261 636b 7570 222c 2075 2277 2229 2061  backup", u"w") a
-000174e0: 7320 7461 673a 0a20 2020 2020 2020 2020  s tag:.         
-000174f0: 2020 2074 6167 2e77 7269 7465 2875 2246     tag.write(u"F
-00017500: 696c 6573 2069 6e20 7468 6973 2066 6f6c  iles in this fol
-00017510: 6465 7220 7368 6f75 6c64 206e 6f74 2062  der should not b
-00017520: 6520 6261 636b 6564 2075 702e 2229 0a20  e backed up."). 
-00017530: 2020 2020 2020 2073 656c 662e 6261 636b         self.back
-00017540: 7570 2875 2266 756c 6c22 2c20 7522 7465  up(u"full", u"te
-00017550: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00017560: 312f 3173 7562 3122 2c0a 2020 2020 2020  1/1sub1",.      
-00017570: 2020 2020 2020 2020 2020 2020 2020 6f70                op
-00017580: 7469 6f6e 733d 5b75 222d 2d65 7863 6c75  tions=[u"--exclu
-00017590: 6465 2d69 662d 7072 6573 656e 7422 2c20  de-if-present", 
-000175a0: 7522 2e6e 6f62 6163 6b75 7022 2c0a 2020  u".nobackup",.  
-000175b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000175c0: 2020 2020 2020 2020 2020 2075 222d 2d69             u"--i
-000175d0: 6e63 6c75 6465 222c 2075 2274 6573 7466  nclude", u"testf
-000175e0: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-000175f0: 7375 6231 2f31 7375 6231 7375 6231 2f2a  sub1/1sub1sub1/*
-00017600: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00017610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017620: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00017630: 2a2a 225d 290a 2020 2020 2020 2020 7365  **"]).        se
-00017640: 6c66 2e72 6573 746f 7265 2829 0a20 2020  lf.restore().   
-00017650: 2020 2020 2072 6573 746f 7265 5f64 6972       restore_dir
-00017660: 203d 2075 2274 6573 7466 696c 6573 2f72   = u"testfiles/r
-00017670: 6573 746f 7265 5f6f 7574 220a 2020 2020  estore_out".    
-00017680: 2020 2020 7265 7374 6f72 6564 203d 2073      restored = s
-00017690: 656c 662e 6469 7265 6374 6f72 795f 7472  elf.directory_tr
-000176a0: 6565 5f74 6f5f 6c69 7374 5f6f 665f 6c69  ee_to_list_of_li
-000176b0: 7374 7328 7265 7374 6f72 655f 6469 7229  sts(restore_dir)
-000176c0: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
-000176d0: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
-000176e0: 6564 2c20 5b5d 290a 0a20 2020 2064 6566  ed, [])..    def
-000176f0: 2074 6573 745f 6578 636c 7564 655f 6966   test_exclude_if
-00017700: 5f70 7265 7365 6e74 5f65 7863 6c75 6465  _present_exclude
-00017710: 735f 3228 7365 6c66 293a 0a20 2020 2020  s_2(self):.     
-00017720: 2020 2075 2222 2220 5465 7374 2074 6861     u""" Test tha
-00017730: 7420 6475 706c 6963 6974 7920 6578 636c  t duplicity excl
-00017740: 7564 6573 2066 696c 6573 2077 6974 6820  udes files with 
-00017750: 7265 6c65 7661 6e74 2074 6167 2222 220a  relevant tag""".
-00017760: 2020 2020 2020 2020 7769 7468 2069 6f2e          with io.
-00017770: 6f70 656e 2875 2274 6573 7466 696c 6573  open(u"testfiles
-00017780: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
-00017790: 2f31 7375 6231 7375 6231 2f45 5843 4c55  /1sub1sub1/EXCLU
-000177a0: 4445 2e74 6167 222c 2075 2277 2229 2061  DE.tag", u"w") a
-000177b0: 7320 7461 673a 0a20 2020 2020 2020 2020  s tag:.         
-000177c0: 2020 2074 6167 2e77 7269 7465 2875 2246     tag.write(u"F
-000177d0: 696c 6573 2069 6e20 7468 6973 2066 6f6c  iles in this fol
-000177e0: 6465 7220 7368 6f75 6c64 2061 6c73 6f20  der should also 
-000177f0: 6e6f 7420 6265 2062 6163 6b65 6420 7570  not be backed up
-00017800: 2e22 290a 2020 2020 2020 2020 7365 6c66  .").        self
-00017810: 2e62 6163 6b75 7028 7522 6675 6c6c 222c  .backup(u"full",
-00017820: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00017830: 6563 7432 2f31 2f31 7375 6231 222c 0a20  ect2/1/1sub1",. 
-00017840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017850: 2020 206f 7074 696f 6e73 3d5b 7522 2d2d     options=[u"--
-00017860: 6578 636c 7564 652d 6966 2d70 7265 7365  exclude-if-prese
-00017870: 6e74 222c 2075 2245 5843 4c55 4445 2e74  nt", u"EXCLUDE.t
-00017880: 6167 222c 0a20 2020 2020 2020 2020 2020  ag",.           
-00017890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000178a0: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-000178b0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-000178c0: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
-000178d0: 3173 7562 312f 2a22 2c0a 2020 2020 2020  1sub1/*",.      
-000178e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000178f0: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-00017900: 6465 222c 2075 222a 2a22 5d29 0a20 2020  de", u"**"]).   
-00017910: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
-00017920: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
-00017930: 6f72 655f 6469 7220 3d20 7522 7465 7374  ore_dir = u"test
-00017940: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
-00017950: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
-00017960: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
-00017970: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
-00017980: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
-00017990: 7265 5f64 6972 290a 2020 2020 2020 2020  re_dir).        
-000179a0: 7365 6c66 2e61 7373 6572 7445 7175 616c  self.assertEqual
-000179b0: 2872 6573 746f 7265 642c 205b 5d29 0a0a  (restored, [])..
-000179c0: 0a63 6c61 7373 2054 6573 744c 6f63 6b65  .class TestLocke
-000179d0: 6446 6f6c 6465 7273 4e6f 4572 726f 7228  dFoldersNoError(
-000179e0: 496e 636c 7564 6545 7863 6c75 6465 4675  IncludeExcludeFu
-000179f0: 6e63 7469 6f6e 616c 5465 7374 293a 0a20  nctionalTest):. 
-00017a00: 2020 2075 2222 2220 5468 6973 2074 6573     u""" This tes
-00017a10: 7473 2074 6861 7420 696e 6163 6365 7373  ts that inaccess
-00017a20: 6962 6c65 2066 6f6c 6465 7273 2064 6f20  ible folders do 
-00017a30: 6e6f 7420 6361 7573 6520 616e 2065 7272  not cause an err
-00017a40: 6f72 2222 220a 0a20 2020 2040 756e 6974  or"""..    @unit
-00017a50: 7465 7374 2e73 6b69 7055 6e6c 6573 7328  test.skipUnless(
-00017a60: 706c 6174 666f 726d 2e70 6c61 7466 6f72  platform.platfor
-00017a70: 6d28 292e 7374 6172 7473 7769 7468 2875  m().startswith(u
-00017a80: 224c 696e 7578 2229 2c0a 2020 2020 2020  "Linux"),.      
-00017a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017aa0: 2020 2075 2253 6b69 7020 6f6e 206e 6f6e     u"Skip on non
-00017ab0: 2d4c 696e 7578 2073 7973 7465 6d73 2229  -Linux systems")
-00017ac0: 0a20 2020 2064 6566 2074 6573 745f 6c6f  .    def test_lo
-00017ad0: 636b 6564 5f62 6173 656c 696e 6528 7365  cked_baseline(se
-00017ae0: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00017af0: 2220 5465 7374 206e 6f20 6572 726f 7220  " Test no error 
-00017b00: 6966 206c 6f63 6b65 6420 696e 2070 6174  if locked in pat
-00017b10: 6820 6275 7420 6578 636c 7564 6564 2222  h but excluded""
-00017b20: 220a 2020 2020 2020 2020 666f 6c64 6572  ".        folder
-00017b30: 5f74 6f5f 6c6f 636b 203d 2075 2274 6573  _to_lock = u"tes
-00017b40: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-00017b50: 2f31 7375 6231 2f31 7375 6231 7375 6233  /1sub1/1sub1sub3
-00017b60: 220a 2020 2020 2020 2020 696e 6974 6961  ".        initia
-00017b70: 6c5f 6d6f 6465 203d 206f 732e 7374 6174  l_mode = os.stat
-00017b80: 2866 6f6c 6465 725f 746f 5f6c 6f63 6b29  (folder_to_lock)
-00017b90: 2e73 745f 6d6f 6465 0a20 2020 2020 2020  .st_mode.       
-00017ba0: 206f 732e 6368 6d6f 6428 666f 6c64 6572   os.chmod(folder
-00017bb0: 5f74 6f5f 6c6f 636b 2c20 306f 3030 3030  _to_lock, 0o0000
-00017bc0: 290a 2020 2020 2020 2020 7365 6c66 2e62  ).        self.b
-00017bd0: 6163 6b75 7028 7522 6675 6c6c 222c 2075  ackup(u"full", u
-00017be0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00017bf0: 7432 2f31 2f31 7375 6231 222c 0a20 2020  t2/1/1sub1",.   
-00017c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017c10: 206f 7074 696f 6e73 3d5b 7522 2d2d 696e   options=[u"--in
-00017c20: 636c 7564 6522 2c20 7522 7465 7374 6669  clude", u"testfi
-00017c30: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-00017c40: 7562 312f 3173 7562 3173 7562 312f 2a22  ub1/1sub1sub1/*"
-00017c50: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00017c60: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00017c70: 222d 2d65 7863 6c75 6465 222c 2075 222a  "--exclude", u"*
-00017c80: 2a22 5d29 0a20 2020 2020 2020 206f 732e  *"]).        os.
-00017c90: 6368 6d6f 6428 666f 6c64 6572 5f74 6f5f  chmod(folder_to_
-00017ca0: 6c6f 636b 2c20 696e 6974 6961 6c5f 6d6f  lock, initial_mo
-00017cb0: 6465 290a 2020 2020 2020 2020 7365 6c66  de).        self
-00017cc0: 2e72 6573 746f 7265 2829 0a20 2020 2020  .restore().     
-00017cd0: 2020 2072 6573 746f 7265 5f64 6972 203d     restore_dir =
-00017ce0: 2075 2274 6573 7466 696c 6573 2f72 6573   u"testfiles/res
-00017cf0: 746f 7265 5f6f 7574 220a 2020 2020 2020  tore_out".      
-00017d00: 2020 7265 7374 6f72 6564 203d 2073 656c    restored = sel
-00017d10: 662e 6469 7265 6374 6f72 795f 7472 6565  f.directory_tree
-00017d20: 5f74 6f5f 6c69 7374 5f6f 665f 6c69 7374  _to_list_of_list
-00017d30: 7328 7265 7374 6f72 655f 6469 7229 0a20  s(restore_dir). 
-00017d40: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
-00017d50: 7274 4571 7561 6c28 7265 7374 6f72 6564  rtEqual(restored
-00017d60: 2c20 5b5b 7522 3173 7562 3173 7562 3122  , [[u"1sub1sub1"
-00017d70: 5d2c 0a20 2020 2020 2020 2020 2020 2020  ],.             
-00017d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017d90: 2020 2020 2020 205b 7522 3173 7562 3173         [u"1sub1s
-00017da0: 7562 315f 6669 6c65 2e74 7874 225d 5d29  ub1_file.txt"]])
-00017db0: 0a0a 2020 2020 4075 6e69 7474 6573 742e  ..    @unittest.
-00017dc0: 736b 6970 556e 6c65 7373 2870 6c61 7466  skipUnless(platf
-00017dd0: 6f72 6d2e 706c 6174 666f 726d 2829 2e73  orm.platform().s
-00017de0: 7461 7274 7377 6974 6828 7522 4c69 6e75  tartswith(u"Linu
-00017df0: 7822 292c 0a20 2020 2020 2020 2020 2020  x"),.           
-00017e00: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00017e10: 536b 6970 206f 6e20 6e6f 6e2d 4c69 6e75  Skip on non-Linu
-00017e20: 7820 7379 7374 656d 7322 290a 2020 2020  x systems").    
-00017e30: 6465 6620 7465 7374 5f6c 6f63 6b65 645f  def test_locked_
-00017e40: 6578 636c 5f69 665f 7072 6573 656e 7428  excl_if_present(
-00017e50: 7365 6c66 293a 0a20 2020 2020 2020 2075  self):.        u
-00017e60: 2222 2220 5465 7374 206e 6f20 6572 726f  """ Test no erro
-00017e70: 7220 6966 2065 7863 6c75 6465 6420 6c6f  r if excluded lo
-00017e80: 636b 6564 2077 6974 6820 2d2d 6578 636c  cked with --excl
-00017e90: 7564 652d 6966 2d70 7265 7365 6e74 2222  ude-if-present""
-00017ea0: 220a 2020 2020 2020 2020 2320 5265 6772  ".        # Regr
-00017eb0: 6573 7369 6f6e 2074 6573 7420 666f 7220  ession test for 
-00017ec0: 4275 6720 2331 3632 3030 3835 0a20 2020  Bug #1620085.   
-00017ed0: 2020 2020 2023 2068 7474 7073 3a2f 2f62       # https://b
-00017ee0: 7567 732e 6c61 756e 6368 7061 642e 6e65  ugs.launchpad.ne
-00017ef0: 742f 6475 706c 6963 6974 792f 2b62 7567  t/duplicity/+bug
-00017f00: 2f31 3632 3030 3835 0a20 2020 2020 2020  /1620085.       
-00017f10: 2066 6f6c 6465 725f 746f 5f6c 6f63 6b20   folder_to_lock 
-00017f20: 3d20 7522 7465 7374 6669 6c65 732f 7365  = u"testfiles/se
-00017f30: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
-00017f40: 7562 3173 7562 3322 0a20 2020 2020 2020  ub1sub3".       
-00017f50: 2069 6e69 7469 616c 5f6d 6f64 6520 3d20   initial_mode = 
-00017f60: 6f73 2e73 7461 7428 666f 6c64 6572 5f74  os.stat(folder_t
-00017f70: 6f5f 6c6f 636b 292e 7374 5f6d 6f64 650a  o_lock).st_mode.
-00017f80: 2020 2020 2020 2020 6f73 2e63 686d 6f64          os.chmod
-00017f90: 2866 6f6c 6465 725f 746f 5f6c 6f63 6b2c  (folder_to_lock,
-00017fa0: 2030 6f30 3030 3029 0a20 2020 2020 2020   0o0000).       
-00017fb0: 2073 656c 662e 6261 636b 7570 2875 2266   self.backup(u"f
-00017fc0: 756c 6c22 2c20 7522 7465 7374 6669 6c65  ull", u"testfile
-00017fd0: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-00017fe0: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
-00017ff0: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-00018000: 5b75 222d 2d65 7863 6c75 6465 2d69 662d  [u"--exclude-if-
-00018010: 7072 6573 656e 7422 2c20 7522 4558 434c  present", u"EXCL
-00018020: 5544 452e 7461 6722 2c0a 2020 2020 2020  UDE.tag",.      
-00018030: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018040: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-00018050: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-00018060: 2f73 656c 6563 7432 2f31 2f31 7375 6231  /select2/1/1sub1
-00018070: 2f31 7375 6231 7375 6231 2f2a 222c 0a20  /1sub1sub1/*",. 
-00018080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018090: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-000180a0: 6578 636c 7564 6522 2c20 7522 2a2a 225d  exclude", u"**"]
-000180b0: 290a 2020 2020 2020 2020 6f73 2e63 686d  ).        os.chm
-000180c0: 6f64 2866 6f6c 6465 725f 746f 5f6c 6f63  od(folder_to_loc
-000180d0: 6b2c 2069 6e69 7469 616c 5f6d 6f64 6529  k, initial_mode)
-000180e0: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
-000180f0: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
-00018100: 7265 7374 6f72 655f 6469 7220 3d20 7522  restore_dir = u"
-00018110: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
-00018120: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
-00018130: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
-00018140: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
-00018150: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
-00018160: 6573 746f 7265 5f64 6972 290a 2020 2020  estore_dir).    
-00018170: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
-00018180: 7175 616c 2872 6573 746f 7265 642c 205b  qual(restored, [
-00018190: 5b75 2231 7375 6231 7375 6231 225d 2c0a  [u"1sub1sub1"],.
-000181a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000181b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000181c0: 2020 2020 5b75 2231 7375 6231 7375 6231      [u"1sub1sub1
-000181d0: 5f66 696c 652e 7478 7422 5d5d 290a 0a0a  _file.txt"]])...
-000181e0: 636c 6173 7320 5465 7374 466f 6c64 6572  class TestFolder
-000181f0: 496e 636c 7564 6573 4669 6c65 7328 496e  IncludesFiles(In
-00018200: 636c 7564 6545 7863 6c75 6465 4675 6e63  cludeExcludeFunc
-00018210: 7469 6f6e 616c 5465 7374 293a 0a20 2020  tionalTest):.   
-00018220: 2075 2222 2220 5468 6973 2074 6573 7473   u""" This tests
-00018230: 2074 6861 7420 696e 636c 7564 696e 6720   that including 
-00018240: 6120 666f 6c64 6572 2069 6e63 6c75 6465  a folder include
-00018250: 7320 7468 6520 6669 6c65 7320 7769 7468  s the files with
-00018260: 696e 2069 7422 2222 0a20 2020 2023 2068  in it""".    # h
-00018270: 7474 7073 3a2f 2f62 7567 732e 6c61 756e  ttps://bugs.laun
-00018280: 6368 7061 642e 6e65 742f 6475 706c 6963  chpad.net/duplic
-00018290: 6974 792f 2b62 7567 2f31 3632 3437 3235  ity/+bug/1624725
-000182a0: 0a0a 2020 2020 6465 6620 7465 7374 5f69  ..    def test_i
-000182b0: 6e63 6c75 6465 735f 6669 6c65 7328 7365  ncludes_files(se
-000182c0: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-000182d0: 2254 6869 7320 7465 7374 7320 7468 6174  "This tests that
-000182e0: 2069 6e63 6c75 6469 6e67 2061 2066 6f6c   including a fol
-000182f0: 6465 7220 696e 636c 7564 6573 2074 6865  der includes the
-00018300: 2066 696c 6573 2077 6974 6869 6e20 6974   files within it
-00018310: 2222 220a 2020 2020 2020 2020 7365 6c66  """.        self
-00018320: 2e62 6163 6b75 7028 7522 6675 6c6c 222c  .backup(u"full",
-00018330: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00018340: 6563 7432 2f31 2f31 7375 6231 222c 0a20  ect2/1/1sub1",. 
-00018350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018360: 2020 206f 7074 696f 6e73 3d5b 7522 2d2d     options=[u"--
-00018370: 696e 636c 7564 6522 2c20 7522 7465 7374  include", u"test
-00018380: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-00018390: 3173 7562 312f 3173 7562 3173 7562 3122  1sub1/1sub1sub1"
-000183a0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-000183b0: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-000183c0: 222d 2d65 7863 6c75 6465 222c 2075 222a  "--exclude", u"*
-000183d0: 2a22 5d29 0a20 2020 2020 2020 2073 656c  *"]).        sel
-000183e0: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
-000183f0: 2020 2020 7265 7374 6f72 655f 6469 7220      restore_dir 
-00018400: 3d20 7522 7465 7374 6669 6c65 732f 7265  = u"testfiles/re
-00018410: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
-00018420: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
-00018430: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
-00018440: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
-00018450: 7473 2872 6573 746f 7265 5f64 6972 290a  ts(restore_dir).
-00018460: 2020 2020 2020 2020 7365 6c66 2e61 7373          self.ass
-00018470: 6572 7445 7175 616c 2872 6573 746f 7265  ertEqual(restore
-00018480: 642c 205b 5b75 2231 7375 6231 7375 6231  d, [[u"1sub1sub1
-00018490: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
-000184a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000184b0: 2020 2020 2020 2020 5b75 2231 7375 6231          [u"1sub1
-000184c0: 7375 6231 5f66 696c 652e 7478 7422 5d5d  sub1_file.txt"]]
-000184d0: 290a 0a20 2020 2064 6566 2074 6573 745f  )..    def test_
-000184e0: 696e 636c 7564 6573 5f66 696c 6573 5f74  includes_files_t
-000184f0: 7261 696c 696e 675f 736c 6173 6828 7365  railing_slash(se
-00018500: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00018510: 2254 6869 7320 7465 7374 7320 7468 6174  "This tests that
-00018520: 2069 6e63 6c75 6469 6e67 2061 2066 6f6c   including a fol
-00018530: 6465 7220 696e 636c 7564 6573 2074 6865  der includes the
-00018540: 2066 696c 6573 2077 6974 6869 6e20 6974   files within it
-00018550: 2222 220a 2020 2020 2020 2020 7365 6c66  """.        self
-00018560: 2e62 6163 6b75 7028 7522 6675 6c6c 222c  .backup(u"full",
-00018570: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00018580: 6563 7432 2f31 2f31 7375 6231 222c 0a20  ect2/1/1sub1",. 
-00018590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000185a0: 2020 206f 7074 696f 6e73 3d5b 7522 2d2d     options=[u"--
-000185b0: 696e 636c 7564 6522 2c20 7522 7465 7374  include", u"test
-000185c0: 6669 6c65 732f 7365 6c65 6374 322f 312f  files/select2/1/
-000185d0: 3173 7562 312f 3173 7562 3173 7562 312f  1sub1/1sub1sub1/
-000185e0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-000185f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018600: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00018610: 2a2a 225d 290a 2020 2020 2020 2020 7365  **"]).        se
-00018620: 6c66 2e72 6573 746f 7265 2829 0a20 2020  lf.restore().   
-00018630: 2020 2020 2072 6573 746f 7265 5f64 6972       restore_dir
-00018640: 203d 2075 2274 6573 7466 696c 6573 2f72   = u"testfiles/r
-00018650: 6573 746f 7265 5f6f 7574 220a 2020 2020  estore_out".    
-00018660: 2020 2020 7265 7374 6f72 6564 203d 2073      restored = s
-00018670: 656c 662e 6469 7265 6374 6f72 795f 7472  elf.directory_tr
-00018680: 6565 5f74 6f5f 6c69 7374 5f6f 665f 6c69  ee_to_list_of_li
-00018690: 7374 7328 7265 7374 6f72 655f 6469 7229  sts(restore_dir)
-000186a0: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
-000186b0: 7365 7274 4571 7561 6c28 7265 7374 6f72  sertEqual(restor
-000186c0: 6564 2c20 5b5b 7522 3173 7562 3173 7562  ed, [[u"1sub1sub
-000186d0: 3122 5d2c 0a20 2020 2020 2020 2020 2020  1"],.           
-000186e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000186f0: 2020 2020 2020 2020 205b 7522 3173 7562           [u"1sub
-00018700: 3173 7562 315f 6669 6c65 2e74 7874 225d  1sub1_file.txt"]
-00018710: 5d29 0a0a 2020 2020 6465 6620 7465 7374  ])..    def test
-00018720: 5f69 6e63 6c75 6465 735f 6669 6c65 735f  _includes_files_
-00018730: 7472 6169 6c69 6e67 5f73 6c61 7368 5f67  trailing_slash_g
-00018740: 6c6f 6262 696e 675f 6368 6172 7328 7365  lobbing_chars(se
-00018750: 6c66 293a 0a20 2020 2020 2020 2075 2222  lf):.        u""
-00018760: 2254 6573 7473 2066 6f6c 6465 7220 696e  "Tests folder in
-00018770: 636c 7564 6573 2077 6974 6820 676c 6f62  cludes with glob
-00018780: 6269 6e67 2063 6861 7220 616e 6420 2f22  bing char and /"
-00018790: 2222 0a20 2020 2020 2020 2073 656c 662e  "".        self.
-000187a0: 6261 636b 7570 2875 2266 756c 6c22 2c20  backup(u"full", 
-000187b0: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-000187c0: 6374 322f 312f 3173 7562 3122 2c0a 2020  ct2/1/1sub1",.  
-000187d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000187e0: 2020 6f70 7469 6f6e 733d 5b75 222d 2d69    options=[u"--i
-000187f0: 6e63 6c75 6465 222c 2075 2274 6573 7466  nclude", u"testf
-00018800: 696c 6573 2f73 3f6c 6563 7432 2f31 2f31  iles/s?lect2/1/1
-00018810: 7375 6231 2f31 7375 6231 7375 6231 2f22  sub1/1sub1sub1/"
-00018820: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00018830: 2020 2020 2020 2020 2020 2020 2020 2075                 u
-00018840: 222d 2d65 7863 6c75 6465 222c 2075 222a  "--exclude", u"*
-00018850: 2a22 5d29 0a20 2020 2020 2020 2073 656c  *"]).        sel
-00018860: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
-00018870: 2020 2020 7265 7374 6f72 655f 6469 7220      restore_dir 
-00018880: 3d20 7522 7465 7374 6669 6c65 732f 7265  = u"testfiles/re
-00018890: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
-000188a0: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
-000188b0: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
-000188c0: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
-000188d0: 7473 2872 6573 746f 7265 5f64 6972 290a  ts(restore_dir).
-000188e0: 2020 2020 2020 2020 7365 6c66 2e61 7373          self.ass
-000188f0: 6572 7445 7175 616c 2872 6573 746f 7265  ertEqual(restore
-00018900: 642c 205b 5b75 2231 7375 6231 7375 6231  d, [[u"1sub1sub1
-00018910: 225d 2c0a 2020 2020 2020 2020 2020 2020  "],.            
-00018920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018930: 2020 2020 2020 2020 5b75 2231 7375 6231          [u"1sub1
-00018940: 7375 6231 5f66 696c 652e 7478 7422 5d5d  sub1_file.txt"]]
-00018950: 290a 0a20 2020 2064 6566 2074 6573 745f  )..    def test_
-00018960: 6578 636c 7564 6573 5f66 696c 6573 5f6e  excludes_files_n
-00018970: 6f5f 7472 6169 6c69 6e67 5f73 6c61 7368  o_trailing_slash
-00018980: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00018990: 7522 2222 5468 6973 2074 6573 7473 2074  u"""This tests t
-000189a0: 6861 7420 6578 636c 7564 696e 6720 6120  hat excluding a 
-000189b0: 666f 6c64 6572 2065 7863 6c75 6465 7320  folder excludes 
-000189c0: 7468 6520 6669 6c65 7320 7769 7468 696e  the files within
-000189d0: 2069 7422 2222 0a20 2020 2020 2020 2073   it""".        s
-000189e0: 656c 662e 6261 636b 7570 2875 2266 756c  elf.backup(u"ful
-000189f0: 6c22 2c20 7522 7465 7374 6669 6c65 732f  l", u"testfiles/
-00018a00: 7365 6c65 6374 322f 312f 3173 7562 3122  select2/1/1sub1"
-00018a10: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-00018a20: 2020 2020 2020 6f70 7469 6f6e 733d 5b75        options=[u
-00018a30: 222d 2d65 7863 6c75 6465 222c 2075 2274  "--exclude", u"t
-00018a40: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-00018a50: 2f31 2f31 7375 6231 2f31 7375 6231 7375  /1/1sub1/1sub1su
-00018a60: 6231 222c 0a20 2020 2020 2020 2020 2020  b1",.           
-00018a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018a80: 2020 7522 2d2d 6578 636c 7564 6522 2c20    u"--exclude", 
-00018a90: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00018aa0: 6374 322f 312f 3173 7562 312f 3173 7562  ct2/1/1sub1/1sub
-00018ab0: 3173 7562 3222 2c0a 2020 2020 2020 2020  1sub2",.        
-00018ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018ad0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00018ae0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00018af0: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
-00018b00: 7375 6231 7375 6233 222c 0a20 2020 2020  sub1sub3",.     
-00018b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018b20: 2020 2020 2020 2020 7522 2d2d 696e 636c          u"--incl
-00018b30: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-00018b40: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-00018b50: 312f 3173 7562 312a 2a22 2c0a 2020 2020  1/1sub1**",.    
-00018b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018b70: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00018b80: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00018b90: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-00018ba0: 6231 2f69 7272 656c 6576 616e 742e 7478  b1/irrelevant.tx
-00018bb0: 7422 5d29 0a20 2020 2020 2020 2073 656c  t"]).        sel
-00018bc0: 662e 7265 7374 6f72 6528 290a 2020 2020  f.restore().    
-00018bd0: 2020 2020 7265 7374 6f72 655f 6469 7220      restore_dir 
-00018be0: 3d20 7522 7465 7374 6669 6c65 732f 7265  = u"testfiles/re
-00018bf0: 7374 6f72 655f 6f75 7422 0a20 2020 2020  store_out".     
-00018c00: 2020 2072 6573 746f 7265 6420 3d20 7365     restored = se
-00018c10: 6c66 2e64 6972 6563 746f 7279 5f74 7265  lf.directory_tre
-00018c20: 655f 746f 5f6c 6973 745f 6f66 5f6c 6973  e_to_list_of_lis
-00018c30: 7473 2872 6573 746f 7265 5f64 6972 290a  ts(restore_dir).
-00018c40: 2020 2020 2020 2020 7365 6c66 2e61 7373          self.ass
-00018c50: 6572 7445 7175 616c 2872 6573 746f 7265  ertEqual(restore
-00018c60: 642c 205b 5d29 0a0a 2020 2020 6465 6620  d, [])..    def 
-00018c70: 7465 7374 5f65 7863 6c75 6465 735f 6669  test_excludes_fi
-00018c80: 6c65 735f 7472 6169 6c69 6e67 5f73 6c61  les_trailing_sla
-00018c90: 7368 2873 656c 6629 3a0a 2020 2020 2020  sh(self):.      
-00018ca0: 2020 7522 2222 4578 636c 7564 696e 6720    u"""Excluding 
-00018cb0: 6120 666f 6c64 6572 2065 7863 6c75 6465  a folder exclude
-00018cc0: 7320 7468 6520 6669 6c65 7320 7769 7468  s the files with
-00018cd0: 696e 2069 742c 2069 6620 656e 6473 2077  in it, if ends w
-00018ce0: 6974 6820 2f22 2222 0a20 2020 2020 2020  ith /""".       
-00018cf0: 2073 656c 662e 6261 636b 7570 2875 2266   self.backup(u"f
-00018d00: 756c 6c22 2c20 7522 7465 7374 6669 6c65  ull", u"testfile
-00018d10: 732f 7365 6c65 6374 322f 312f 3173 7562  s/select2/1/1sub
-00018d20: 3122 2c0a 2020 2020 2020 2020 2020 2020  1",.            
-00018d30: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-00018d40: 5b75 222d 2d65 7863 6c75 6465 222c 2075  [u"--exclude", u
-00018d50: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00018d60: 7432 2f31 2f31 7375 6231 2f31 7375 6231  t2/1/1sub1/1sub1
-00018d70: 7375 6231 2f22 2c0a 2020 2020 2020 2020  sub1/",.        
-00018d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018d90: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-00018da0: 222c 2075 2274 6573 7466 696c 6573 2f73  ", u"testfiles/s
-00018db0: 656c 6563 7432 2f31 2f31 7375 6231 2f31  elect2/1/1sub1/1
-00018dc0: 7375 6231 7375 6232 2f22 2c0a 2020 2020  sub1sub2/",.    
-00018dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018de0: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-00018df0: 6c75 6465 222c 2075 2274 6573 7466 696c  lude", u"testfil
-00018e00: 6573 2f73 656c 6563 7432 2f31 2f31 7375  es/select2/1/1su
-00018e10: 6231 2f31 7375 6231 7375 6233 2f22 2c0a  b1/1sub1sub3/",.
-00018e20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018e30: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00018e40: 2d69 6e63 6c75 6465 222c 2075 2274 6573  -include", u"tes
-00018e50: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-00018e60: 2f31 7375 6231 2f31 7375 6231 2a2a 222c  /1sub1/1sub1**",
-00018e70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00018e80: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00018e90: 2d2d 6578 636c 7564 6522 2c20 7522 7465  --exclude", u"te
-00018ea0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-00018eb0: 312f 3173 7562 312f 6972 7265 6c65 7661  1/1sub1/irreleva
-00018ec0: 6e74 2e74 7874 225d 290a 2020 2020 2020  nt.txt"]).      
-00018ed0: 2020 7365 6c66 2e72 6573 746f 7265 2829    self.restore()
-00018ee0: 0a20 2020 2020 2020 2072 6573 746f 7265  .        restore
-00018ef0: 5f64 6972 203d 2075 2274 6573 7466 696c  _dir = u"testfil
-00018f00: 6573 2f72 6573 746f 7265 5f6f 7574 220a  es/restore_out".
-00018f10: 2020 2020 2020 2020 7265 7374 6f72 6564          restored
-00018f20: 203d 2073 656c 662e 6469 7265 6374 6f72   = self.director
-00018f30: 795f 7472 6565 5f74 6f5f 6c69 7374 5f6f  y_tree_to_list_o
-00018f40: 665f 6c69 7374 7328 7265 7374 6f72 655f  f_lists(restore_
-00018f50: 6469 7229 0a20 2020 2020 2020 2073 656c  dir).        sel
-00018f60: 662e 6173 7365 7274 4571 7561 6c28 7265  f.assertEqual(re
-00018f70: 7374 6f72 6564 2c20 5b5d 290a 0a20 2020  stored, [])..   
-00018f80: 2064 6566 2074 6573 745f 6578 636c 7564   def test_exclud
-00018f90: 6573 5f66 696c 6573 5f74 7261 696c 696e  es_files_trailin
-00018fa0: 675f 736c 6173 685f 676c 6f62 6269 6e67  g_slash_globbing
-00018fb0: 5f63 6861 7273 2873 656c 6629 3a0a 2020  _chars(self):.  
-00018fc0: 2020 2020 2020 7522 2222 5465 7374 7320        u"""Tests 
-00018fd0: 666f 6c64 6572 2065 7863 6c75 6465 7320  folder excludes 
-00018fe0: 7769 7468 2067 6c6f 6262 696e 6720 6368  with globbing ch
-00018ff0: 6172 2061 6e64 202f 2222 220a 2020 2020  ar and /""".    
-00019000: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
-00019010: 7522 6675 6c6c 222c 2075 2274 6573 7466  u"full", u"testf
-00019020: 696c 6573 2f73 656c 6563 7432 2f31 2f31  iles/select2/1/1
-00019030: 7375 6231 222c 0a20 2020 2020 2020 2020  sub1",.         
-00019040: 2020 2020 2020 2020 2020 206f 7074 696f             optio
-00019050: 6e73 3d5b 7522 2d2d 6578 636c 7564 6522  ns=[u"--exclude"
-00019060: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00019070: 6c3f 6374 322f 312f 3173 7562 312f 3173  l?ct2/1/1sub1/1s
-00019080: 7562 3173 7562 312f 222c 0a20 2020 2020  ub1sub1/",.     
-00019090: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000190a0: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-000190b0: 7564 6522 2c20 7522 7465 7374 6669 6c65  ude", u"testfile
-000190c0: 732f 7365 6c5b 652c 665d 6374 322f 312f  s/sel[e,f]ct2/1/
-000190d0: 3173 7562 312f 3173 7562 3173 7562 322f  1sub1/1sub1sub2/
-000190e0: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-000190f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019100: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00019110: 7465 7374 6669 6c65 732f 7365 6c2a 7432  testfiles/sel*t2
-00019120: 2f31 2f31 7375 6231 2f31 7375 6231 7375  /1/1sub1/1sub1su
-00019130: 6233 2f22 2c0a 2020 2020 2020 2020 2020  b3/",.          
-00019140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019150: 2020 2075 222d 2d69 6e63 6c75 6465 222c     u"--include",
-00019160: 2075 2274 6573 7466 696c 6573 2f73 656c   u"testfiles/sel
-00019170: 6563 7432 2f31 2f31 7375 6231 2f31 7375  ect2/1/1sub1/1su
-00019180: 6231 2a2a 222c 0a20 2020 2020 2020 2020  b1**",.         
-00019190: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000191a0: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-000191b0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-000191c0: 6c65 6374 322f 312f 3173 7562 312f 6972  lect2/1/1sub1/ir
-000191d0: 7265 6c65 7661 6e74 2e74 7874 225d 290a  relevant.txt"]).
-000191e0: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
-000191f0: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
-00019200: 6573 746f 7265 5f64 6972 203d 2075 2274  estore_dir = u"t
-00019210: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
-00019220: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
-00019230: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
-00019240: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
-00019250: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
-00019260: 7374 6f72 655f 6469 7229 0a20 2020 2020  store_dir).     
-00019270: 2020 2073 656c 662e 6173 7365 7274 4571     self.assertEq
-00019280: 7561 6c28 7265 7374 6f72 6564 2c20 5b5d  ual(restored, []
-00019290: 290a 0a0a 636c 6173 7320 5465 7374 4162  )...class TestAb
-000192a0: 736f 6c75 7465 5061 7468 7328 496e 636c  solutePaths(Incl
-000192b0: 7564 6545 7863 6c75 6465 4675 6e63 7469  udeExcludeFuncti
-000192c0: 6f6e 616c 5465 7374 293a 0a20 2020 2075  onalTest):.    u
-000192d0: 2222 2220 5465 7374 7320 696e 636c 7564  """ Tests includ
-000192e0: 652f 6578 636c 7564 6520 6f70 7469 6f6e  e/exclude option
-000192f0: 7320 7769 7468 2061 6273 6f6c 7574 6520  s with absolute 
-00019300: 7061 7468 7322 2222 0a0a 2020 2020 6465  paths"""..    de
-00019310: 6620 7465 7374 5f61 6273 6f6c 7574 655f  f test_absolute_
-00019320: 7061 7468 735f 6e6f 6e5f 676c 6f62 6269  paths_non_globbi
-00019330: 6e67 2873 656c 6629 3a0a 2020 2020 2020  ng(self):.      
-00019340: 2020 7522 2222 2054 6573 7420 2d2d 696e    u""" Test --in
-00019350: 636c 7564 6520 616e 6420 2d2d 6578 636c  clude and --excl
-00019360: 7564 6520 776f 726b 2077 6974 6820 6162  ude work with ab
-00019370: 736f 6c75 7465 2070 6174 6873 2222 220a  solute paths""".
-00019380: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
-00019390: 6b75 7028 7522 6675 6c6c 222c 206f 732e  kup(u"full", os.
-000193a0: 7061 7468 2e61 6273 7061 7468 2875 2274  path.abspath(u"t
-000193b0: 6573 7466 696c 6573 2f73 656c 6563 7432  estfiles/select2
-000193c0: 2229 2c0a 2020 2020 2020 2020 2020 2020  "),.            
-000193d0: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
-000193e0: 5b75 222d 2d69 6e63 6c75 6465 222c 206f  [u"--include", o
-000193f0: 732e 7061 7468 2e61 6273 7061 7468 2875  s.path.abspath(u
-00019400: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00019410: 7432 2f33 2f33 7375 6233 2f33 7375 6233  t2/3/3sub3/3sub3
-00019420: 7375 6232 2f33 7375 6233 7375 6232 5f66  sub2/3sub3sub2_f
-00019430: 696c 652e 7478 7422 292c 0a20 2020 2020  ile.txt"),.     
-00019440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019450: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-00019460: 7564 6522 2c20 6f73 2e70 6174 682e 6162  ude", os.path.ab
-00019470: 7370 6174 6828 7522 7465 7374 6669 6c65  spath(u"testfile
-00019480: 732f 7365 6c65 6374 322f 332f 3373 7562  s/select2/3/3sub
-00019490: 332f 3373 7562 3373 7562 3222 292c 0a20  3/3sub3sub2"),. 
-000194a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000194b0: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-000194c0: 696e 636c 7564 6522 2c20 6f73 2e70 6174  include", os.pat
-000194d0: 682e 6162 7370 6174 6828 7522 7465 7374  h.abspath(u"test
-000194e0: 6669 6c65 732f 7365 6c65 6374 322f 332f  files/select2/3/
-000194f0: 3373 7562 322f 3373 7562 3273 7562 3222  3sub2/3sub2sub2"
-00019500: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
-00019510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019520: 7522 2d2d 696e 636c 7564 6522 2c20 6f73  u"--include", os
-00019530: 2e70 6174 682e 6162 7370 6174 6828 7522  .path.abspath(u"
-00019540: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00019550: 322f 332f 3373 7562 3322 292c 0a20 2020  2/3/3sub3"),.   
-00019560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019570: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-00019580: 636c 7564 6522 2c20 6f73 2e70 6174 682e  clude", os.path.
-00019590: 6162 7370 6174 6828 7522 7465 7374 6669  abspath(u"testfi
-000195a0: 6c65 732f 7365 6c65 6374 322f 332f 3373  les/select2/3/3s
-000195b0: 7562 3122 292c 0a20 2020 2020 2020 2020  ub1"),.         
-000195c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000195d0: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-000195e0: 2c20 6f73 2e70 6174 682e 6162 7370 6174  , os.path.abspat
-000195f0: 6828 7522 7465 7374 6669 6c65 732f 7365  h(u"testfiles/se
-00019600: 6c65 6374 322f 322f 3273 7562 312f 3273  lect2/2/2sub1/2s
-00019610: 7562 3173 7562 3322 292c 0a20 2020 2020  ub1sub3"),.     
-00019620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019630: 2020 2020 2020 2020 7522 2d2d 6578 636c          u"--excl
-00019640: 7564 6522 2c20 6f73 2e70 6174 682e 6162  ude", os.path.ab
-00019650: 7370 6174 6828 7522 7465 7374 6669 6c65  spath(u"testfile
-00019660: 732f 7365 6c65 6374 322f 322f 3273 7562  s/select2/2/2sub
-00019670: 312f 3273 7562 3173 7562 3222 292c 0a20  1/2sub1sub2"),. 
-00019680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019690: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-000196a0: 696e 636c 7564 6522 2c20 6f73 2e70 6174  include", os.pat
-000196b0: 682e 6162 7370 6174 6828 7522 7465 7374  h.abspath(u"test
-000196c0: 6669 6c65 732f 7365 6c65 6374 322f 322f  files/select2/2/
-000196d0: 3273 7562 3122 292c 0a20 2020 2020 2020  2sub1"),.       
-000196e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000196f0: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-00019700: 6522 2c20 6f73 2e70 6174 682e 6162 7370  e", os.path.absp
-00019710: 6174 6828 7522 7465 7374 6669 6c65 732f  ath(u"testfiles/
-00019720: 7365 6c65 6374 322f 312f 3173 7562 332f  select2/1/1sub3/
-00019730: 3173 7562 3373 7562 3222 292c 0a20 2020  1sub3sub2"),.   
-00019740: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019750: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-00019760: 636c 7564 6522 2c20 6f73 2e70 6174 682e  clude", os.path.
-00019770: 6162 7370 6174 6828 7522 7465 7374 6669  abspath(u"testfi
-00019780: 6c65 732f 7365 6c65 6374 322f 312f 3173  les/select2/1/1s
-00019790: 7562 332f 3173 7562 3373 7562 3122 292c  ub3/1sub3sub1"),
-000197a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000197b0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-000197c0: 2d2d 6578 636c 7564 6522 2c20 6f73 2e70  --exclude", os.p
-000197d0: 6174 682e 6162 7370 6174 6828 7522 7465  ath.abspath(u"te
-000197e0: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
-000197f0: 312f 3173 7562 322f 3173 7562 3273 7562  1/1sub2/1sub2sub
-00019800: 3322 292c 0a20 2020 2020 2020 2020 2020  3"),.           
-00019810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019820: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-00019830: 6f73 2e70 6174 682e 6162 7370 6174 6828  os.path.abspath(
-00019840: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00019850: 6374 322f 312f 3173 7562 322f 3173 7562  ct2/1/1sub2/1sub
-00019860: 3273 7562 3122 292c 0a20 2020 2020 2020  2sub1"),.       
-00019870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019880: 2020 2020 2020 7522 2d2d 6578 636c 7564        u"--exclud
-00019890: 6522 2c20 6f73 2e70 6174 682e 6162 7370  e", os.path.absp
-000198a0: 6174 6828 7522 7465 7374 6669 6c65 732f  ath(u"testfiles/
-000198b0: 7365 6c65 6374 322f 312f 3173 7562 312f  select2/1/1sub1/
-000198c0: 3173 7562 3173 7562 332f 3173 7562 3173  1sub1sub3/1sub1s
-000198d0: 7562 335f 6669 6c65 2e74 7874 2229 2c0a  ub3_file.txt"),.
-000198e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000198f0: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-00019900: 2d65 7863 6c75 6465 222c 206f 732e 7061  -exclude", os.pa
-00019910: 7468 2e61 6273 7061 7468 2875 2274 6573  th.abspath(u"tes
-00019920: 7466 696c 6573 2f73 656c 6563 7432 2f31  tfiles/select2/1
-00019930: 2f31 7375 6231 2f31 7375 6231 7375 6232  /1sub1/1sub1sub2
-00019940: 2229 2c0a 2020 2020 2020 2020 2020 2020  "),.            
-00019950: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019960: 2075 222d 2d65 7863 6c75 6465 222c 206f   u"--exclude", o
-00019970: 732e 7061 7468 2e61 6273 7061 7468 2875  s.path.abspath(u
-00019980: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
-00019990: 7432 2f31 2f31 7375 6232 2229 2c0a 2020  t2/1/1sub2"),.  
-000199a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000199b0: 2020 2020 2020 2020 2020 2075 222d 2d69             u"--i
-000199c0: 6e63 6c75 6465 222c 206f 732e 7061 7468  nclude", os.path
-000199d0: 2e61 6273 7061 7468 2875 2274 6573 7466  .abspath(u"testf
-000199e0: 696c 6573 2f73 656c 6563 7432 2f31 2e70  iles/select2/1.p
-000199f0: 7922 292c 0a20 2020 2020 2020 2020 2020  y"),.           
-00019a00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019a10: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-00019a20: 6f73 2e70 6174 682e 6162 7370 6174 6828  os.path.abspath(
-00019a30: 7522 7465 7374 6669 6c65 732f 7365 6c65  u"testfiles/sele
-00019a40: 6374 322f 3322 292c 0a20 2020 2020 2020  ct2/3"),.       
-00019a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019a60: 2020 2020 2020 7522 2d2d 696e 636c 7564        u"--includ
-00019a70: 6522 2c20 6f73 2e70 6174 682e 6162 7370  e", os.path.absp
-00019a80: 6174 6828 7522 7465 7374 6669 6c65 732f  ath(u"testfiles/
-00019a90: 7365 6c65 6374 322f 3122 292c 0a20 2020  select2/1"),.   
-00019aa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019ab0: 2020 2020 2020 2020 2020 7522 2d2d 6578            u"--ex
-00019ac0: 636c 7564 6522 2c20 6f73 2e70 6174 682e  clude", os.path.
-00019ad0: 6162 7370 6174 6828 7522 7465 7374 6669  abspath(u"testfi
-00019ae0: 6c65 732f 7365 6c65 6374 322f 2a2a 2229  les/select2/**")
-00019af0: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
-00019b00: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
-00019b10: 2020 7265 7374 6f72 655f 6469 7220 3d20    restore_dir = 
-00019b20: 7522 7465 7374 6669 6c65 732f 7265 7374  u"testfiles/rest
-00019b30: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
-00019b40: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
-00019b50: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
-00019b60: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-00019b70: 2872 6573 746f 7265 5f64 6972 290a 2020  (restore_dir).  
-00019b80: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
-00019b90: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
-00019ba0: 2073 656c 662e 6578 7065 6374 6564 5f72   self.expected_r
-00019bb0: 6573 746f 7265 645f 7472 6565 290a 0a0a  estored_tree)...
-00019bc0: 4075 6e69 7474 6573 742e 736b 6970 556e  @unittest.skipUn
-00019bd0: 6c65 7373 2870 6c61 7466 6f72 6d2e 706c  less(platform.pl
-00019be0: 6174 666f 726d 2829 2e73 7461 7274 7377  atform().startsw
-00019bf0: 6974 6828 7522 4c69 6e75 7822 292c 2075  ith(u"Linux"), u
-00019c00: 2253 6b69 7020 6f6e 206e 6f6e 2d4c 696e  "Skip on non-Lin
-00019c10: 7578 2073 7973 7465 6d73 2229 0a40 756e  ux systems").@un
-00019c20: 6974 7465 7374 2e73 6b69 7055 6e6c 6573  ittest.skipUnles
-00019c30: 7328 7379 732e 6765 7466 696c 6573 7973  s(sys.getfilesys
-00019c40: 7465 6d65 6e63 6f64 696e 6728 292e 7570  temencoding().up
-00019c50: 7065 7228 2920 3d3d 2075 2255 5446 2d38  per() == u"UTF-8
-00019c60: 222c 2075 2253 6b69 7020 6f6e 206e 6f6e  ", u"Skip on non
-00019c70: 2d55 5446 2d38 2073 7973 7465 6d73 2229  -UTF-8 systems")
-00019c80: 0a40 756e 6974 7465 7374 2e73 6b69 7049  .@unittest.skipI
-00019c90: 6628 7379 732e 7665 7273 696f 6e5f 696e  f(sys.version_in
-00019ca0: 666f 5b3a 325d 203c 2028 332c 2037 292c  fo[:2] < (3, 7),
-00019cb0: 2075 2253 6b69 7020 6f6e 2062 6164 2075   u"Skip on bad u
-00019cc0: 6e69 636f 6465 2068 616e 646c 696e 6722  nicode handling"
-00019cd0: 290a 636c 6173 7320 5465 7374 556e 6963  ).class TestUnic
-00019ce0: 6f64 6528 496e 636c 7564 6545 7863 6c75  ode(IncludeExclu
-00019cf0: 6465 4675 6e63 7469 6f6e 616c 5465 7374  deFunctionalTest
-00019d00: 293a 0a20 2020 2075 2222 2220 5465 7374  ):.    u""" Test
-00019d10: 7320 696e 636c 7564 652f 6578 636c 7564  s include/exclud
-00019d20: 6520 6f70 7469 6f6e 7320 7769 7468 2075  e options with u
-00019d30: 6e69 636f 6465 2070 6174 6873 2222 220a  nicode paths""".
-00019d40: 0a20 2020 2064 6566 2074 6573 745f 756e  .    def test_un
-00019d50: 6963 6f64 655f 7061 7468 735f 6e6f 6e5f  icode_paths_non_
-00019d60: 676c 6f62 6269 6e67 2873 656c 6629 3a0a  globbing(self):.
-00019d70: 2020 2020 2020 2020 7522 2222 2054 6573          u""" Tes
-00019d80: 7420 2d2d 696e 636c 7564 6520 616e 6420  t --include and 
-00019d90: 2d2d 6578 636c 7564 6520 776f 726b 2077  --exclude work w
-00019da0: 6974 6820 756e 6963 6f64 6520 7061 7468  ith unicode path
-00019db0: 7322 2222 0a20 2020 2020 2020 2073 656c  s""".        sel
-00019dc0: 662e 6261 636b 7570 2875 2266 756c 6c22  f.backup(u"full"
-00019dd0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-00019de0: 6c65 6374 2d75 6e69 636f 6465 222c 0a20  lect-unicode",. 
-00019df0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019e00: 2020 206f 7074 696f 6e73 3d5b 7522 2d2d     options=[u"--
-00019e10: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-00019e20: 6669 6c65 732f 7365 6c65 6374 2d75 6e69  files/select-uni
-00019e30: 636f 6465 2fd0 bfd1 80d1 8bd0 bad0 bbd0  code/...........
-00019e40: b0d0 b42f d0bf d180 d0b8 d0bc d0b5 d180  .../............
-00019e50: 2fe4 be8b 2fce a0ce b1cf 81ce acce b4ce  /.../...........
-00019e60: b5ce b9ce b3ce bcce b12f e0a4 89e0 a4a6  ........./......
-00019e70: e0a4 bee0 a4b9 e0a4 b0e0 a4a3 2e74 7874  .............txt
-00019e80: 222c 0a20 2020 2020 2020 2020 2020 2020  ",.             
-00019e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019ea0: 7522 2d2d 6578 636c 7564 6522 2c20 7522  u"--exclude", u"
-00019eb0: 7465 7374 6669 6c65 732f 7365 6c65 6374  testfiles/select
-00019ec0: 2d75 6e69 636f 6465 2fd0 bfd1 80d1 8bd0  -unicode/.......
-00019ed0: bad0 bbd0 b0d0 b42f d0bf d180 d0b8 d0bc  ......./........
-00019ee0: d0b5 d180 2fe4 be8b 2fce a0ce b1cf 81ce  ..../.../.......
-00019ef0: acce b4ce b5ce b9ce b3ce bcce b12f d793  ............./..
-00019f00: d795 d792 d79e d790 2e74 7874 222c 0a20  .........txt",. 
-00019f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019f20: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-00019f30: 6578 636c 7564 6522 2c20 7522 7465 7374  exclude", u"test
-00019f40: 6669 6c65 732f 7365 6c65 6374 2d75 6e69  files/select-uni
-00019f50: 636f 6465 2fd0 bfd1 80d1 8bd0 bad0 bbd0  code/...........
-00019f60: b0d0 b42f d0bf d180 d0b8 d0bc d0b5 d180  .../............
-00019f70: 2fe4 be8b 2fe1 839b e183 90e1 8392 e183  /.../...........
-00019f80: 90e1 839a e183 98e1 8397 e183 982f 222c  ............./",
-00019f90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019fa0: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-00019fb0: 2d2d 696e 636c 7564 6522 2c20 7522 7465  --include", u"te
-00019fc0: 7374 6669 6c65 732f 7365 6c65 6374 2d75  stfiles/select-u
-00019fd0: 6e69 636f 6465 2fd0 bfd1 80d1 8bd0 bad0  nicode/.........
-00019fe0: bbd0 b0d0 b42f d0bf d180 d0b8 d0bc d0b5  ...../..........
-00019ff0: d180 2fe4 be8b 2f22 2c0a 2020 2020 2020  ../.../",.      
-0001a000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a010: 2020 2020 2020 2075 222d 2d65 7863 6c75         u"--exclu
-0001a020: 6465 222c 2075 2274 6573 7466 696c 6573  de", u"testfiles
-0001a030: 2f73 656c 6563 742d 756e 6963 6f64 652f  /select-unicode/
-0001a040: d0bf d180 d18b d0ba d0bb d0b0 d0b4 2fd0  ............../.
-0001a050: bfd1 80d0 b8d0 bcd0 b5d1 802f 222c 0a20  .........../",. 
-0001a060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a070: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-0001a080: 696e 636c 7564 6522 2c20 7522 7465 7374  include", u"test
-0001a090: 6669 6c65 732f 7365 6c65 6374 2d75 6e69  files/select-uni
-0001a0a0: 636f 6465 2fd0 bfd1 80d1 8bd0 bad0 bbd0  code/...........
-0001a0b0: b0d0 b42f 222c 0a20 2020 2020 2020 2020  .../",.         
-0001a0c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a0d0: 2020 2020 7522 2d2d 696e 636c 7564 6522      u"--include"
-0001a0e0: 2c20 7522 7465 7374 6669 6c65 732f 7365  , u"testfiles/se
-0001a0f0: 6c65 6374 2d75 6e69 636f 6465 2fd6 85d6  lect-unicode/...
-0001a100: 80d5 abd5 b6d5 a1d5 af2e 7478 7422 2c0a  ..........txt",.
-0001a110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a120: 2020 2020 2020 2020 2020 2020 2075 222d               u"-
-0001a130: 2d65 7863 6c75 6465 222c 2075 2274 6573  -exclude", u"tes
-0001a140: 7466 696c 6573 2f73 656c 6563 742d 756e  tfiles/select-un
-0001a150: 6963 6f64 652f 2a2a 225d 290a 2020 2020  icode/**"]).    
-0001a160: 2020 2020 7365 6c66 2e72 6573 746f 7265      self.restore
-0001a170: 2829 0a20 2020 2020 2020 2072 6573 746f  ().        resto
-0001a180: 7265 5f64 6972 203d 2075 2274 6573 7466  re_dir = u"testf
-0001a190: 696c 6573 2f72 6573 746f 7265 5f6f 7574  iles/restore_out
-0001a1a0: 220a 2020 2020 2020 2020 7265 7374 6f72  ".        restor
-0001a1b0: 6564 203d 2073 656c 662e 6469 7265 6374  ed = self.direct
-0001a1c0: 6f72 795f 7472 6565 5f74 6f5f 6c69 7374  ory_tree_to_list
-0001a1d0: 5f6f 665f 6c69 7374 7328 7265 7374 6f72  _of_lists(restor
-0001a1e0: 655f 6469 7229 0a20 2020 2020 2020 2073  e_dir).        s
-0001a1f0: 656c 662e 6173 7365 7274 4571 7561 6c28  elf.assertEqual(
-0001a200: 7265 7374 6f72 6564 2c20 5b5b 7522 d0bf  restored, [[u"..
-0001a210: d180 d18b d0ba d0bb d0b0 d0b4 222c 2075  ............", u
-0001a220: 22d6 85d6 80d5 abd5 b6d5 a1d5 af2e 7478  ".............tx
-0001a230: 7422 5d2c 0a20 2020 2020 2020 2020 2020  t"],.           
-0001a240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a250: 2020 2020 2020 2020 205b 7522 d0bf d180           [u"....
-0001a260: d0b8 d0bc d0b5 d180 222c 2075 22e0 a689  ........", u"...
-0001a270: e0a6 a6e0 a6be e0a6 b9e0 a6b0 e0a6 a322  ..............."
-0001a280: 5d2c 205b 7522 e4be 8b22 5d2c 205b 7522  ], [u"..."], [u"
-0001a290: cea0 ceb1 cf81 ceac ceb4 ceb5 ceb9 ceb3  ................
-0001a2a0: cebc ceb1 225d 2c20 5b75 22e0 aa89 e0aa  ...."], [u".....
-0001a2b0: a6e0 aabe e0aa b9e0 aab0 e0aa a32e 6c6f  ..............lo
-0001a2c0: 6722 5d5d 290a 0a20 2020 2064 6566 2074  g"]])..    def t
-0001a2d0: 6573 745f 756e 6963 6f64 655f 7061 7468  est_unicode_path
-0001a2e0: 735f 6173 7465 7269 736b 7328 7365 6c66  s_asterisks(self
-0001a2f0: 293a 0a20 2020 2020 2020 2075 2222 2220  ):.        u""" 
-0001a300: 5465 7374 202d 2d69 6e63 6c75 6465 2061  Test --include a
-0001a310: 6e64 202d 2d65 7863 6c75 6465 2077 6f72  nd --exclude wor
-0001a320: 6b20 7769 7468 2075 6e69 636f 6465 2070  k with unicode p
-0001a330: 6174 6873 2061 6e64 2067 6c6f 6273 2063  aths and globs c
-0001a340: 6f6e 7461 696e 696e 6720 2a20 616e 6420  ontaining * and 
-0001a350: 2a2a 2222 220a 2020 2020 2020 2020 7020  **""".        p 
-0001a360: 3d20 7522 7465 7374 6669 6c65 732f 7365  = u"testfiles/se
-0001a370: 6c65 6374 2d75 6e69 636f 6465 2f22 0a20  lect-unicode/". 
-0001a380: 2020 2020 2020 2073 656c 662e 6261 636b         self.back
-0001a390: 7570 2875 2266 756c 6c22 2c20 7522 7465  up(u"full", u"te
-0001a3a0: 7374 6669 6c65 732f 7365 6c65 6374 2d75  stfiles/select-u
-0001a3b0: 6e69 636f 6465 222c 0a20 2020 2020 2020  nicode",.       
-0001a3c0: 2020 2020 2020 2020 2020 2020 206f 7074               opt
-0001a3d0: 696f 6e73 3d5b 7522 2d2d 6578 636c 7564  ions=[u"--exclud
-0001a3e0: 6522 2c20 7020 2b20 7522 d0bf d180 d18b  e", p + u"......
-0001a3f0: d0ba d0bb d0b0 d0b4 2fd0 bfd1 80d0 b8d0  ......../.......
-0001a400: bcd0 b5d1 802f e4be 8b2f cea0 ceb1 cf81  ...../.../......
-0001a410: ceac 2ace b5ce b9ce b3ce bcce b12f e0a4  ..*........../..
-0001a420: 89e0 a4a6 e0a4 bee0 a4b9 e0a4 b0e0 a4a3  ................
-0001a430: 2e74 7874 222c 2020 2320 4e6f 7465 202a  .txt",  # Note *
-0001a440: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001a450: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0001a460: 2d2d 6578 636c 7564 6522 2c20 7020 2b20  --exclude", p + 
-0001a470: 7522 d0bf d180 d18b d0ba d0bb d0b0 d0b4  u"..............
-0001a480: 2fd0 bfd1 80d0 b8d0 bcd0 b5d1 802f e4be  /............/..
-0001a490: 8b2f cea0 ceb1 cf81 ceac ceb4 ceb5 ceb9  ./..............
-0001a4a0: ceb3 cebc ceb1 2fd7 93d7 95d7 92d7 9ed7  ....../.........
-0001a4b0: 902e 7478 7422 2c0a 2020 2020 2020 2020  ..txt",.        
-0001a4c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a4d0: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-0001a4e0: 222c 2070 202b 2075 22d0 bfd1 80d1 8bd0  ", p + u".......
-0001a4f0: bad0 bbd0 b0d0 b42f d0bf d180 d0b8 d0bc  ......./........
-0001a500: d0b5 d180 2fe4 be8b 2fe1 839b e183 90e1  ..../.../.......
-0001a510: 8392 e183 90e1 839a e183 98e1 8397 e183  ................
-0001a520: 982f 222c 0a20 2020 2020 2020 2020 2020  ./",.           
-0001a530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a540: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-0001a550: 7020 2b20 7522 d0bf d180 2a2a 2fe4 be8b  p + u"....**/...
-0001a560: 2f22 2c20 2023 204e 6f74 6520 2a2a 0a20  /",  # Note **. 
-0001a570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a580: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-0001a590: 6578 636c 7564 6522 2c20 7020 2b20 7522  exclude", p + u"
-0001a5a0: d0bf d180 d18b d0ba d0bb d0b0 d0b4 2fd0  ............../.
-0001a5b0: bfd1 80d0 b8d0 bcd0 b5d1 802f 222c 0a20  .........../",. 
-0001a5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a5d0: 2020 2020 2020 2020 2020 2020 7522 2d2d              u"--
-0001a5e0: 696e 636c 7564 6522 2c20 7020 2b20 7522  include", p + u"
-0001a5f0: d0bf d180 d18b d0ba d0bb d0b0 2a2f 222c  ............*/",
-0001a600: 2020 2320 4e6f 7465 202a 0a20 2020 2020    # Note *.     
-0001a610: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a620: 2020 2020 2020 2020 7522 2d2d 696e 636c          u"--incl
-0001a630: 7564 6522 2c20 7020 2b20 7522 d685 d680  ude", p + u"....
-0001a640: 2ad5 a1d5 af2e 7478 7422 2c20 2023 204e  *.....txt",  # N
-0001a650: 6f74 6520 2a0a 2020 2020 2020 2020 2020  ote *.          
-0001a660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a670: 2020 2075 222d 2d65 7863 6c75 6465 222c     u"--exclude",
-0001a680: 2070 202b 2075 222a 2a22 5d29 0a20 2020   p + u"**"]).   
-0001a690: 2020 2020 2073 656c 662e 7265 7374 6f72       self.restor
-0001a6a0: 6528 290a 2020 2020 2020 2020 7265 7374  e().        rest
-0001a6b0: 6f72 655f 6469 7220 3d20 7522 7465 7374  ore_dir = u"test
-0001a6c0: 6669 6c65 732f 7265 7374 6f72 655f 6f75  files/restore_ou
-0001a6d0: 7422 0a20 2020 2020 2020 2072 6573 746f  t".        resto
-0001a6e0: 7265 6420 3d20 7365 6c66 2e64 6972 6563  red = self.direc
-0001a6f0: 746f 7279 5f74 7265 655f 746f 5f6c 6973  tory_tree_to_lis
-0001a700: 745f 6f66 5f6c 6973 7473 2872 6573 746f  t_of_lists(resto
-0001a710: 7265 5f64 6972 290a 2020 2020 2020 2020  re_dir).        
-0001a720: 7365 6c66 2e61 7373 6572 7445 7175 616c  self.assertEqual
-0001a730: 2872 6573 746f 7265 642c 205b 5b75 22d0  (restored, [[u".
-0001a740: bfd1 80d1 8bd0 bad0 bbd0 b0d0 b422 2c20  .............", 
-0001a750: 7522 d685 d680 d5ab d5b6 d5a1 d5af 2e74  u".............t
-0001a760: 7874 225d 2c0a 2020 2020 2020 2020 2020  xt"],.          
-0001a770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a780: 2020 2020 2020 2020 2020 5b75 22d0 bfd1            [u"...
-0001a790: 80d0 b8d0 bcd0 b5d1 8022 2c20 7522 e0a6  .........", u"..
-0001a7a0: 89e0 a6a6 e0a6 bee0 a6b9 e0a6 b0e0 a6a3  ................
-0001a7b0: 225d 2c20 5b75 22e4 be8b 225d 2c20 5b75  "], [u"..."], [u
-0001a7c0: 22ce a0ce b1cf 81ce acce b4ce b5ce b9ce  "...............
-0001a7d0: b3ce bcce b122 5d2c 205b 7522 e0aa 89e0  ....."], [u"....
-0001a7e0: aaa6 e0aa bee0 aab9 e0aa b0e0 aaa3 2e6c  ...............l
-0001a7f0: 6f67 225d 5d29 0a0a 2020 2020 6465 6620  og"]])..    def 
-0001a800: 7465 7374 5f75 6e69 636f 6465 5f70 6174  test_unicode_pat
-0001a810: 6873 5f73 7175 6172 655f 6272 6163 6b65  hs_square_bracke
-0001a820: 7473 2873 656c 6629 3a0a 2020 2020 2020  ts(self):.      
-0001a830: 2020 7522 2222 2054 6573 7420 2d2d 696e    u""" Test --in
-0001a840: 636c 7564 6520 616e 6420 2d2d 6578 636c  clude and --excl
-0001a850: 7564 6520 776f 726b 2077 6974 6820 756e  ude work with un
-0001a860: 6963 6f64 6520 7061 7468 7320 7769 7468  icode paths with
-0001a870: 2063 6861 7261 6374 6572 206f 7074 696f   character optio
-0001a880: 6e73 2069 6e20 5b5d 7320 616e 6420 5b21  ns in []s and [!
-0001a890: 5d73 2222 220a 2020 2020 2020 2020 7020  ]s""".        p 
-0001a8a0: 3d20 7522 7465 7374 6669 6c65 732f 7365  = u"testfiles/se
-0001a8b0: 6c65 6374 2d75 6e69 636f 6465 2f22 0a20  lect-unicode/". 
-0001a8c0: 2020 2020 2020 2073 656c 662e 6261 636b         self.back
-0001a8d0: 7570 2875 2266 756c 6c22 2c20 7522 7465  up(u"full", u"te
-0001a8e0: 7374 6669 6c65 732f 7365 6c65 6374 2d75  stfiles/select-u
-0001a8f0: 6e69 636f 6465 222c 0a20 2020 2020 2020  nicode",.       
-0001a900: 2020 2020 2020 2020 2020 2020 206f 7074               opt
-0001a910: 696f 6e73 3d5b 7522 2d2d 6578 636c 7564  ions=[u"--exclud
-0001a920: 6522 2c20 7020 2b20 7522 d0bf d180 d18b  e", p + u"......
-0001a930: d0ba d0bb d0b0 d0b4 2fd0 bfd1 80d0 b8d0  ......../.......
-0001a940: bcd0 b5d1 802f e4be 8b2f cea0 ceb1 cf81  ...../.../......
-0001a950: ceac ceb4 ceb5 ceb9 ceb3 cebc ceb1 2fe0  ............../.
-0001a960: a489 e0a4 a6e0 a4be e0a4 b9e0 a4b0 e0a4  ................
-0001a970: a32e 7478 7422 2c0a 2020 2020 2020 2020  ..txt",.        
-0001a980: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a990: 2020 2020 2075 222d 2d65 7863 6c75 6465       u"--exclude
-0001a9a0: 222c 2070 202b 2075 22d0 bfd1 80d1 8b5b  ", p + u"......[
-0001a9b0: d0ba 2cd0 b82c d180 5dd0 bbd0 b0d0 b42f  ..,..,..]....../
-0001a9c0: d0bf d180 d0b8 d0bc d0b5 d180 2fe4 be8b  ............/...
-0001a9d0: 2fce a0ce b1cf 81ce acce b4ce b5ce b9ce  /...............
-0001a9e0: b3ce bcce b12f d793 d795 d792 d79e d790  ...../..........
-0001a9f0: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
-0001aa00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aa10: 2020 2020 7522 2d2d 6578 636c 7564 6522      u"--exclude"
-0001aa20: 2c20 7020 2b20 7522 d0bf d180 d18b d0ba  , p + u"........
-0001aa30: d0bb d0b0 d0b4 2fd0 bfd1 805b 2161 2c62  ....../....[!a,b
-0001aa40: 2c63 5dd0 bcd0 b5d1 802f e4be 8b2f e183  ,c]....../.../..
-0001aa50: 9be1 8390 e183 92e1 8390 e183 9ae1 8398  ................
-0001aa60: e183 97e1 8398 2f22 2c0a 2020 2020 2020  ....../",.      
-0001aa70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aa80: 2020 2020 2020 2075 222d 2d69 6e63 6c75         u"--inclu
-0001aa90: 6465 222c 2070 202b 2075 22d0 bfd1 80d1  de", p + u".....
-0001aaa0: 8bd0 bad0 bbd0 b0d0 b42f d0bf d180 d0b8  ........./......
-0001aab0: 5b67 2cd0 bc2c d0b4 5dd0 b5d1 802f e4be  [g,..,..]..../..
-0001aac0: 8b2f 222c 0a20 2020 2020 2020 2020 2020  ./",.           
-0001aad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001aae0: 2020 7522 2d2d 6578 636c 7564 6522 2c20    u"--exclude", 
-0001aaf0: 7020 2b20 7522 d0bf d180 d18b d0ba d0bb  p + u"..........
-0001ab00: d0b0 d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1  ..../...........
-0001ab10: 802f 222c 0a20 2020 2020 2020 2020 2020  ./",.           
-0001ab20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ab30: 2020 7522 2d2d 696e 636c 7564 6522 2c20    u"--include", 
-0001ab40: 7020 2b20 7522 d0bf d180 d18b d0ba d0bb  p + u"..........
-0001ab50: d0b0 d0b4 2f22 2c0a 2020 2020 2020 2020  ..../",.        
-0001ab60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ab70: 2020 2020 2075 222d 2d69 6e63 6c75 6465       u"--include
-0001ab80: 222c 2070 202b 2075 22d6 85d6 80d5 abd5  ", p + u".......
-0001ab90: b6d5 a1d5 af2e 7478 7422 2c0a 2020 2020  ......txt",.    
-0001aba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001abb0: 2020 2020 2020 2020 2075 222d 2d65 7863           u"--exc
-0001abc0: 6c75 6465 222c 2070 202b 2075 222a 2a22  lude", p + u"**"
-0001abd0: 5d29 0a20 2020 2020 2020 2073 656c 662e  ]).        self.
-0001abe0: 7265 7374 6f72 6528 290a 2020 2020 2020  restore().      
-0001abf0: 2020 7265 7374 6f72 655f 6469 7220 3d20    restore_dir = 
-0001ac00: 7522 7465 7374 6669 6c65 732f 7265 7374  u"testfiles/rest
-0001ac10: 6f72 655f 6f75 7422 0a20 2020 2020 2020  ore_out".       
-0001ac20: 2072 6573 746f 7265 6420 3d20 7365 6c66   restored = self
-0001ac30: 2e64 6972 6563 746f 7279 5f74 7265 655f  .directory_tree_
-0001ac40: 746f 5f6c 6973 745f 6f66 5f6c 6973 7473  to_list_of_lists
-0001ac50: 2872 6573 746f 7265 5f64 6972 290a 2020  (restore_dir).  
-0001ac60: 2020 2020 2020 7365 6c66 2e61 7373 6572        self.asser
-0001ac70: 7445 7175 616c 2872 6573 746f 7265 642c  tEqual(restored,
-0001ac80: 205b 5b75 22d0 bfd1 80d1 8bd0 bad0 bbd0   [[u"...........
-0001ac90: b0d0 b422 2c20 7522 d685 d680 d5ab d5b6  ...", u"........
-0001aca0: d5a1 d5af 2e74 7874 225d 2c0a 2020 2020  .....txt"],.    
-0001acb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001acc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001acd0: 5b75 22d0 bfd1 80d0 b8d0 bcd0 b5d1 8022  [u"............"
-0001ace0: 2c20 7522 e0a6 89e0 a6a6 e0a6 bee0 a6b9  , u"............
-0001acf0: e0a6 b0e0 a6a3 225d 2c20 5b75 22e4 be8b  ......"], [u"...
-0001ad00: 225d 2c20 5b75 22ce a0ce b1cf 81ce acce  "], [u".........
-0001ad10: b4ce b5ce b9ce b3ce bcce b122 5d2c 205b  ..........."], [
-0001ad20: 7522 e0aa 89e0 aaa6 e0aa bee0 aab9 e0aa  u"..............
-0001ad30: b0e0 aaa3 2e6c 6f67 225d 5d29 0a0a 2020  .....log"]])..  
-0001ad40: 2020 6465 6620 7465 7374 5f75 6e69 636f    def test_unico
-0001ad50: 6465 5f66 696c 656c 6973 7428 7365 6c66  de_filelist(self
-0001ad60: 293a 0a20 2020 2020 2020 2075 2222 2254  ):.        u"""T
-0001ad70: 6573 7420 7468 6174 2065 7863 6c75 6465  est that exclude
-0001ad80: 2066 696c 656c 6973 7420 776f 726b 7320   filelist works 
-0001ad90: 7769 7468 2075 6e69 636f 6465 2066 696c  with unicode fil
-0001ada0: 656e 616d 6573 2222 220a 2020 2020 2020  enames""".      
-0001adb0: 2020 2320 4173 2074 6869 7320 6973 2061    # As this is a
-0001adc0: 6e20 6578 636c 7564 6520 6669 6c65 6c69  n exclude fileli
-0001add0: 7374 2061 6e79 206c 696e 6573 2077 6974  st any lines wit
-0001ade0: 6820 6e6f 202b 2f2d 206d 6f64 6966 6965  h no +/- modifie
-0001adf0: 7220 7368 6f75 6c64 2062 6520 7472 6561  r should be trea
-0001ae00: 7465 6420 6173 2069 6620 7468 6579 2068  ted as if they h
-0001ae10: 6176 6520 6120 2d2e 0a20 2020 2020 2020  ave a -..       
-0001ae20: 2070 6174 6820 3d20 7522 7465 7374 6669   path = u"testfi
-0001ae30: 6c65 732f 7365 6c65 6374 2d75 6e69 636f  les/select-unico
-0001ae40: 6465 2f22 0a20 2020 2020 2020 2023 2043  de/".        # C
-0001ae50: 7265 6174 6520 6120 6669 6c65 6c69 7374  reate a filelist
-0001ae60: 0a20 2020 2020 2020 2077 6974 6820 696f  .        with io
-0001ae70: 2e6f 7065 6e28 7522 7465 7374 6669 6c65  .open(u"testfile
-0001ae80: 732f 6578 636c 7564 652e 7478 7422 2c20  s/exclude.txt", 
-0001ae90: 7522 7722 2c20 656e 636f 6469 6e67 3d75  u"w", encoding=u
-0001aea0: 2255 5446 2d38 2229 2061 7320 663a 0a20  "UTF-8") as f:. 
-0001aeb0: 2020 2020 2020 2020 2020 2066 2e77 7269             f.wri
-0001aec0: 7465 2875 222d 2022 202b 2070 6174 6820  te(u"- " + path 
-0001aed0: 2b20 7522 d0bf d180 d18b d0ba d0bb d0b0  + u"............
-0001aee0: d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1 802f  ../............/
-0001aef0: e4be 8b2f cea0 ceb1 cf81 ceac ceb4 ceb5  .../............
-0001af00: ceb9 ceb3 cebc ceb1 2fe0 a489 e0a4 a6e0  ......../.......
-0001af10: a4be e0a4 b9e0 a4b0 e0a4 a32e 7478 745c  ............txt\
-0001af20: 6e22 0a20 2020 2020 2020 2020 2020 2020  n".             
-0001af30: 2020 2020 2020 2075 222d 2022 202b 2070         u"- " + p
-0001af40: 6174 6820 2b20 7522 d0bf d180 d18b d0ba  ath + u"........
-0001af50: d0bb d0b0 d0b4 2fd0 bfd1 80d0 b8d0 bcd0  ....../.........
-0001af60: b5d1 802f e4be 8b2f cea0 ceb1 cf81 ceac  .../.../........
-0001af70: ceb4 ceb5 ceb9 ceb3 cebc ceb1 2fd7 93d7  ............/...
-0001af80: 95d7 92d7 9ed7 902e 7478 745c 6e22 0a20  ........txt\n". 
-0001af90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001afa0: 2020 2075 222d 2022 202b 2070 6174 6820     u"- " + path 
-0001afb0: 2b20 7522 d0bf d180 d18b d0ba d0bb d0b0  + u"............
-0001afc0: d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1 802f  ../............/
-0001afd0: e4be 8b2f e183 9be1 8390 e183 92e1 8390  .../............
-0001afe0: e183 9ae1 8398 e183 97e1 8398 2f5c 6e22  ............/\n"
-0001aff0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b000: 2020 2020 2075 222b 2022 202b 2070 6174       u"+ " + pat
-0001b010: 6820 2b20 7522 d0bf d180 d18b d0ba d0bb  h + u"..........
-0001b020: d0b0 d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1  ..../...........
-0001b030: 802f e4be 8b2f 5c6e 220a 2020 2020 2020  ./.../\n".      
-0001b040: 2020 2020 2020 2020 2020 2020 2020 7522                u"
-0001b050: 2d20 2220 2b20 7061 7468 202b 2075 22d0  - " + path + u".
-0001b060: bfd1 80d1 8bd0 bad0 bbd0 b0d0 b42f d0bf  ............./..
-0001b070: d180 d0b8 d0bc d0b5 d180 2f5c 6e22 0a20  ........../\n". 
-0001b080: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b090: 2020 2075 222b 2022 202b 2070 6174 6820     u"+ " + path 
-0001b0a0: 2b20 7522 d0bf d180 d18b d0ba d0bb d0b0  + u"............
-0001b0b0: d0b4 2f5c 6e22 0a20 2020 2020 2020 2020  ../\n".         
-0001b0c0: 2020 2020 2020 2020 2020 2075 222b 2022             u"+ "
-0001b0d0: 202b 2070 6174 6820 2b20 7522 d685 d680   + path + u"....
-0001b0e0: d5ab d5b6 d5a1 d5af 2e74 7874 5c6e 220a  .........txt\n".
-0001b0f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b100: 2020 2020 7522 2d20 2220 2b20 7061 7468      u"- " + path
-0001b110: 202b 2075 222a 2a22 290a 2020 2020 2020   + u"**").      
-0001b120: 2020 7365 6c66 2e62 6163 6b75 7028 7522    self.backup(u"
-0001b130: 6675 6c6c 222c 2070 6174 682c 206f 7074  full", path, opt
-0001b140: 696f 6e73 3d5b 7522 2d2d 6578 636c 7564  ions=[u"--exclud
-0001b150: 652d 6669 6c65 6c69 7374 3d74 6573 7466  e-filelist=testf
-0001b160: 696c 6573 2f65 7863 6c75 6465 2e74 7874  iles/exclude.txt
-0001b170: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
-0001b180: 2e72 6573 746f 7265 2829 0a20 2020 2020  .restore().     
-0001b190: 2020 2072 6573 746f 7265 5f64 6972 203d     restore_dir =
-0001b1a0: 2075 2274 6573 7466 696c 6573 2f72 6573   u"testfiles/res
-0001b1b0: 746f 7265 5f6f 7574 220a 2020 2020 2020  tore_out".      
-0001b1c0: 2020 7265 7374 6f72 6564 203d 2073 656c    restored = sel
-0001b1d0: 662e 6469 7265 6374 6f72 795f 7472 6565  f.directory_tree
-0001b1e0: 5f74 6f5f 6c69 7374 5f6f 665f 6c69 7374  _to_list_of_list
-0001b1f0: 7328 7265 7374 6f72 655f 6469 7229 0a20  s(restore_dir). 
-0001b200: 2020 2020 2020 2073 656c 662e 6173 7365         self.asse
-0001b210: 7274 4571 7561 6c28 7265 7374 6f72 6564  rtEqual(restored
-0001b220: 2c20 5b5b 7522 d0bf d180 d18b d0ba d0bb  , [[u"..........
-0001b230: d0b0 d0b4 222c 2075 22d6 85d6 80d5 abd5  ....", u".......
-0001b240: b6d5 a1d5 af2e 7478 7422 5d2c 0a20 2020  ......txt"],.   
-0001b250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b270: 205b 7522 d0bf d180 d0b8 d0bc d0b5 d180   [u"............
-0001b280: 222c 2075 22e0 a689 e0a6 a6e0 a6be e0a6  ", u"...........
-0001b290: b9e0 a6b0 e0a6 a322 5d2c 205b 7522 e4be  ......."], [u"..
-0001b2a0: 8b22 5d2c 205b 7522 cea0 ceb1 cf81 ceac  ."], [u"........
-0001b2b0: ceb4 ceb5 ceb9 ceb3 cebc ceb1 225d 2c20  ............"], 
-0001b2c0: 5b75 22e0 aa89 e0aa a6e0 aabe e0aa b9e0  [u".............
-0001b2d0: aab0 e0aa a32e 6c6f 6722 5d5d 290a 0a0a  ......log"]])...
-0001b2e0: 6966 205f 5f6e 616d 655f 5f20 3d3d 2075  if __name__ == u
-0001b2f0: 225f 5f6d 6169 6e5f 5f22 3a0a 2020 2020  "__main__":.    
-0001b300: 756e 6974 7465 7374 2e6d 6169 6e28 290a  unittest.main().
+000160a0: 2020 2020 2020 222d 2d65 7863 6c75 6465        "--exclude
+000160b0: 222c 206f 732e 7061 7468 2e61 6273 7061  ", os.path.abspa
+000160c0: 7468 2822 7465 7374 6669 6c65 732f 7365  th("testfiles/se
+000160d0: 6c65 6374 322f 312f 3173 7562 312f 3173  lect2/1/1sub1/1s
+000160e0: 7562 3173 7562 3222 292c 0a20 2020 2020  ub1sub2"),.     
+000160f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016100: 2020 2020 2020 2020 222d 2d65 7863 6c75          "--exclu
+00016110: 6465 222c 206f 732e 7061 7468 2e61 6273  de", os.path.abs
+00016120: 7061 7468 2822 7465 7374 6669 6c65 732f  path("testfiles/
+00016130: 7365 6c65 6374 322f 312f 3173 7562 3222  select2/1/1sub2"
+00016140: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
+00016150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016160: 222d 2d69 6e63 6c75 6465 222c 206f 732e  "--include", os.
+00016170: 7061 7468 2e61 6273 7061 7468 2822 7465  path.abspath("te
+00016180: 7374 6669 6c65 732f 7365 6c65 6374 322f  stfiles/select2/
+00016190: 312e 7079 2229 2c0a 2020 2020 2020 2020  1.py"),.        
+000161a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000161b0: 2020 2020 2022 2d2d 696e 636c 7564 6522       "--include"
+000161c0: 2c20 6f73 2e70 6174 682e 6162 7370 6174  , os.path.abspat
+000161d0: 6828 2274 6573 7466 696c 6573 2f73 656c  h("testfiles/sel
+000161e0: 6563 7432 2f33 2229 2c0a 2020 2020 2020  ect2/3"),.      
+000161f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016200: 2020 2020 2020 2022 2d2d 696e 636c 7564         "--includ
+00016210: 6522 2c20 6f73 2e70 6174 682e 6162 7370  e", os.path.absp
+00016220: 6174 6828 2274 6573 7466 696c 6573 2f73  ath("testfiles/s
+00016230: 656c 6563 7432 2f31 2229 2c0a 2020 2020  elect2/1"),.    
+00016240: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016250: 2020 2020 2020 2020 2022 2d2d 6578 636c           "--excl
+00016260: 7564 6522 2c20 6f73 2e70 6174 682e 6162  ude", os.path.ab
+00016270: 7370 6174 6828 2274 6573 7466 696c 6573  spath("testfiles
+00016280: 2f73 656c 6563 7432 2f2a 2a22 295d 290a  /select2/**")]).
+00016290: 2020 2020 2020 2020 7365 6c66 2e72 6573          self.res
+000162a0: 746f 7265 2829 0a20 2020 2020 2020 2072  tore().        r
+000162b0: 6573 746f 7265 5f70 6174 6820 3d20 2274  estore_path = "t
+000162c0: 6573 7466 696c 6573 2f72 6573 746f 7265  estfiles/restore
+000162d0: 5f6f 7574 220a 2020 2020 2020 2020 7265  _out".        re
+000162e0: 7374 6f72 6564 203d 2073 656c 662e 6469  stored = self.di
+000162f0: 7265 6374 6f72 795f 7472 6565 5f74 6f5f  rectory_tree_to_
+00016300: 6c69 7374 5f6f 665f 6c69 7374 7328 7265  list_of_lists(re
+00016310: 7374 6f72 655f 7061 7468 290a 2020 2020  store_path).    
+00016320: 2020 2020 7365 6c66 2e61 7373 6572 7445      self.assertE
+00016330: 7175 616c 2872 6573 746f 7265 642c 2073  qual(restored, s
+00016340: 656c 662e 6578 7065 6374 6564 5f72 6573  elf.expected_res
+00016350: 746f 7265 645f 7472 6565 290a 0a0a 4075  tored_tree)...@u
+00016360: 6e69 7474 6573 742e 736b 6970 556e 6c65  nittest.skipUnle
+00016370: 7373 2870 6c61 7466 6f72 6d2e 706c 6174  ss(platform.plat
+00016380: 666f 726d 2829 2e73 7461 7274 7377 6974  form().startswit
+00016390: 6828 224c 696e 7578 2229 2c20 2253 6b69  h("Linux"), "Ski
+000163a0: 7020 6f6e 206e 6f6e 2d4c 696e 7578 2073  p on non-Linux s
+000163b0: 7973 7465 6d73 2229 0a40 756e 6974 7465  ystems").@unitte
+000163c0: 7374 2e73 6b69 7055 6e6c 6573 7328 7379  st.skipUnless(sy
+000163d0: 732e 6765 7466 696c 6573 7973 7465 6d65  s.getfilesysteme
+000163e0: 6e63 6f64 696e 6728 292e 7570 7065 7228  ncoding().upper(
+000163f0: 2920 3d3d 2022 5554 462d 3822 2c20 2253  ) == "UTF-8", "S
+00016400: 6b69 7020 6f6e 206e 6f6e 2d55 5446 2d38  kip on non-UTF-8
+00016410: 2073 7973 7465 6d73 2229 0a40 756e 6974   systems").@unit
+00016420: 7465 7374 2e73 6b69 7049 6628 7379 732e  test.skipIf(sys.
+00016430: 7665 7273 696f 6e5f 696e 666f 5b3a 325d  version_info[:2]
+00016440: 203c 2028 332c 2037 292c 2022 536b 6970   < (3, 7), "Skip
+00016450: 206f 6e20 6261 6420 756e 6963 6f64 6520   on bad unicode 
+00016460: 6861 6e64 6c69 6e67 2229 0a63 6c61 7373  handling").class
+00016470: 2054 6573 7455 6e69 636f 6465 2849 6e63   TestUnicode(Inc
+00016480: 6c75 6465 4578 636c 7564 6546 756e 6374  ludeExcludeFunct
+00016490: 696f 6e61 6c54 6573 7429 3a0a 2020 2020  ionalTest):.    
+000164a0: 2222 2220 5465 7374 7320 696e 636c 7564  """ Tests includ
+000164b0: 652f 6578 636c 7564 6520 6f70 7469 6f6e  e/exclude option
+000164c0: 7320 7769 7468 2075 6e69 636f 6465 2070  s with unicode p
+000164d0: 6174 6873 2222 220a 0a20 2020 2064 6566  aths"""..    def
+000164e0: 2074 6573 745f 756e 6963 6f64 655f 7061   test_unicode_pa
+000164f0: 7468 735f 6e6f 6e5f 676c 6f62 6269 6e67  ths_non_globbing
+00016500: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00016510: 2222 2220 5465 7374 202d 2d69 6e63 6c75  """ Test --inclu
+00016520: 6465 2061 6e64 202d 2d65 7863 6c75 6465  de and --exclude
+00016530: 2077 6f72 6b20 7769 7468 2075 6e69 636f   work with unico
+00016540: 6465 2070 6174 6873 2222 220a 2020 2020  de paths""".    
+00016550: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
+00016560: 2266 756c 6c22 2c20 2274 6573 7466 696c  "full", "testfil
+00016570: 6573 2f73 656c 6563 742d 756e 6963 6f64  es/select-unicod
+00016580: 6522 2c0a 2020 2020 2020 2020 2020 2020  e",.            
+00016590: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
+000165a0: 5b22 2d2d 6578 636c 7564 6522 2c20 2274  ["--exclude", "t
+000165b0: 6573 7466 696c 6573 2f73 656c 6563 742d  estfiles/select-
+000165c0: 756e 6963 6f64 652f d0bf d180 d18b d0ba  unicode/........
+000165d0: d0bb d0b0 d0b4 2fd0 bfd1 80d0 b8d0 bcd0  ....../.........
+000165e0: b5d1 802f e4be 8b2f cea0 ceb1 cf81 ceac  .../.../........
+000165f0: ceb4 ceb5 ceb9 ceb3 cebc ceb1 2fe0 a489  ............/...
+00016600: e0a4 a6e0 a4be e0a4 b9e0 a4b0 e0a4 a32e  ................
+00016610: 7478 7422 2c0a 2020 2020 2020 2020 2020  txt",.          
+00016620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016630: 2020 2022 2d2d 6578 636c 7564 6522 2c20     "--exclude", 
+00016640: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00016650: 742d 756e 6963 6f64 652f d0bf d180 d18b  t-unicode/......
+00016660: d0ba d0bb d0b0 d0b4 2fd0 bfd1 80d0 b8d0  ......../.......
+00016670: bcd0 b5d1 802f e4be 8b2f cea0 ceb1 cf81  ...../.../......
+00016680: ceac ceb4 ceb5 ceb9 ceb3 cebc ceb1 2fd7  ............../.
+00016690: 93d7 95d7 92d7 9ed7 902e 7478 7422 2c0a  ..........txt",.
+000166a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000166b0: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+000166c0: 6578 636c 7564 6522 2c20 2274 6573 7466  exclude", "testf
+000166d0: 696c 6573 2f73 656c 6563 742d 756e 6963  iles/select-unic
+000166e0: 6f64 652f d0bf d180 d18b d0ba d0bb d0b0  ode/............
+000166f0: d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1 802f  ../............/
+00016700: e4be 8b2f e183 9be1 8390 e183 92e1 8390  .../............
+00016710: e183 9ae1 8398 e183 97e1 8398 2f22 2c0a  ............/",.
+00016720: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016730: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00016740: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+00016750: 696c 6573 2f73 656c 6563 742d 756e 6963  iles/select-unic
+00016760: 6f64 652f d0bf d180 d18b d0ba d0bb d0b0  ode/............
+00016770: d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1 802f  ../............/
+00016780: e4be 8b2f 222c 0a20 2020 2020 2020 2020  .../",.         
+00016790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000167a0: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+000167b0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+000167c0: 6374 2d75 6e69 636f 6465 2fd0 bfd1 80d1  ct-unicode/.....
+000167d0: 8bd0 bad0 bbd0 b0d0 b42f d0bf d180 d0b8  ........./......
+000167e0: d0bc d0b5 d180 2f22 2c0a 2020 2020 2020  ....../",.      
+000167f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016800: 2020 2020 2020 2022 2d2d 696e 636c 7564         "--includ
+00016810: 6522 2c20 2274 6573 7466 696c 6573 2f73  e", "testfiles/s
+00016820: 656c 6563 742d 756e 6963 6f64 652f d0bf  elect-unicode/..
+00016830: d180 d18b d0ba d0bb d0b0 d0b4 2f22 2c0a  ............/",.
+00016840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016850: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00016860: 696e 636c 7564 6522 2c20 2274 6573 7466  include", "testf
+00016870: 696c 6573 2f73 656c 6563 742d 756e 6963  iles/select-unic
+00016880: 6f64 652f d685 d680 d5ab d5b6 d5a1 d5af  ode/............
+00016890: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
+000168a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000168b0: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+000168c0: 2022 7465 7374 6669 6c65 732f 7365 6c65   "testfiles/sele
+000168d0: 6374 2d75 6e69 636f 6465 2f2a 2a22 5d29  ct-unicode/**"])
+000168e0: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+000168f0: 7374 6f72 6528 290a 2020 2020 2020 2020  store().        
+00016900: 7265 7374 6f72 655f 7061 7468 203d 2022  restore_path = "
+00016910: 7465 7374 6669 6c65 732f 7265 7374 6f72  testfiles/restor
+00016920: 655f 6f75 7422 0a20 2020 2020 2020 2072  e_out".        r
+00016930: 6573 746f 7265 6420 3d20 7365 6c66 2e64  estored = self.d
+00016940: 6972 6563 746f 7279 5f74 7265 655f 746f  irectory_tree_to
+00016950: 5f6c 6973 745f 6f66 5f6c 6973 7473 2872  _list_of_lists(r
+00016960: 6573 746f 7265 5f70 6174 6829 0a20 2020  estore_path).   
+00016970: 2020 2020 2073 656c 662e 6173 7365 7274       self.assert
+00016980: 4571 7561 6c28 7265 7374 6f72 6564 2c20  Equal(restored, 
+00016990: 5b5b 22d0 bfd1 80d1 8bd0 bad0 bbd0 b0d0  [[".............
+000169a0: b422 2c20 22d6 85d6 80d5 abd5 b6d5 a1d5  .", "...........
+000169b0: af2e 7478 7422 5d2c 0a20 2020 2020 2020  ..txt"],.       
+000169c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000169d0: 2020 2020 2020 2020 2020 2020 205b 22d0               [".
+000169e0: bfd1 80d0 b8d0 bcd0 b5d1 8022 2c20 22e0  ...........", ".
+000169f0: a689 e0a6 a6e0 a6be e0a6 b9e0 a6b0 e0a6  ................
+00016a00: a322 5d2c 205b 22e4 be8b 225d 2c20 5b22  ."], ["..."], ["
+00016a10: cea0 ceb1 cf81 ceac ceb4 ceb5 ceb9 ceb3  ................
+00016a20: cebc ceb1 225d 2c20 5b22 e0aa 89e0 aaa6  ...."], ["......
+00016a30: e0aa bee0 aab9 e0aa b0e0 aaa3 2e6c 6f67  .............log
+00016a40: 225d 5d29 0a0a 2020 2020 6465 6620 7465  "]])..    def te
+00016a50: 7374 5f75 6e69 636f 6465 5f70 6174 6873  st_unicode_paths
+00016a60: 5f61 7374 6572 6973 6b73 2873 656c 6629  _asterisks(self)
+00016a70: 3a0a 2020 2020 2020 2020 2222 2220 5465  :.        """ Te
+00016a80: 7374 202d 2d69 6e63 6c75 6465 2061 6e64  st --include and
+00016a90: 202d 2d65 7863 6c75 6465 2077 6f72 6b20   --exclude work 
+00016aa0: 7769 7468 2075 6e69 636f 6465 2070 6174  with unicode pat
+00016ab0: 6873 2061 6e64 2067 6c6f 6273 2063 6f6e  hs and globs con
+00016ac0: 7461 696e 696e 6720 2a20 616e 6420 2a2a  taining * and **
+00016ad0: 2222 220a 2020 2020 2020 2020 7020 3d20  """.        p = 
+00016ae0: 2274 6573 7466 696c 6573 2f73 656c 6563  "testfiles/selec
+00016af0: 742d 756e 6963 6f64 652f 220a 2020 2020  t-unicode/".    
+00016b00: 2020 2020 7365 6c66 2e62 6163 6b75 7028      self.backup(
+00016b10: 2266 756c 6c22 2c20 2274 6573 7466 696c  "full", "testfil
+00016b20: 6573 2f73 656c 6563 742d 756e 6963 6f64  es/select-unicod
+00016b30: 6522 2c0a 2020 2020 2020 2020 2020 2020  e",.            
+00016b40: 2020 2020 2020 2020 6f70 7469 6f6e 733d          options=
+00016b50: 5b22 2d2d 6578 636c 7564 6522 2c20 7020  ["--exclude", p 
+00016b60: 2b20 22d0 bfd1 80d1 8bd0 bad0 bbd0 b0d0  + ".............
+00016b70: b42f d0bf d180 d0b8 d0bc d0b5 d180 2fe4  ./............/.
+00016b80: be8b 2fce a0ce b1cf 81ce ac2a ceb5 ceb9  ../........*....
+00016b90: ceb3 cebc ceb1 2fe0 a489 e0a4 a6e0 a4be  ....../.........
+00016ba0: e0a4 b9e0 a4b0 e0a4 a32e 7478 7422 2c20  ..........txt", 
+00016bb0: 2023 204e 6f74 6520 2a0a 2020 2020 2020   # Note *.      
+00016bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016bd0: 2020 2020 2020 2022 2d2d 6578 636c 7564         "--exclud
+00016be0: 6522 2c20 7020 2b20 22d0 bfd1 80d1 8bd0  e", p + ".......
+00016bf0: bad0 bbd0 b0d0 b42f d0bf d180 d0b8 d0bc  ......./........
+00016c00: d0b5 d180 2fe4 be8b 2fce a0ce b1cf 81ce  ..../.../.......
+00016c10: acce b4ce b5ce b9ce b3ce bcce b12f d793  ............./..
+00016c20: d795 d792 d79e d790 2e74 7874 222c 0a20  .........txt",. 
+00016c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016c40: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00016c50: 7863 6c75 6465 222c 2070 202b 2022 d0bf  xclude", p + "..
+00016c60: d180 d18b d0ba d0bb d0b0 d0b4 2fd0 bfd1  ............/...
+00016c70: 80d0 b8d0 bcd0 b5d1 802f e4be 8b2f e183  ........./.../..
+00016c80: 9be1 8390 e183 92e1 8390 e183 9ae1 8398  ................
+00016c90: e183 97e1 8398 2f22 2c0a 2020 2020 2020  ....../",.      
+00016ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016cb0: 2020 2020 2020 2022 2d2d 696e 636c 7564         "--includ
+00016cc0: 6522 2c20 7020 2b20 22d0 bfd1 802a 2a2f  e", p + "....**/
+00016cd0: e4be 8b2f 222c 2020 2320 4e6f 7465 202a  .../",  # Note *
+00016ce0: 2a0a 2020 2020 2020 2020 2020 2020 2020  *.              
+00016cf0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00016d00: 2d2d 6578 636c 7564 6522 2c20 7020 2b20  --exclude", p + 
+00016d10: 22d0 bfd1 80d1 8bd0 bad0 bbd0 b0d0 b42f  "............../
+00016d20: d0bf d180 d0b8 d0bc d0b5 d180 2f22 2c0a  ............/",.
+00016d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016d40: 2020 2020 2020 2020 2020 2020 2022 2d2d               "--
+00016d50: 696e 636c 7564 6522 2c20 7020 2b20 22d0  include", p + ".
+00016d60: bfd1 80d1 8bd0 bad0 bbd0 b02a 2f22 2c20  ...........*/", 
+00016d70: 2023 204e 6f74 6520 2a0a 2020 2020 2020   # Note *.      
+00016d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016d90: 2020 2020 2020 2022 2d2d 696e 636c 7564         "--includ
+00016da0: 6522 2c20 7020 2b20 22d6 85d6 802a d5a1  e", p + "....*..
+00016db0: d5af 2e74 7874 222c 2020 2320 4e6f 7465  ...txt",  # Note
+00016dc0: 202a 0a20 2020 2020 2020 2020 2020 2020   *.             
+00016dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016de0: 222d 2d65 7863 6c75 6465 222c 2070 202b  "--exclude", p +
+00016df0: 2022 2a2a 225d 290a 2020 2020 2020 2020   "**"]).        
+00016e00: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
+00016e10: 2020 2020 2020 2072 6573 746f 7265 5f70         restore_p
+00016e20: 6174 6820 3d20 2274 6573 7466 696c 6573  ath = "testfiles
+00016e30: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
+00016e40: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
+00016e50: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
+00016e60: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
+00016e70: 6c69 7374 7328 7265 7374 6f72 655f 7061  lists(restore_pa
+00016e80: 7468 290a 2020 2020 2020 2020 7365 6c66  th).        self
+00016e90: 2e61 7373 6572 7445 7175 616c 2872 6573  .assertEqual(res
+00016ea0: 746f 7265 642c 205b 5b22 d0bf d180 d18b  tored, [["......
+00016eb0: d0ba d0bb d0b0 d0b4 222c 2022 d685 d680  ........", "....
+00016ec0: d5ab d5b6 d5a1 d5af 2e74 7874 225d 2c0a  .........txt"],.
+00016ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016ef0: 2020 2020 5b22 d0bf d180 d0b8 d0bc d0b5      ["..........
+00016f00: d180 222c 2022 e0a6 89e0 a6a6 e0a6 bee0  ..", "..........
+00016f10: a6b9 e0a6 b0e0 a6a3 225d 2c20 5b22 e4be  ........"], ["..
+00016f20: 8b22 5d2c 205b 22ce a0ce b1cf 81ce acce  ."], [".........
+00016f30: b4ce b5ce b9ce b3ce bcce b122 5d2c 205b  ..........."], [
+00016f40: 22e0 aa89 e0aa a6e0 aabe e0aa b9e0 aab0  "...............
+00016f50: e0aa a32e 6c6f 6722 5d5d 290a 0a20 2020  ....log"]])..   
+00016f60: 2064 6566 2074 6573 745f 756e 6963 6f64   def test_unicod
+00016f70: 655f 7061 7468 735f 7371 7561 7265 5f62  e_paths_square_b
+00016f80: 7261 636b 6574 7328 7365 6c66 293a 0a20  rackets(self):. 
+00016f90: 2020 2020 2020 2022 2222 2054 6573 7420         """ Test 
+00016fa0: 2d2d 696e 636c 7564 6520 616e 6420 2d2d  --include and --
+00016fb0: 6578 636c 7564 6520 776f 726b 2077 6974  exclude work wit
+00016fc0: 6820 756e 6963 6f64 6520 7061 7468 7320  h unicode paths 
+00016fd0: 7769 7468 2063 6861 7261 6374 6572 206f  with character o
+00016fe0: 7074 696f 6e73 2069 6e20 5b5d 7320 616e  ptions in []s an
+00016ff0: 6420 5b21 5d73 2222 220a 2020 2020 2020  d [!]s""".      
+00017000: 2020 7020 3d20 2274 6573 7466 696c 6573    p = "testfiles
+00017010: 2f73 656c 6563 742d 756e 6963 6f64 652f  /select-unicode/
+00017020: 220a 2020 2020 2020 2020 7365 6c66 2e62  ".        self.b
+00017030: 6163 6b75 7028 2266 756c 6c22 2c20 2274  ackup("full", "t
+00017040: 6573 7466 696c 6573 2f73 656c 6563 742d  estfiles/select-
+00017050: 756e 6963 6f64 6522 2c0a 2020 2020 2020  unicode",.      
+00017060: 2020 2020 2020 2020 2020 2020 2020 6f70                op
+00017070: 7469 6f6e 733d 5b22 2d2d 6578 636c 7564  tions=["--exclud
+00017080: 6522 2c20 7020 2b20 22d0 bfd1 80d1 8bd0  e", p + ".......
+00017090: bad0 bbd0 b0d0 b42f d0bf d180 d0b8 d0bc  ......./........
+000170a0: d0b5 d180 2fe4 be8b 2fce a0ce b1cf 81ce  ..../.../.......
+000170b0: acce b4ce b5ce b9ce b3ce bcce b12f e0a4  ............./..
+000170c0: 89e0 a4a6 e0a4 bee0 a4b9 e0a4 b0e0 a4a3  ................
+000170d0: 2e74 7874 222c 0a20 2020 2020 2020 2020  .txt",.         
+000170e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000170f0: 2020 2020 222d 2d65 7863 6c75 6465 222c      "--exclude",
+00017100: 2070 202b 2022 d0bf d180 d18b 5bd0 ba2c   p + "......[..,
+00017110: d0b8 2cd1 805d d0bb d0b0 d0b4 2fd0 bfd1  ..,..]....../...
+00017120: 80d0 b8d0 bcd0 b5d1 802f e4be 8b2f cea0  ........./.../..
+00017130: ceb1 cf81 ceac ceb4 ceb5 ceb9 ceb3 cebc  ................
+00017140: ceb1 2fd7 93d7 95d7 92d7 9ed7 902e 7478  ../...........tx
+00017150: 7422 2c0a 2020 2020 2020 2020 2020 2020  t",.            
+00017160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017170: 2022 2d2d 6578 636c 7564 6522 2c20 7020   "--exclude", p 
+00017180: 2b20 22d0 bfd1 80d1 8bd0 bad0 bbd0 b0d0  + ".............
+00017190: b42f d0bf d180 5b21 612c 622c 635d d0bc  ./....[!a,b,c]..
+000171a0: d0b5 d180 2fe4 be8b 2fe1 839b e183 90e1  ..../.../.......
+000171b0: 8392 e183 90e1 839a e183 98e1 8397 e183  ................
+000171c0: 982f 222c 0a20 2020 2020 2020 2020 2020  ./",.           
+000171d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000171e0: 2020 222d 2d69 6e63 6c75 6465 222c 2070    "--include", p
+000171f0: 202b 2022 d0bf d180 d18b d0ba d0bb d0b0   + "............
+00017200: d0b4 2fd0 bfd1 80d0 b85b 672c d0bc 2cd0  ../......[g,..,.
+00017210: b45d d0b5 d180 2fe4 be8b 2f22 2c0a 2020  .]..../.../",.  
+00017220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017230: 2020 2020 2020 2020 2020 2022 2d2d 6578             "--ex
+00017240: 636c 7564 6522 2c20 7020 2b20 22d0 bfd1  clude", p + "...
+00017250: 80d1 8bd0 bad0 bbd0 b0d0 b42f d0bf d180  .........../....
+00017260: d0b8 d0bc d0b5 d180 2f22 2c0a 2020 2020  ......../",.    
+00017270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017280: 2020 2020 2020 2020 2022 2d2d 696e 636c           "--incl
+00017290: 7564 6522 2c20 7020 2b20 22d0 bfd1 80d1  ude", p + ".....
+000172a0: 8bd0 bad0 bbd0 b0d0 b42f 222c 0a20 2020  ........./",.   
+000172b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000172c0: 2020 2020 2020 2020 2020 222d 2d69 6e63            "--inc
+000172d0: 6c75 6465 222c 2070 202b 2022 d685 d680  lude", p + "....
+000172e0: d5ab d5b6 d5a1 d5af 2e74 7874 222c 0a20  .........txt",. 
+000172f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017300: 2020 2020 2020 2020 2020 2020 222d 2d65              "--e
+00017310: 7863 6c75 6465 222c 2070 202b 2022 2a2a  xclude", p + "**
+00017320: 225d 290a 2020 2020 2020 2020 7365 6c66  "]).        self
+00017330: 2e72 6573 746f 7265 2829 0a20 2020 2020  .restore().     
+00017340: 2020 2072 6573 746f 7265 5f70 6174 6820     restore_path 
+00017350: 3d20 2274 6573 7466 696c 6573 2f72 6573  = "testfiles/res
+00017360: 746f 7265 5f6f 7574 220a 2020 2020 2020  tore_out".      
+00017370: 2020 7265 7374 6f72 6564 203d 2073 656c    restored = sel
+00017380: 662e 6469 7265 6374 6f72 795f 7472 6565  f.directory_tree
+00017390: 5f74 6f5f 6c69 7374 5f6f 665f 6c69 7374  _to_list_of_list
+000173a0: 7328 7265 7374 6f72 655f 7061 7468 290a  s(restore_path).
+000173b0: 2020 2020 2020 2020 7365 6c66 2e61 7373          self.ass
+000173c0: 6572 7445 7175 616c 2872 6573 746f 7265  ertEqual(restore
+000173d0: 642c 205b 5b22 d0bf d180 d18b d0ba d0bb  d, [["..........
+000173e0: d0b0 d0b4 222c 2022 d685 d680 d5ab d5b6  ....", "........
+000173f0: d5a1 d5af 2e74 7874 225d 2c0a 2020 2020  .....txt"],.    
+00017400: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017420: 5b22 d0bf d180 d0b8 d0bc d0b5 d180 222c  ["............",
+00017430: 2022 e0a6 89e0 a6a6 e0a6 bee0 a6b9 e0a6   "..............
+00017440: b0e0 a6a3 225d 2c20 5b22 e4be 8b22 5d2c  ...."], ["..."],
+00017450: 205b 22ce a0ce b1cf 81ce acce b4ce b5ce   [".............
+00017460: b9ce b3ce bcce b122 5d2c 205b 22e0 aa89  ......."], ["...
+00017470: e0aa a6e0 aabe e0aa b9e0 aab0 e0aa a32e  ................
+00017480: 6c6f 6722 5d5d 290a 0a20 2020 2064 6566  log"]])..    def
+00017490: 2074 6573 745f 756e 6963 6f64 655f 6669   test_unicode_fi
+000174a0: 6c65 6c69 7374 2873 656c 6629 3a0a 2020  lelist(self):.  
+000174b0: 2020 2020 2020 2222 2254 6573 7420 7468        """Test th
+000174c0: 6174 2065 7863 6c75 6465 2066 696c 656c  at exclude filel
+000174d0: 6973 7420 776f 726b 7320 7769 7468 2075  ist works with u
+000174e0: 6e69 636f 6465 2066 696c 656e 616d 6573  nicode filenames
+000174f0: 2222 220a 2020 2020 2020 2020 2320 4173  """.        # As
+00017500: 2074 6869 7320 6973 2061 6e20 6578 636c   this is an excl
+00017510: 7564 6520 6669 6c65 6c69 7374 2061 6e79  ude filelist any
+00017520: 206c 696e 6573 2077 6974 6820 6e6f 202b   lines with no +
+00017530: 2f2d 206d 6f64 6966 6965 7220 7368 6f75  /- modifier shou
+00017540: 6c64 2062 6520 7472 6561 7465 6420 6173  ld be treated as
+00017550: 2069 6620 7468 6579 2068 6176 6520 6120   if they have a 
+00017560: 2d2e 0a20 2020 2020 2020 2070 6174 6820  -..        path 
+00017570: 3d20 2274 6573 7466 696c 6573 2f73 656c  = "testfiles/sel
+00017580: 6563 742d 756e 6963 6f64 652f 220a 2020  ect-unicode/".  
+00017590: 2020 2020 2020 2320 4372 6561 7465 2061        # Create a
+000175a0: 2066 696c 656c 6973 740a 2020 2020 2020   filelist.      
+000175b0: 2020 7769 7468 2069 6f2e 6f70 656e 2822    with io.open("
+000175c0: 7465 7374 6669 6c65 732f 6578 636c 7564  testfiles/exclud
+000175d0: 652e 7478 7422 2c20 2277 222c 2065 6e63  e.txt", "w", enc
+000175e0: 6f64 696e 673d 2255 5446 2d38 2229 2061  oding="UTF-8") a
+000175f0: 7320 663a 0a20 2020 2020 2020 2020 2020  s f:.           
+00017600: 2066 2e77 7269 7465 2822 2d20 2220 2b20   f.write("- " + 
+00017610: 7061 7468 202b 2022 d0bf d180 d18b d0ba  path + "........
+00017620: d0bb d0b0 d0b4 2fd0 bfd1 80d0 b8d0 bcd0  ....../.........
+00017630: b5d1 802f e4be 8b2f cea0 ceb1 cf81 ceac  .../.../........
+00017640: ceb4 ceb5 ceb9 ceb3 cebc ceb1 2fe0 a489  ............/...
+00017650: e0a4 a6e0 a4be e0a4 b9e0 a4b0 e0a4 a32e  ................
+00017660: 7478 745c 6e22 0a20 2020 2020 2020 2020  txt\n".         
+00017670: 2020 2020 2020 2020 2020 2022 2d20 2220             "- " 
+00017680: 2b20 7061 7468 202b 2022 d0bf d180 d18b  + path + "......
+00017690: d0ba d0bb d0b0 d0b4 2fd0 bfd1 80d0 b8d0  ......../.......
+000176a0: bcd0 b5d1 802f e4be 8b2f cea0 ceb1 cf81  ...../.../......
+000176b0: ceac ceb4 ceb5 ceb9 ceb3 cebc ceb1 2fd7  ............../.
+000176c0: 93d7 95d7 92d7 9ed7 902e 7478 745c 6e22  ..........txt\n"
+000176d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000176e0: 2020 2020 2022 2d20 2220 2b20 7061 7468       "- " + path
+000176f0: 202b 2022 d0bf d180 d18b d0ba d0bb d0b0   + "............
+00017700: d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1 802f  ../............/
+00017710: e4be 8b2f e183 9be1 8390 e183 92e1 8390  .../............
+00017720: e183 9ae1 8398 e183 97e1 8398 2f5c 6e22  ............/\n"
+00017730: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017740: 2020 2020 2022 2b20 2220 2b20 7061 7468       "+ " + path
+00017750: 202b 2022 d0bf d180 d18b d0ba d0bb d0b0   + "............
+00017760: d0b4 2fd0 bfd1 80d0 b8d0 bcd0 b5d1 802f  ../............/
+00017770: e4be 8b2f 5c6e 220a 2020 2020 2020 2020  .../\n".        
+00017780: 2020 2020 2020 2020 2020 2020 222d 2022              "- "
+00017790: 202b 2070 6174 6820 2b20 22d0 bfd1 80d1   + path + ".....
+000177a0: 8bd0 bad0 bbd0 b0d0 b42f d0bf d180 d0b8  ........./......
+000177b0: d0bc d0b5 d180 2f5c 6e22 0a20 2020 2020  ....../\n".     
+000177c0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000177d0: 2b20 2220 2b20 7061 7468 202b 2022 d0bf  + " + path + "..
+000177e0: d180 d18b d0ba d0bb d0b0 d0b4 2f5c 6e22  ............/\n"
+000177f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017800: 2020 2020 2022 2b20 2220 2b20 7061 7468       "+ " + path
+00017810: 202b 2022 d685 d680 d5ab d5b6 d5a1 d5af   + "............
+00017820: 2e74 7874 5c6e 220a 2020 2020 2020 2020  .txt\n".        
+00017830: 2020 2020 2020 2020 2020 2020 222d 2022              "- "
+00017840: 202b 2070 6174 6820 2b20 222a 2a22 290a   + path + "**").
+00017850: 2020 2020 2020 2020 7365 6c66 2e62 6163          self.bac
+00017860: 6b75 7028 2266 756c 6c22 2c20 7061 7468  kup("full", path
+00017870: 2c20 6f70 7469 6f6e 733d 5b22 2d2d 6578  , options=["--ex
+00017880: 636c 7564 652d 6669 6c65 6c69 7374 3d74  clude-filelist=t
+00017890: 6573 7466 696c 6573 2f65 7863 6c75 6465  estfiles/exclude
+000178a0: 2e74 7874 225d 290a 2020 2020 2020 2020  .txt"]).        
+000178b0: 7365 6c66 2e72 6573 746f 7265 2829 0a20  self.restore(). 
+000178c0: 2020 2020 2020 2072 6573 746f 7265 5f70         restore_p
+000178d0: 6174 6820 3d20 2274 6573 7466 696c 6573  ath = "testfiles
+000178e0: 2f72 6573 746f 7265 5f6f 7574 220a 2020  /restore_out".  
+000178f0: 2020 2020 2020 7265 7374 6f72 6564 203d        restored =
+00017900: 2073 656c 662e 6469 7265 6374 6f72 795f   self.directory_
+00017910: 7472 6565 5f74 6f5f 6c69 7374 5f6f 665f  tree_to_list_of_
+00017920: 6c69 7374 7328 7265 7374 6f72 655f 7061  lists(restore_pa
+00017930: 7468 290a 2020 2020 2020 2020 7365 6c66  th).        self
+00017940: 2e61 7373 6572 7445 7175 616c 2872 6573  .assertEqual(res
+00017950: 746f 7265 642c 205b 5b22 d0bf d180 d18b  tored, [["......
+00017960: d0ba d0bb d0b0 d0b4 222c 2022 d685 d680  ........", "....
+00017970: d5ab d5b6 d5a1 d5af 2e74 7874 225d 2c0a  .........txt"],.
+00017980: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000179a0: 2020 2020 5b22 d0bf d180 d0b8 d0bc d0b5      ["..........
+000179b0: d180 222c 2022 e0a6 89e0 a6a6 e0a6 bee0  ..", "..........
+000179c0: a6b9 e0a6 b0e0 a6a3 225d 2c20 5b22 e4be  ........"], ["..
+000179d0: 8b22 5d2c 205b 22ce a0ce b1cf 81ce acce  ."], [".........
+000179e0: b4ce b5ce b9ce b3ce bcce b122 5d2c 205b  ..........."], [
+000179f0: 22e0 aa89 e0aa a6e0 aabe e0aa b9e0 aab0  "...............
+00017a00: e0aa a32e 6c6f 6722 5d5d 290a 0a0a 6966  ....log"]])...if
+00017a10: 205f 5f6e 616d 655f 5f20 3d3d 2022 5f5f   __name__ == "__
+00017a20: 6d61 696e 5f5f 223a 0a20 2020 2075 6e69  main__":.    uni
+00017a30: 7474 6573 742e 6d61 696e 2829 0a         ttest.main().
```

### Comparing `duplicity-1.2.3.dev43/testing/conftest.py` & `duplicity-2.0.0rc0/testing/conftest.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,31 +1,29 @@
-# -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
-#
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-
-import os
-import sys
-import pytest
-
-
-@pytest.fixture(scope=u"function")
-def redirect_stdin():
-    u"""GPG requires stdin to be open and have real file descriptor, which interferes with pytest's capture facility.
-    Work around this by redirecting /dev/null to stdin temporarily.
-
-    Activate this fixture on unittest test methods and classes by means of:
-    @pytest.mark.usefixtures("redirect_stdin")."""
-    try:
-        targetfd_save = os.dup(0)
-        stdin_save = sys.stdin
-
-        nullfile = open(os.devnull, u"r")
-        sys.stdin = nullfile
-        os.dup2(nullfile.fileno(), 0)
-        yield
-    finally:
-        os.dup2(targetfd_save, 0)  # pylint: disable=used-before-assignment
-        sys.stdin = stdin_save  # pylint: disable=used-before-assignment
-        os.close(targetfd_save)
-        nullfile.close()  # pylint: disable=used-before-assignment
+# -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
+#
+
+import os
+import sys
+
+import pytest
+
+
+@pytest.fixture(scope="function")
+def redirect_stdin():
+    """GPG requires stdin to be open and have real file descriptor, which interferes with pytest's capture facility.
+    Work around this by redirecting /dev/null to stdin temporarily.
+
+    Activate this fixture on unittest test methods and classes by means of:
+    @pytest.mark.usefixtures("redirect_stdin")."""
+    try:
+        targetfd_save = os.dup(0)
+        stdin_save = sys.stdin
+
+        nullfile = open(os.devnull, "r")
+        sys.stdin = nullfile
+        os.dup2(nullfile.fileno(), 0)
+        yield
+    finally:
+        os.dup2(targetfd_save, 0)  # pylint: disable=used-before-assignment
+        sys.stdin = stdin_save  # pylint: disable=used-before-assignment
+        os.close(targetfd_save)
+        nullfile.close()  # pylint: disable=used-before-assignment
```

### Comparing `duplicity-1.2.3.dev43/testing/gnupg/pubring.gpg` & `duplicity-2.0.0rc0/testing/gnupg/pubring.gpg`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/testing/gnupg/secring.gpg` & `duplicity-2.0.0rc0/testing/gnupg/secring.gpg`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/testing/gnupg/trustdb.gpg` & `duplicity-2.0.0rc0/testing/gnupg/trustdb.gpg`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/duplicity/dup_time.py` & `duplicity-2.0.0rc0/duplicity/dup_time.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,122 +15,104 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Provide time related exceptions and functions"""
-from __future__ import division
+"""Provide time related exceptions and functions"""
 
-from past.utils import old_div
-from builtins import map
-
-import time
-import types
-import re
 import calendar
-import sys
+import re
+import time
+
 from duplicity import config
 from duplicity import util
 
-# For type testing against both int and long types that works in python 2/3
-if sys.version_info < (3,):
-    integer_types = (int, types.LongType)
-else:
-    integer_types = (int,)
-
 
 class TimeException(Exception):
     pass
 
 
-_interval_conv_dict = {u"s": 1, u"m": 60, u"h": 3600, u"D": 86400,
-                       u"W": 7 * 86400, u"M": 30 * 86400, u"Y": 365 * 86400}
-_integer_regexp = re.compile(u"^[0-9]+$")
-_interval_regexp = re.compile(u"^([0-9]+)([smhDWMY])")
-_genstr_date_regexp1 = re.compile(u"^(?P<year>[0-9]{4})[-/]"
-                                  u"(?P<month>[0-9]{1,2})[-/]"
-                                  u"(?P<day>[0-9]{1,2})$")
-_genstr_date_regexp2 = re.compile(u"^(?P<month>[0-9]{1,2})[-/]"
-                                  u"(?P<day>[0-9]{1,2})[-/]"
-                                  u"(?P<year>[0-9]{4})$")
-_genstr_date_regexp3 = re.compile(u"^(?P<year>[0-9]{4})"
-                                  u"(?P<month>[0-9]{2})"
-                                  u"(?P<day>[0-9]{2})Z$")
+_interval_conv_dict = {"s": 1, "m": 60, "h": 3600, "D": 86400,
+                       "W": 7 * 86400, "M": 30 * 86400, "Y": 365 * 86400}
+_integer_regexp = re.compile("^[0-9]+$")
+_interval_regexp = re.compile("^([0-9]+)([smhDWMY])")
+_genstr_date_regexp1 = re.compile("^(?P<year>[0-9]{4})[-/]"
+                                  "(?P<month>[0-9]{1,2})[-/]"
+                                  "(?P<day>[0-9]{1,2})$")
+_genstr_date_regexp2 = re.compile("^(?P<month>[0-9]{1,2})[-/]"
+                                  "(?P<day>[0-9]{1,2})[-/]"
+                                  "(?P<year>[0-9]{4})$")
+_genstr_date_regexp3 = re.compile("^(?P<year>[0-9]{4})"
+                                  "(?P<month>[0-9]{2})"
+                                  "(?P<day>[0-9]{2})Z$")
 curtime = curtimestr = None
 prevtime = prevtimestr = None
 
-bad_interval_string = _(u"""Bad interval string "%s"
+bad_interval_string = _("""\
+Bad interval string "%s"
 
 Intervals are specified like 2Y (2 years) or 2h30m (2.5 hours).  The
 allowed special characters are s, m, h, D, W, M, and Y.  See the man
 page for more information.""")
 
-bad_time_string = _(u"""Bad time string "%s"
+bad_time_string = _("""\
+Bad time string "%s"
 
 The acceptible time strings are intervals (like "3D64s"), w3-datetime
 strings, like "2002-04-26T04:22:01-07:00" (strings like
 "2002-04-26T04:22:01" are also acceptable - duplicity will use the
 current time zone), or ordinary dates like 2/4/1997 or 2001-04-23
 (various combinations are acceptable, but the month always precedes
 the day).""")
 
 
 def setcurtime(time_in_secs=None):
-    u"""Sets the current time in curtime and curtimestr"""
+    """Sets the current time in curtime and curtimestr"""
     global curtime, curtimestr
     t = time_in_secs or int(time.time())
-    assert type(t) in integer_types
+    assert isinstance(t, int)
     curtime, curtimestr = t, timetostring(t)
 
 
 def setprevtime(time_in_secs):
-    u"""Sets the previous time in prevtime and prevtimestr"""
+    """Sets the previous time in prevtime and prevtimestr"""
     global prevtime, prevtimestr
-    assert type(time_in_secs) in integer_types, prevtime
+    assert isinstance(time_in_secs, int), prevtime
     prevtime, prevtimestr = time_in_secs, timetostring(time_in_secs)
 
 
 def timetostring(timeinseconds):
-    u"""Return w3 or duplicity datetime compliant listing of timeinseconds"""
+    """Return w3 or duplicity datetime compliant listing of timeinseconds"""
 
-    if config.old_filenames:
-        # We need to know if DST applies to append the correct offset. So
-        #    1. Save the tuple returned by localtime.
-        #    2. Pass the DST flag into gettzd
-        lcltime = time.localtime(timeinseconds)
-        return time.strftime(u"%Y-%m-%dT%H" + config.time_separator +
-                             u"%M" + config.time_separator + u"%S",
-                             lcltime) + gettzd(lcltime[-1])
-    else:
-        # DST never applies to UTC
-        lcltime = time.gmtime(timeinseconds)
-        return time.strftime(u"%Y%m%dT%H%M%SZ", lcltime)
+    # DST never applies to UTC
+    lcltime = time.gmtime(timeinseconds)
+    return time.strftime("%Y%m%dT%H%M%SZ", lcltime)
 
 
 def stringtotime(timestring):
-    u"""Return time in seconds from w3 or duplicity timestring
+    """Return time in seconds from w3 or duplicity timestring
 
     If there is an error parsing the string, or it doesn't look
     like a valid datetime string, return None.
     """
     try:
-        date, daytime = timestring[:19].split(u"T")
+        date, daytime = timestring[:19].split("T")
         if len(timestring) == 16:
             # new format for filename time
             year, month, day = list(map(int,
-                                    [date[0:4], date[4:6], date[6:8]]))
+                                        [date[0:4], date[4:6], date[6:8]]))
             hour, minute, second = list(map(int,
-                                        [daytime[0:2], daytime[2:4], daytime[4:6]]))
+                                            [daytime[0:2], daytime[2:4], daytime[4:6]]))
         else:
             # old format for filename time
-            year, month, day = list(map(int, date.split(u"-")))
+            year, month, day = list(map(int, date.split("-")))
             hour, minute, second = list(map(int,
-                                        daytime.split(config.time_separator)))
+                                            daytime.split(config.time_separator)))
         assert 1900 < year < 2100, year
         assert 1 <= month <= 12
         assert 1 <= day <= 31
         assert 0 <= hour <= 23
         assert 0 <= minute <= 59
         assert 0 <= second <= 61  # leap seconds
         # We want to return the time in units of seconds since the
@@ -161,50 +143,51 @@
         else:
             return int(utc_in_secs + tzdtoseconds(timestring[19:]))
     except (TypeError, ValueError, AssertionError):
         return None
 
 
 def timetopretty(timeinseconds):
-    u"""Return pretty version of time"""
+    """Return pretty version of time"""
     return time.asctime(time.localtime(timeinseconds))
 
 
 def stringtopretty(timestring):
-    u"""Return pretty version of time given w3 time string"""
+    """Return pretty version of time given w3 time string"""
     return timetopretty(stringtotime(timestring))
 
 
 def inttopretty(seconds):
-    u"""Convert num of seconds to readable string like "2 hours"."""
+    """Convert num of seconds to readable string like "2 hours"."""
     partlist = []
     hours, seconds = divmod(seconds, 3600)
     if hours > 1:
-        partlist.append(u"%d hours" % hours)
+        partlist.append(f"{int(hours)} hours")
     elif hours == 1:
-        partlist.append(u"1 hour")
+        partlist.append("1 hour")
 
     minutes, seconds = divmod(seconds, 60)
     if minutes > 1:
-        partlist.append(u"%d minutes" % minutes)
+        partlist.append(f"{int(minutes)} minutes")
     elif minutes == 1:
-        partlist.append(u"1 minute")
+        partlist.append("1 minute")
 
     if seconds == 1:
-        partlist.append(u"1 second")
+        partlist.append("1 second")
     elif not partlist or seconds > 1:
-        if isinstance(seconds, integer_types):
-            partlist.append(u"%s seconds" % seconds)
+        if isinstance(seconds, int):
+            partlist.append(f"{seconds} seconds")
         else:
-            partlist.append(u"%.2f seconds" % seconds)
-    return u" ".join(partlist)
+            partlist.append(f"{seconds:.2f} seconds")
+    return " ".join(partlist)
 
 
 def intstringtoseconds(interval_string):
-    u"""Convert a string expressing an interval (e.g. "4D2s") to seconds"""
+    """Convert a string expressing an interval (e.g. "4D2s") to seconds"""
+
     def error():
         raise TimeException(bad_interval_string % util.escape(interval_string))
 
     if len(interval_string) < 2:
         error()
 
     total = 0
@@ -217,75 +200,75 @@
             error()
         total += num * _interval_conv_dict[ext]
         interval_string = interval_string[match.end(0):]
     return total
 
 
 def gettzd(dstflag):
-    u"""Return w3's timezone identification string.
+    """Return w3's timezone identification string.
 
     Expresed as [+/-]hh:mm.  For instance, PST is -08:00.  Zone is
     coincides with what localtime(), etc., use.
 
     """
     # time.daylight doesn't help us. It's a flag that indicates that we
     # have a dst option for the current timezone. Compensate by allowing
     # the caller to pass a flag to indicate that DST applies. This flag
     # is in the same format as the last member of the tuple returned by
     # time.localtime()
 
     if dstflag > 0:
-        offset = old_div(-1 * time.altzone, 60)
+        offset = -1 * time.altzone // 60
     else:
-        offset = old_div(-1 * time.timezone, 60)
+        offset = -1 * time.timezone // 60
     if offset > 0:
-        prefix = u"+"
+        prefix = "+"
     elif offset < 0:
-        prefix = u"-"
+        prefix = "-"
     else:
-        return u"Z"  # time is already in UTC
+        return "Z"  # time is already in UTC
 
     hours, minutes = list(map(abs, divmod(offset, 60)))
     assert 0 <= hours <= 23
     assert 0 <= minutes <= 59
-    return u"%s%02d%s%02d" % (prefix, hours, config.time_separator, minutes)
+    return f"{prefix}{int(hours):02}{config.time_separator}{int(minutes):02}"
 
 
 def tzdtoseconds(tzd):
-    u"""Given w3 compliant TZD, return how far ahead UTC is"""
-    if tzd == u"Z":
+    """Given w3 compliant TZD, return how far ahead UTC is"""
+    if tzd == "Z":
         return 0
     assert len(tzd) == 6  # only accept forms like +08:00 for now
-    assert (tzd[0] == u"-" or tzd[0] == u"+") and \
-        tzd[3] == config.time_separator
+    assert (tzd[0] == "-" or tzd[0] == "+") and \
+           tzd[3] == config.time_separator
     return -60 * (60 * int(tzd[:3]) + int(tzd[4:]))
 
 
 def cmp(time1, time2):
-    u"""Compare time1 and time2 and return -1, 0, or 1"""
-    if isinstance(time1, (str, u"".__class__)):
+    """Compare time1 and time2 and return -1, 0, or 1"""
+    if isinstance(time1, (str, string)):
         time1 = stringtotime(time1)
         assert time1 is not None
-    if isinstance(time2, (str, u"".__class__)):
+    if isinstance(time2, (str, "".__class__)):
         time2 = stringtotime(time2)
         assert time2 is not None
 
     if time1 < time2:
         return -1
     elif time1 == time2:
         return 0
     else:
         return 1
 
 
 def genstrtotime(timestr, override_curtime=None):
-    u"""Convert a generic time string to a time in seconds"""
+    """Convert a generic time string to a time in seconds"""
     if override_curtime is None:
         override_curtime = curtime
-    if timestr == u"now":
+    if timestr == "now":
         return override_curtime
 
     def error():
         raise TimeException(bad_time_string % util.escape(timestr))
 
     # Test for straight integer
     if _integer_regexp.search(timestr):
@@ -309,16 +292,14 @@
 
     # Now check for dates like 2001/3/23
     match = (_genstr_date_regexp1.search(timestr) or
              _genstr_date_regexp2.search(timestr) or
              _genstr_date_regexp3.search(timestr))
     if not match:
         error()
-    timestr = u"%s-%02d-%02dT00:00:00%s" % (match.group(u'year'),
-                                            int(match.group(u'month')),
-                                            int(match.group(u'day')),
-                                            gettzd(0))
+    timestr = f"{match.group('year')}-{int(int(match.group('month'))):02}-{int(int(match.group('day'))):02}" \
+              f"T00:00:00{gettzd(0)}"
     t = stringtotime(timestr)
     if t:
         return t
     else:
         error()
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/localbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/localbackend.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,30 +18,34 @@
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 import os
 
 import duplicity.backend
-from duplicity import path, progress
+from duplicity import (
+    path,
+    progress,
+)
 from duplicity.errors import BackendException
 
 
 class LocalBackend(duplicity.backend.Backend):
-    u"""Use this backend when saving to local disk
+    """Use this backend when saving to local disk
 
     Urls look like file://testfiles/output.  Relative to root can be
     gotten with extra slash (file:///usr/local).
 
     """
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
         # The URL form "file:MyFile" is not a valid duplicity target.
-        if not parsed_url.path.startswith(u'//'):
-            raise BackendException(u"Bad file:// path syntax.")
+        if not parsed_url.path.startswith('//'):
+            raise BackendException("Bad file:// path syntax.")
         self.remote_pathdir = path.Path(parsed_url.path[2:])
         try:
             os.makedirs(self.remote_pathdir.base)
         except Exception:
             pass
 
     def _move(self, source_path, remote_filename):
@@ -53,20 +57,20 @@
             return False
 
     def _put(self, source_path, remote_filename):
         target_path = self.remote_pathdir.append(remote_filename)
         source_path.setdata()
         source_size = source_path.getsize()
         progress.report_transfer(0, source_size)
-        target_path.writefileobj(source_path.open(u"rb"))
+        target_path.writefileobj(source_path.open("rb"))
         progress.report_transfer(source_size, source_size)
 
     def _get(self, filename, local_path):
         source_path = self.remote_pathdir.append(filename)
-        local_path.writefileobj(source_path.open(u"rb"))
+        local_path.writefileobj(source_path.open("rb"))
 
     def _list(self):
         return self.remote_pathdir.listdir()
 
     def _delete(self, filename):
         self.remote_pathdir.append(filename).delete()
 
@@ -74,11 +78,11 @@
         for filename in filenames:
             self.remote_pathdir.append(filename).delete()
 
     def _query(self, filename):
         target_file = self.remote_pathdir.append(filename)
         target_file.setdata()
         size = target_file.getsize() if target_file.exists() else -1
-        return {u'size': size}
+        return {'size': size}
 
 
-duplicity.backend.register_backend(u"file", LocalBackend)
+duplicity.backend.register_backend("file", LocalBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/onedrivebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/onedrivebackend.py`

 * *Files 14% similar despite different names*

```diff
@@ -18,229 +18,220 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from __future__ import division
-from past.utils import old_div
-from builtins import input
-from builtins import str
-import time
+
 import json
 import os
 import sys
+import time
 
 import duplicity.backend
-from duplicity.errors import BackendException
 from duplicity import config
 from duplicity import log
 from duplicity import util
+from duplicity.errors import BackendException
+
 
 # For documentation on the API, see
 # The previous Live SDK API required the use of opaque folder IDs to navigate paths, but the Microsoft Graph
 # API allows the use of parent/child/grandchild pathnames.
 # Old Live SDK API: https://docs.microsoft.com/en-us/previous-versions/office/developer/onedrive-live-sdk/dn659731(v%3doffice.15)  # noqa
 # Files API: https://docs.microsoft.com/en-us/graph/api/resources/onedrive?view=graph-rest-1.0
 # Large file upload API: https://docs.microsoft.com/en-us/onedrive/developer/rest-api/api/driveitem_createuploadsession?view=odsp-graph-online  # noqa
 
 
 class OneDriveBackend(duplicity.backend.Backend):
-    u"""Uses Microsoft OneDrive (formerly SkyDrive) for backups."""
+    """Uses Microsoft OneDrive (formerly SkyDrive) for backups."""
 
-    API_URI = u'https://graph.microsoft.com/v1.0/'
+    API_URI = 'https://graph.microsoft.com/v1.0/'
     # The large file upload API says that uploaded chunks (except the last) must be multiples of 327680 bytes.
     REQUIRED_FRAGMENT_SIZE_MULTIPLE = 327680
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
-        self.directory = parsed_url.path.lstrip(u'/')
+        self.directory = parsed_url.path.lstrip('/')
 
         # this drive_root works for personal and business onedrive
         # to use a sharepoint 365 default drive this needs to be set to
         # 'sites/<xxxx.sharepoint.com>,<site id>/drive'
-        self.drive_root = os.environ.get(u'DUPLICITY_ONEDRIVE_ROOT', u'me/drive')
+        self.drive_root = os.environ.get('DUPLICITY_ONEDRIVE_ROOT', 'me/drive')
 
-        self.directory_onedrive_path = u'%s:/%s/' % (self.drive_root + u'/root', self.directory)
-        if self.directory == u"":
+        self.directory_onedrive_path = f"{self.drive_root + '/root'}:/{self.directory}/"
+        if self.directory == "":
             raise BackendException((
-                u'You did not specify a path. '
-                u'Please specify a path, e.g. onedrive://duplicity_backups'))
+                'You did not specify a path. '
+                'Please specify a path, e.g. onedrive://duplicity_backups'))
 
         if config.volsize > (10 * 1024 * 1024 * 1024):
             raise BackendException((
-                u'Your --volsize is bigger than 10 GiB, which is the maximum '
-                u'file size on OneDrive.'))
+                'Your --volsize is bigger than 10 GiB, which is the maximum '
+                'file size on OneDrive.'))
 
         self.initialize_oauth2_session()
 
     def initialize_oauth2_session(self):
-        client_id = os.environ.get(u'OAUTH2_CLIENT_ID')
-        refresh_token = os.environ.get(u'OAUTH2_REFRESH_TOKEN')
+        client_id = os.environ.get('OAUTH2_CLIENT_ID')
+        refresh_token = os.environ.get('OAUTH2_REFRESH_TOKEN')
         for n in range(1, config.num_retries + 1):
             try:
                 if client_id and refresh_token:
                     self.http_client = ExternalOAuth2Session(client_id, refresh_token)
                 else:
                     self.http_client = DefaultOAuth2Session(self.API_URI)
                 break
             except Exception as e:
                 if n >= config.num_retries:
                     raise e
-                log.Warn(_(u"Attempt of initialize_oauth2_session Nr. %s failed. %s: %s")
+                log.Warn(_("Attempt of initialize_oauth2_session Nr. %s failed. %s: %s")
                          % (n, e.__class__.__name__, util.uexc(e)))
                 time.sleep(config.backend_retry_delay)
 
     def _list(self):
         accum = []
         # Strip last slash, because graph can give a 404 in some cases with it
-        next_url = self.API_URI + self.directory_onedrive_path.rstrip(u'/') + u':/children'
+        next_url = self.API_URI + self.directory_onedrive_path.rstrip('/') + ':/children'
         while True:
             response = self.http_client.get(next_url, timeout=config.timeout)
             if response.status_code == 404:
                 # No further files here
                 break
             response.raise_for_status()
             responseJson = response.json()
-            if u'value' not in responseJson:
+            if 'value' not in responseJson:
                 raise BackendException((
-                    u'Malformed JSON: expected "value" member in %s' % (
-                        responseJson)))
-            accum += responseJson[u'value']
-            if u'@odata.nextLink' in responseJson:
-                next_url = responseJson[u'@odata.nextLink']
+                    f'Malformed JSON: expected "value" member in {responseJson}'))
+            accum += responseJson['value']
+            if '@odata.nextLink' in responseJson:
+                next_url = responseJson['@odata.nextLink']
             else:
                 break
 
-        return [x[u'name'] for x in accum]
+        return [x['name'] for x in accum]
 
     def _get(self, remote_filename, local_path):
-        remote_filename = remote_filename.decode(u"UTF-8")
-        with local_path.open(u'wb') as f:
+        remote_filename = remote_filename.decode("UTF-8")
+        with local_path.open('wb') as f:
             response = self.http_client.get(
-                self.API_URI + self.directory_onedrive_path + remote_filename + u':/content',
+                self.API_URI + self.directory_onedrive_path + remote_filename + ':/content',
                 stream=True, timeout=config.timeout)
             response.raise_for_status()
             for chunk in response.iter_content(chunk_size=4096):
                 if chunk:
                     f.write(chunk)
             f.flush()
 
     def _put(self, source_path, remote_filename):
         # Happily, the OneDrive API will lazily create the folder hierarchy required to contain a pathname
 
         # Check if the user has enough space available on OneDrive before even
         # attempting to upload the file.
-        remote_filename = remote_filename.decode(u"UTF-8")
+        remote_filename = remote_filename.decode("UTF-8")
         source_size = os.path.getsize(source_path.name)
         start = time.time()
-        response = self.http_client.get(self.API_URI + self.drive_root + u'?$select=quota', timeout=config.timeout)
+        response = self.http_client.get(self.API_URI + self.drive_root + '?$select=quota', timeout=config.timeout)
         response.raise_for_status()
-        if (u'quota' in response.json()):
-            available = response.json()[u'quota'].get(u'remaining', None)
+        if 'quota' in response.json():
+            available = response.json()['quota'].get('remaining', None)
             if available:
-                log.Debug(u'Bytes available: %d' % available)
+                log.Debug(f'Bytes available: {int(available)}')
                 if source_size > available:
                     raise BackendException((
-                        u'Out of space: trying to store "%s" (%d bytes), but only '
-                        u'%d bytes available on OneDrive.' % (
-                            source_path.name, source_size,
-                            available)))
-        log.Debug(u"Checked quota in %fs" % (time.time() - start))
+                        f'Out of space: trying to store "{source_path.name}" ({int(source_size)} bytes), '
+                        f'but only {int(available)} bytes available on OneDrive.'))
+        log.Debug(f"Checked quota in {time.time() - start:f}s")
 
         with source_path.open() as source_file:
             start = time.time()
-            url = self.API_URI + self.directory_onedrive_path + remote_filename + u':/createUploadSession'
+            url = self.API_URI + self.directory_onedrive_path + remote_filename + ':/createUploadSession'
 
             response = self.http_client.post(url, timeout=config.timeout)
             response.raise_for_status()
-            response_json = json.loads(response.content.decode(u"UTF-8"))
-            if u'uploadUrl' not in response_json:
+            response_json = json.loads(response.content.decode("UTF-8"))
+            if 'uploadUrl' not in response_json:
                 raise BackendException((
-                    u'File "%s" cannot be uploaded: could not create upload session: %s' % (
-                        remote_filename, response.content)))
-            uploadUrl = response_json[u'uploadUrl']
+                    f'File "{remote_filename}" cannot be uploaded: '
+                    f'could not create upload session: {response.content}'))
+            uploadUrl = response_json['uploadUrl']
 
             # https://docs.microsoft.com/en-us/onedrive/developer/rest-api/api/driveitem_createuploadsession?
             # indicates 10 MiB is optimal for stable high speed connections.
             offset = 0
-            desired_num_fragments = old_div(10 * 1024 * 1024, self.REQUIRED_FRAGMENT_SIZE_MULTIPLE)
+            desired_num_fragments = 10 * 1024 * 1024 // self.REQUIRED_FRAGMENT_SIZE_MULTIPLE
             while True:
                 chunk = source_file.read(desired_num_fragments * self.REQUIRED_FRAGMENT_SIZE_MULTIPLE)
                 if len(chunk) == 0:
                     break
                 headers = {
-                    u'Content-Length': u'%d' % (len(chunk)),
-                    u'Content-Range': u'bytes %d-%d/%d' % (offset, offset + len(chunk) - 1, source_size),
+                    'Content-Length': f'{len(chunk)}',
+                    'Content-Range': f'bytes {int(offset)}-{int(offset + len(chunk) - 1)}/{int(source_size)}',
                 }
-                log.Debug(u'PUT %s %s' % (remote_filename, headers[u'Content-Range']))
+                log.Debug(f"PUT {remote_filename} {headers['Content-Range']}")
                 response = self.http_client.put(
                     uploadUrl,
                     headers=headers,
                     data=chunk,
                     timeout=config.timeout)
                 response.raise_for_status()
                 offset += len(chunk)
 
-            log.Debug(u"PUT file in %fs" % (time.time() - start))
+            log.Debug(f"PUT file in {time.time() - start:f}s")
 
     def _delete(self, remote_filename):
-        remote_filename = remote_filename.decode(u"UTF-8")
+        remote_filename = remote_filename.decode("UTF-8")
         response = self.http_client.delete(
             self.API_URI + self.directory_onedrive_path + remote_filename, timeout=config.timeout)
         if response.status_code == 404:
             raise BackendException((
-                u'File "%s" cannot be deleted: it does not exist' % (
-                    remote_filename)))
+                f'File "{remote_filename}" cannot be deleted: it does not exist'))
         response.raise_for_status()
 
     def _query(self, remote_filename):
-        remote_filename = remote_filename.decode(u"UTF-8")
+        remote_filename = remote_filename.decode("UTF-8")
         response = self.http_client.get(
             self.API_URI + self.directory_onedrive_path + remote_filename, timeout=config.timeout)
         if response.status_code != 200:
-            return {u'size': -1}
-        if u'size' not in response.json():
+            return {'size': -1}
+        if 'size' not in response.json():
             raise BackendException((
-                u'Malformed JSON: expected "size" member in %s' % (
-                    response.json())))
-        return {u'size': response.json()[u'size']}
+                f'Malformed JSON: expected "size" member in {response.json()}'))
+        return {'size': response.json()['size']}
 
     def _retry_cleanup(self):
         self.initialize_oauth2_session()
 
 
 class OneDriveOAuth2Session(object):
-    u"""A tiny wrapper for OAuth2Session that handles some OneDrive details."""
+    """A tiny wrapper for OAuth2Session that handles some OneDrive details."""
 
-    OAUTH_TOKEN_URI = u'https://login.microsoftonline.com/common/oauth2/v2.0/token'
+    OAUTH_TOKEN_URI = 'https://login.microsoftonline.com/common/oauth2/v2.0/token'
 
     def __init__(self):
         # OAUTHLIB_RELAX_TOKEN_SCOPE prevents the oauthlib from complaining
         # about a mismatch between the requested scope and the delivered scope.
         # We need this because we don't get a refresh token without asking for
         # offline_access, but Microsoft Graph doesn't include offline_access
         # in its response (even though it does send a refresh_token).
-        os.environ[u'OAUTHLIB_RELAX_TOKEN_SCOPE'] = u'TRUE'
+        os.environ['OAUTHLIB_RELAX_TOKEN_SCOPE'] = 'TRUE'
 
         # Import requests-oauthlib
         try:
             # On debian (and derivatives), get these dependencies using:
             # apt-get install python-requests-oauthlib
             # On fedora (and derivatives), get these dependencies using:
             # yum install python-requests-oauthlib
             from requests_oauthlib import OAuth2Session
             self.session_class = OAuth2Session
         except ImportError as e:
-            raise BackendException((
-                u'OneDrive backend requires python-requests-oauthlib to be '
-                u'installed. Please install it and try again.\n' + str(e)))
+            raise BackendException(f'OneDrive backend requires python-requests-oauthlib to be '
+                                   f'installed. Please install it and try again.\n{str(e)}')
 
         # Should be filled by a subclass
         self.session = None
 
     def get(self, *args, **kwargs):
         return self.session.get(*args, **kwargs)
 
@@ -251,134 +242,125 @@
         return self.session.post(*args, **kwargs)
 
     def delete(self, *args, **kwargs):
         return self.session.delete(*args, **kwargs)
 
 
 class DefaultOAuth2Session(OneDriveOAuth2Session):
-    u"""A possibly-interactive console session using a built-in API key"""
+    """A possibly-interactive console session using a built-in API key"""
 
     OAUTH_TOKEN_PATH = os.path.expanduser(
-        os.environ.get(u'DUPLICITY_ONEDRIVE_TOKEN',
-                       u'~/.duplicity_onedrive_oauthtoken.json'))
+        os.environ.get('DUPLICITY_ONEDRIVE_TOKEN',
+                       '~/.duplicity_onedrive_oauthtoken.json'))
 
-    CLIENT_ID = os.getenv(u'DUPLICITY_ONEDRIVE_CLIENT_ID', u'1612f841-ae01-46ab-9535-43ba6ec04029')
-    OAUTH_AUTHORIZE_URI = u'https://login.microsoftonline.com/common/oauth2/v2.0/authorize'
-    OAUTH_REDIRECT_URI = u'https://login.microsoftonline.com/common/oauth2/nativeclient'
+    CLIENT_ID = os.getenv('DUPLICITY_ONEDRIVE_CLIENT_ID', '1612f841-ae01-46ab-9535-43ba6ec04029')
+    OAUTH_AUTHORIZE_URI = 'https://login.microsoftonline.com/common/oauth2/v2.0/authorize'
+    OAUTH_REDIRECT_URI = 'https://login.microsoftonline.com/common/oauth2/nativeclient'
     # Files.Read is for reading files,
     # Files.ReadWrite  is for creating/writing files,
     # Files.Read.All and Files.Read.All are used if a sharepoint drive is provided by ONEDRIVE_ROOT in env
     # User.Read is needed for the /me request to see if the token works.
     # offline_access is necessary for duplicity to access onedrive without
     # the user being logged in right now.
     OAUTH_SCOPE = [
-        u'Files.Read', u'Files.ReadWrite',
-        u'Files.Read.All', u'Files.ReadWrite.All',
-        u'User.Read', u'offline_access'
+        'Files.Read', 'Files.ReadWrite',
+        'Files.Read.All', 'Files.ReadWrite.All',
+        'User.Read', 'offline_access'
     ]
 
     def __init__(self, api_uri):
-        super(DefaultOAuth2Session, self).__init__()
+        super().__init__()
 
         token = None
         try:
             with open(self.OAUTH_TOKEN_PATH) as f:
                 token = json.load(f)
         except IOError as e:
-            log.Error((u'Could not load OAuth2 token. '
-                       u'Trying to create a new one. (original error: %s)' % e))
+            log.Error(f'Could not load OAuth2 token. Trying to create a new one. (original error: {e})')
 
         self.session = self.session_class(
             self.CLIENT_ID,
             scope=self.OAUTH_SCOPE,
             redirect_uri=self.OAUTH_REDIRECT_URI,
             token=token,
             auto_refresh_kwargs={
-                u'client_id': self.CLIENT_ID,
+                'client_id': self.CLIENT_ID,
             },
             auto_refresh_url=self.OAUTH_TOKEN_URI,
             token_updater=self.token_updater)
 
         # We have to refresh token manually because it's not working "under the covers"
         if token is not None:
             self.session.refresh_token(self.OAUTH_TOKEN_URI, timeout=config.timeout)
 
         # Send a request to make sure the token is valid (or could at least be
         # refreshed successfully, which will happen under the covers). In case
         # this request fails, the provided token was too old (i.e. expired),
         # and we need to get a new token.
-        user_info_response = self.session.get(api_uri + u'me', timeout=config.timeout)
+        user_info_response = self.session.get(api_uri + 'me', timeout=config.timeout)
         if user_info_response.status_code != 200:
             token = None
 
         if token is None:
             if not sys.stdout.isatty() or not sys.stdin.isatty():
-                log.FatalError((u'The OAuth2 token could not be loaded from %s '
-                                u'and you are not running duplicity '
-                                u'interactively, so duplicity cannot possibly '
-                                u'access OneDrive.' % self.OAUTH_TOKEN_PATH))
+                log.FatalError(
+                    f'The OAuth2 token could not be loaded from {self.OAUTH_TOKEN_PATH} and you are not '
+                    f'running duplicity interactively, so duplicity cannot possibly access OneDrive.')
             authorization_url, state = self.session.authorization_url(
-                self.OAUTH_AUTHORIZE_URI, display=u'touch')
+                self.OAUTH_AUTHORIZE_URI, display='touch')
 
-            print()
-            print(u'In order to authorize duplicity to access your OneDrive, '
-                  u'please open %s in a browser and copy the URL of the blank '
-                  u'page the dialog leads to.' % authorization_url)
-            print()
+            print(f'\nIn order to authorize duplicity to access your OneDrive, please open {authorization_url} '
+                  f'in a browser and copy the URL of the blank page the dialog leads to.\n')
 
-            redirected_to = input(u'URL of the blank page: ').strip()
+            redirected_to = input('URL of the blank page: ').strip()
 
             token = self.session.fetch_token(
                 self.OAUTH_TOKEN_URI,
                 authorization_response=redirected_to,
                 include_client_id=True,
                 timeout=config.timeout)
 
-            user_info_response = self.session.get(api_uri + u'me', timeout=config.timeout)
+            user_info_response = self.session.get(api_uri + 'me', timeout=config.timeout)
             user_info_response.raise_for_status()
 
             try:
-                with open(self.OAUTH_TOKEN_PATH, u'w') as f:
+                with open(self.OAUTH_TOKEN_PATH, 'w') as f:
                     json.dump(token, f)
             except Exception as e:
-                log.Error((u'Could not save the OAuth2 token to %s. '
-                           u'This means you need to do the OAuth2 authorization '
-                           u'process on every start of duplicity. '
-                           u'Original error: %s' % (
-                               self.OAUTH_TOKEN_PATH, e)))
+                log.Error(
+                    f'Could not save the OAuth2 token to {self.OAUTH_TOKEN_PATH}. This means you need to do the '
+                    f'OAuth2 authorization process on every start of duplicity. Original error: {e}')
 
     def token_updater(self, token):
         try:
-            with open(self.OAUTH_TOKEN_PATH, u'w') as f:
+            with open(self.OAUTH_TOKEN_PATH, 'w') as f:
                 json.dump(token, f)
         except Exception as e:
-            log.Error((u'Could not save the OAuth2 token to %s. '
-                       u'This means you may need to do the OAuth2 '
-                       u'authorization process again soon. '
-                       u'Original error: %s' % (
-                           self.OAUTH_TOKEN_PATH, e)))
+            log.Error(
+                f'Could not save the OAuth2 token to {self.OAUTH_TOKEN_PATH}. This means you may need to do the '
+                f'OAuth2 authorization process again soon. Original error: {e}')
 
 
 class ExternalOAuth2Session(OneDriveOAuth2Session):
-    u"""Caller is managing tokens and provides an active refresh token."""
+    """Caller is managing tokens and provides an active refresh token."""
 
     def __init__(self, client_id, refresh_token):
-        super(ExternalOAuth2Session, self).__init__()
+        super().__init__()
 
         token = {
-            u'refresh_token': refresh_token,
+            'refresh_token': refresh_token,
         }
 
         self.session = self.session_class(
             client_id,
             token=token,
             auto_refresh_kwargs={
-                u'client_id': client_id,
+                'client_id': client_id,
             },
             auto_refresh_url=self.OAUTH_TOKEN_URI)
 
         # Get an initial refresh under our belts, since we don't have an access
         # token to start with.
         self.session.refresh_token(self.OAUTH_TOKEN_URI, timeout=config.timeout)
 
 
-duplicity.backend.register_backend(u'onedrive', OneDriveBackend)
+duplicity.backend.register_backend('onedrive', OneDriveBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/adbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/adbackend.py`

 * *Files 20% similar despite different names*

```diff
@@ -15,396 +15,378 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from __future__ import division
-from builtins import input
-import os.path
+
 import json
+import os.path
+import re
 import sys
 import time
-import re
 from io import DEFAULT_BUFFER_SIZE
 
 import duplicity.backend
-from duplicity.errors import BackendException
 from duplicity import config
 from duplicity import log
+from duplicity.errors import BackendException
 
 
 class ADBackend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for Amazon Drive. It communicates directly with Amazon Drive using
     their RESTful API and does not rely on externally setup software (like
     acd_cli).
     """
 
-    OAUTH_TOKEN_PATH = os.path.expanduser(u'~/.duplicity_ad_oauthtoken.json')
+    OAUTH_TOKEN_PATH = os.path.expanduser('~/.duplicity_ad_oauthtoken.json')
 
-    OAUTH_AUTHORIZE_URL = u'https://www.amazon.com/ap/oa'
-    OAUTH_TOKEN_URL = u'https://api.amazon.com/auth/o2/token'
+    OAUTH_AUTHORIZE_URL = 'https://www.amazon.com/ap/oa'
+    OAUTH_TOKEN_URL = 'https://api.amazon.com/auth/o2/token'
     # NOTE: Amazon requires https, which is why I am using my domain/setup
     # instead of Duplicity's. Mail me at stefan-duplicity@breunig.xyz once it is
     # available through https and I will whitelist the new URL.
-    OAUTH_REDIRECT_URL = u'https://breunig.xyz/duplicity/copy.html'
-    OAUTH_SCOPE = [u'clouddrive:read_other', u'clouddrive:write']
+    OAUTH_REDIRECT_URL = 'https://breunig.xyz/duplicity/copy.html'
+    OAUTH_SCOPE = ['clouddrive:read_other', 'clouddrive:write']
 
-    CLIENT_ID = u'amzn1.application-oa2-client.791c9c2d78444e85a32eb66f92eb6bcc'
-    CLIENT_SECRET = u'5b322c6a37b25f16d848a6a556eddcc30314fc46ae65c87068ff1bc4588d715b'
+    CLIENT_ID = 'amzn1.application-oa2-client.791c9c2d78444e85a32eb66f92eb6bcc'
+    CLIENT_SECRET = '5b322c6a37b25f16d848a6a556eddcc30314fc46ae65c87068ff1bc4588d715b'
 
-    MULTIPART_BOUNDARY = u'DuplicityFormBoundaryd66364f7f8924f7e9d478e19cf4b871d114a1e00262542'
+    MULTIPART_BOUNDARY = 'DuplicityFormBoundaryd66364f7f8924f7e9d478e19cf4b871d114a1e00262542'
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
-        self.metadata_url = u'https://drive.amazonaws.com/drive/v1/'
-        self.content_url = u'https://content-na.drive.amazonaws.com/cdproxy/'
+        self.metadata_url = 'https://drive.amazonaws.com/drive/v1/'
+        self.content_url = 'https://content-na.drive.amazonaws.com/cdproxy/'
 
         self.names_to_ids = {}
         self.backup_target_id = None
-        self.backup_target = parsed_url.path.lstrip(u'/')
+        self.backup_target = parsed_url.path.lstrip('/')
 
         if config.volsize > (10 * 1024 * 1024 * 1024):
             # https://forums.developer.amazon.com/questions/22713/file-size-limits.html
             # https://forums.developer.amazon.com/questions/22038/support-for-chunked-transfer-encoding.html
             log.FatalError(
-                u'Your --volsize is bigger than 10 GiB, which is the maximum '
-                u'file size on Amazon Drive that does not require work arounds.')
+                'Your --volsize is bigger than 10 GiB, which is the maximum '
+                'file size on Amazon Drive that does not require work arounds.')
 
         try:
             global requests
             global OAuth2Session
             import requests
             from requests_oauthlib import OAuth2Session
         except ImportError:
             raise BackendException(
-                u'Amazon Drive backend requires python-requests and '
-                u'python-requests-oauthlib to be installed.\n\n'
-                u'For Debian and derivates use:\n'
-                u'  apt-get install python-requests python-requests-oauthlib\n'
-                u'For Fedora and derivates use:\n'
-                u'  yum install python-requests python-requests-oauthlib')
+                'Amazon Drive backend requires python-requests and '
+                'python-requests-oauthlib to be installed.\n\n'
+                'For Debian and derivates use:\n'
+                '  apt-get install python-requests python-requests-oauthlib\n'
+                'For Fedora and derivates use:\n'
+                '  yum install python-requests python-requests-oauthlib')
 
         self.initialize_oauth2_session()
         self.resolve_backup_target()
 
     def initialize_oauth2_session(self):
-        u"""Setup or refresh oauth2 session with Amazon Drive"""
+        """Setup or refresh oauth2 session with Amazon Drive"""
 
         def token_updater(token):
-            u"""Stores oauth2 token on disk"""
+            """Stores oauth2 token on disk"""
             try:
-                with open(self.OAUTH_TOKEN_PATH, u'w') as f:
+                with open(self.OAUTH_TOKEN_PATH, 'w') as f:
                     json.dump(token, f)
             except Exception as err:
-                log.Error(u'Could not save the OAuth2 token to %s. This means '
-                          u'you may need to do the OAuth2 authorization '
-                          u'process again soon. Original error: %s' % (
-                              self.OAUTH_TOKEN_PATH, err))
+                log.Error(f'Could not save the OAuth2 token to {self.OAUTH_TOKEN_PATH}. '
+                          f'This means you may need to do the OAuth2 authorization process again soon. '
+                          f'Original error: {err}')
 
         token = None
         try:
             with open(self.OAUTH_TOKEN_PATH) as f:
                 token = json.load(f)
         except IOError as err:
-            log.Notice(u'Could not load OAuth2 token. '
-                       u'Trying to create a new one. (original error: %s)' % err)
+            log.Notice(f'Could not load OAuth2 token. Trying to create a new one. (original error: {err})')
 
         self.http_client = OAuth2Session(
             self.CLIENT_ID,
             scope=self.OAUTH_SCOPE,
             redirect_uri=self.OAUTH_REDIRECT_URL,
             token=token,
             auto_refresh_kwargs={
-                u'client_id': self.CLIENT_ID,
-                u'client_secret': self.CLIENT_SECRET,
+                'client_id': self.CLIENT_ID,
+                'client_secret': self.CLIENT_SECRET,
             },
             auto_refresh_url=self.OAUTH_TOKEN_URL,
             token_updater=token_updater)
 
         if token is not None:
             self.http_client.refresh_token(self.OAUTH_TOKEN_URL)
 
         endpoints_response = self.http_client.get(self.metadata_url +
-                                                  u'account/endpoint')
+                                                  'account/endpoint')
         if endpoints_response.status_code != requests.codes.ok:
             token = None
 
         if token is None:
             if not sys.stdout.isatty() or not sys.stdin.isatty():
-                log.FatalError(u'The OAuth2 token could not be loaded from %s '
-                               u'and you are not running duplicity '
-                               u'interactively, so duplicity cannot possibly '
-                               u'access Amazon Drive.' % self.OAUTH_TOKEN_PATH)
+                log.FatalError(f'The OAuth2 token could not be loaded from {self.OAUTH_TOKEN_PATH} '
+                               f'and you are not running duplicity interactively, so duplicity '
+                               f'cannot possibly access Amazon Drive.')
             authorization_url, _ = self.http_client.authorization_url(
                 self.OAUTH_AUTHORIZE_URL)
 
-            print(u'')
-            print(u'In order to allow duplicity to access Amazon Drive, please '
-                  u'open the following URL in a browser and copy the URL of the '
-                  u'page you see after authorization here:')
+            print('')
+            print('In order to allow duplicity to access Amazon Drive, please '
+                  'open the following URL in a browser and copy the URL of the '
+                  'page you see after authorization here:')
             print(authorization_url)
-            print(u'')
+            print('')
 
-            redirected_to = (input(u'URL of the resulting page: ')
-                             .replace(u'http://', u'https://', 1)).strip()
+            redirected_to = (input('URL of the resulting page: ')
+                             .replace('http://', 'https://', 1)).strip()
 
             token = self.http_client.fetch_token(
                 self.OAUTH_TOKEN_URL,
                 client_secret=self.CLIENT_SECRET,
                 authorization_response=redirected_to)
 
             endpoints_response = self.http_client.get(self.metadata_url +
-                                                      u'account/endpoint')
+                                                      'account/endpoint')
             endpoints_response.raise_for_status()
             token_updater(token)
 
         urls = endpoints_response.json()
-        if u'metadataUrl' not in urls or u'contentUrl' not in urls:
-            log.FatalError(u'Could not retrieve endpoint URLs for this account')
-        self.metadata_url = urls[u'metadataUrl']
-        self.content_url = urls[u'contentUrl']
+        if 'metadataUrl' not in urls or 'contentUrl' not in urls:
+            log.FatalError('Could not retrieve endpoint URLs for this account')
+        self.metadata_url = urls['metadataUrl']
+        self.content_url = urls['contentUrl']
 
     def resolve_backup_target(self):
-        u"""Resolve node id for remote backup target folder"""
+        """Resolve node id for remote backup target folder"""
 
         response = self.http_client.get(
-            self.metadata_url + u'nodes?filters=kind:FOLDER AND isRoot:true')
-        parent_node_id = response.json()[u'data'][0][u'id']
+            self.metadata_url + 'nodes?filters=kind:FOLDER AND isRoot:true')
+        parent_node_id = response.json()['data'][0]['id']
 
-        for component in [x for x in self.backup_target.split(u'/') if x]:
+        for component in [x for x in self.backup_target.split('/') if x]:
             # There doesn't seem to be escaping support, so cut off filter
             # after first unsupported character
-            query = re.search(u'^[A-Za-z0-9_-]*', component).group(0)
+            query = re.search('^[A-Za-z0-9_-]*', component).group(0)
             if component != query:
-                query = query + u'*'
+                query = query + '*'
 
             matches = self.read_all_pages(
-                self.metadata_url + u'nodes?filters=kind:FOLDER AND name:%s '
-                                    u'AND parents:%s' % (query, parent_node_id))
-            candidates = [f for f in matches if f.get(u'name') == component]
+                self.metadata_url + f'nodes?filters=kind:FOLDER AND name:{query} AND parents:{parent_node_id}')
+            candidates = [f for f in matches if f.get('name') == component]
 
             if len(candidates) >= 2:
-                log.FatalError(u'There are multiple folders with the same name '
-                               u'below one parent.\nParentID: %s\nFolderName: '
-                               u'%s' % (parent_node_id, component))
+                log.FatalError(f'There are multiple folders with the same name below one parent.\n'
+                               f'ParentID: {parent_node_id}\nFolderName: {component}')
             elif len(candidates) == 1:
-                parent_node_id = candidates[0][u'id']
+                parent_node_id = candidates[0]['id']
             else:
-                log.Debug(u'Folder %s does not exist yet. Creating.' % component)
+                log.Debug(f'Folder {component} does not exist yet. Creating.')
                 parent_node_id = self.mkdir(parent_node_id, component)
 
-        log.Debug(u"Backup target folder has id: %s" % parent_node_id)
+        log.Debug(f"Backup target folder has id: {parent_node_id}")
         self.backup_target_id = parent_node_id
 
     def get_file_id(self, remote_filename):
-        u"""Find id of remote file in backup target folder"""
+        """Find id of remote file in backup target folder"""
 
         if remote_filename not in self.names_to_ids:
             self._list()
 
         return self.names_to_ids.get(remote_filename)
 
     def mkdir(self, parent_node_id, folder_name):
-        u"""Create a new folder as a child of a parent node"""
+        """Create a new folder as a child of a parent node"""
 
-        data = {u'name': folder_name, u'parents': [parent_node_id], u'kind': u'FOLDER'}
+        data = {'name': folder_name, 'parents': [parent_node_id], 'kind': 'FOLDER'}
         response = self.http_client.post(
-            self.metadata_url + u'nodes',
+            self.metadata_url + 'nodes',
             data=json.dumps(data))
         response.raise_for_status()
-        return response.json()[u'id']
+        return response.json()['id']
 
     def multipart_stream(self, metadata, source_path):
-        u"""Generator for multipart/form-data file upload from source file"""
+        """Generator for multipart/form-data file upload from source file"""
 
         boundary = self.MULTIPART_BOUNDARY
 
-        yield str.encode(u'--%s\r\nContent-Disposition: form-data; '
-                         u'name="metadata"\r\n\r\n' % boundary +
-                         u'%s\r\n' % json.dumps(metadata) +
-                         u'--%s\r\n' % boundary)
+        yield str.encode(f'--{boundary}\r\nContent-Disposition: form-data; name="metadata"\r\n\r\n' +
+                         f'{json.dumps(metadata)}\r\n' +
+                         f'--{boundary}\r\n')
         yield b'Content-Disposition: form-data; name="content"; filename="i_love_backups"\r\n'
         yield b'Content-Type: application/octet-stream\r\n\r\n'
 
         with source_path.open() as stream:
             while True:
                 f = stream.read(DEFAULT_BUFFER_SIZE)
                 if f:
                     yield f
                 else:
                     break
 
-        yield str.encode(u'\r\n--%s--\r\n' % boundary +
-                         u'multipart/form-data; boundary=%s' % boundary)
+        yield str.encode(f'\r\n--{boundary}--\r\n' +
+                         f'multipart/form-data; boundary={boundary}')
 
     def read_all_pages(self, url):
-        u"""Iterates over nodes API URL until all pages were read"""
+        """Iterates over nodes API URL until all pages were read"""
 
         result = []
-        next_token = u''
-        token_param = u'&startToken=' if u'?' in url else u'?startToken='
+        next_token = ''
+        token_param = '&startToken=' if '?' in url else '?startToken='
 
         while True:
             paginated_url = url + token_param + next_token
             response = self.http_client.get(paginated_url)
             if response.status_code != 200:
-                raise BackendException(u"Pagination failed with status=%s on "
-                                       u"URL=%s" % (response.status_code, url))
+                raise BackendException(f"Pagination failed with status={response.status_code} on URL={url}")
 
             parsed = response.json()
-            if u'data' in parsed and len(parsed[u'data']) > 0:
-                result.extend(parsed[u'data'])
+            if 'data' in parsed and len(parsed['data']) > 0:
+                result.extend(parsed['data'])
             else:
                 break
 
             # Do not make another HTTP request if everything is here already
-            if len(result) >= parsed[u'count']:
+            if len(result) >= parsed['count']:
                 break
 
-            if u'nextToken' not in parsed:
+            if 'nextToken' not in parsed:
                 break
-            next_token = parsed[u'nextToken']
+            next_token = parsed['nextToken']
 
         return result
 
     def raise_for_existing_file(self, remote_filename):
-        u"""Report error when file already existed in location and delete it"""
+        """Report error when file already existed in location and delete it"""
 
         self._delete(remote_filename)
-        raise BackendException(u'Upload failed, because there was a file with '
-                               u'the same name as %s already present. The file was '
-                               u'deleted, and duplicity will retry the upload unless '
-                               u'the retry limit has been reached.' % remote_filename)
+        raise BackendException(f'Upload failed, because there was a file with the same name as {remote_filename} '
+                               f'already present. The file was deleted, and duplicity will retry the upload '
+                               f'unless the retry limit has been reached.')
 
     def _put(self, source_path, remote_filename):
-        u"""Upload a local file to Amazon Drive"""
+        """Upload a local file to Amazon Drive"""
 
-        quota = self.http_client.get(self.metadata_url + u'account/quota')
+        quota = self.http_client.get(self.metadata_url + 'account/quota')
         quota.raise_for_status()
-        available = quota.json()[u'available']
+        available = quota.json()['available']
 
         source_size = os.path.getsize(source_path.name)
 
         if source_size > available:
             raise BackendException(
-                u'Out of space: trying to store "%s" (%d bytes), but only '
-                u'%d bytes available on Amazon Drive.' % (
-                    source_path.name, source_size, available))
+                f'Out of space: trying to store "{source_path.name}" ({int(source_size)} bytes), '
+                f'but only {int(available)} bytes available on Amazon Drive.')
 
         # Just check the cached list, to avoid _list for every new file being
         # uploaded
         if remote_filename in self.names_to_ids:
-            log.Debug(u'File %s seems to already exist on Amazon Drive. Deleting '
-                      u'before attempting to upload it again.' % remote_filename)
+            log.Debug(f'File {remote_filename} seems to already exist on Amazon Drive. '
+                      f'Deleting before attempting to upload it again.')
             self._delete(remote_filename)
 
-        metadata = {u'name': remote_filename, u'kind': u'FILE',
-                    u'parents': [self.backup_target_id]}
-        headers = {u'Content-Type': u'multipart/form-data; boundary=%s' % self.MULTIPART_BOUNDARY}
+        metadata = {'name': remote_filename, 'kind': 'FILE',
+                    'parents': [self.backup_target_id]}
+        headers = {'Content-Type': f'multipart/form-data; boundary={self.MULTIPART_BOUNDARY}'}
         data = self.multipart_stream(metadata, source_path)
 
         response = self.http_client.post(
-            self.content_url + u'nodes?suppress=deduplication',
+            self.content_url + 'nodes?suppress=deduplication',
             data=data,
             headers=headers)
 
         if response.status_code == 409:  # "409 : Duplicate file exists."
             self.raise_for_existing_file(remote_filename)
         elif response.status_code == 201:
-            log.Debug(u'%s uploaded successfully' % remote_filename)
+            log.Debug(f'{remote_filename} uploaded successfully')
         elif response.status_code == 408 or response.status_code == 504:
-            log.Info(u'%s upload failed with timeout status code=%d. Speculatively '
-                     u'waiting for %d seconds to see if Amazon Drive finished the '
-                     u'upload anyway' % (remote_filename, response.status_code,
-                                         config.timeout))
+            log.Info(f'{remote_filename} upload failed with timeout status code={int(response.status_code)}. '
+                     f'Speculatively waiting for {int(config.timeout)} seconds to see if Amazon Drive '
+                     f'finished the upload anyway')
             tries = config.timeout / 15
             while tries >= 0:
                 tries -= 1
                 time.sleep(15)
 
-                remote_size = self._query(remote_filename)[u'size']
+                remote_size = self._query(remote_filename)['size']
                 if source_size == remote_size:
-                    log.Debug(u'Upload turned out to be successful after all.')
+                    log.Debug('Upload turned out to be successful after all.')
                     return
                 elif remote_size == -1:
-                    log.Debug(u'Uploaded file is not yet there, %d tries left.'
-                              % (tries + 1))
+                    log.Debug(f'Uploaded file is not yet there, {int(tries + 1)} tries left.')
                     continue
                 else:
                     self.raise_for_existing_file(remote_filename)
-            raise BackendException(u'%s upload failed and file did not show up '
-                                   u'within time limit.' % remote_filename)
+            raise BackendException(f'{remote_filename} upload failed and file did not show up within time limit.')
         else:
-            log.Debug(u'%s upload returned an undesirable status code %s'
-                      % (remote_filename, response.status_code))
+            log.Debug(f'{remote_filename} upload returned an undesirable status code {response.status_code}')
             response.raise_for_status()
 
         parsed = response.json()
-        if u'id' not in parsed:
-            raise BackendException(u'%s was uploaded, but returned JSON does not '
-                                   u'contain ID of new file. Retrying.\nJSON:\n\n%s'
-                                   % (remote_filename, parsed))
+        if 'id' not in parsed:
+            raise BackendException(f'{remote_filename} was uploaded but returned JSON does not contain ID of new file. '
+                                   f'Retrying.\nJSON:\n\n{parsed}')
 
         # XXX: The upload may be considered finished before the file shows up
         # in the file listing. As such, the following is required to avoid race
         # conditions when duplicity calls _query or _list.
-        self.names_to_ids[parsed[u'name']] = parsed[u'id']
+        self.names_to_ids[parsed['name']] = parsed['id']
 
     def _get(self, remote_filename, local_path):
-        u"""Download file from Amazon Drive"""
+        """Download file from Amazon Drive"""
 
-        with local_path.open(u'wb') as local_file:
+        with local_path.open('wb') as local_file:
             file_id = self.get_file_id(remote_filename)
             if file_id is None:
                 raise BackendException(
-                    u'File "%s" cannot be downloaded: it does not exist' %
-                    remote_filename)
+                    f'File "{remote_filename}" cannot be downloaded: it does not exist')
 
             response = self.http_client.get(
-                self.content_url + u'/nodes/' + file_id + u'/content', stream=True)
+                self.content_url + '/nodes/' + file_id + '/content', stream=True)
             response.raise_for_status()
             for chunk in response.iter_content(chunk_size=DEFAULT_BUFFER_SIZE):
                 if chunk:
                     local_file.write(chunk)
             local_file.flush()
 
     def _query(self, remote_filename):
-        u"""Retrieve file size info from Amazon Drive"""
+        """Retrieve file size info from Amazon Drive"""
 
         file_id = self.get_file_id(remote_filename)
         if file_id is None:
-            return {u'size': -1}
-        response = self.http_client.get(self.metadata_url + u'nodes/' + file_id)
+            return {'size': -1}
+        response = self.http_client.get(self.metadata_url + 'nodes/' + file_id)
         response.raise_for_status()
 
-        return {u'size': response.json()[u'contentProperties'][u'size']}
+        return {'size': response.json()['contentProperties']['size']}
 
     def _list(self):
-        u"""List files in Amazon Drive backup folder"""
+        """List files in Amazon Drive backup folder"""
 
         files = self.read_all_pages(
-            self.metadata_url + u'nodes/' + self.backup_target_id +
-            u'/children?filters=kind:FILE')
+            self.metadata_url + 'nodes/' + self.backup_target_id +
+            '/children?filters=kind:FILE')
 
-        self.names_to_ids = {f[u'name']: f[u'id'] for f in files}
+        self.names_to_ids = {f['name']: f['id'] for f in files}
 
         return list(self.names_to_ids.keys())
 
     def _delete(self, remote_filename):
-        u"""Delete file from Amazon Drive"""
+        """Delete file from Amazon Drive"""
 
         file_id = self.get_file_id(remote_filename)
         if file_id is None:
             raise BackendException(
-                u'File "%s" cannot be deleted: it does not exist' % (
-                    remote_filename))
-        response = self.http_client.put(self.metadata_url + u'trash/' + file_id)
+                f'File "{remote_filename}" cannot be deleted: it does not exist')
+        response = self.http_client.put(self.metadata_url + 'trash/' + file_id)
         response.raise_for_status()
         del self.names_to_ids[remote_filename]
 
 
-duplicity.backend.register_backend(u'ad', ADBackend)
+duplicity.backend.register_backend('ad', ADBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/megav2backend.py` & `duplicity-2.0.0rc0/duplicity/backends/megav2backend.py`

 * *Files 16% similar despite different names*

```diff
@@ -14,201 +14,195 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-
-from duplicity import util
-from duplicity.errors import BackendException
-import duplicity.backend
 
 import os
-import subprocess
 import re
+import subprocess
+
+import duplicity.backend
+from duplicity.errors import BackendException
 
 
 class Megav2Backend(duplicity.backend.Backend):
-    u""" Backend for MEGA.nz cloud storage, only one that works for accounts created since Nov. 2018
+    """ Backend for MEGA.nz cloud storage, only one that works for accounts created since Nov. 2018
          See https://github.com/megous/megatools/issues/411 for more details
 
          This MEGA backend resorts to official tools (MEGAcmd) as available at https://mega.nz/cmd
          MEGAcmd works through a single binary called "mega-cmd", which talks to a backend server
          "mega-cmd-server", which keeps state (for example, persisting a session). Multiple "mega-*"
          shell wrappers (ie. "mega-ls") exist as the user interface to "mega-cmd" and MEGA API
          The full MEGAcmd User Guide can be found in the software's GitHub page below :
          https://github.com/meganz/MEGAcmd/blob/master/UserGuide.md """
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # Sanity check : ensure all the necessary "MEGAcmd" binaries exist
-        self._check_binary_exists(u'mega-login')
-        self._check_binary_exists(u'mega-logout')
-        self._check_binary_exists(u'mega-cmd')
-        self._check_binary_exists(u'mega-cmd-server')
-        self._check_binary_exists(u'mega-ls')
-        self._check_binary_exists(u'mega-mkdir')
-        self._check_binary_exists(u'mega-get')
-        self._check_binary_exists(u'mega-put')
-        self._check_binary_exists(u'mega-rm')
+        self._check_binary_exists('mega-login')
+        self._check_binary_exists('mega-logout')
+        self._check_binary_exists('mega-cmd')
+        self._check_binary_exists('mega-cmd-server')
+        self._check_binary_exists('mega-ls')
+        self._check_binary_exists('mega-mkdir')
+        self._check_binary_exists('mega-get')
+        self._check_binary_exists('mega-put')
+        self._check_binary_exists('mega-rm')
 
         # "MEGAcmd" does not use a config file, however it is handy to keep one (with the old ".megarc" format) to
         # securely store the username and password
         self._hostname = parsed_url.hostname
         if parsed_url.password is None:
-            self._megarc = os.getenv(u'HOME') + u'/.megav2rc'
+            self._megarc = f"{os.getenv('HOME')}/.megav2rc"
             try:
-                conf_file = open(self._megarc, u"r")
+                conf_file = open(self._megarc, "r")
             except Exception as e:
-                raise BackendException(u"No password provided in URL and MEGA configuration "
-                                       u"file for duplicity does not exist as '%s'" %
-                                       (self._megarc,))
+                raise BackendException(f"No password provided in URL and MEGA configuration file for "
+                                       f"duplicity does not exist as '{self._megarc}'")
 
             myvars = {}
             for line in conf_file:
-                name, var = line.partition(u"=")[::2]
+                name, var = line.partition("=")[::2]
                 myvars[name.strip()] = str(var.strip())
             conf_file.close()
-            self._username = myvars[u"Username"]
-            self._password = myvars[u"Password"]
+            self._username = myvars["Username"]
+            self._password = myvars["Password"]
 
         else:
             self._username = parsed_url.username
             self._password = self.get_password()
 
         # Remote folder ("MEGAcmd" no longer shows "Root/" at the top of the hierarchy)
-        self._folder = u'/' + parsed_url.path[1:]
+        self._folder = f"/{parsed_url.path[1:]}"
 
         # Only create the remote folder if it doesn't exist yet
         self.mega_login()
-        cmd = [u'mega-ls', self._folder]
+        cmd = ['mega-ls', self._folder]
         try:
             self.subprocess_popen(cmd)
         except Exception as e:
             self._makedir(self._folder)
 
     def _check_binary_exists(self, cmd):
-        u'Checks that a specified command exists in the running user command path'
+        """Checks that a specified command exists in the running user command path"""
 
         try:
             # Ignore the output, as we only need the return code
-            subprocess.check_output([u'which', cmd])
+            subprocess.check_output(['which', cmd])
         except Exception as e:
-            raise BackendException(u"Command '%s' not found, make sure 'MEGAcmd' tools (https://mega.nz/cmd) is "
-                                   u"properly installed and in the running user command path" % (cmd,))
+            raise BackendException(f"Command '{cmd}' not found, make sure 'MEGAcmd' tools (https://mega.nz/cmd) "
+                                   f"is properly installed and in the running user command path")
 
     def _makedir(self, path):
-        u'Creates a remote directory (recursively if necessary)'
+        """Creates a remote directory (recursively if necessary)"""
 
         self.mega_login()
-        cmd = [u'mega-mkdir', u'-p', path]
+        cmd = ['mega-mkdir', '-p', path]
         try:
             self.subprocess_popen(cmd)
         except Exception as e:
             error_str = str(e)
-            if u"Folder already exists" in error_str:
-                raise BackendException(u"Folder '%s' could not be created on MEGA because it already exists. "
-                                       u"Use another path or remove the folder in MEGA manually" % (path,))
+            if "Folder already exists" in error_str:
+                raise BackendException(f"Folder '{path}' could not be created on MEGA because it already exists. "
+                                       f"Use another path or remove the folder in MEGA manually")
             else:
-                raise BackendException(u"Folder '%s' could not be created, reason : '%s'" % (path, e))
+                raise BackendException(f"Folder '{path}' could not be created, reason : '{e}'")
 
     def _put(self, source_path, remote_filename):
-        u'''Uploads file to the specified remote folder (tries to delete it first to make
-            sure the new one can be uploaded)'''
+        """Uploads file to the specified remote folder (tries to delete it first to make
+            sure the new one can be uploaded)"""
 
         try:
             self.delete(remote_filename.decode())
         except Exception:
             pass
         self.upload(local_file=source_path.get_canonical().decode(), remote_file=remote_filename.decode())
 
     def _get(self, remote_filename, local_path):
-        u'Downloads file from the specified remote path'
+        """Downloads file from the specified remote path"""
 
         self.download(remote_file=remote_filename.decode(), local_file=local_path.name.decode())
 
     def _list(self):
-        u'Lists files in the specified remote path'
+        """Lists files in the specified remote path"""
 
         return self.folder_contents(files_only=True)
 
     def _delete(self, filename):
-        u'Deletes file from the specified remote path'
+        """Deletes file from the specified remote path"""
 
         self.delete(remote_file=filename.decode())
 
     def _close(self):
-        u'Function called when backend is done being used'
+        """Function called when backend is done being used"""
 
-        cmd = [u'mega-logout']
+        cmd = ['mega-logout']
         self.subprocess_popen(cmd)
 
     def mega_login(self):
-        u'''Helper function to call from each method interacting with MEGA to make
-            sure a session already exists or one is created to start with'''
+        """Helper function to call from each method interacting with MEGA to make
+            sure a session already exists or one is created to start with"""
 
         # Abort if command doesn't return in a reasonable time (somehow "mega-session" sometimes
         # doesn't return), and create session if one doesn't exist yet
         try:
-            subprocess.check_output(u'mega-session', timeout=30)
+            subprocess.check_output('mega-session', timeout=30)
         except subprocess.TimeoutExpired:
-            raise BackendException(u"Timed out while trying to determine if a MEGA session exists")
+            raise BackendException("Timed out while trying to determine if a MEGA session exists")
         except Exception as e:
-            cmd = [u'mega-login', self._username, self._password]
+            cmd = ['mega-login', self._username, self._password]
             try:
                 subprocess.check_output(cmd, stderr=subprocess.DEVNULL)
             except Exception as e:
-                raise BackendException(u"Could not log in to MEGA, error : '%s'" % (e,))
+                raise BackendException(f"Could not log in to MEGA, error : '{e}'")
 
     def folder_contents(self, files_only=False):
-        u'Lists contents of a remote MEGA path, optionally ignoring subdirectories'
+        """Lists contents of a remote MEGA path, optionally ignoring subdirectories"""
 
-        cmd = [u'mega-ls', u'-l', self._folder]
+        cmd = ['mega-ls', '-l', self._folder]
 
         self.mega_login()
         files = subprocess.check_output(cmd)
-        files = files.decode().split(u'\n')
+        files = files.decode().split('\n')
 
         # Optionally ignore directories
         if files_only:
-            files = [f.split()[5] for f in files if re.search(u'^-', f)]
+            files = [f.split()[5] for f in files if re.search('^-', f)]
 
         return files
 
     def download(self, remote_file, local_file):
-        u'Downloads a file from a remote MEGA path'
+        """Downloads a file from a remote MEGA path"""
 
-        cmd = [u'mega-get', self._folder + u'/' + remote_file, local_file]
+        cmd = ['mega-get', f"{self._folder}/{remote_file}", local_file]
         self.mega_login()
         self.subprocess_popen(cmd)
 
     def upload(self, local_file, remote_file):
-        u'Uploads a file to a remote MEGA path'
+        """Uploads a file to a remote MEGA path"""
 
-        cmd = [u'mega-put', local_file, self._folder + u'/' + remote_file]
+        cmd = ['mega-put', local_file, f"{self._folder}/{remote_file}"]
         self.mega_login()
         try:
             self.subprocess_popen(cmd)
         except Exception as e:
             error_str = str(e)
-            if u"Reached storage quota" in error_str:
-                raise BackendException(u"MEGA account over quota, could not write file : '%s' . "
-                                       u"Upgrade your storage at https://mega.nz/pro or remove some data." %
-                                       (remote_file,))
+            if "Reached storage quota" in error_str:
+                raise BackendException(f"MEGA account over quota, could not write file : '{remote_file}'. "
+                                       f"Upgrade your storage at https://mega.nz/pro or remove some data.")
             else:
-                raise BackendException(u"Failed writing file '%s' to MEGA, reason : '%s'" % (remote_file, e))
+                raise BackendException(f"Failed writing file '{remote_file}' to MEGA, reason : '{e}'")
 
     def delete(self, remote_file):
-        u'Deletes a file from a remote MEGA path'
+        """Deletes a file from a remote MEGA path"""
 
-        cmd = [u'mega-rm', u'-f', self._folder + u'/' + remote_file]
+        cmd = ['mega-rm', '-f', f"{self._folder}/{remote_file}"]
         self.mega_login()
         self.subprocess_popen(cmd)
 
 
-duplicity.backend.register_backend(u'megav2', Megav2Backend)
-duplicity.backend.uses_netloc.extend([u'megav2'])
+duplicity.backend.register_backend('megav2', Megav2Backend)
+duplicity.backend.uses_netloc.extend(['megav2'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/swiftbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/swiftbackend.py`

 * *Files 17% similar despite different names*

```diff
@@ -14,209 +14,203 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
 import os
 
 import duplicity.backend
 from duplicity import config
 from duplicity import log
-from duplicity import util
 from duplicity.errors import BackendException
 
 
 class SwiftBackend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for Swift
     """
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         try:
             from swiftclient.service import SwiftService
             from swiftclient import Connection
             from swiftclient import ClientException
         except ImportError as e:
-            raise BackendException(u"""\
-Swift backend requires the python-swiftclient library.
-Exception: %s""" % str(e))
+            raise BackendException(f"""Swift backend requires the python-swiftclient library.
+Exception: {str(e)}""")
 
         self.resp_exc = ClientException
         conn_kwargs = {}
         os_options = {}
         svc_options = {}
 
         # if the user has already authenticated
-        if u'SWIFT_PREAUTHURL' in os.environ and u'SWIFT_PREAUTHTOKEN' in os.environ:
-            conn_kwargs[u'preauthurl'] = os.environ[u'SWIFT_PREAUTHURL']
-            conn_kwargs[u'preauthtoken'] = os.environ[u'SWIFT_PREAUTHTOKEN']
+        if 'SWIFT_PREAUTHURL' in os.environ and 'SWIFT_PREAUTHTOKEN' in os.environ:
+            conn_kwargs['preauthurl'] = os.environ['SWIFT_PREAUTHURL']
+            conn_kwargs['preauthtoken'] = os.environ['SWIFT_PREAUTHTOKEN']
 
         else:
-            if u'SWIFT_USERNAME' not in os.environ:
-                raise BackendException(u'SWIFT_USERNAME environment variable '
-                                       u'not set.')
-
-            if u'SWIFT_PASSWORD' not in os.environ:
-                raise BackendException(u'SWIFT_PASSWORD environment variable '
-                                       u'not set.')
-
-            if u'SWIFT_AUTHURL' not in os.environ:
-                raise BackendException(u'SWIFT_AUTHURL environment variable '
-                                       u'not set.')
-
-            svc_options[u'os_username'] = conn_kwargs[u'user'] = os.environ[u'SWIFT_USERNAME']
-            svc_options[u'os_password'] = conn_kwargs[u'key'] = os.environ[u'SWIFT_PASSWORD']
-            svc_options[u'os_auth_url'] = conn_kwargs[u'authurl'] = os.environ[u'SWIFT_AUTHURL']
-
-        if u'SWIFT_AUTHVERSION' in os.environ:
-            svc_options[u'auth_version'] = conn_kwargs[u'auth_version'] = os.environ[u'SWIFT_AUTHVERSION']
-            if os.environ[u'SWIFT_AUTHVERSION'] == u'3':
-                if u'SWIFT_USER_DOMAIN_NAME' in os.environ:
-                    os_options.update({u'user_domain_name': os.environ[u'SWIFT_USER_DOMAIN_NAME']})
-                if u'SWIFT_USER_DOMAIN_ID' in os.environ:
-                    os_options.update({u'user_domain_id': os.environ[u'SWIFT_USER_DOMAIN_ID']})
-                if u'SWIFT_PROJECT_DOMAIN_NAME' in os.environ:
-                    os_options.update({u'project_domain_name': os.environ[u'SWIFT_PROJECT_DOMAIN_NAME']})
-                if u'SWIFT_PROJECT_DOMAIN_ID' in os.environ:
-                    os_options.update({u'project_domain_id': os.environ[u'SWIFT_PROJECT_DOMAIN_ID']})
-                if u'SWIFT_PROJECT_ID' in os.environ:
-                    os_options.update({u'project_id': os.environ[u'SWIFT_PROJECT_ID']})
-                if u'SWIFT_PROJECT_NAME' in os.environ:
-                    os_options.update({u'project_name': os.environ[u'SWIFT_PROJECT_NAME']})
-                if u'SWIFT_TENANTNAME' in os.environ:
-                    os_options.update({u'tenant_name': os.environ[u'SWIFT_TENANTNAME']})
-                if u'SWIFT_ENDPOINT_TYPE' in os.environ:
-                    os_options.update({u'endpoint_type': os.environ[u'SWIFT_ENDPOINT_TYPE']})
-                if u'SWIFT_USERID' in os.environ:
-                    os_options.update({u'user_id': os.environ[u'SWIFT_USERID']})
-                if u'SWIFT_TENANTID' in os.environ:
-                    os_options.update({u'tenant_id': os.environ[u'SWIFT_TENANTID']})
-                if u'SWIFT_REGIONNAME' in os.environ:
-                    os_options.update({u'region_name': os.environ[u'SWIFT_REGIONNAME']})
+            if 'SWIFT_USERNAME' not in os.environ:
+                raise BackendException('SWIFT_USERNAME environment variable '
+                                       'not set.')
+
+            if 'SWIFT_PASSWORD' not in os.environ:
+                raise BackendException('SWIFT_PASSWORD environment variable '
+                                       'not set.')
+
+            if 'SWIFT_AUTHURL' not in os.environ:
+                raise BackendException('SWIFT_AUTHURL environment variable '
+                                       'not set.')
+
+            svc_options['os_username'] = conn_kwargs['user'] = os.environ['SWIFT_USERNAME']
+            svc_options['os_password'] = conn_kwargs['key'] = os.environ['SWIFT_PASSWORD']
+            svc_options['os_auth_url'] = conn_kwargs['authurl'] = os.environ['SWIFT_AUTHURL']
+
+        if 'SWIFT_AUTHVERSION' in os.environ:
+            svc_options['auth_version'] = conn_kwargs['auth_version'] = os.environ['SWIFT_AUTHVERSION']
+            if os.environ['SWIFT_AUTHVERSION'] == '3':
+                if 'SWIFT_USER_DOMAIN_NAME' in os.environ:
+                    os_options.update({'user_domain_name': os.environ['SWIFT_USER_DOMAIN_NAME']})
+                if 'SWIFT_USER_DOMAIN_ID' in os.environ:
+                    os_options.update({'user_domain_id': os.environ['SWIFT_USER_DOMAIN_ID']})
+                if 'SWIFT_PROJECT_DOMAIN_NAME' in os.environ:
+                    os_options.update({'project_domain_name': os.environ['SWIFT_PROJECT_DOMAIN_NAME']})
+                if 'SWIFT_PROJECT_DOMAIN_ID' in os.environ:
+                    os_options.update({'project_domain_id': os.environ['SWIFT_PROJECT_DOMAIN_ID']})
+                if 'SWIFT_PROJECT_ID' in os.environ:
+                    os_options.update({'project_id': os.environ['SWIFT_PROJECT_ID']})
+                if 'SWIFT_PROJECT_NAME' in os.environ:
+                    os_options.update({'project_name': os.environ['SWIFT_PROJECT_NAME']})
+                if 'SWIFT_TENANTNAME' in os.environ:
+                    os_options.update({'tenant_name': os.environ['SWIFT_TENANTNAME']})
+                if 'SWIFT_ENDPOINT_TYPE' in os.environ:
+                    os_options.update({'endpoint_type': os.environ['SWIFT_ENDPOINT_TYPE']})
+                if 'SWIFT_USERID' in os.environ:
+                    os_options.update({'user_id': os.environ['SWIFT_USERID']})
+                if 'SWIFT_TENANTID' in os.environ:
+                    os_options.update({'tenant_id': os.environ['SWIFT_TENANTID']})
+                if 'SWIFT_REGIONNAME' in os.environ:
+                    os_options.update({'region_name': os.environ['SWIFT_REGIONNAME']})
 
         else:
-            conn_kwargs[u'auth_version'] = u'1'
-        if u'SWIFT_TENANTNAME' in os.environ:
-            conn_kwargs[u'tenant_name'] = os.environ[u'SWIFT_TENANTNAME']
-        if u'SWIFT_REGIONNAME' in os.environ:
-            os_options.update({u'region_name': os.environ[u'SWIFT_REGIONNAME']})
+            conn_kwargs['auth_version'] = '1'
+        if 'SWIFT_TENANTNAME' in os.environ:
+            conn_kwargs['tenant_name'] = os.environ['SWIFT_TENANTNAME']
+        if 'SWIFT_REGIONNAME' in os.environ:
+            os_options.update({'region_name': os.environ['SWIFT_REGIONNAME']})
 
         # formatting options for swiftclient.SwiftService
         for key in os_options.keys():
-            svc_options[u'os_' + key] = os_options[key]
+            svc_options[f"os_{key}"] = os_options[key]
 
-        conn_kwargs[u'os_options'] = os_options
+        conn_kwargs['os_options'] = os_options
 
         # This folds the null prefix and all null parts, which means that:
         #  //MyContainer/ and //MyContainer are equivalent.
         #  //MyContainer//My/Prefix/ and //MyContainer/My/Prefix are equivalent.
-        url_parts = [x for x in parsed_url.path.split(u'/') if x != u'']
+        url_parts = [x for x in parsed_url.path.split('/') if x != '']
 
         self.container = url_parts.pop(0)
         if url_parts:
-            self.prefix = u'%s/' % u'/'.join(url_parts)
+            self.prefix = f"{'/'.join(url_parts)}/"
         else:
-            self.prefix = u''
+            self.prefix = ''
 
         policy = config.swift_storage_policy
-        policy_header = u'X-Storage-Policy'
+        policy_header = 'X-Storage-Policy'
 
         container_metadata = None
         try:
-            log.Debug(u"Starting connection with arguments:'%s'" % conn_kwargs)
+            log.Debug(f"Starting connection with arguments:'{conn_kwargs}'")
             self.conn = Connection(**conn_kwargs)
             container_metadata = self.conn.head_container(self.container)
         except ClientException as e:
-            log.Debug(u"Connection failed: %s %s"
-                      % (e.__class__.__name__, str(e)))
+            log.Debug(f"Connection failed: {e.__class__.__name__} {str(e)}")
             pass
         except Exception as e:
-            log.FatalError(u"Connection failed: %s %s"
-                           % (e.__class__.__name__, str(e)),
+            log.FatalError(f"Connection failed: {e.__class__.__name__} {str(e)}",
                            log.ErrorCode.connection_failed)
 
         if container_metadata is None:
-            log.Info(u"Creating container %s" % self.container)
+            log.Info(f"Creating container {self.container}")
             try:
                 headers = dict([[policy_header, policy]]) if policy else None
                 self.conn.put_container(self.container, headers=headers)
             except Exception as e:
-                log.FatalError(u"Container creation failed: %s %s"
-                               % (e.__class__.__name__, str(e)),
+                log.FatalError(f"Container creation failed: {e.__class__.__name__} {str(e)}",
                                log.ErrorCode.connection_failed)
         elif policy and container_metadata[policy_header.lower()] != policy:
-            log.FatalError(u"Container '%s' exists but its storage policy is '%s' not '%s'."
-                           % (self.container, container_metadata[policy_header.lower()], policy))
+            log.FatalError(f"Container '{self.container}' exists but its storage policy is "
+                           f"'{container_metadata[policy_header.lower()]}' not '{policy}'.")
         else:
-            log.Debug(u"Container already created: %s" % container_metadata)
+            log.Debug(f"Container already created: {container_metadata}")
 
         # checking service connection
         try:
-            log.Debug(u"Starting  Swiftservice: '%s'" % svc_options)
+            log.Debug(f"Starting  Swiftservice: '{svc_options}'")
             self.svc = SwiftService(options=svc_options)
             container_stat = self.svc.stat(self.container)
         except ClientException as e:
-            log.FatalError(u"Connection failed: %s %s"
-                           % (e.__class__.__name__, str(e)),
+            log.FatalError(f"Connection failed: {e.__class__.__name__} {str(e)}",
                            log.ErrorCode.connection_failed)
-        log.Debug(u"Container stats: %s" % container_stat)
+        log.Debug(f"Container stats: {container_stat}")
 
     def _error_code(self, operation, e):  # pylint: disable=unused-argument
         if isinstance(e, self.resp_exc):
             if e.http_status == 404:
                 return log.ErrorCode.backend_not_found
 
     def _put(self, source_path, remote_filename):
-        lp = util.fsdecode(source_path.name)
+        lp = os.fsdecode(source_path.name)
         if config.mp_segment_size > 0:
             from swiftclient.service import SwiftUploadObject
             st = os.stat(lp)
             # only upload using Dynamic Large Object if mpvolsize is triggered
             if st.st_size >= config.mp_segment_size:
-                log.Debug(u"Uploading Dynamic Large Object")
+                log.Debug("Uploading Dynamic Large Object")
                 mp = self.svc.upload(
                     self.container,
                     [SwiftUploadObject(lp,
-                                       object_name=self.prefix + util.fsdecode(remote_filename))],
-                    options={u'segment_size': config.mp_segment_size}
+                                       object_name=self.prefix + os.fsdecode(remote_filename))],
+                    options={'segment_size': config.mp_segment_size}
                 )
-                uploads = [a for a in mp if u'container' not in a[u'action']]
+                uploads = [a for a in mp if 'container' not in a['action']]
                 for upload in uploads:
-                    if not upload[u'success']:
-                        raise BackendException(upload[u'traceback'])
+                    if not upload['success']:
+                        raise BackendException(upload['traceback'])
                 return
-        rp = self.prefix + util.fsdecode(remote_filename)
-        log.Debug(u"Uploading '%s' to '%s' in remote container '%s'" % (lp, rp, self.container))
+        rp = self.prefix + os.fsdecode(remote_filename)
+        log.Debug(f"Uploading '{lp}' to '{rp}' in remote container '{self.container}'")
         self.conn.put_object(container=self.container,
-                             obj=self.prefix + util.fsdecode(remote_filename),
-                             contents=open(lp, u'rb'))
+                             obj=self.prefix + os.fsdecode(remote_filename),
+                             contents=open(lp, 'rb'))
 
     def _get(self, remote_filename, local_path):
         headers, body = self.conn.get_object(self.container,
-                                             self.prefix + util.fsdecode(remote_filename),
+                                             self.prefix + os.fsdecode(remote_filename),
                                              resp_chunk_size=1024)
-        with open(local_path.name, u'wb') as f:
+        with open(local_path.name, 'wb') as f:
             for chunk in body:
                 f.write(chunk)
 
     def _list(self):
         headers, objs = self.conn.get_container(self.container, full_listing=True, path=self.prefix)
         # removes prefix from return values. should check for the prefix ?
-        return [o[u'name'][len(self.prefix):] for o in objs]
+        return [o['name'][len(self.prefix):] for o in objs]
 
     def _delete(self, filename):
         # use swiftservice to correctly delete all segments in case of multipart uploads
-        deleted = [a for a in self.svc.delete(self.container, [self.prefix + util.fsdecode(filename)])]
+        deleted = [a for a in self.svc.delete(self.container, [self.prefix + os.fsdecode(filename)])]
 
     def _query(self, filename):
         # use swiftservice to correctly report filesize in case of multipart uploads
-        sobject = [a for a in self.svc.stat(self.container, [self.prefix + util.fsdecode(filename)])][0]
-        sobj = {u'size': int(sobject[u'headers'][u'content-length'])}
-        log.Debug(u"Objectquery: '%s' has size %s." % (util.fsdecode(filename), sobj[u'size']))
+        sobject = [a for a in self.svc.stat(self.container, [self.prefix + os.fsdecode(filename)])][0]
+        sobj = {'size': int(sobject['headers']['content-length'])}
+        log.Debug(f"Objectquery: '{os.fsdecode(filename)}' has size {sobj['size']}.")
         return sobj
 
 
-duplicity.backend.register_backend(u"swift", SwiftBackend)
+duplicity.backend.register_backend("swift", SwiftBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/rclonebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/rclonebackend.py`

 * *Files 25% similar despite different names*

```diff
@@ -15,101 +15,97 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from future import standard_library
-standard_library.install_aliases()
 
 import os
 import os.path
 
+import duplicity.backend
 from duplicity import log
-from duplicity import util
 from duplicity.errors import BackendException
-import duplicity.backend
 
 
 class RcloneBackend(duplicity.backend.Backend):
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
         self.parsed_url = parsed_url
         self.remote_path = self.parsed_url.path
-        self.rclone_cmd = u"rclone"
+        self.rclone_cmd = "rclone"
 
         try:
-            rc, o, e = self._subprocess_safe_popen(self.rclone_cmd + u" version")
+            rc, o, e = self._subprocess_safe_popen(f"{self.rclone_cmd} version")
         except Exception:
-            log.FatalError(u"rclone not found: please install rclone", log.ErrorCode.backend_error)
+            log.FatalError("rclone not found: please install rclone", log.ErrorCode.backend_error)
 
         verb = log.getverbosity()
         if verb >= log.DEBUG:
-            os.environ[u"RCLONE_LOG_LEVEL"] = u"DEBUG"
+            os.environ["RCLONE_LOG_LEVEL"] = "DEBUG"
         elif verb >= log.INFO:
-            os.environ[u"RCLONE_LOG_LEVEL"] = u"INFO"
+            os.environ["RCLONE_LOG_LEVEL"] = "INFO"
         elif verb >= log.NOTICE:
-            os.environ[u"RCLONE_LOG_LEVEL"] = u"NOTICE"
+            os.environ["RCLONE_LOG_LEVEL"] = "NOTICE"
         elif verb >= log.ERROR:
-            os.environ[u"RCLONE_LOG_LEVEL"] = u"ERROR"
+            os.environ["RCLONE_LOG_LEVEL"] = "ERROR"
 
-        if parsed_url.path.startswith(u"//"):
-            self.remote_path = self.remote_path[2:].replace(u":/", u":", 1)
+        if parsed_url.path.startswith("//"):
+            self.remote_path = self.remote_path[2:].replace(":/", ":", 1)
 
-        self.remote_path = util.fsdecode(self.remote_path)
+        self.remote_path = os.fsdecode(self.remote_path)
 
     def _get(self, remote_filename, local_path):
-        remote_filename = util.fsdecode(remote_filename)
-        local_pathname = util.fsdecode(local_path.name)
-        commandline = u"%s copyto '%s/%s' '%s'" % (
-            self.rclone_cmd, self.remote_path, remote_filename, local_pathname)
+        remote_filename = os.fsdecode(remote_filename)
+        local_pathname = os.fsdecode(local_path.name)
+        commandline = f"{self.rclone_cmd} copyto '{self.remote_path}/{remote_filename}' '{local_pathname}'"
         rc, o, e = self._subprocess_safe_popen(commandline)
         if rc != 0:
             if os.path.isfile(local_pathname):
                 os.remove(local_pathname)
-            raise BackendException(u"rclone returned rc = %d: %s" % (rc, e))
+            raise BackendException(f"rclone returned rc = {int(rc)}: {e}")
 
     def _put(self, source_path, remote_filename):
-        source_pathname = util.fsdecode(source_path.name)
-        remote_filename = util.fsdecode(remote_filename)
-        commandline = u"%s copyto '%s' '%s/%s'" % (
-            self.rclone_cmd, source_pathname, self.remote_path, remote_filename)
+        source_pathname = os.fsdecode(source_path.name)
+        remote_filename = os.fsdecode(remote_filename)
+        commandline = f"{self.rclone_cmd} copyto '{source_pathname}' '{self.remote_path}/{remote_filename}'"
         rc, o, e = self._subprocess_safe_popen(commandline)
         if rc != 0:
-            raise BackendException(u"rclone returned rc = %d: %s" % (rc, e))
+            raise BackendException(f"rclone returned rc = {int(rc)}: {e}")
 
     def _list(self):
         filelist = []
-        commandline = u"%s lsf '%s'" % (
-            self.rclone_cmd, self.remote_path)
+        commandline = f"{self.rclone_cmd} lsf '{self.remote_path}'"
         rc, o, e = self._subprocess_safe_popen(commandline)
         if rc == 3:
             return filelist
         if rc != 0:
-            raise BackendException(u"rclone returned rc = %d: %s" % (rc, e))
+            raise BackendException(f"rclone returned rc = {int(rc)}: {e}")
         if not o:
             return filelist
-        return [util.fsencode(x) for x in o.split(u'\n') if x]
+        return [os.fsencode(x) for x in o.split('\n') if x]
 
     def _delete(self, remote_filename):
-        remote_filename = util.fsdecode(remote_filename)
-        commandline = u"%s deletefile --drive-use-trash=false '%s/%s'" % (
-            self.rclone_cmd, self.remote_path, remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
+        commandline = f"{self.rclone_cmd} deletefile --drive-use-trash=false '{self.remote_path}/{remote_filename}'"
         rc, o, e = self._subprocess_safe_popen(commandline)
         if rc != 0:
-            raise BackendException(u"rclone returned rc = %d: %s" % (rc, e))
+            raise BackendException(f"rclone returned rc = {int(rc)}: {e}")
 
     def _subprocess_safe_popen(self, commandline):
         import shlex
-        from subprocess import Popen, PIPE
+        from subprocess import (
+            Popen,
+            PIPE,
+        )
         args = shlex.split(commandline)
         p = Popen(args, stdout=PIPE, stderr=PIPE, universal_newlines=True)
         stdout, stderr = p.communicate()
-        for l in stderr.split(u'\n'):
+        for l in stderr.split('\n'):
             if len(l) > 1:
                 print(l)
         return p.returncode, stdout, stderr
 
 
-duplicity.backend.register_backend(u"rclone", RcloneBackend)
+duplicity.backend.register_backend("rclone", RcloneBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/b2backend.py` & `duplicity-2.0.0rc0/duplicity/backends/b2backend.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,26 +19,27 @@
 # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE
 # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 # THE SOFTWARE.
 
-from future import standard_library
-standard_library.install_aliases()
-from builtins import object
 
-from urllib.parse import quote_plus  # pylint: disable=import-error
+from urllib.parse import quote_plus
 
+import duplicity.backend
+from duplicity import config
 from duplicity import log
 from duplicity import progress
 from duplicity import util
 from duplicity import config
-from duplicity.errors import BackendException, FatalBackendException
-import duplicity.backend
+from duplicity.errors import (
+    BackendException,
+    FatalBackendException,
+)
 
 
 class B2ProgressListener(object):
     def __enter__(self):
         pass
 
     def set_total_bytes(self, total_byte_count):
@@ -51,167 +52,153 @@
         pass
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         pass
 
 
 class B2Backend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for BackBlaze's B2 storage service
     """
 
     def __init__(self, parsed_url):
-        u"""
+        """
         Authorize to B2 api and set up needed variables
         """
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         global DownloadDestLocalFile, FileVersionInfoFactory
 
         try:  # figure out what version of b2sdk we have
             from b2sdk import __version__ as VERSION  # pylint: disable=import-error
-            v_split = VERSION.split(u'.')
+            v_split = VERSION.split('.')
             self.v_num = [int(x) for x in v_split]
-        except:
+        except Exception as e:
             self.v_num = [0, 0, 0]
 
         try:  # public API v2 is recommended, if available
             from b2sdk.v2 import B2Api  # pylint: disable=import-error
             from b2sdk.v2 import InMemoryAccountInfo  # pylint: disable=import-error
             from b2sdk.v2.exception import NonExistentBucket  # pylint: disable=import-error
         except ImportError:
             try:  # if public API v2 not found, try to use public API v1
                 from b2sdk.v1 import B2Api  # pylint: disable=import-error
                 from b2sdk.v1 import InMemoryAccountInfo  # pylint: disable=import-error
                 from b2sdk.v1 import DownloadDestLocalFile  # pylint: disable=import-error
                 from b2sdk.v1.exception import NonExistentBucket  # pylint: disable=import-error
-
                 if self.v_num < [1, 9, 0]:
                     from b2sdk.v1.file_version import FileVersionInfoFactory
             except ImportError:
                 try:  # try to import the new b2sdk internal API if available (and public API isn't)
                     from b2sdk.api import B2Api  # pylint: disable=import-error
                     from b2sdk.account_info import InMemoryAccountInfo  # pylint: disable=import-error
                     from b2sdk.download_dest import DownloadDestLocalFile  # pylint: disable=import-error
                     from b2sdk.exception import NonExistentBucket  # pylint: disable=import-error
                     from b2sdk.file_version import FileVersionInfoFactory  # pylint: disable=import-error
                 except ImportError as e:
-                    if u'b2sdk' in getattr(e, u'name', u'b2sdk'):
-                        raise
-                    try:  # fall back to import the old b2 client
-                        from b2.api import B2Api
-                        from b2.account_info import InMemoryAccountInfo
-                        from b2.download_dest import DownloadDestLocalFile
-                        from b2.exception import NonExistentBucket
-                        from b2.file_version import FileVersionInfoFactory
-                    except ImportError:
-                        if u'b2' in getattr(e, u'name', u'b2'):
-                            raise
-                        raise BackendException(u'B2 backend requires B2 Python SDK (pip install b2sdk)')
+                    raise BackendException('B2 backend requires B2 Python SDK (pip install b2sdk)')
 
         self.service = B2Api(InMemoryAccountInfo())
-        self.parsed_url.hostname = u'B2'
+        self.parsed_url.hostname = 'B2'
 
         account_id = parsed_url.username
         account_key = self.get_password()
 
         self.url_parts = [
-            x for x in parsed_url.path.replace(u"@", u"/").split(u'/') if x != u''
+            x for x in parsed_url.path.replace("@", "/").split('/') if x != ''
         ]
         if self.url_parts:
             self.username = self.url_parts.pop(0)
             bucket_name = self.url_parts.pop(0)
         else:
-            raise BackendException(u"B2 requires a bucket name")
-        self.path = u"".join([url_part + u"/" for url_part in self.url_parts])
-        self.service.authorize_account(u'production', account_id, account_key)
+            raise BackendException("B2 requires a bucket name")
+        self.path = "".join([f"{url_part}/" for url_part in self.url_parts])
+        self.service.authorize_account('production', account_id, account_key)
 
         try:
-            log.Log(u"B2 Backend (path= %s, bucket= %s, recommended_part_size= %s)" %
-                    (self.path, bucket_name, self.service.account_info.get_recommended_part_size()), log.INFO)
+            log.Log(f"B2 Backend (path= {self.path}, bucket= {bucket_name}, "
+                    f"recommended_part_size= {self.service.account_info.get_recommended_part_size()})", log.INFO)
         except AttributeError:
-            log.Log(u"B2 Backend (path= %s, bucket= %s, minimum_part_size= %s)" %
-                    (self.path, bucket_name, self.service.account_info.get_minimum_part_size()), log.INFO)
+            log.Log(f"B2 Backend (path= {self.path}, bucket= {bucket_name}, "
+                    f"minimum_part_size= {self.service.account_info.get_minimum_part_size()})", log.INFO)
 
         try:
             self.bucket = self.service.get_bucket_by_name(bucket_name)
-            log.Log(u"Bucket found", log.INFO)
+            log.Log("Bucket found", log.INFO)
         except NonExistentBucket:
             try:
-                log.Log(u"Bucket not found, creating one", log.INFO)
-                self.bucket = self.service.create_bucket(bucket_name, u'allPrivate')
-            except:
-                raise FatalBackendException(u"Bucket cannot be created")
+                log.Log("Bucket not found, creating one", log.INFO)
+                self.bucket = self.service.create_bucket(bucket_name, 'allPrivate')
+            except Exception as e:
+                raise FatalBackendException("Bucket cannot be created")
 
     def _get(self, remote_filename, local_path):
-        u"""
+        """
         Download remote_filename to local_path
         """
-        log.Log(u"Get: %s -> %s" % (self.path + util.fsdecode(remote_filename),
-                                    util.fsdecode(local_path.name)),
+        log.Log(f"Get: {self.path + os.fsdecode(remote_filename)} -> {os.fsdecode(local_path.name)}",
                 log.INFO)
         if self.v_num < [1, 11, 0]:
-            self.bucket.download_file_by_name(quote_plus(self.path + util.fsdecode(remote_filename), u'/'),
+            self.bucket.download_file_by_name(quote_plus(self.path + os.fsdecode(remote_filename), '/'),
                                               DownloadDestLocalFile(local_path.name))
         else:
-            df = self.bucket.download_file_by_name(quote_plus(self.path + util.fsdecode(remote_filename), u'/'))
+            df = self.bucket.download_file_by_name(quote_plus(self.path + util.fsdecode(remote_filename), '/'))
             try:
                 # b2sdk >= 1.19.0
                 df.save_to(local_path.uc_name)
-            except:
+            except Exception as e:
                 # b2sdk < 1.19.0
                 df.save_to(local_path.name)
 
     def _put(self, source_path, remote_filename):
-        u"""
+        """
         Copy source_path to remote_filename
         """
-        log.Log(u"Put: %s -> %s" % (util.fsdecode(source_path.name),
-                                    self.path + util.fsdecode(remote_filename)),
+        log.Log(f"Put: {os.fsdecode(source_path.name)} -> {self.path + os.fsdecode(remote_filename)}",
                 log.INFO)
-        self.bucket.upload_local_file(util.fsdecode(source_path.name),
-                                      quote_plus(self.path + util.fsdecode(remote_filename), u'/'),
-                                      content_type=u'application/pgp-encrypted',
+        self.bucket.upload_local_file(os.fsdecode(source_path.name),
+                                      quote_plus(self.path + os.fsdecode(remote_filename), '/'),
+                                      content_type='application/pgp-encrypted',
                                       progress_listener=B2ProgressListener())
 
     def _list(self):
-        u"""
+        """
         List files on remote server
         """
         return [file_version_info.file_name[len(self.path):]
                 for (file_version_info, folder_name) in self.bucket.ls(self.path)]
 
     def _delete(self, filename):
-        u"""
+        """
         Delete filename from remote server
         """
-        full_filename = self.path + util.fsdecode(filename)
-        log.Log(u"Delete: %s" % full_filename, log.INFO)
+        full_filename = self.path + os.fsdecode(filename)
+        log.Log(f"Delete: {full_filename}", log.INFO)
 
         if config.b2_hide_files:
             self.bucket.hide_file(full_filename)
         else:
-            file_version_info = self.file_info(quote_plus(full_filename, u'/'))
+            file_version_info = self.file_info(quote_plus(full_filename, '/'))
             self.bucket.delete_file_version(file_version_info.id_, file_version_info.file_name)
 
     def _query(self, filename):
-        u"""
+        """
         Get size info of filename
         """
-        log.Log(u"Query: %s" % self.path + util.fsdecode(filename), log.INFO)
-        file_version_info = self.file_info(quote_plus(self.path + util.fsdecode(filename), u'/'))
-        return {u'size': int(file_version_info.size)
+        log.Log(f"Query: {self.path}{os.fsdecode(filename)}", log.INFO)
+        file_version_info = self.file_info(quote_plus(self.path + os.fsdecode(filename), '/'))
+        return {'size': int(file_version_info.size)
                 if file_version_info is not None and file_version_info.size is not None else -1}
 
     def file_info(self, filename):
         if self.v_num >= [1, 9, 0]:
             return self.bucket.get_file_info_by_name(filename)
         else:
             response = self.bucket.api.session.list_file_names(self.bucket.id_, filename, 1, self.path)
-            for entry in response[u'files']:
+            for entry in response['files']:
                 file_version_info = FileVersionInfoFactory.from_api_response(entry)
                 if file_version_info.file_name == filename:
                     return file_version_info
-            raise BackendException(u'File not found')
+            raise BackendException('File not found')
 
 
-duplicity.backend.register_backend(u"b2", B2Backend)
+duplicity.backend.register_backend("b2", B2Backend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/tahoebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/hsibackend.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,78 +1,68 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
-# Copyright 2008 Francois Deppierraz
+# Copyright 2002 Ben Escoto <ben@emerose.org>
+# Copyright 2007 Kenneth Loafman <kenneth@loafman.com>
 #
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
 # under the terms of the GNU General Public License as published by the
-# Free Software Foundation; either version 3 of the License, or (at your
+# Free Software Foundation; either version 2 of the License, or (at your
 # option) any later version.
 #
 # Duplicity is distributed in the hope that it will be useful, but
 # WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from duplicity import log
-from duplicity import util
+import os
+
 import duplicity.backend
 
+hsi_command = "hsi"
 
-class TAHOEBackend(duplicity.backend.Backend):
-    u"""
-    Backend for the Tahoe file system
-    """
 
+class HSIBackend(duplicity.backend.Backend):
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
-
-        url = parsed_url.path.strip(u'/').split(u'/')
-
-        self.alias = url[0]
-
-        if len(url) > 1:
-            self.directory = u"/".join(url[1:])
+        self.host_string = parsed_url.hostname
+        self.remote_dir = parsed_url.path
+        if self.remote_dir:
+            self.remote_prefix = f"{self.remote_dir}/"
         else:
-            self.directory = u""
-
-        log.Debug(u"tahoe: %s -> %s:%s" % (url, self.alias, self.directory))
-
-    def get_remote_path(self, filename=None):
-        if filename is None:
-            if self.directory != u"":
-                return u"%s:%s" % (self.alias, self.directory)
-            else:
-                return u"%s:" % self.alias
-
-        if isinstance(filename, b"".__class__):
-            filename = util.fsdecode(filename)
-        if self.directory != u"":
-            return u"%s:%s/%s" % (self.alias, self.directory, filename)
-        else:
-            return u"%s:%s" % (self.alias, filename)
-
-    def run(self, *args):
-        cmd = u" ".join(args)
-        _, output, _ = self.subprocess_popen(cmd)
-        return output
+            self.remote_prefix = ""
 
     def _put(self, source_path, remote_filename):
-        self.run(u"tahoe", u"cp", source_path.uc_name, self.get_remote_path(remote_filename))
+        if isinstance(remote_filename, b"".__class__):
+            remote_filename = os.fsdecode(remote_filename)
+        commandline = f'{hsi_command} "put {source_path.uc_name} : {self.remote_prefix}{remote_filename}"'
+        self.subprocess_popen(commandline)
 
     def _get(self, remote_filename, local_path):
-        self.run(u"tahoe", u"cp", self.get_remote_path(remote_filename), local_path.uc_name)
+        if isinstance(remote_filename, b"".__class__):
+            remote_filename = os.fsdecode(remote_filename)
+        commandline = f'{hsi_command} "get {local_path.uc_name} : {self.remote_prefix}{remote_filename}"'
+        self.subprocess_popen(commandline)
 
     def _list(self):
-        output = self.run(u"tahoe", u"ls", self.get_remote_path())
-        return [util.fsencode(x) for x in output.split(u'\n') if x]
+        commandline = f'{hsi_command} "ls -l {self.remote_dir}"'
+        l = self.subprocess_popen(commandline)[2]
+        l = l.split(os.linesep.encode())[3:]
+        for i in range(0, len(l)):
+            if l[i]:
+                l[i] = l[i].split()[-1]
+        return [os.fsencode(x) for x in l if x]
 
     def _delete(self, filename):
-        self.run(u"tahoe", u"rm", self.get_remote_path(filename))
+        if isinstance(filename, b"".__class__):
+            filename = os.fsdecode(filename)
+        commandline = f'{hsi_command} "rm {self.remote_prefix}{filename}"'
+        self.subprocess_popen(commandline)
 
 
-duplicity.backend.register_backend(u"tahoe", TAHOEBackend)
+duplicity.backend.register_backend("hsi", HSIBackend)
+duplicity.backend.uses_netloc.extend(['hsi'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/gdrivebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/gdrivebackend.py`

 * *Files 16% similar despite different names*

```diff
@@ -13,41 +13,38 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
 
 import os
 import pickle
 
+import duplicity.backend
 from duplicity import log
-from duplicity import util
 from duplicity.errors import BackendException
-import duplicity.backend
 
 
 class GDriveBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using Google Drive API V3"""
+    """Connect to remote store using Google Drive API V3"""
 
     PAGE_SIZE = 100
     MIN_RESUMABLE_UPLOAD = 5 * 1024 * 1024
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
         try:
             from googleapiclient.discovery import build
             from google.oauth2.service_account import Credentials
         except ImportError as e:
-            raise BackendException(u"""\
-GDrive backend requires Google API client installation.
+            raise BackendException(f"""GDrive backend requires Google API client installation.
 Please read the manpage for setup details.
-Exception: %s""" % str(e))
+Exception: {str(e)}""")
 
         # Note Google has 2 drive methods, `Shared(previously Team) Drives` and `My Drive`
         #   both can be shared but require different addressing
         # For a Google Shared Drives folder
         # ---------------------------------
         # Share Drive ID specified as a query parameter in the backend URL.
         # Example:
@@ -70,283 +67,277 @@
         # which will do the web based authentication.
 
         self.shared_drive_corpora = {}
         self.shared_drive_id = {}
         self.shared_drive_flags_include = {}
         self.shared_drive_flags_support = {}
         self.shared_root_folder_id = None
-        if u'driveID' in parsed_url.query_args:
-            self.shared_drive_corpora = {u'corpora': u'drive'}
-            self.shared_drive_id = {u'driveId': parsed_url.query_args[u'driveID'][0]}
-            self.shared_drive_flags_include = {u'includeItemsFromAllDrives': True}
-            self.shared_drive_flags_support = {u'supportsAllDrives': True}
-        elif u'myDriveFolderID' in parsed_url.query_args:
-            self.shared_drive_corpora = {u'corpora': u'user'}
-            self.shared_drive_flags_include = {u'includeItemsFromAllDrives': True}
-            self.shared_drive_flags_support = {u'supportsAllDrives': True}
-            self.shared_root_folder_id = parsed_url.query_args[u'myDriveFolderID'][0]
+        if 'driveID' in parsed_url.query_args:
+            self.shared_drive_corpora = {'corpora': 'drive'}
+            self.shared_drive_id = {'driveId': parsed_url.query_args['driveID'][0]}
+            self.shared_drive_flags_include = {'includeItemsFromAllDrives': True}
+            self.shared_drive_flags_support = {'supportsAllDrives': True}
+        elif 'myDriveFolderID' in parsed_url.query_args:
+            self.shared_drive_corpora = {'corpora': 'user'}
+            self.shared_drive_flags_include = {'includeItemsFromAllDrives': True}
+            self.shared_drive_flags_support = {'supportsAllDrives': True}
+            self.shared_root_folder_id = parsed_url.query_args['myDriveFolderID'][0]
         else:
             raise BackendException(
-                u"gdrive: backend requires a query paramater should either be driveID or myDriveFolderID")
+                "gdrive: backend requires a query paramater should either be driveID or myDriveFolderID")
         if parsed_url.username is not None:
-            client_id = parsed_url.username + u'@' + parsed_url.hostname
+            client_id = f"{parsed_url.username}@{parsed_url.hostname}"
         else:
             client_id = parsed_url.hostname
 
-        if u'GOOGLE_SERVICE_JSON_FILE' in os.environ:
-            credentials = Credentials.from_service_account_file(os.environ[u'GOOGLE_SERVICE_JSON_FILE'])
+        if 'GOOGLE_SERVICE_JSON_FILE' in os.environ:
+            credentials = Credentials.from_service_account_file(os.environ['GOOGLE_SERVICE_JSON_FILE'])
             if credentials.service_account_email != client_id:
                 raise BackendException(
-                    u'Service account email in the JSON file (%s) does not match the URL (%s)' %
-                    (credentials.service_account_email, client_id))
+                    f'Service account email in the JSON file ({credentials.service_account_email}) '
+                    f'does not match the URL ({client_id})')
 
-        elif u'GOOGLE_CLIENT_SECRET_JSON_FILE' in os.environ and u'GOOGLE_CREDENTIALS_FILE' in os.environ:
+        elif 'GOOGLE_CLIENT_SECRET_JSON_FILE' in os.environ and 'GOOGLE_CREDENTIALS_FILE' in os.environ:
             from google_auth_oauthlib.flow import InstalledAppFlow
             from google.auth.transport.requests import Request
 
             credentials = None
-            if os.path.exists(os.environ[u'GOOGLE_CREDENTIALS_FILE']):
-                with open(os.environ[u'GOOGLE_CREDENTIALS_FILE'], u'rb') as token:
+            if os.path.exists(os.environ['GOOGLE_CREDENTIALS_FILE']):
+                with open(os.environ['GOOGLE_CREDENTIALS_FILE'], 'rb') as token:
                     credentials = pickle.load(token)
 
             # If there are no (valid) credentials available, let the user log in.
             if not credentials or not credentials.valid:
                 if credentials and credentials.expired and credentials.refresh_token:
                     credentials.refresh(Request())
                 else:
                     flow = InstalledAppFlow.from_client_secrets_file(
-                        os.environ[u'GOOGLE_CLIENT_SECRET_JSON_FILE'],
-                        [u'https://www.googleapis.com/auth/drive.file'])
+                        os.environ['GOOGLE_CLIENT_SECRET_JSON_FILE'],
+                        ['https://www.googleapis.com/auth/drive.file'])
 
-                    if flow.client_config[u'client_id'] != client_id:
+                    if flow.client_config['client_id'] != client_id:
                         raise BackendException(
-                            u'Client ID in the JSON file (%s) does not match the URL (%s)' %
-                            (flow.client_config[u'client_id'], client_id))
+                            f"Client ID in the JSON file ({flow.client_config['client_id']}) "
+                            f"does not match the URL ({client_id})")
 
                     flow_args = {}
-                    if u'GOOGLE_OAUTH_LOCAL_SERVER_PORT' in os.environ:
-                        flow_args[u'port'] = int(os.environ[u'GOOGLE_OAUTH_LOCAL_SERVER_PORT'])
-                    if u'GOOGLE_OAUTH_LOCAL_SERVER_HOST' in os.environ:
-                        flow_args[u'host'] = os.environ[u'GOOGLE_OAUTH_LOCAL_SERVER_HOST']
+                    if 'GOOGLE_OAUTH_LOCAL_SERVER_PORT' in os.environ:
+                        flow_args['port'] = int(os.environ['GOOGLE_OAUTH_LOCAL_SERVER_PORT'])
+                    if 'GOOGLE_OAUTH_LOCAL_SERVER_HOST' in os.environ:
+                        flow_args['host'] = os.environ['GOOGLE_OAUTH_LOCAL_SERVER_HOST']
                     credentials = flow.run_local_server(**flow_args)
                 # Save the credentials for the next run
-                with open(os.environ[u'GOOGLE_CREDENTIALS_FILE'], u'wb') as token:
+                with open(os.environ['GOOGLE_CREDENTIALS_FILE'], 'wb') as token:
                     pickle.dump(credentials, token)
 
             if credentials.client_id != client_id:
                 raise BackendException(
-                    u'Client ID in the credentials file (%s) does not match the URL (%s)' %
-                    (credentials.client_id, client_id))
+                    f'Client ID in the credentials file ({credentials.client_id}) does not match the URL ({client_id})')
 
         else:
             raise BackendException(
-                u'GOOGLE_SERVICE_JSON_FILE or GOOGLE_CLIENT_SECRET_JSON_FILE environment '
-                u'variable not set. Please read the manpage to fix.')
+                'GOOGLE_SERVICE_JSON_FILE or GOOGLE_CLIENT_SECRET_JSON_FILE environment '
+                'variable not set. Please read the manpage to fix.')
 
-        self.drive = build(u'drive', u'v3', credentials=credentials)
+        self.drive = build('drive', 'v3', credentials=credentials)
 
         if self.shared_drive_id:
-            parent_folder_id = self.shared_drive_id[u'driveId']
+            parent_folder_id = self.shared_drive_id['driveId']
         elif self.shared_root_folder_id:
             parent_folder_id = self.shared_root_folder_id
         else:
-            parent_folder_id = u'root'
+            parent_folder_id = 'root'
 
         # Fetch destination folder entry and create hierarchy if required.
-        folder_names = parsed_url.path.split(u'/')
+        folder_names = parsed_url.path.split('/')
         for folder_name in folder_names:
 
             if not folder_name:
                 continue
-            q = (u"name = '" + folder_name + u"' and '" + parent_folder_id +
-                 u"' in parents and mimeType = 'application/vnd.google-apps.folder' and trashed=false")
+            q = ("name = '" + folder_name + "' and '" + parent_folder_id +
+                 "' in parents and mimeType = 'application/vnd.google-apps.folder' and trashed=false")
             results = self.drive.files().list(q=q,
                                               pageSize=1,
-                                              fields=u"files(name,id),nextPageToken",
+                                              fields="files(name,id),nextPageToken",
                                               **self.shared_drive_corpora,
                                               **self.shared_drive_id,
                                               **self.shared_drive_flags_include,
                                               **self.shared_drive_flags_support).execute()
-            file_list = results.get(u'files', [])
+            file_list = results.get('files', [])
             if len(file_list) == 0:
-                file_metadata = {u'name': folder_name,
-                                 u'mimeType': u"application/vnd.google-apps.folder",
-                                 u'parents': [parent_folder_id]}
+                file_metadata = {'name': folder_name,
+                                 'mimeType': "application/vnd.google-apps.folder",
+                                 'parents': [parent_folder_id]}
                 file_metadata.update(self.shared_drive_id)
                 folder = self.drive.files().create(body=file_metadata,
-                                                   fields=u'id',
+                                                   fields='id',
                                                    **self.shared_drive_flags_support).execute()
             else:
                 folder = file_list[0]
 
-            parent_folder_id = folder[u'id']
+            parent_folder_id = folder['id']
 
         self.folder = parent_folder_id
         self.id_cache = {}
 
     def file_by_name(self, filename):
         from googleapiclient.errors import HttpError
 
-        filename = util.fsdecode(filename)
+        filename = os.fsdecode(filename)
 
         if filename in self.id_cache:
             # It might since have been locally moved, renamed or deleted, so we
             # need to validate the entry.
             file_id = self.id_cache[filename]
             try:
                 drive_file = self.drive.files().get(fileId=file_id,
-                                                    fields=u'id,size,name,parents,trashed',
+                                                    fields='id,size,name,parents,trashed',
                                                     **self.shared_drive_flags_support).execute()
-                if drive_file[u'name'] == filename and not drive_file[u'trashed']:
-                    for parent in drive_file[u'parents']:
+                if drive_file['name'] == filename and not drive_file['trashed']:
+                    for parent in drive_file['parents']:
                         if parent == self.folder:
-                            log.Info(u"GDrive backend: found file '%s' with id %s in ID cache" %
-                                     (filename, file_id))
+                            log.Info(f"GDrive backend: found file '{filename}' with id {file_id} in ID cache")
                             return drive_file
             except HttpError as error:
                 # A 404 occurs if the ID is no longer valid
                 if error.resp.status != 404:
                     raise
             # If we get here, the cache entry is invalid
-            log.Info(u"GDrive backend: invalidating '%s' (previously ID %s) from ID cache" %
-                     (filename, file_id))
+            log.Info(f"GDrive backend: invalidating '{filename}' (previously ID {file_id}) from ID cache")
             del self.id_cache[filename]
 
         # Not found in the cache, so use directory listing. This is less
         # reliable because there is no strong consistency.
-        q = u"name = '%s' and '%s' in parents and trashed = false" % (filename, self.folder)
-        results = self.drive.files().list(q=q, fields=u'files(name,id,size),nextPageToken',
+        q = f"name = '{filename}' and '{self.folder}' in parents and trashed = false"
+        results = self.drive.files().list(q=q, fields='files(name,id,size),nextPageToken',
                                           pageSize=2,
                                           **self.shared_drive_corpora,
                                           **self.shared_drive_id,
                                           **self.shared_drive_flags_include,
                                           **self.shared_drive_flags_support).execute()
-        file_list = results.get(u'files', [])
+        file_list = results.get('files', [])
         if len(file_list) > 1:
-            log.FatalError(u"GDrive backend: multiple files called '%s'." % (filename,))
+            log.FatalError(f"GDrive backend: multiple files called '{filename}'.")
         elif len(file_list) > 0:
-            file_id = file_list[0][u'id']
-            self.id_cache[filename] = file_list[0][u'id']
-            log.Info(u"GDrive backend: found file '%s' with id %s on server, "
-                     u"adding to cache" % (filename, file_id))
+            file_id = file_list[0]['id']
+            self.id_cache[filename] = file_list[0]['id']
+            log.Info(f"GDrive backend: found file '{filename}' with id {file_id} on server, adding to cache")
             return file_list[0]
 
-        log.Info(u"GDrive backend: file '%s' not found in cache or on server" %
-                 (filename,))
+        log.Info(f"GDrive backend: file '{filename}' not found in cache or on server")
         return None
 
     def id_by_name(self, filename):
         drive_file = self.file_by_name(filename)
         if drive_file is None:
-            return u''
+            return ''
         else:
-            return drive_file[u'id']
+            return drive_file['id']
 
     def _put(self, source_path, remote_filename):
         from googleapiclient.http import MediaFileUpload
 
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         drive_file = self.file_by_name(remote_filename)
-        if remote_filename.endswith(u'.gpg'):
-            mime_type = u'application/pgp-encrypted'
+        if remote_filename.endswith('.gpg'):
+            mime_type = 'application/pgp-encrypted'
         else:
-            mime_type = u'text/plain'
+            mime_type = 'text/plain'
 
         file_size = os.path.getsize(source_path.name)
         if file_size >= self.MIN_RESUMABLE_UPLOAD:
             resumable = True
             num_retries = 5
         else:
             resumable = False
             num_retries = 0
 
         media = MediaFileUpload(source_path.name, mimetype=mime_type, resumable=resumable)
         if drive_file is None:
             # No existing file, make a new one
-            file_metadata = {u'name': remote_filename, u'parents': [self.folder]}
+            file_metadata = {'name': remote_filename, 'parents': [self.folder]}
             file_metadata.update(self.shared_drive_id)
-            log.Info(u"GDrive backend: creating new file '%s'" % (remote_filename,))
+            log.Info(f"GDrive backend: creating new file '{remote_filename}'")
             drive_file = self.drive.files().create(
                 body=file_metadata,
                 media_body=media,
                 **self.shared_drive_flags_support).execute(num_retries=num_retries)
         else:
-            log.Info(u"GDrive backend: replacing existing file '%s' with id '%s'" % (
-                remote_filename, drive_file[u'id']))
+            log.Info(f"GDrive backend: replacing existing file '{remote_filename}' with id '{drive_file['id']}'")
             drive_file = self.drive.files().update(
                 media_body=media,
-                fileId=drive_file[u'id'],
+                fileId=drive_file['id'],
                 **self.shared_drive_flags_support).execute(num_retries=num_retries)
 
-        self.id_cache[remote_filename] = drive_file[u'id']
+        self.id_cache[remote_filename] = drive_file['id']
 
     def _get(self, remote_filename, local_path):
         from googleapiclient.http import MediaIoBaseDownload
 
         drive_file = self.file_by_name(remote_filename)
-        request = self.drive.files().get_media(fileId=drive_file[u'id'],
+        request = self.drive.files().get_media(fileId=drive_file['id'],
                                                **self.shared_drive_flags_support)
-        with open(util.fsdecode(local_path.name), u"wb") as fh:
+        with open(os.fsdecode(local_path.name), "wb") as fh:
             done = False
             downloader = MediaIoBaseDownload(fh, request)
             while done is False:
                 status, done = downloader.next_chunk()
 
     def _list(self):
         page_token = None
         drive_files = []
         while True:
             response = self.drive.files().list(
-                q=u"'" + self.folder + u"' in parents and trashed=false",
+                q=f"'{self.folder}' in parents and trashed=false",
                 pageSize=self.PAGE_SIZE,
-                fields=u"files(name,id),nextPageToken",
+                fields="files(name,id),nextPageToken",
                 pageToken=page_token,
                 **self.shared_drive_corpora,
                 **self.shared_drive_id,
                 **self.shared_drive_flags_include,
                 **self.shared_drive_flags_support).execute()
 
-            drive_files += response.get(u'files', [])
+            drive_files += response.get('files', [])
 
-            page_token = response.get(u'nextPageToken', None)
+            page_token = response.get('nextPageToken', None)
             if page_token is None:
                 break
 
-        filenames = set(item[u'name'] for item in drive_files)
+        filenames = set(item['name'] for item in drive_files)
         # Check the cache as well. A file might have just been uploaded but
         # not yet appear in the listing.
         # Note: do not use iterkeys() here, because file_by_name will modify
         # the cache if it finds invalid entries.
         for filename in list(self.id_cache.keys()):
             if (filename not in filenames) and (self.file_by_name(filename) is not None):
                 filenames.add(filename)
         return list(filenames)
 
     def _delete(self, filename):
         file_id = self.id_by_name(filename)
-        if file_id == u'':
-            log.Warn(u"File '%s' does not exist while trying to delete it" % (util.fsdecode(filename),))
+        if file_id == '':
+            log.Warn(f"File '{os.fsdecode(filename)}' does not exist while trying to delete it")
         else:
             self.drive.files().delete(fileId=file_id,
                                       **self.shared_drive_flags_support).execute()
 
     def _query(self, filename):
         drive_file = self.file_by_name(filename)
         if drive_file is None:
             size = -1
         else:
-            size = int(drive_file[u'size'])
-        return {u'size': size}
+            size = int(drive_file['size'])
+        return {'size': size}
 
     def _error_code(self, operation, error):  # pylint: disable=unused-argument
         from google.auth.exceptions import RefreshError
         from googleapiclient.errors import HttpError
         if isinstance(error, HttpError):
             return log.ErrorCode.backend_not_found
         elif isinstance(error, RefreshError):
             return log.ErrorCode.backend_permission_denied
         return log.ErrorCode.backend_error
 
 
-duplicity.backend.register_backend(u'gdrive', GDriveBackend)
+duplicity.backend.register_backend('gdrive', GDriveBackend)
 
-duplicity.backend.uses_netloc.extend([u'gdrive'])
+duplicity.backend.uses_netloc.extend(['gdrive'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/ssh_pexpect_backend.py` & `duplicity-2.0.0rc0/duplicity/backends/ssh_pexpect_backend.py`

 * *Files 14% similar despite different names*

```diff
@@ -20,297 +20,284 @@
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 # The following can be redefined to use different shell commands from
 # ssh or scp or to add more arguments.  However, the replacements must
 # have the same syntax.  Also these strings will be executed by the
 # shell, so shouldn't have strange characters in them.
 
-from __future__ import division
-from future import standard_library
-standard_library.install_aliases()
-from builtins import map
 
 import os
 import re
 
+import duplicity.backend
 from duplicity import config
 from duplicity import log
-from duplicity import util
 from duplicity.errors import BackendException
-import duplicity.backend
 
 
 class SSHPExpectBackend(duplicity.backend.Backend):
-    u"""This backend copies files using scp.  List not supported.  Filenames
+    """This backend copies files using scp.  List not supported.  Filenames
        should not need any quoting or this will break."""
+
     def __init__(self, parsed_url):
-        u"""scpBackend initializer"""
+        """scpBackend initializer"""
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         try:
             global pexpect
             import pexpect
         except ImportError:
             raise
 
-        if pexpect.__version__ < u"4.5.0":
-            log.FatalError(u"""
-                The version of pexpect, '%s`, is too old.  We need version 4.5.0 or above to run.
+        if pexpect.__version__ < "4.5.0":
+            log.FatalError(f"""
+                The version of pexpect, '{pexexpect.__version__}`, is too old.  We need version 4.5.0 or above to run.
                 See https://gitlab.com/duplicity/duplicity/-/issues/125 for the gory details.
 
                 Use "python3 -m pip install pexpect" to install the latest version.
-                """ % pexexpect.__version__)
+                """)
 
         self.retry_delay = 10
 
-        self.scp_command = u"scp"
+        self.scp_command = "scp"
         if config.scp_command:
             self.scp_command = config.scp_command
 
-        self.sftp_command = u"sftp"
+        self.sftp_command = "sftp"
         if config.sftp_command:
             self.sftp_command = config.sftp_command
 
-        self.scheme = duplicity.backend.strip_prefix(parsed_url.scheme, u'pexpect')
-        self.use_scp = (self.scheme == u'scp')
+        self.scheme = duplicity.backend.strip_prefix(parsed_url.scheme, 'pexpect')
+        self.use_scp = (self.scheme == 'scp')
 
         # host string of form [user@]hostname
         if parsed_url.username:
-            self.host_string = parsed_url.username + u"@" + parsed_url.hostname
+            self.host_string = f"{parsed_url.username}@{parsed_url.hostname}"
         else:
             self.host_string = parsed_url.hostname
         # make sure remote_dir is always valid
         if parsed_url.path:
             # remove leading '/'
             self.remote_dir = re.sub(r'^/', r'', parsed_url.path, 1)
         else:
-            self.remote_dir = u'.'
-        self.remote_prefix = self.remote_dir + u'/'
+            self.remote_dir = '.'
+        self.remote_prefix = f"{self.remote_dir}/"
         # maybe use different ssh port
         if parsed_url.port:
-            config.ssh_options = config.ssh_options + u" -oPort=%s" % parsed_url.port
+            config.ssh_options = f"{config.ssh_options} -oPort={parsed_url.port}"
         # set some defaults if user has not specified already.
-        if u"ServerAliveInterval" not in config.ssh_options:
-            config.ssh_options += u" -oServerAliveInterval=%d" % ((int)(config.timeout / 2))
-        if u"ServerAliveCountMax" not in config.ssh_options:
-            config.ssh_options += u" -oServerAliveCountMax=2"
+        if "ServerAliveInterval" not in config.ssh_options:
+            config.ssh_options += f" -oServerAliveInterval={int(int(config.timeout / 2))}"
+        if "ServerAliveCountMax" not in config.ssh_options:
+            config.ssh_options += " -oServerAliveCountMax=2"
 
         # set up password
         self.use_getpass = config.ssh_askpass
         self.password = self.get_password()
 
     def run_scp_command(self, commandline):
-        u""" Run an scp command, responding to password prompts """
-        log.Info(u"Running '%s'" % commandline)
+        """ Run an scp command, responding to password prompts """
+        log.Info(f"Running '{commandline}'")
         child = pexpect.spawn(commandline, timeout=None, use_poll=True)
         if config.ssh_askpass:
-            state = u"authorizing"
+            state = "authorizing"
         else:
-            state = u"copying"
-        while 1:
-            if state == u"authorizing":
+            state = "copying"
+        while True:
+            if state == "authorizing":
                 match = child.expect([pexpect.EOF,
-                                      u"(?i)timeout, server not responding",
-                                      u"(?i)pass(word|phrase .*):",
-                                      u"(?i)permission denied",
-                                      u"authenticity"])
-                log.Debug(u"State = %s, Before = '%s'" % (state, child.before.strip()))
+                                      "(?i)timeout, server not responding",
+                                      "(?i)pass(word|phrase .*):",
+                                      "(?i)permission denied",
+                                      "authenticity"])
+                log.Debug(f"State = {state}, Before = '{child.before.strip()}'")
                 if match == 0:
-                    log.Warn(u"Failed to authenticate")
+                    log.Warn("Failed to authenticate")
                     break
                 elif match == 1:
-                    log.Warn(u"Timeout waiting to authenticate")
+                    log.Warn("Timeout waiting to authenticate")
                     break
                 elif match == 2:
                     child.sendline(self.password)
-                    state = u"copying"
+                    state = "copying"
                 elif match == 3:
-                    log.Warn(u"Invalid SSH password")
+                    log.Warn("Invalid SSH password")
                     break
                 elif match == 4:
-                    log.Warn(u"Remote host authentication failed (missing known_hosts entry?)")
+                    log.Warn("Remote host authentication failed (missing known_hosts entry?)")
                     break
-            elif state == u"copying":
+            elif state == "copying":
                 match = child.expect([pexpect.EOF,
-                                      u"(?i)timeout, server not responding",
-                                      u"stalled",
-                                      u"authenticity",
-                                      u"ETA"])
-                log.Debug(u"State = %s, Before = '%s'" % (state, child.before.strip()))
+                                      "(?i)timeout, server not responding",
+                                      "stalled",
+                                      "authenticity",
+                                      "ETA"])
+                log.Debug(f"State = {state}, Before = '{child.before.strip()}'")
                 if match == 0:
                     break
                 elif match == 1:
-                    log.Warn(u"Timeout waiting for response")
+                    log.Warn("Timeout waiting for response")
                     break
                 elif match == 2:
-                    state = u"stalled"
+                    state = "stalled"
                 elif match == 3:
-                    log.Warn(u"Remote host authentication failed (missing known_hosts entry?)")
+                    log.Warn("Remote host authentication failed (missing known_hosts entry?)")
                     break
-            elif state == u"stalled":
+            elif state == "stalled":
                 match = child.expect([pexpect.EOF,
-                                      u"(?i)timeout, server not responding",
-                                      u"ETA"])
-                log.Debug(u"State = %s, Before = '%s'" % (state, child.before.strip()))
+                                      "(?i)timeout, server not responding",
+                                      "ETA"])
+                log.Debug(f"State = {state}, Before = '{child.before.strip()}'")
                 if match == 0:
                     break
                 elif match == 1:
-                    log.Warn(u"Stalled for too long, aborted copy")
+                    log.Warn("Stalled for too long, aborted copy")
                     break
                 elif match == 2:
-                    state = u"copying"
+                    state = "copying"
         child.close(force=True)
         if child.exitstatus != 0:
-            raise BackendException(u"Error running '%s'" % commandline)
+            raise BackendException(f"Error running '{commandline}'")
 
     def run_sftp_command(self, commandline, commands):
-        u""" Run an sftp command, responding to password prompts, passing commands from list """
+        """ Run an sftp command, responding to password prompts, passing commands from list """
         maxread = 2000  # expected read buffer size
         responses = [pexpect.EOF,
-                     u"(?i)timeout, server not responding",
-                     u"sftp>",
-                     u"(?i)pass(word|phrase .*):",
-                     u"(?i)permission denied",
-                     u"authenticity",
-                     u"(?i)no such file or directory",
-                     u"Couldn't delete file: No such file or directory",
-                     u"Couldn't delete file",
-                     u"open(.*): Failure"]
+                     "(?i)timeout, server not responding",
+                     "sftp>",
+                     "(?i)pass(word|phrase .*):",
+                     "(?i)permission denied",
+                     "authenticity",
+                     "(?i)no such file or directory",
+                     "Couldn't delete file: No such file or directory",
+                     "Couldn't delete file",
+                     "open(.*): Failure"]
         max_response_len = max([len(p) for p in responses[1:]])
-        log.Info(u"Running '%s'" % (commandline))
+        log.Info(f"Running '{commandline}'")
         child = pexpect.spawn(commandline, timeout=None, maxread=maxread, encoding=config.fsencoding, use_poll=True)
         cmdloc = 0
         passprompt = 0
-        while 1:
-            msg = u""
+        while True:
+            msg = ""
             match = child.expect(responses,
                                  searchwindowsize=maxread + max_response_len)
-            log.Debug(u"State = sftp, Before = '%s'" % (child.before.strip()))
+            log.Debug(f"State = sftp, Before = '{child.before.strip()}'")
             if match == 0:
                 break
             elif match == 1:
-                msg = u"Timeout waiting for response"
+                msg = "Timeout waiting for response"
                 break
             if match == 2:
                 if cmdloc < len(commands):
                     command = commands[cmdloc]
-                    log.Info(u"sftp command: '%s'" % (command,))
+                    log.Info(f"sftp command: '{command}'")
                     child.sendline(command)
                     cmdloc += 1
                 else:
-                    command = u'quit'
+                    command = 'quit'
                     child.sendline(command)
                     res = child.before
             elif match == 3:
                 passprompt += 1
                 child.sendline(self.password)
-                if (passprompt > 1):
-                    raise BackendException(u"Invalid SSH password.")
+                if passprompt > 1:
+                    raise BackendException("Invalid SSH password.")
             elif match == 4:
-                if not child.before.strip().startswith(u"mkdir"):
-                    msg = u"Permission denied"
+                if not child.before.strip().startswith("mkdir"):
+                    msg = "Permission denied"
                     break
             elif match == 5:
-                msg = u"Host key authenticity could not be verified (missing known_hosts entry?)"
+                msg = "Host key authenticity could not be verified (missing known_hosts entry?)"
                 break
             elif match == 6:
-                if not child.before.strip().startswith(u"rm"):
-                    msg = u"Remote file or directory does not exist in command='%s'" % (commandline,)
+                if not child.before.strip().startswith("rm"):
+                    msg = f"Remote file or directory does not exist in command='{commandline}'"
                     break
             elif match == 7:
-                if not child.before.strip().startswith(u"Removing"):
-                    msg = u"Could not delete file in command='%s'" % (commandline,)
+                if not child.before.strip().startswith("Removing"):
+                    msg = f"Could not delete file in command='{commandline}'"
                     break
             elif match == 8:
-                msg = u"Could not delete file in command='%s'" % (commandline,)
+                msg = f"Could not delete file in command='{commandline}'"
                 break
             elif match == 9:
-                msg = u"Could not open file in command='%s'" % (commandline,)
+                msg = f"Could not open file in command='{commandline}'"
                 break
         child.close(force=True)
         if child.exitstatus == 0:
             return res
         else:
-            raise BackendException(u"Error running '%s': %s" % (commandline, msg))
+            raise BackendException(f"Error running '{commandline}': {msg}")
 
     def _put(self, source_path, remote_filename):
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         if self.use_scp:
             self.put_scp(source_path, remote_filename)
         else:
             self.put_sftp(source_path, remote_filename)
 
     def put_sftp(self, source_path, remote_filename):
-        commands = [u"put \"%s\" \"%s.%s.part\"" %
-                    (source_path.uc_name, self.remote_prefix, remote_filename),
-                    u"rename \"%s.%s.part\" \"%s%s\"" %
-                    (self.remote_prefix, remote_filename, self.remote_prefix, remote_filename)]
-        commandline = (u"%s %s %s" % (self.sftp_command,
-                                      config.ssh_options,
-                                      self.host_string))
+        commands = [f"put \"{source_path.uc_name}\" \"{self.remote_prefix}.{remote_filename}.part\"",
+                    f"rename \"{self.remote_prefix}.{remote_filename}.part\" \"{self.remote_prefix}{remote_filename}\""]
+        commandline = f"{self.sftp_command} {config.ssh_options} {self.host_string}"
         self.run_sftp_command(commandline, commands)
 
     def put_scp(self, source_path, remote_filename):
-        commandline = u"%s %s %s %s:%s%s" % \
-            (self.scp_command, config.ssh_options, source_path.uc_name, self.host_string,
-             self.remote_prefix, remote_filename)
+        commandline = f"{self.scp_command} {config.ssh_options} {source_path.uc_name} " \
+                      f"{self.host_string}:{self.remote_prefix}{remote_filename}"
         self.run_scp_command(commandline)
 
     def _get(self, remote_filename, local_path):
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         if self.use_scp:
             self.get_scp(remote_filename, local_path)
         else:
             self.get_sftp(remote_filename, local_path)
 
     def get_sftp(self, remote_filename, local_path):
-        commands = [u"get \"%s%s\" \"%s\"" %
-                    (self.remote_prefix, remote_filename, local_path.uc_name)]
-        commandline = (u"%s %s %s" % (self.sftp_command,
-                                      config.ssh_options,
-                                      self.host_string))
+        commands = [f"get \"{self.remote_prefix}{remote_filename}\" \"{local_path.uc_name}\""]
+        commandline = f"{self.sftp_command} {config.ssh_options} {self.host_string}"
         self.run_sftp_command(commandline, commands)
 
     def get_scp(self, remote_filename, local_path):
-        commandline = u"%s %s %s:%s%s %s" % \
-            (self.scp_command, config.ssh_options, self.host_string, self.remote_prefix,
-             remote_filename, local_path.uc_name)
+        commandline = f"{self.scp_command} " \
+                      f"{config.ssh_options} " \
+                      f"{self.host_string}:{self.remote_prefix}{remote_filename} " \
+                      f"{local_path.uc_name}"
         self.run_scp_command(commandline)
 
     def _list(self):
         # Note that this command can get confused when dealing with
         # files with newlines in them, as the embedded newlines cannot
         # be distinguished from the file boundaries.
         dirs = self.remote_dir.split(os.sep)
         if len(dirs) > 0:
-            if dirs[0] == u'':
-                dirs[0] = u'/'
+            if dirs[0] == '':
+                dirs[0] = '/'
         mkdir_commands = []
         for d in dirs:
-            mkdir_commands += [u"mkdir \"%s\"" % (d)] + [u"cd \"%s\"" % (d)]
+            mkdir_commands += [f"mkdir \"{d}\""] + [f"cd \"{d}\""]
 
-        commands = mkdir_commands + [u"ls -1"]
-        commandline = (u"%s %s %s" % (self.sftp_command,
-                                      config.ssh_options,
-                                      self.host_string))
+        commands = mkdir_commands + ["ls -1"]
+        commandline = f"{self.sftp_command} {config.ssh_options} {self.host_string}"
 
-        l = self.run_sftp_command(commandline, commands).split(u'\n')[1:]
+        l = self.run_sftp_command(commandline, commands).split('\n')[1:]
 
-        return [x for x in map(u"".__class__.strip, l) if x]
+        return [x for x in map(string.strip, l) if x]
 
     def _delete(self, filename):
-        commands = [u"cd \"%s\"" % (self.remote_dir,)]
-        commands.append(u"rm \"%s\"" % util.fsdecode(filename))
-        commandline = (u"%s %s %s" % (self.sftp_command, config.ssh_options, self.host_string))
+        commands = [f"cd \"{self.remote_dir}\""]
+        commands.append(f"rm \"{os.fsdecode(filename)}\"")
+        commandline = f"{self.sftp_command} {config.ssh_options} {self.host_string}"
         self.run_sftp_command(commandline, commands)
 
     def _delete_list(self, filename_list):
-        commands = [u"cd \"%s\"" % (self.remote_dir,)]
+        commands = [f"cd \"{self.remote_dir}\""]
         for filename in filename_list:
-            commands.append(u"rm \"%s\"" % util.fsdecode(filename))
-        commandline = (u"%s %s %s" % (self.sftp_command, config.ssh_options, self.host_string))
+            commands.append(f"rm \"{os.fsdecode(filename)}\"")
+        commandline = f"{self.sftp_command} {config.ssh_options} {self.host_string}"
         self.run_sftp_command(commandline, commands)
 
 
-duplicity.backend.register_backend(u"pexpect+sftp", SSHPExpectBackend)
-duplicity.backend.register_backend(u"pexpect+scp", SSHPExpectBackend)
-duplicity.backend.uses_netloc.extend([u'pexpect+sftp', u'pexpect+scp'])
+duplicity.backend.register_backend("pexpect+sftp", SSHPExpectBackend)
+duplicity.backend.register_backend("pexpect+scp", SSHPExpectBackend)
+duplicity.backend.uses_netloc.extend(['pexpect+sftp', 'pexpect+scp'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/gdocsbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/gdocsbackend.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,78 +14,74 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import input
-from builtins import str
+
 import os.path
 import string
-import urllib.request  # pylint: disable=import-error
-import urllib.parse  # pylint: disable=import-error
-import urllib.error  # pylint: disable=import-error
+import urllib.error
+import urllib.parse
+import urllib.request
 
 import duplicity.backend
 from duplicity import __version__
 from duplicity.errors import BackendException
 
 
 class GDocsBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using Google Google Documents List API"""
+    """Connect to remote store using Google Google Documents List API"""
 
-    ROOT_FOLDER_ID = u'folder%3Aroot'
-    BACKUP_DOCUMENT_TYPE = u'application/binary'
+    ROOT_FOLDER_ID = 'folder%3Aroot'
+    BACKUP_DOCUMENT_TYPE = 'application/binary'
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # Import Google Data APIs libraries.
         try:
             global atom
             global gdata
             import atom.data
             import gdata.client
             import gdata.docs.client
             import gdata.docs.data
         except ImportError as e:
-            raise BackendException(u"""\
-Google Docs backend requires Google Data APIs Python Client Library (see http://code.google.com/p/gdata-python-client/).
-Exception: %s""" % str(e))
+            raise BackendException(f"Google Docs backend requires Google Data APIs Python Client Library\n"
+                                   f"(see http://code.google.com/p/gdata-python-client/).\n"
+                                   f"Exception: {str(e)}")
 
         # Setup client instance.
-        self.client = gdata.docs.client.DocsClient(source=u'duplicity %s' % __version__)
+        self.client = gdata.docs.client.DocsClient(source=f'duplicity {__version__}')
         self.client.ssl = True
         self.client.http_client.debug = False
-        self._authorize(parsed_url.username + u'@' + parsed_url.hostname, self.get_password())
+        self._authorize(f"{parsed_url.username}@{parsed_url.hostname}", self.get_password())
 
         # Fetch destination folder entry (and crete hierarchy if required).
-        folder_names = string.split(parsed_url.path[1:], u'/')
+        folder_names = string.split(parsed_url.path[1:], '/')
         parent_folder = None
         parent_folder_id = GDocsBackend.ROOT_FOLDER_ID
         for folder_name in folder_names:
-            entries = self._fetch_entries(parent_folder_id, u'folder', folder_name)
+            entries = self._fetch_entries(parent_folder_id, 'folder', folder_name)
             if entries is not None:
                 if len(entries) == 1:
                     parent_folder = entries[0]
                 elif len(entries) == 0:
-                    folder = gdata.docs.data.Resource(type=u'folder', title=folder_name)
+                    folder = gdata.docs.data.Resource(type='folder', title=folder_name)
                     parent_folder = self.client.create_resource(folder, collection=parent_folder)
                 else:
                     parent_folder = None
                 if parent_folder:
                     parent_folder_id = parent_folder.resource_id.text
                 else:
-                    raise BackendException(u"Error while creating destination folder '%s'." % folder_name)
+                    raise BackendException(f"Error while creating destination folder '{folder_name}'.")
             else:
-                raise BackendException(u"Error while fetching destination folder '%s'." % folder_name)
+                raise BackendException(f"Error while fetching destination folder '{folder_name}'.")
         self.folder = parent_folder
 
     def _put(self, source_path, remote_filename):
         self._delete(remote_filename)
 
         # Set uploader instance. Note that resumable uploads are required in order to
         # enable uploads for all file types.
@@ -96,93 +92,93 @@
             GDocsBackend.BACKUP_DOCUMENT_TYPE,
             os.path.getsize(file.name),
             chunk_size=gdata.client.ResumableUploader.DEFAULT_CHUNK_SIZE,
             desired_class=gdata.docs.data.Resource)
         if uploader:
             # Chunked upload.
             entry = gdata.docs.data.Resource(title=atom.data.Title(text=remote_filename))
-            uri = self.folder.get_resumable_create_media_link().href + u'?convert=false'
+            uri = f"{self.folder.get_resumable_create_media_link().href}?convert=false"
             entry = uploader.UploadFile(uri, entry=entry)
             if not entry:
-                raise BackendException(u"Failed to upload file '%s' to remote folder '%s'"
-                                       % (source_path.get_filename(), self.folder.title.text))
+                raise BackendException(f"Failed to upload file '{source_path.get_filename()}' "
+                                       f"to remote folder '{self.folder.title.text}'")
         else:
-            raise BackendException(u"Failed to initialize upload of file '%s' to remote folder '%s'"
-                                   % (source_path.get_filename(), self.folder.title.text))
+            raise BackendException(f"Failed to initialize upload of file '{source_path.get_filename()}' "
+                                   f"to remote folder '{self.folder.title.text}'")
         assert not file.close()
 
     def _get(self, remote_filename, local_path):
         entries = self._fetch_entries(self.folder.resource_id.text,
                                       GDocsBackend.BACKUP_DOCUMENT_TYPE,
                                       remote_filename)
         if len(entries) == 1:
             entry = entries[0]
             self.client.DownloadResource(entry, local_path.name)
         else:
-            raise BackendException(u"Failed to find file '%s' in remote folder '%s'"
-                                   % (remote_filename, self.folder.title.text))
+            raise BackendException(f"Failed to find file '{remote_filename}' "
+                                   f"in remote folder '{self.folder.title.text}'")
 
     def _list(self):
         entries = self._fetch_entries(self.folder.resource_id.text,
                                       GDocsBackend.BACKUP_DOCUMENT_TYPE)
         return [entry.title.text for entry in entries]
 
     def _delete(self, filename):
         entries = self._fetch_entries(self.folder.resource_id.text,
                                       GDocsBackend.BACKUP_DOCUMENT_TYPE,
                                       filename)
         for entry in entries:
-            self.client.delete(entry.get_edit_link().href + u'?delete=true', force=True)
+            self.client.delete(f"{entry.get_edit_link().href}?delete=true", force=True)
 
     def _authorize(self, email, password, captcha_token=None, captcha_response=None):
         try:
             self.client.client_login(email,
                                      password,
-                                     source=u'duplicity %s' % __version__,
-                                     service=u'writely',
+                                     source=f'duplicity {__version__}',
+                                     service='writely',
                                      captcha_token=captcha_token,
                                      captcha_response=captcha_response)
         except gdata.client.CaptchaChallenge as challenge:
-            print(u'A captcha challenge in required. Please visit ' + challenge.captcha_url)
+            print(f"A captcha challenge in required. Please visit {challenge.captcha_url}")
             answer = None
             while not answer:
-                answer = eval(input(u'Answer to the challenge? '))
+                answer = eval(input('Answer to the challenge? '))
             self._authorize(email, password, challenge.captcha_token, answer)
         except gdata.client.BadAuthentication:
             raise BackendException(
-                u'Invalid user credentials given. Be aware that accounts '
-                u'that use 2-step verification require creating an application specific '
-                u'access code for using this Duplicity backend. Follow the instruction in '
-                u'http://www.google.com/support/accounts/bin/static.py?page=guide.cs&guide=1056283&topic=1056286 '
-                u'and create your application-specific password to run duplicity backups.')
+                'Invalid user credentials given. Be aware that accounts '
+                'that use 2-step verification require creating an application specific '
+                'access code for using this Duplicity backend. Follow the instruction in '
+                'http://www.google.com/support/accounts/bin/static.py?page=guide.cs&guide=1056283&topic=1056286 '
+                'and create your application-specific password to run duplicity backups.')
 
     def _fetch_entries(self, folder_id, type, title=None):  # pylint: disable=redefined-builtin
         # Build URI.
-        uri = u'/feeds/default/private/full/%s/contents' % folder_id
-        if type == u'folder':
-            uri += u'/-/folder?showfolders=true'
+        uri = f'/feeds/default/private/full/{folder_id}/contents'
+        if type == 'folder':
+            uri += '/-/folder?showfolders=true'
         elif type == GDocsBackend.BACKUP_DOCUMENT_TYPE:
-            uri += u'?showfolders=false'
+            uri += '?showfolders=false'
         else:
-            uri += u'?showfolders=true'
+            uri += '?showfolders=true'
         if title:
-            uri += u'&title=' + urllib.parse.quote(title) + u'&title-exact=true'
+            uri += f"&title={urllib.parse.quote(title)}&title-exact=true"
 
         # Fetch entries.
         entries = self.client.get_all_resources(uri=uri)
 
         # When filtering by entry title, API is returning (don't know why) documents in other
         # folders (apart from folder_id) matching the title, so some extra filtering is required.
         if title:
             result = []
             for entry in entries:
                 resource_type = entry.get_resource_type()
                 if (not type) \
-                   or (type == u'folder' and resource_type == u'folder') \
-                   or (type == GDocsBackend.BACKUP_DOCUMENT_TYPE and resource_type != u'folder'):
+                        or (type == 'folder' and resource_type == 'folder') \
+                        or (type == GDocsBackend.BACKUP_DOCUMENT_TYPE and resource_type != 'folder'):
 
                     if folder_id != GDocsBackend.ROOT_FOLDER_ID:
                         for link in entry.in_collections():
                             folder_entry = self.client.get_entry(link.href, None, None,
                                                                  desired_class=gdata.docs.data.Resource)
                             if folder_entry and (folder_entry.resource_id.text == folder_id):
                                 result.append(entry)
@@ -191,10 +187,10 @@
         else:
             result = entries
 
         # Done!
         return result
 
 
-u""" gdata is an alternate way to access gdocs, currently 05/2015 lacking OAuth support """
-duplicity.backend.register_backend(u'gdata+gdocs', GDocsBackend)
-duplicity.backend.uses_netloc.extend([u'gdata+gdocs'])
+""" gdata is an alternate way to access gdocs, currently 05/2015 lacking OAuth support """
+duplicity.backend.register_backend('gdata+gdocs', GDocsBackend)
+duplicity.backend.uses_netloc.extend(['gdata+gdocs'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/giobackend.py` & `duplicity-2.0.0rc0/duplicity/backends/giobackend.py`

 * *Files 4% similar despite different names*

```diff
@@ -14,58 +14,60 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-import os
-import subprocess
 import atexit
+import os
 import signal
+import subprocess
 
 import duplicity.backend
 from duplicity import log
 from duplicity import util
 
 
 def ensure_dbus():
     # GIO requires a dbus session bus which can start the gvfs daemons
     # when required.  So we make sure that such a bus exists and that our
     # environment points to it.
-    if u'DBUS_SESSION_BUS_ADDRESS' not in os.environ:
-        p = subprocess.Popen([u'dbus-launch'], stdout=subprocess.PIPE, universal_newlines=True)
+    if 'DBUS_SESSION_BUS_ADDRESS' not in os.environ:
+        p = subprocess.Popen(['dbus-launch'], stdout=subprocess.PIPE, universal_newlines=True)
         output = p.communicate()[0]
-        lines = output.split(u'\n')
+        lines = output.split('\n')
         for line in lines:
-            parts = line.split(u'=', 1)
+            parts = line.split('=', 1)
             if len(parts) == 2:
-                if parts[0] == u'DBUS_SESSION_BUS_PID':  # cleanup at end
+                if parts[0] == 'DBUS_SESSION_BUS_PID':  # cleanup at end
                     atexit.register(os.kill, int(parts[1]), signal.SIGTERM)
                 os.environ[parts[0]] = parts[1]
 
 
 class GIOBackend(duplicity.backend.Backend):
-    u"""Use this backend when saving to a GIO URL.
+    """Use this backend when saving to a GIO URL.
        This is a bit of a meta-backend, in that it can handle multiple schemas.
        URLs look like schema://user@server/path.
     """
+
     def __init__(self, parsed_url):
-        from gi.repository import Gio   # pylint: disable=import-error
-        from gi.repository import GLib   # pylint: disable=import-error
+        from gi.repository import Gio  # pylint: disable=import-error
+        from gi.repository import GLib  # pylint: disable=import-error
 
         class DupMountOperation(Gio.MountOperation):
-            u"""A simple MountOperation that grabs the password from the environment
+            """A simple MountOperation that grabs the password from the environment
                or the user.
             """
+
             def __init__(self, backend):
                 Gio.MountOperation.__init__(self)
                 self.backend = backend
-                self.connect(u'ask-password', self.ask_password_cb)
-                self.connect(u'ask-question', self.ask_question_cb)
+                self.connect('ask-password', self.ask_password_cb)
+                self.connect('ask-question', self.ask_question_cb)
 
             def ask_password_cb(self, *args, **kwargs):
                 self.set_password(self.backend.get_password())
                 self.reply(Gio.MountOperationResult.HANDLED)
 
             def ask_question_cb(self, *args, **kwargs):
                 # Obviously just always answering with the first choice is a naive
@@ -88,73 +90,70 @@
         loop = GLib.MainLoop()
         self.remote_file.mount_enclosing_volume(Gio.MountMountFlags.NONE,
                                                 op, None,
                                                 self.__done_with_mount, loop)
         loop.run()  # halt program until we're done mounting
 
         # Now make the directory if it doesn't exist
-        try:
+        if not self.remote_file.query_exists():
             self.remote_file.make_directory_with_parents(None)
-        except GLib.GError as e:
-            if e.code != Gio.IOErrorEnum.EXISTS:
-                raise
 
     def __done_with_mount(self, fileobj, result, loop):
-        from gi.repository import Gio   # pylint: disable=import-error
-        from gi.repository import GLib   # pylint: disable=import-error
+        from gi.repository import Gio  # pylint: disable=import-error
+        from gi.repository import GLib  # pylint: disable=import-error
         try:
             fileobj.mount_enclosing_volume_finish(result)
         except GLib.GError as e:
             # check for NOT_SUPPORTED because some schemas (e.g. file://) validly don't
             if e.code != Gio.IOErrorEnum.ALREADY_MOUNTED and e.code != Gio.IOErrorEnum.NOT_SUPPORTED:
-                log.FatalError(_(u"Connection failed, please check your password: %s")
+                log.FatalError(_("Connection failed, please check your password: %s")
                                % util.uexc(e), log.ErrorCode.connection_failed)
         loop.quit()
 
     def __copy_progress(self, *args, **kwargs):
         pass
 
     def __copy_file(self, source, target):
-        from gi.repository import Gio   # pylint: disable=import-error
+        from gi.repository import Gio  # pylint: disable=import-error
         # Don't pass NOFOLLOW_SYMLINKS here. Some backends (e.g. google-drive:)
         # use symlinks internally for all files. In the normal course of
         # events, we never deal with symlinks anyway, just tarballs.
         source.copy(target,
                     Gio.FileCopyFlags.OVERWRITE,
                     None, self.__copy_progress, None)
 
     def _error_code(self, operation, e):
-        from gi.repository import Gio   # pylint: disable=import-error
-        from gi.repository import GLib   # pylint: disable=import-error
+        from gi.repository import Gio  # pylint: disable=import-error
+        from gi.repository import GLib  # pylint: disable=import-error
         if isinstance(e, GLib.GError):
-            if e.code == Gio.IOErrorEnum.FAILED and operation == u'delete':
+            if e.code == Gio.IOErrorEnum.FAILED and operation == 'delete':
                 # Sometimes delete will return a generic failure on a file not
                 # found (notably the FTP does that)
                 return log.ErrorCode.backend_not_found
             elif e.code == Gio.IOErrorEnum.PERMISSION_DENIED:
                 return log.ErrorCode.backend_permission_denied
             elif e.code == Gio.IOErrorEnum.NOT_FOUND:
                 return log.ErrorCode.backend_not_found
             elif e.code == Gio.IOErrorEnum.NO_SPACE:
                 return log.ErrorCode.backend_no_space
 
     def _put(self, source_path, remote_filename):
-        from gi.repository import Gio   # pylint: disable=import-error
+        from gi.repository import Gio  # pylint: disable=import-error
         source_file = Gio.File.new_for_path(source_path.name)
-        target_file = self.remote_file.get_child_for_display_name(util.fsdecode(remote_filename))
+        target_file = self.remote_file.get_child_for_display_name(os.fsdecode(remote_filename))
         self.__copy_file(source_file, target_file)
 
     def _get(self, filename, local_path):
-        from gi.repository import Gio   # pylint: disable=import-error
-        source_file = self.remote_file.get_child_for_display_name(util.fsdecode(filename))
+        from gi.repository import Gio  # pylint: disable=import-error
+        source_file = self.remote_file.get_child_for_display_name(os.fsdecode(filename))
         target_file = Gio.File.new_for_path(local_path.name)
         self.__copy_file(source_file, target_file)
 
     def _list(self):
-        from gi.repository import Gio   # pylint: disable=import-error
+        from gi.repository import Gio  # pylint: disable=import-error
         files = []
         # We grab display name, rather than file name because some backends
         # (e.g. google-drive:) use filesystem-specific IDs as file names and
         # only expose the "normal" name as display names. We need the display
         # name, because we try to parse them.
         enum = self.remote_file.enumerate_children(Gio.FILE_ATTRIBUTE_STANDARD_DISPLAY_NAME,
                                                    Gio.FileQueryInfoFlags.NONE,
@@ -162,19 +161,19 @@
         info = enum.next_file(None)
         while info:
             files.append(info.get_display_name())
             info = enum.next_file(None)
         return files
 
     def _delete(self, filename):
-        target_file = self.remote_file.get_child_for_display_name(util.fsdecode(filename))
+        target_file = self.remote_file.get_child_for_display_name(os.fsdecode(filename))
         target_file.delete(None)
 
     def _query(self, filename):
-        from gi.repository import Gio   # pylint: disable=import-error
-        target_file = self.remote_file.get_child_for_display_name(util.fsdecode(filename))
+        from gi.repository import Gio  # pylint: disable=import-error
+        target_file = self.remote_file.get_child_for_display_name(os.fsdecode(filename))
         info = target_file.query_info(Gio.FILE_ATTRIBUTE_STANDARD_SIZE,
                                       Gio.FileQueryInfoFlags.NONE, None)
-        return {u'size': info.get_size()}
+        return {'size': info.get_size()}
 
 
-duplicity.backend.register_backend_prefix(u'gio', GIOBackend)
+duplicity.backend.register_backend_prefix('gio', GIOBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/megabackend.py` & `duplicity-2.0.0rc0/duplicity/backends/megabackend.py`

 * *Files 18% similar despite different names*

```diff
@@ -15,180 +15,175 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-
-from duplicity import util
-from duplicity.errors import BackendException
-import duplicity.backend
 
 import os
 import subprocess
 
+import duplicity.backend
+from duplicity.errors import BackendException
+
 
 class MegaBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using Mega.co.nz API"""
+    """Connect to remote store using Mega.co.nz API"""
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # ensure all the necessary megatools binaries exist
-        self._check_binary_exists(u'megals')
-        self._check_binary_exists(u'megamkdir')
-        self._check_binary_exists(u'megaget')
-        self._check_binary_exists(u'megaput')
-        self._check_binary_exists(u'megarm')
+        self._check_binary_exists('megals')
+        self._check_binary_exists('megamkdir')
+        self._check_binary_exists('megaget')
+        self._check_binary_exists('megaput')
+        self._check_binary_exists('megarm')
 
         # store some basic info
         self._hostname = parsed_url.hostname
 
         if parsed_url.password is None:
-            self._megarc = os.getenv(u'HOME') + u'/.megarc'
+            self._megarc = f"{os.getenv('HOME')}/.megarc"
         else:
             self._megarc = False
             self._username = parsed_url.username
             self._password = self.get_password()
 
         # remote folder (Can we assume /Root prefix?)
-        self._root = u'/Root'
-        self._folder = self._root + u'/' + parsed_url.path[1:]
+        self._root = '/Root'
+        self._folder = f"{self._root}/{parsed_url.path[1:]}"
 
         # make sure the remote folder exists (the whole path)
-        self._makedir_recursive(parsed_url.path[1:].split(u'/'))
+        self._makedir_recursive(parsed_url.path[1:].split('/'))
 
     def _check_binary_exists(self, cmd):
-        u'checks that a specified command exists in the current path'
+        """checks that a specified command exists in the current path"""
 
         try:
             # ignore the output, we only need the return code
-            subprocess.check_output([u'which', cmd])
+            subprocess.check_output(['which', cmd])
         except Exception as e:
-            raise BackendException(u"command '%s' not found, make sure megatools are installed" % (cmd,))
+            raise BackendException(f"command '{cmd}' not found, make sure megatools are installed")
 
     def _makedir(self, path):
-        u'creates a remote directory'
+        """creates a remote directory"""
 
         if self._megarc:
-            cmd = [u'megamkdir', u'--config', self._megarc, path]
+            cmd = ['megamkdir', '--config', self._megarc, path]
         else:
-            cmd = [u'megamkdir', u'-u', self._username, u'-p', self._password, path]
+            cmd = ['megamkdir', '-', self._username, '-p', self._password, path]
 
         self.subprocess_popen(cmd)
 
     def _makedir_recursive(self, path):
-        u'creates a remote directory (recursively the whole path), ingores errors'
+        """creates a remote directory (recursively the whole path), ingores errors"""
 
-        print(u"mkdir: %s" % (u'/'.join(path),))
+        print(f"mkdir: {'/'.join(path)}")
 
         p = self._root
 
         for folder in path:
-            p = p + u'/' + folder
+            p = f"{p}/{folder}"
             try:
                 self._makedir(p)
-            except:
+            except Exception as e:
                 pass
 
     def _put(self, source_path, remote_filename):
-        u'uploads file to Mega (deletes it first, to ensure it does not exist)'
+        """uploads file to Mega (deletes it first, to ensure it does not exist)"""
 
         try:
-            self.delete(util.fsdecode(remote_filename))
+            self.delete(os.fsdecode(remote_filename))
         except Exception:
             pass
 
-        self.upload(local_file=util.fsdecode(source_path.get_canonical()),
-                    remote_file=util.fsdecode(remote_filename))
+        self.upload(local_file=os.fsdecode(source_path.get_canonical()),
+                    remote_file=os.fsdecode(remote_filename))
 
     def _get(self, remote_filename, local_path):
-        u'downloads file from Mega'
+        """downloads file from Mega"""
 
-        self.download(remote_file=util.fsdecode(remote_filename),
-                      local_file=util.fsdecode(local_path.name))
+        self.download(remote_file=os.fsdecode(remote_filename),
+                      local_file=os.fsdecode(local_path.name))
 
     def _list(self):
-        u'list files in the backup folder'
+        """list files in the backup folder"""
 
         return self.folder_contents(files_only=True)
 
     def _delete(self, filename):
-        u'deletes remote '
+        """deletes remote """
 
-        self.delete(remote_file=util.fsdecode(filename))
+        self.delete(remote_file=os.fsdecode(filename))
 
     def folder_contents(self, files_only=False):
-        u'lists contents of a folder, optionally ignoring subdirectories'
+        """lists contents of a folder, optionally ignoring subdirectories"""
 
-        print(u"megals: %s" % (self._folder,))
+        print(f"megals: {self._folder}")
 
         if self._megarc:
-            cmd = [u'megals', u'--config', self._megarc, self._folder]
+            cmd = ['megals', '--config', self._megarc, self._folder]
         else:
-            cmd = [u'megals', u'-u', self._username, u'-p', self._password, self._folder]
+            cmd = ['megals', '-', self._username, '-p', self._password, self._folder]
 
         files = subprocess.check_output(cmd)
-        files = util.fsdecode(files.strip()).split(u'\n')
+        files = os.fsdecode(files.strip()).split('\n')
 
         # remove the folder name, including the path separator
         files = [f[len(self._folder) + 1:] for f in files]
 
         # optionally ignore entries containing path separator (i.e. not files)
         if files_only:
-            files = [f for f in files if u'/' not in f]
+            files = [f for f in files if '/' not in f]
 
-        return [util.fsencode(f) for f in files]
+        return [os.fsencode(f) for f in files]
 
     def download(self, remote_file, local_file):
 
-        print(u"megaget: %s" % (remote_file,))
+        print(f"megaget: {remote_file}")
 
         if self._megarc:
-            cmd = [u'megaget', u'--config', self._megarc, u'--no-progress',
-                   u'--path', local_file, self._folder + u'/' + remote_file]
+            cmd = ['megaget', '--config', self._megarc, '--no-progress',
+                   '--path', local_file, f"{self._folder}/{remote_file}"]
         else:
-            cmd = [u'megaget', u'-u', self._username, u'-p', self._password, u'--no-progress',
-                   u'--path', local_file, self._folder + u'/' + remote_file]
+            cmd = ['megaget', '-u', self._username, '-p', self._password, '--no-progress',
+                   '--path', local_file, f"{self._folder}/{remote_file}"]
 
         self.subprocess_popen(cmd)
 
     def upload(self, local_file, remote_file):
 
-        print(u"megaput: %s" % (remote_file,))
+        print(f"megaput: {remote_file}")
 
         if self._megarc:
-            cmd = [u'megaput', u'--config', self._megarc, u'--no-progress',
-                   u'--path', self._folder + u'/' + remote_file, local_file]
+            cmd = ['megaput', '--config', self._megarc, '--no-progress',
+                   '--path', f"{self._folder}/{remote_file}", local_file]
         else:
-            cmd = [u'megaput', u'-u', self._username, u'-p', self._password, u'--no-progress',
-                   u'--path', self._folder + u'/' + remote_file, local_file]
+            cmd = ['megaput', '-u', self._username, '-p', self._password, '--no-progress',
+                   '--path', f"{self._folder}/{remote_file}", local_file]
 
         try:
             self.subprocess_popen(cmd)
         except Exception as e:
             error_str = str(e)
-            if u"EOVERQUOTA" in error_str:
-                raise BackendException(u"MEGA account over quota, could not write file : '%s' . "
-                                       u"Upgrade your storage at https://mega.nz/pro or remove some data." %
-                                       (remote_file,))
+            if "EOVERQUOTA" in error_str:
+                raise BackendException(f"MEGA account over quota, could not write file : '{remote_file}'. "
+                                       f"Upgrade your storage at https://mega.nz/pro or remove some data.")
             else:
-                raise BackendException(u"Failed writing file '%s' to MEGA , reason : '%s'" % (remote_file, e))
+                raise BackendException(f"Failed writing file '{remote_file}' to MEGA , reason : '{e}'")
 
     def delete(self, remote_file):
 
-        print(u"megarm: %s" % (remote_file,))
+        print(f"megarm: {remote_file}")
 
         if self._megarc:
-            cmd = [u'megarm', u'--config', self._megarc, self._folder + u'/' + remote_file]
+            cmd = ['megarm', '--config', self._megarc, f"{self._folder}/{remote_file}"]
         else:
-            cmd = [u'megarm', u'-u', self._username, u'-p', self._password, self._folder + u'/' + remote_file]
+            cmd = ['megarm', '-', self._username, '-p', self._password, f"{self._folder}/{remote_file}"]
 
         self.subprocess_popen(cmd)
 
 
-duplicity.backend.register_backend(u'mega', MegaBackend)
-duplicity.backend.uses_netloc.extend([u'mega'])
+duplicity.backend.register_backend('mega', MegaBackend)
+duplicity.backend.uses_netloc.extend(['mega'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/pydrivebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/pydrivebackend.py`

 * *Files 7% similar despite different names*

```diff
@@ -12,262 +12,258 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import next
-from builtins import str
 
 import os
 
+import duplicity.backend
 from duplicity import log
-from duplicity import util
 from duplicity.errors import BackendException
-import duplicity.backend
 
 
 class PyDriveBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using PyDrive API"""
+    """Connect to remote store using PyDrive API"""
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
         try:
             import httplib2
             from apiclient.discovery import build
         except ImportError as e:
-            raise BackendException(u"""\
-PyDrive backend requires PyDrive2 and Google API client installation.
+            raise BackendException(f"""PyDrive backend requires PyDrive2 and Google API client installation.
 Please read the manpage for setup details.
-Exception: %s""" % str(e))
+Exception: {str(e)}""")
 
         # Shared Drive ID specified as a query parameter in the backend URL.
         # Example: pydrive://developer.gserviceaccount.com/target-folder/?driveID=<SHARED DRIVE ID>
         self.api_params = {}
         self.shared_drive_id = None
-        if u'driveID' in parsed_url.query_args:
-            self.shared_drive_id = parsed_url.query_args[u'driveID'][0]
-            self.api_params = {u'corpora': u'teamDrive',
-                               u'teamDriveId': self.shared_drive_id,
-                               u'includeTeamDriveItems': True,
-                               u'supportsTeamDrives': True}
+        if 'driveID' in parsed_url.query_args:
+            self.shared_drive_id = parsed_url.query_args['driveID'][0]
+            self.api_params = {'corpora': 'teamDrive',
+                               'teamDriveId': self.shared_drive_id,
+                               'includeTeamDriveItems': True,
+                               'supportsTeamDrives': True}
 
         try:
             from pydrive2.auth import GoogleAuth
             from pydrive2.drive import GoogleDrive
-            from pydrive2.files import ApiRequestError, FileNotUploadedError
+            from pydrive2.files import (
+                ApiRequestError,
+                FileNotUploadedError,
+            )
         except ImportError as e:
-            raise BackendException(u"""\
-PyDrive backend requires PyDrive2 installation.  Please read the manpage for setup details.
-Exception: %s""" % str(e))
+            raise BackendException(f"PyDrive backend requires PyDrive2 installation.\n"
+                                   f"Please read the manpage for setup details.\n"
+                                   f"Exception: {str(e)}")
 
         # let user get by with old client while he can
         try:
             from oauth2client.client import SignedJwtAssertionCredentials
             self.oldClient = True
-        except:
+        except Exception as e:
             from oauth2client.service_account import ServiceAccountCredentials
             from oauth2client import crypt
             self.oldClient = False
 
-        if u'GOOGLE_DRIVE_ACCOUNT_KEY' in os.environ:
-            account_key = os.environ[u'GOOGLE_DRIVE_ACCOUNT_KEY']
+        if 'GOOGLE_DRIVE_ACCOUNT_KEY' in os.environ:
+            account_key = os.environ['GOOGLE_DRIVE_ACCOUNT_KEY']
             if self.oldClient:
                 credentials = SignedJwtAssertionCredentials(parsed_url.username +
-                                                            u'@' + parsed_url.hostname,
+                                                            '@' + parsed_url.hostname,
                                                             account_key,
-                                                            scopes=u'https://www.googleapis.com/auth/drive')
+                                                            scopes='https://www.googleapis.com/auth/drive')
             else:
                 signer = crypt.Signer.from_string(account_key)  # pylint: disable=used-before-assignment
                 credentials = ServiceAccountCredentials(parsed_url.username +  # pylint: disable=used-before-assignment
-                                                        u'@' + parsed_url.hostname, signer,
-                                                        scopes=u'https://www.googleapis.com/auth/drive')
+                                                        '@' + parsed_url.hostname, signer,
+                                                        scopes='https://www.googleapis.com/auth/drive')
             credentials.authorize(httplib2.Http())
             gauth = GoogleAuth(http_timeout=60)
             gauth.credentials = credentials
-        elif u'GOOGLE_DRIVE_SETTINGS' in os.environ:
-            gauth = GoogleAuth(settings_file=os.environ[u'GOOGLE_DRIVE_SETTINGS'], http_timeout=60)
+        elif 'GOOGLE_DRIVE_SETTINGS' in os.environ:
+            gauth = GoogleAuth(settings_file=os.environ['GOOGLE_DRIVE_SETTINGS'], http_timeout=60)
             gauth.CommandLineAuth()
-        elif (u'GOOGLE_SECRETS_FILE' in os.environ and u'GOOGLE_CREDENTIALS_FILE' in os.environ):
+        elif 'GOOGLE_SECRETS_FILE' in os.environ and 'GOOGLE_CREDENTIALS_FILE' in os.environ:
             gauth = GoogleAuth(http_timeout=60)
-            gauth.LoadClientConfigFile(os.environ[u'GOOGLE_SECRETS_FILE'])
-            gauth.LoadCredentialsFile(os.environ[u'GOOGLE_CREDENTIALS_FILE'])
+            gauth.LoadClientConfigFile(os.environ['GOOGLE_SECRETS_FILE'])
+            gauth.LoadCredentialsFile(os.environ['GOOGLE_CREDENTIALS_FILE'])
             if gauth.credentials is None:
                 gauth.CommandLineAuth()
             elif gauth.access_token_expired:
                 gauth.Refresh()
             else:
                 gauth.Authorize()
-            gauth.SaveCredentialsFile(os.environ[u'GOOGLE_CREDENTIALS_FILE'])
+            gauth.SaveCredentialsFile(os.environ['GOOGLE_CREDENTIALS_FILE'])
         else:
             raise BackendException(
-                u'GOOGLE_DRIVE_ACCOUNT_KEY or GOOGLE_DRIVE_SETTINGS environment '
-                u'variable not set. Please read the manpage to fix.')
+                'GOOGLE_DRIVE_ACCOUNT_KEY or GOOGLE_DRIVE_SETTINGS environment '
+                'variable not set. Please read the manpage to fix.')
         self.drive = GoogleDrive(gauth)
 
         if self.shared_drive_id:
             parent_folder_id = self.shared_drive_id
         else:
             # Dirty way to find root folder id
-            file_list = self.drive.ListFile({u'q': u"'Root' in parents and trashed=false"}).GetList()
+            file_list = self.drive.ListFile({'q': "'Root' in parents and trashed=false"}).GetList()
             if file_list:
-                parent_folder_id = file_list[0][u'parents'][0][u'id']
+                parent_folder_id = file_list[0]['parents'][0]['id']
             else:
-                file_in_root = self.drive.CreateFile({u'title': u'i_am_in_root'})
+                file_in_root = self.drive.CreateFile({'title': 'i_am_in_root'})
                 file_in_root.Upload()
-                parent_folder_id = file_in_root[u'parents'][0][u'id']
+                parent_folder_id = file_in_root['parents'][0]['id']
                 file_in_root.Delete()
 
         # Fetch destination folder entry and create hierarchy if required.
-        folder_names = parsed_url.path.split(u'/')
+        folder_names = parsed_url.path.split('/')
         for folder_name in folder_names:
             if not folder_name:
                 continue
-            list_file_args = {u'q': u"'" + parent_folder_id +
-                              u"' in parents and trashed=false"}
+            list_file_args = {'q': f"'{parent_folder_id}' in parents and trashed=false"}
             list_file_args.update(self.api_params)
             file_list = self.drive.ListFile(list_file_args).GetList()
-            folder = next((item for item in file_list if item[u'title'] == folder_name and
-                           item[u'mimeType'] == u'application/vnd.google-apps.folder'), None)
+            folder = next((item for item in file_list if item['title'] == folder_name and
+                           item['mimeType'] == 'application/vnd.google-apps.folder'), None)
             if folder is None:
-                create_file_args = {u'title': folder_name,
-                                    u'mimeType': u"application/vnd.google-apps.folder",
-                                    u'parents': [{u'id': parent_folder_id}]}
-                create_file_args[u'parents'][0].update(self.api_params)
+                create_file_args = {'title': folder_name,
+                                    'mimeType': "application/vnd.google-apps.folder",
+                                    'parents': [{'id': parent_folder_id}]}
+                create_file_args['parents'][0].update(self.api_params)
                 create_file_args.update(self.api_params)
                 folder = self.drive.CreateFile(create_file_args)
                 if self.shared_drive_id:
-                    folder.Upload(param={u'supportsTeamDrives': True})
+                    folder.Upload(param={'supportsTeamDrives': True})
                 else:
                     folder.Upload()
-            parent_folder_id = folder[u'id']
+            parent_folder_id = folder['id']
         self.folder = parent_folder_id
         self.id_cache = {}
 
     def file_by_name(self, filename):
         from pydrive2.files import ApiRequestError  # pylint: disable=import-error
 
-        filename = util.fsdecode(filename)  # PyDrive deals with unicode filenames
+        filename = os.fsdecode(filename)  # PyDrive deals with unicode filenames
 
         if filename in self.id_cache:
             # It might since have been locally moved, renamed or deleted, so we
             # need to validate the entry.
             file_id = self.id_cache[filename]
-            drive_file = self.drive.CreateFile({u'id': file_id})
+            drive_file = self.drive.CreateFile({'id': file_id})
             try:
-                if drive_file[u'title'] == filename and not drive_file[u'labels'][u'trashed']:
-                    for parent in drive_file[u'parents']:
-                        if parent[u'id'] == self.folder:
-                            log.Info(u"PyDrive backend: found file '%s' with id %s in ID cache" %
-                                     (filename, file_id))
+                if drive_file['title'] == filename and not drive_file['labels']['trashed']:
+                    for parent in drive_file['parents']:
+                        if parent['id'] == self.folder:
+                            log.Info(f"PyDrive backend: found file '{filename}' with id {file_id} in ID cache")
                             return drive_file
             except ApiRequestError as error:
                 # A 404 occurs if the ID is no longer valid
                 if error.args[0].resp.status != 404:
                     raise
             # If we get here, the cache entry is invalid
-            log.Info(u"PyDrive backend: invalidating '%s' (previously ID %s) from ID cache" %
-                     (filename, file_id))
+            log.Info(f"PyDrive backend: invalidating '{filename}' (previously ID {file_id}) from ID cache")
             del self.id_cache[filename]
 
         # Not found in the cache, so use directory listing. This is less
         # reliable because there is no strong consistency.
-        q = u"title='%s' and '%s' in parents and trashed=false" % (filename, self.folder)
-        fields = u'items(title,id,fileSize,downloadUrl,exportLinks),nextPageToken'
-        list_file_args = {u'q': q, u'fields': fields}
+        q = f"title='{filename}' and '{self.folder}' in parents and trashed=false"
+        fields = 'items(title,id,fileSize,downloadUrl,exportLinks),nextPageToken'
+        list_file_args = {'q': q, 'fields': fields}
         list_file_args.update(self.api_params)
         flist = self.drive.ListFile(list_file_args).GetList()
         if len(flist) > 1:
-            log.FatalError(_(u"PyDrive backend: multiple files called '%s'.") % (filename,))
+            log.FatalError(_("PyDrive backend: multiple files called '%s'.") % (filename,))
         elif flist:
-            file_id = flist[0][u'id']
-            self.id_cache[filename] = flist[0][u'id']
-            log.Info(u"PyDrive backend: found file '%s' with id %s on server, "
-                     u"adding to cache" % (filename, file_id))
+            file_id = flist[0]['id']
+            self.id_cache[filename] = flist[0]['id']
+            log.Info(f"PyDrive backend: found file '{filename}' with id {file_id} on server, adding to cache")
             return flist[0]
-        log.Info(u"PyDrive backend: file '%s' not found in cache or on server" %
-                 (filename,))
+        log.Info(f"PyDrive backend: file '{filename}' not found in cache or on server")
         return None
 
     def id_by_name(self, filename):
         drive_file = self.file_by_name(filename)
         if drive_file is None:
-            return u''
+            return ''
         else:
-            return drive_file[u'id']
+            return drive_file['id']
 
     def _put(self, source_path, remote_filename):
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         drive_file = self.file_by_name(remote_filename)
         if drive_file is None:
             # No existing file, make a new one
-            create_file_args = {u'title': remote_filename,
-                                u'parents': [{u"kind": u"drive#fileLink",
-                                             u"id": self.folder}]}
-            create_file_args[u'parents'][0].update(self.api_params)
+            create_file_args = {'title': remote_filename,
+                                'parents': [{"kind": "drive#fileLink",
+                                             "id": self.folder}]}
+            create_file_args['parents'][0].update(self.api_params)
             drive_file = self.drive.CreateFile(create_file_args)
-            log.Info(u"PyDrive backend: creating new file '%s'" % (remote_filename,))
+            log.Info(f"PyDrive backend: creating new file '{remote_filename}'")
         else:
-            log.Info(u"PyDrive backend: replacing existing file '%s' with id '%s'" % (
-                remote_filename, drive_file[u'id']))
-        drive_file.SetContentFile(util.fsdecode(source_path.name))
+            log.Info(f"PyDrive backend: replacing existing file '{remote_filename}' with id '{drive_file['id']}'")
+        drive_file.SetContentFile(os.fsdecode(source_path.name))
         if self.shared_drive_id:
-            drive_file.Upload(param={u'supportsTeamDrives': True})
+            drive_file.Upload(param={'supportsTeamDrives': True})
         else:
             drive_file.Upload()
-        self.id_cache[remote_filename] = drive_file[u'id']
+        self.id_cache[remote_filename] = drive_file['id']
 
     def _get(self, remote_filename, local_path):
         drive_file = self.file_by_name(remote_filename)
-        drive_file.GetContentFile(util.fsdecode(local_path.name))
+        drive_file.GetContentFile(os.fsdecode(local_path.name))
 
     def _list(self):
         list_file_args = {
-            u'q': u"'" + self.folder + u"' in parents and trashed=false",
-            u'fields': u'items(title,id),nextPageToken'}
+            'q': f"'{self.folder}' in parents and trashed=false",
+            'fields': 'items(title,id),nextPageToken'}
         list_file_args.update(self.api_params)
         drive_files = self.drive.ListFile(list_file_args).GetList()
-        filenames = set(item[u'title'] for item in drive_files)
+        filenames = set(item['title'] for item in drive_files)
         # Check the cache as well. A file might have just been uploaded but
         # not yet appear in the listing.
         # Note: do not use iterkeys() here, because file_by_name will modify
         # the cache if it finds invalid entries.
         for filename in list(self.id_cache.keys()):
             if (filename not in filenames) and (self.file_by_name(filename) is not None):
                 filenames.add(filename)
         return list(filenames)
 
     def _delete(self, filename):
         file_id = self.id_by_name(filename)
-        if file_id == u'':
-            log.Warn(u"File '%s' does not exist while trying to delete it" % (util.fsdecode(filename),))
+        if file_id == '':
+            log.Warn(f"File '{os.fsdecode(filename)}' does not exist while trying to delete it")
         elif self.shared_drive_id:
-            self.drive.auth.service.files().delete(fileId=file_id, param={u'supportsTeamDrives': True}).execute()
+            self.drive.auth.service.files().delete(fileId=file_id, param={'supportsTeamDrives': True}).execute()
         else:
             self.drive.auth.service.files().delete(fileId=file_id).execute()
 
     def _query(self, filename):
         drive_file = self.file_by_name(filename)
         if drive_file is None:
             size = -1
         else:
-            size = int(drive_file[u'fileSize'])
-        return {u'size': size}
+            size = int(drive_file['fileSize'])
+        return {'size': size}
 
     def _error_code(self, operation, error):  # pylint: disable=unused-argument
-        from pydrive2.files import ApiRequestError, FileNotUploadedError  # pylint: disable=import-error
+        from pydrive2.files import (
+            ApiRequestError,
+            FileNotUploadedError,  # pylint: disable=import-error
+        )
 
         if isinstance(error, FileNotUploadedError):
             return log.ErrorCode.backend_not_found
         elif isinstance(error, ApiRequestError):
             return log.ErrorCode.backend_permission_denied
         return log.ErrorCode.backend_error
 
 
-duplicity.backend.register_backend(u'pydrive', PyDriveBackend)
-u""" pydrive is an alternate way to access gdocs """
-duplicity.backend.register_backend(u'pydrive+gdocs', PyDriveBackend)
-u""" register pydrive as the default way to access gdocs """
-duplicity.backend.register_backend(u'gdocs', PyDriveBackend)
+duplicity.backend.register_backend('pydrive', PyDriveBackend)
+""" pydrive is an alternate way to access gdocs """
+duplicity.backend.register_backend('pydrive+gdocs', PyDriveBackend)
+""" register pydrive as the default way to access gdocs """
+duplicity.backend.register_backend('gdocs', PyDriveBackend)
 
-duplicity.backend.uses_netloc.extend([u'pydrive', u'pydrive+gdocs', u'gdocs'])
+duplicity.backend.uses_netloc.extend(['pydrive', 'pydrive+gdocs', 'gdocs'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/azurebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/azurebackend.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,130 +15,129 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
 import os
 import re
 
 import duplicity.backend
 from duplicity import config
 from duplicity import log
 from duplicity.errors import BackendException
-from duplicity.util import fsdecode
-
 
 _VALID_CONTAINER_NAME_RE = re.compile(r"^[a-z0-9](?!.*--)[a-z0-9-]{1,61}[a-z0-9]$")
 
 
 def _is_valid_container_name(name):
-    u"""
+    """
     Check, whether the given name conforms to the rules as defined in
     https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata
     for valid names.
     """
     match = _VALID_CONTAINER_NAME_RE.match(name)
     return match is not None
 
 
 class AzureBackend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for Azure Blob Storage Service
     """
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # Import Microsoft Azure Storage SDK for Python library.
         try:
-            import azure
-            import azure.storage
-            import azure.storage.blob
-            from azure.storage.blob import BlobServiceClient
+            import azure_core
+            import azure_storage
+            import azure_storage_blob
+            from azure_storage_blob import BlobServiceClient
         except ImportError as e:
-            raise BackendException(u"""\
-Azure backend requires Microsoft Azure Storage SDK for Python (https://pypi.org/project/azure-storage-blob/).
-Exception: %s""" % str(e))
+            raise BackendException(f"Azure backend requires Microsoft Azure Storage SDK for Python\n"
+                                   f"(https://pypi.org/project/azure-storage-blob/).\n"
+                                   f"Exception: {str(e)}")
 
-        self.container_name = parsed_url.path.lstrip(u'/')
+        self.container_name = parsed_url.path.lstrip('/')
 
         if not _is_valid_container_name(self.container_name):
-            raise BackendException(u'Invalid Azure Storage Blob container name.')
+            raise BackendException('Invalid Azure Storage Blob container name.')
 
-        if u'AZURE_CONNECTION_STRING' not in os.environ:
-            raise BackendException(u'AZURE_CONNECTION_STRING environment variable not set.')
+        if 'AZURE_CONNECTION_STRING' not in os.environ:
+            raise BackendException('AZURE_CONNECTION_STRING environment variable not set.')
 
         kwargs = {}
 
         if config.timeout:
-            kwargs[u'timeout'] = config.timeout
+            kwargs['timeout'] = config.timeout
 
         if config.azure_max_single_put_size:
-            kwargs[u'max_single_put_size'] = config.azure_max_single_put_size
+            kwargs['max_single_put_size'] = config.azure_max_single_put_size
 
         if config.azure_max_block_size:
-            kwargs[u'max_block_size'] = config.azure_max_single_put_size
+            kwargs['max_block_size'] = config.azure_max_single_put_size
 
-        conn_str = os.environ[u'AZURE_CONNECTION_STRING']
+        conn_str = os.environ['AZURE_CONNECTION_STRING']
         self.blob_service = BlobServiceClient.from_connection_string(conn_str, None, **kwargs)
         self._get_or_create_container()
 
     def _get_or_create_container(self):
+        # Note: azure comes from azure-core module
         from azure.core.exceptions import ResourceExistsError
 
         try:
             self.container = self.blob_service.get_container_client(self.container_name)
             self.container.create_container()
         except ResourceExistsError:
             pass
         except Exception as e:
-            log.FatalError(u"Could not create Azure container: %s"
-                           % str(e.message).split(u'\n', 1)[0],
+            log.FatalError("Could not create Azure container: %s"
+                           % str(e).split('\n', 1)[0],
                            log.ErrorCode.connection_failed)
 
     def _put(self, source_path, remote_filename):
-        remote_filename = fsdecode(remote_filename)
-        kwargs = {u"overwrite": True}
+        remote_filename = os.fsdecode(remote_filename)
+        kwargs = {}
 
         if config.azure_max_connections:
-            kwargs[u'max_concurrency'] = config.azure_max_connections
+            kwargs['max_concurrency'] = config.azure_max_connections
 
-        with source_path.open(u"rb") as data:
+        with source_path.open("rb") as data:
             self.container.upload_blob(remote_filename, data, **kwargs)
 
         self._set_tier(remote_filename)
 
     def _set_tier(self, remote_filename):
         if config.azure_blob_tier is not None:
             self.container.set_standard_blob_tier_blobs(config.azure_blob_tier, remote_filename)
 
     def _get(self, remote_filename, local_path):
         # https://docs.microsoft.com/en-us/python/api/azure-storage-blob/azure.storage.blob.containerclient?view=azure-python#download-blob-blob--offset-none--length-none----kwargs-
         blob = self.container.download_blob(remote_filename)
-        with local_path.open(u"wb") as download_file:
+        with local_path.open("wb") as download_file:
             download_file.write(blob.readall())
 
     def _list(self):
         # https://docs.microsoft.com/en-us/python/api/azure-storage-blob/azure.storage.blob.containerclient?view=azure-python#list-blobs-name-starts-with-none--include-none----kwargs-
         blobs = []
         blob_list = self.container.list_blobs()
         for blob in blob_list:
             blobs.append(blob)
 
         return [blob.name for blob in blobs]
 
     def _delete(self, filename):
         # https://docs.microsoft.com/en-us/python/api/azure-storage-blob/azure.storage.blob.containerclient?view=azure-python#delete-blob-blob--delete-snapshots-none----kwargs-
-        self.container.delete_blob(fsdecode(filename))
+        self.container.delete_blob(os.fsdecode(filename))
 
     def _query(self, filename):
-        client = self.container.get_blob_client(fsdecode(filename))
+        client = self.container.get_blob_client(os.fsdecode(filename))
         prop = client.get_blob_properties()
-        return {u'size': int(prop.size)}
+        return {'size': int(prop.size)}
 
     def _error_code(self, operation, e):  # pylint: disable=unused-argument
         return log.ErrorCode.backend_not_found
 
 
-duplicity.backend.register_backend(u'azure', AzureBackend)
+duplicity.backend.register_backend('azure', AzureBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/__init__.py` & `duplicity-2.0.0rc0/duplicity/backends/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -15,12 +15,12 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Imports of backends should not be done directly in this module.  All
 backend imports are done via import_backends() in backend.py.  This
 file is only to instantiate the duplicity.backends module itself.
 """
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/idrivedbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/idrivedbackend.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,30 +14,28 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
+import errno
 import os
-import urllib
-import tempfile
 import re
-import xml.etree.ElementTree as ET
 import shutil
-import errno
-
+import tempfile
+import urllib
+import xml.etree.ElementTree as ET
 
 import duplicity.backend
 from duplicity import config
 from duplicity import log
-from duplicity import tempdir
-from duplicity import progress
 from duplicity.errors import BackendException
 
+
 #
 #   This backend works with the IDrive  "dedup implementation". V0.1
 #               (for all new and recent accounts)
 #
 #   Credits: This code is loosely inspired by the work of <aappddeevv>
 #
 #
@@ -104,366 +102,369 @@
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # parsed_url will have leading slashes in it, 4 slashes typically.
         self.parsed_url = parsed_url
         self.url_string = duplicity.backend.strip_auth_from_url(self.parsed_url)
-        log.Debug(u"parsed_url: {0}".format(parsed_url))
+        log.Debug(f"parsed_url: {parsed_url}")
 
         self.connected = False
 
     def user_connected(self):
         return self.connected
 
     def request(self, commandline):
         # request for commands returning data in XML format
-        log.Debug(u"Request command: {0}".format(commandline))
+        log.Debug(f"Request command: {commandline}")
         try:
             _, reply, error = self.subprocess_popen(commandline)
         except KeyError:
-            raise BackendException(u"Unknown protocol failure on request {0}".format(commandline))
+            raise BackendException(f"Unknown protocol failure on request {commandline}")
 
         response = reply + error
         try:
-            xml = u"<root>" + u''.join(re.findall(u"<[^>]+>", response)) + u"</root>"
+            xml = f"<root>{''.join(re.findall('<[^>]+>', response))}</root>"
             el = ET.fromstring(xml)
 
-        except:
+        except Exception as e:
             el = None
-        log.Debug(u"Request response: {0}".format(response))
+        log.Debug(f"Request response: {response}")
 
         return el
 
     def connect(self):
         # get the path to the command executable
-        path = os.environ.get(u"IDEVSPATH")
+        path = os.environ.get("IDEVSPATH")
         if path is None:
-            log.Warn(u"-" * 72)
-            log.Warn(u"WARNING: No path to 'idevsutil_dedup' has been set. Download module from")
-            log.Warn(u"   https://www.idrivedownloads.com/downloads/linux/download-options/IDrive_linux_64bit.zip")
-            log.Warn(u"or")
-            log.Warn(u"   https://www.idrivedownloads.com/downloads/linux/download-options/IDrive_linux_32bit.zip")
-            log.Warn(u"and place anywhere with exe rights. Then creat env var 'IDEVSPATH' with path to file")
-            log.Warn(u"-" * 72)
-            raise BackendException(u"No IDEVSPATH env var set. Should contain folder to idevsutil_dedup")
-        self.cmd = os.path.join(path, u"idevsutil_dedup")
-        log.Debug(u"IDrive command base: %s" % (self.cmd))
+            log.Warn("-" * 72)
+            log.Warn("WARNING: No path to 'idevsutil_dedup' has been set. Download module from")
+            log.Warn("   https://www.idrivedownloads.com/downloads/linux/download-options/IDrive_linux_64bit.zip")
+            log.Warn("or")
+            log.Warn("   https://www.idrivedownloads.com/downloads/linux/download-options/IDrive_linux_32bit.zip")
+            log.Warn("and place anywhere with exe rights. Then creat env var 'IDEVSPATH' with path to file")
+            log.Warn("-" * 72)
+            raise BackendException("No IDEVSPATH env var set. Should contain folder to idevsutil_dedup")
+        self.cmd = os.path.join(path, "idevsutil_dedup")
+        log.Debug(f"IDrive command base: {self.cmd}")
 
         # get the account-id
-        self.idriveid = os.environ.get(u"IDRIVEID")
+        self.idriveid = os.environ.get("IDRIVEID")
         if self.idriveid is None:
-            log.Warn(u"-" * 72)
-            log.Warn(u"WARNING: IDrive logon ID missing")
-            log.Warn(u"Create an environment variable IDriveID with your IDrive logon ID")
-            log.Warn(u"-" * 72)
-            raise BackendException(u"No IDRIVEID env var set. Should contain IDrive id")
-        log.Debug(u"IDrive id: %s" % (self.idriveid))
+            log.Warn("-" * 72)
+            log.Warn("WARNING: IDrive logon ID missing")
+            log.Warn("Create an environment variable IDriveID with your IDrive logon ID")
+            log.Warn("-" * 72)
+            raise BackendException("No IDRIVEID env var set. Should contain IDrive id")
+        log.Debug(f"IDrive id: {self.idriveid}")
 
         # Get the full-path to the account password file
-        filepath = os.environ.get(u"IDPWDFILE")
+        filepath = os.environ.get("IDPWDFILE")
         if filepath is None:
-            log.Warn(u"-" * 72)
-            log.Warn(u"WARNING: IDrive password file missging")
-            log.Warn(u"Please create a file with your IDrive logon password,")
-            log.Warn(u"Then create an environment variable IDPWDFILE with path/filename of said file")
-            log.Warn(u"-" * 72)
-            raise BackendException(u"No IDPWDFILE env var set. Should contain file with password")
-        log.Debug(u"IDrive pwdpath: %s" % (filepath))
-        self.auth_switch = u" --password-file={0}".format(filepath)
+            log.Warn("-" * 72)
+            log.Warn("WARNING: IDrive password file missging")
+            log.Warn("Please create a file with your IDrive logon password,")
+            log.Warn("Then create an environment variable IDPWDFILE with path/filename of said file")
+            log.Warn("-" * 72)
+            raise BackendException("No IDPWDFILE env var set. Should contain file with password")
+        log.Debug(f"IDrive pwdpath: {filepath}")
+        self.auth_switch = f" --password-file={filepath}"
 
         # fakeroot set? Create directory and mark for cleanup
         if config.fakeroot is None:
             self.cleanup = False
-            self.fakeroot = u''
+            self.fakeroot = ''
         else:
             # Make sure fake root is created at root level!
-            self.fakeroot = os.path.join(u'/', config.fakeroot)
+            self.fakeroot = os.path.join('/', config.fakeroot)
             try:
                 os.mkdir(self.fakeroot)
             except OSError as e:
                 self.cleanup = False
                 if e.errno == errno.EEXIST:
-                    log.Debug(u"Using existing directory {0} as fake-root".format(self.fakeroot))
+                    log.Debug(f"Using existing directory {self.fakeroot} as fake-root")
                 else:
-                    log.Warn(u"-" * 72)
-                    log.Warn(u"WARNING: Creation of FAKEROOT {0} failed; backup will use system temp directory"
-                             .format(self.fakeroot))
-                    log.Warn(u"This might interfere with incremental backups")
-                    log.Warn(u"-" * 72)
-                    raise BackendException(u"Creation of the directory {0} failed".format(self.fakeroot))
+                    log.Warn("-" * 72)
+                    log.Warn(f"WARNING: Creation of FAKEROOT {self.fakeroot} failed; "
+                             f"backup will use system temp directory")
+                    log.Warn("This might interfere with incremental backups")
+                    log.Warn("-" * 72)
+                    raise BackendException(f"Creation of the directory {self.fakeroot} failed")
             else:
-                log.Debug(u"Directory {0} created as fake-root (Will clean-up afterwards!)".format(self.fakeroot))
+                log.Debug(f"Directory {self.fakeroot} created as fake-root (Will clean-up afterwards!)")
                 self.cleanup = True
 
         # get the bucket
-        self.bucket = os.environ.get(u"IDBUCKET")
+        self.bucket = os.environ.get("IDBUCKET")
         if self.bucket is None:
-            log.Warn(u"-" * 72)
-            log.Warn(u"WARNING: IDrive backup bucket missing")
-            log.Warn(u"Create an environment variable IDBUCKET specifying the target bucket")
-            log.Warn(u"-" * 72)
-            raise BackendException(u"No IDBUCKET env var set. Should contain IDrive backup bucket")
-        log.Debug(u"IDrive bucket: %s" % (self.bucket))
+            log.Warn("-" * 72)
+            log.Warn("WARNING: IDrive backup bucket missing")
+            log.Warn("Create an environment variable IDBUCKET specifying the target bucket")
+            log.Warn("-" * 72)
+            raise BackendException("No IDBUCKET env var set. Should contain IDrive backup bucket")
+        log.Debug(f"IDrive bucket: {self.bucket}")
 
         # check account / get config status and config type
-        el = self.request(self.cmd + self.auth_switch + u" --validate --user={0}".format(self.idriveid)).find(u'tree')
+        el = self.request(f"{self.cmd + self.auth_switch} --validate --user={self.idriveid}").find('tree')
 
-        if el.attrib[u"message"] != u"SUCCESS":
-            raise BackendException(u"Protocol failure - " + el.attrib[u"desc"])
-        if el.attrib[u"desc"] != u"VALID ACCOUNT":
-            raise BackendException(u"IDrive account invalid")
-        if el.attrib[u"configstatus"] != u"SET":
-            raise BackendException(u"IDrive account not set")
+        if el.attrib["message"] != "SUCCESS":
+            raise BackendException(f"Protocol failure - {el.attrib['desc']}")
+        if el.attrib["desc"] != "VALID ACCOUNT":
+            raise BackendException("IDrive account invalid")
+        if el.attrib["configstatus"] != "SET":
+            raise BackendException("IDrive account not set")
 
         # When private encryption enabled: get the full-path to a encription key file
-        if el.attrib[u"configtype"] == u"PRIVATE":
-            filepath = os.environ.get(u"IDKEYFILE")
+        if el.attrib["configtype"] == "PRIVATE":
+            filepath = os.environ.get("IDKEYFILE")
             if filepath is None:
-                log.Warn(u"-" * 72)
-                log.Warn(u"WARNING: IDrive encryption key file missging")
-                log.Warn(u"Please create a file with your IDrive encryption key,")
-                log.Warn(u"Then create an environment variable IDKEYFILE with path/filename of said file")
-                log.Warn(u"-" * 72)
-                raise BackendException(u"No IDKEYFILE env var set. Should contain file with encription key")
-            log.Debug(u"IDrive keypath: %s" % (filepath))
-            self.auth_switch += u" --pvt-key={0}".format(filepath)
+                log.Warn("-" * 72)
+                log.Warn("WARNING: IDrive encryption key file missging")
+                log.Warn("Please create a file with your IDrive encryption key,")
+                log.Warn("Then create an environment variable IDKEYFILE with path/filename of said file")
+                log.Warn("-" * 72)
+                raise BackendException("No IDKEYFILE env var set. Should contain file with encription key")
+            log.Debug(f"IDrive keypath: {filepath}")
+            self.auth_switch += f" --pvt-key={filepath}"
 
         # get the server address
-        el = self.request(self.cmd + self.auth_switch + u" --getServerAddress {0}".format(self.idriveid)).find(u'tree')
-        self.idriveserver = el.attrib[u"cmdUtilityServer"]
+        el = self.request(f"{self.cmd + self.auth_switch} --getServerAddress {self.idriveid}").find('tree')
+        self.idriveserver = el.attrib["cmdUtilityServer"]
 
         # get the device list - primarely used to get device-id string
-        el = self.request(self.cmd + self.auth_switch + u" --list-device {0}@{1}::home".
-                          format(self.idriveid, self.idriveserver))
+        el = self.request(self.cmd + self.auth_switch + f" --list-device {self.idriveid}@{self.idriveserver}::home")
         # scan all returned devices for requested device (== bucket)
         self.idrivedevid = None
-        for item in el.findall(u'item'):
-            if item.attrib[u'nick_name'] == self.bucket:
+        for item in el.findall('item'):
+            if item.attrib['nick_name'] == self.bucket:
                 # prefix and suffix reverse-engineered from Common.pl!
-                self.idrivedevid = u"5c0b" + item.attrib[u"device_id"] + u"4b5z"
+                self.idrivedevid = f"5c0b{item.attrib['device_id']}4b5z"
         if self.idrivedevid is None:
             el = self.request(
                 self.cmd + self.auth_switch +
-                u" --create-bucket --bucket-type=D --nick-name={0} --os=Linux --uid=987654321 {1}@{2}::home/"
-                .format(self.bucket, self.idriveid, self.idriveserver)).find(u'item')
+                f" --create-bucket --bucket-type=D --nick-name={self.bucket} --os=Linux --uid=987654321 "
+                f"{self.idriveid}@{self.idriveserver}::home/").find('item')
             # prefix and suffix reverse-engineered from Common.pl!
-            self.idrivedevid = u"5c0b" + el.attrib[u"device_id"] + u"4b5z"
+            self.idrivedevid = f"5c0b{el.attrib['device_id']}4b5z"
 
         # We're fully connected!
         self.connected = True
-        log.Debug(u"User fully connected")
+        log.Debug("User fully connected")
 
     def list_raw(self):
         # get raw list; used by _list, _query and _query_list
-        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip(u'/')),
-                                   self.fakeroot.lstrip(u'/')).rstrip()
-        commandline = ((self.cmd + self.auth_switch + u" --auth-list --device-id={0} {1}@{2}::home/{3}"
-                       .format(self.idrivedevid, self.idriveid, self.idriveserver, remote_path)))
+        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip('/')),
+                                   self.fakeroot.lstrip('/')).rstrip()
+        commandline = (self.cmd + self.auth_switch +
+                       f" --auth-list --device-id={self.idrivedevid} "
+                       f"{self.idriveid}@{self.idriveserver}::home/{remote_path}")
         try:
             _, l, _ = self.subprocess_popen(commandline)
-        except:
+        except Exception as e:
             # error: treat as empty response
-            log.Debug(u"list EMPTY response ")
+            log.Debug("list EMPTY response ")
             return []
 
-        log.Debug(u"list response: {0}".format(l))
+        log.Debug(f"list response: {l}")
 
         # get a list of lists from data lines returned by idevsutil_dedup --auth-list
-        filtered = map((lambda line: re.split(r"\[|\]", line)), [x for x in l.splitlines() if x.startswith(u"[")])
+        filtered = list(map((lambda line: re.split(r"\[|\]", line)), [x for x in l.splitlines() if x.startswith("[")]))
         # remove whitespace from elements
-        filtered = map((lambda line: map((lambda c: c.strip()), line)), filtered)
+        filtered = list(map((lambda line: list(map((lambda c: c.strip()), line))), filtered))
         # remove empty elements
-        filtered = list(map((lambda cols: list(filter((lambda c: c != u''), cols))), filtered))
+        filtered = list(map((lambda cols: list(filter((lambda c: c != ''), cols))), filtered))
 
         return filtered
 
     def _put(self, source_path, remote_filename):
         # Put a file.
-        log.Debug(u"_PUT")
+        log.Debug("_PUT")
         if not self.user_connected():
             self.connect()
 
         # decode from byte-stream to utf-8 string
-        filename = remote_filename.decode(u'utf-8')
+        filename = remote_filename.decode('utf-8')
 
         intrim_file = os.path.join(self.fakeroot, filename)
-        remote_dirpath = urllib.parse.unquote(self.parsed_url.path.lstrip(u'/'))
+        remote_dirpath = urllib.parse.unquote(self.parsed_url.path.lstrip('/'))
 
         os.rename(source_path.name, intrim_file)
 
-        log.Debug(u"put_file: source_path={0}, remote_file={1}".format(source_path.name, filename))
+        log.Debug(f"put_file: source_path={source_path.name}, remote_file={filename}")
 
-        flist = tempfile.NamedTemporaryFile(u'w')
+        flist = tempfile.NamedTemporaryFile('w')
         flist.write(intrim_file)
         flist.seek(0)
 
-        putrequest = ((self.cmd + self.auth_switch + u"  --device-id={0} --files-from={1} / {2}@{3}::home/{4}")
+        putrequest = (f"{self.cmd + self.auth_switch}  --device-id={{0}} --files-from={{1}} / {{2}}@{{3}}::home/{{4}}"
                       .format(self.idrivedevid, flist.name, self.idriveid, self.idriveserver, remote_dirpath))
-        log.Debug(u"put_file put command: {0}".format(putrequest))
+        log.Debug(f"put_file put command: {putrequest}")
         _, putresponse, _ = self.subprocess_popen(putrequest)
-        log.Debug(u"put_file put response: {0}".format(putresponse))
+        log.Debug(f"put_file put response: {putresponse}")
 
         flist.close()
         os.remove(intrim_file)
 
     def _get(self, remote_filename, local_path):
         # Get a file.
-        log.Debug(u"_GET")
+        log.Debug("_GET")
         if not self.user_connected():
             self.connect()
 
         # decode from byte-stream to utf-8 string
-        filename = remote_filename.decode(u'utf-8')
+        filename = remote_filename.decode('utf-8')
 
-        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip(u'/')),
-                                   self.fakeroot.lstrip(u'/'), filename).rstrip()
+        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip('/')),
+                                   self.fakeroot.lstrip('/'), filename).rstrip()
 
-        log.Debug(u"_get: remote_filename={0}, local_path={1}, remote_path={2}, parsed_url.path={3}"
-                  .format(filename, local_path, remote_path, self.parsed_url.path))
+        log.Debug(f"_get: remote_filename={filename}, local_path={local_path}, "
+                  f"remote_path={remote_path}, parsed_url.path={self.parsed_url.path}")
 
         # Create tempdir to downlaod file into
         tmpdir = tempfile.mkdtemp()
-        log.Debug(u"_get created temporary download folder: {}".format(tmpdir))
+        log.Debug(f"_get created temporary download folder: {tmpdir}")
 
         # The filelist file
-        flist = tempfile.NamedTemporaryFile(u'w')
+        flist = tempfile.NamedTemporaryFile('w')
         flist.write(remote_path)
         flist.seek(0)
 
-        commandline = ((self.cmd + self.auth_switch + u" --device-id={0} --files-from={1} {2}@{3}::home/ {4}")
-                       .format(self.idrivedevid, flist.name, self.idriveid, self.idriveserver, tmpdir))
-        log.Debug(u"get command: {0}".format(commandline))
+        commandline = f"{self.cmd + self.auth_switch} " \
+                      f"--device-id={self.idrivedevid} " \
+                      f"--files-from={flist.name} " \
+                      f"{self.idriveid}@{self.idriveserver}::home/ " \
+                      f"{tmpdir}"
+        log.Debug(f"get command: {commandline}")
         _, getresponse, _ = self.subprocess_popen(commandline)
-        log.Debug(u"_get response: {0}".format(getresponse))
+        log.Debug(f"_get response: {getresponse}")
 
         flist.close()
 
         # move to the final location
-        downloadedSrcPath = os.path.join(tmpdir, remote_path.lstrip(u'/').rstrip(u'/'))
-        log.Debug(u"_get moving file {0} to final location: {1}".format(downloadedSrcPath, local_path.name))
+        downloadedSrcPath = os.path.join(tmpdir, remote_path.lstrip('/').rstrip('/'))
+        log.Debug(f"_get moving file {downloadedSrcPath} to final location: {local_path.name}")
 
         os.rename(downloadedSrcPath, local_path.name)
 
         shutil.rmtree(tmpdir)
 
     def _list(self):
         # List files on remote folder
-        log.Debug(u"_LIST")
+        log.Debug("_LIST")
         if not self.user_connected():
             self.connect()
 
         filtered = self.list_raw()
         filtered = [x[-1] for x in filtered]
 
         return filtered
 
     def _delete(self, remote_filename):
         # Delete single file
-        log.Debug(u"_DELETE")
+        log.Debug("_DELETE")
         if not self.user_connected():
             self.connect()
 
         # decode from byte-stream to utf-8 string
-        filename = remote_filename.decode(u'utf-8')
+        filename = remote_filename.decode('utf-8')
 
         # create a file-list file
-        flist = tempfile.NamedTemporaryFile(u'w')
-        flist.write(filename.lstrip(u'/'))
+        flist = tempfile.NamedTemporaryFile('w')
+        flist.write(filename.lstrip('/'))
         flist.seek(0)
 
         # target path (remote) on IDrive
-        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip(u'/')),
-                                   self.fakeroot.lstrip(u'/')).rstrip()
-        log.Debug(u"delete: {0} from remote file path {1}".format(filename, remote_path))
+        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip('/')),
+                                   self.fakeroot.lstrip('/')).rstrip()
+        log.Debug(f"delete: {filename} from remote file path {remote_path}")
 
         # delete files from file-list
         delrequest = ((self.cmd + self.auth_switch +
-                       u" --delete-items --device-id={0} --files-from={1} {2}@{3}::home/{4}")
+                       " --delete-items --device-id={0} --files-from={1} {2}@{3}::home/{4}")
                       .format(self.idrivedevid, flist.name, self.idriveid, self.idriveserver, remote_path))
-        log.Debug(u"delete: {0}".format(delrequest))
+        log.Debug(f"delete: {delrequest}")
         _, delresponse, _ = self.subprocess_popen(delrequest)
-        log.Debug(u"delete response: {0}".format(delresponse))
+        log.Debug(f"delete response: {delresponse}")
 
         # close tempfile
         flist.close()
 
     def _delete_list(self, filename_list):
         # Delete multiple files
-        log.Debug(u"_DELETE LIST")
+        log.Debug("_DELETE LIST")
         if not self.user_connected():
             self.connect()
 
         # create a file-list file
-        flist = tempfile.NamedTemporaryFile(u'w')
+        flist = tempfile.NamedTemporaryFile('w')
 
         # create file-list
         for filename in filename_list:
-            flist.write(filename.decode(u'utf-8').lstrip(u'/') + u'\n')
+            flist.write(f"{filename.decode('utf-8').lstrip('/')}\n")
         flist.seek(0)
 
         # target path (remote) on IDrive
-        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip(u'/')),
-                                   self.fakeroot.lstrip(u'/')).rstrip()
-        log.Debug(u"delete multiple files from remote file path {0}".format(remote_path))
+        remote_path = os.path.join(urllib.parse.unquote(self.parsed_url.path.lstrip('/')),
+                                   self.fakeroot.lstrip('/')).rstrip()
+        log.Debug(f"delete multiple files from remote file path {remote_path}")
 
         # delete files from file-list
         delrequest = ((self.cmd + self.auth_switch +
-                       u" --delete-items --device-id={0} --files-from={1} {2}@{3}::home/{4}")
+                       " --delete-items --device-id={0} --files-from={1} {2}@{3}::home/{4}")
                       .format(self.idrivedevid, flist.name, self.idriveid, self.idriveserver, remote_path))
-        log.Debug(u"delete: {0}".format(delrequest))
+        log.Debug(f"delete: {delrequest}")
         _, delresponse, _ = self.subprocess_popen(delrequest)
-        log.Debug(u"delete response: {0}".format(delresponse))
+        log.Debug(f"delete response: {delresponse}")
 
         # close tempfile
         flist.close()
 
     def _close(self):
         # Remove EVS_temp directory + contents
-        log.Debug(u"Removing IDrive temp folder evs_temp")
+        log.Debug("Removing IDrive temp folder evs_temp")
         try:
-            shutil.rmtree(u"evs_temp")
-        except:
+            shutil.rmtree("evs_temp")
+        except Exception as e:
             pass
 
     def _query(self, filename):
-        log.Debug(u"_QUERY")
+        log.Debug("_QUERY")
         if not self.user_connected():
             self.connect()
 
         # Get raw directory list; take-out size (index 1) for requested filename (index -1)
         filtered = self.list_raw()
         if filtered:
-            filtered = [x[1] for x in filtered if x[-1] == filename.decode(u'utf-8')]
+            filtered = [x[1] for x in filtered if x[-1] == filename.decode('utf-8')]
         if filtered:
-            return {u'size': int(filtered[0])}
+            return {'size': int(filtered[0])}
 
-        return {u'size': -1}
+        return {'size': -1}
 
     def _query_list(self, filename_list):
-        log.Debug(u"_QUERY_LIST")
+        log.Debug("_QUERY_LIST")
         if not self.user_connected():
             self.connect()
 
         # Get raw directory list
         filtered = self.list_raw()
 
         # For each filename in list: take-out size (index 1) for requested filename (index -1)
         info = {}
         for filename in filename_list:
             if filtered:
-                result = [x[1] for x in filtered if x[-1] == filename.decode(u'utf-8')]
+                result = [x[1] for x in filtered if x[-1] == filename.decode('utf-8')]
             if result:
-                info[filename] = {u'size': int(result[0])}
+                info[filename] = {'size': int(result[0])}
             else:
-                info[filename] = {u'size': -1}
+                info[filename] = {'size': -1}
 
         return info
 
     def __del__(self):
         # remove the self-created temp dir.
         # We do it here, AFTER the clean-up of Duplicity, so it will be empty!
         if self.cleanup:
             os.rmdir(self.fakeroot)
 
 
-duplicity.backend.register_backend(u"idrived", IDriveBackend)
+duplicity.backend.register_backend("idrived", IDriveBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/multibackend.py` & `duplicity-2.0.0rc0/duplicity/backends/multibackend.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,67 +19,64 @@
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 #
 
-from future import standard_library
-standard_library.install_aliases()
+import json
 import os
 import os.path
-import sys
-import urllib.request  # pylint: disable=import-error
-import urllib.parse  # pylint: disable=import-error
-import urllib.error  # pylint: disable=import-error
-import json
+import urllib.error
+import urllib.parse
+import urllib.request
 
 import duplicity.backend
-from duplicity.errors import BackendException
 from duplicity import config
 from duplicity import log
 from duplicity import util
+from duplicity.errors import BackendException
 
 
 class MultiBackend(duplicity.backend.Backend):
-    u"""Store files across multiple remote stores. URL is a path to a local file
+    """Store files across multiple remote stores. URL is a path to a local file
     containing URLs/other config defining the remote store"""
 
     # the stores we are managing
     __stores = []
     __affinities = {}
 
     # Set of known query paramaters
     __knownQueryParameters = frozenset([
-        u'mode',
-        u'onfail',
-        u'subpath',
+        'mode',
+        'onfail',
+        'subpath',
     ])
 
     # the mode of operation to follow
     # can be one of 'stripe' or 'mirror' currently
-    __mode = u'stripe'
+    __mode = 'stripe'
     __mode_allowedSet = frozenset([
-        u'mirror',
-        u'stripe',
+        'mirror',
+        'stripe',
     ])
 
     # the write error handling logic
     # can be one of the following:
     # * continue - default, on failure continues to next source
     # * abort - stop all further operations
-    __onfail_mode = u'continue'
+    __onfail_mode = 'continue'
     __onfail_mode_allowedSet = frozenset([
-        u'abort',
-        u'continue',
+        'abort',
+        'continue',
     ])
 
     # sub path to dynamically add sub directories to backends
     # will be appended to the url value
-    __subpath = u''
+    __subpath = ''
 
     # when we write in stripe mode, we "stripe" via a simple round-robin across
     # remote stores.  It's hard to get too much more sophisticated
     # since we can't rely on the backend to give us any useful meta
     # data (e.g. sizes of files, capacity of the store (quotas)) to do
     # a better job of balancing load across stores.
     __write_cursor = 0
@@ -89,32 +86,32 @@
         # Reparse so the query string is available
         reparsed_url = urllib.parse.urlparse(parsed_url.geturl())
         if len(reparsed_url.query) == 0:
             return dict()
         try:
             queryMultiDict = urllib.parse.parse_qs(reparsed_url.query, strict_parsing=True)
         except ValueError as e:
-            log.Log(_(u"MultiBackend: Could not parse query string %s: %s ")
+            log.Log(_("MultiBackend: Could not parse query string %s: %s ")
                     % (reparsed_url.query, e),
                     log.ERROR)
-            raise BackendException(u'Could not parse query string')
+            raise BackendException('Could not parse query string')
         queryDict = dict()
         # Convert the multi-dict to a single dictionary
         # while checking to make sure that no unrecognized values are found
         for name, valueList in list(queryMultiDict.items()):
             if len(valueList) != 1:
-                log.Log(_(u"MultiBackend: Invalid query string %s: more than one value for %s")
+                log.Log(_("MultiBackend: Invalid query string %s: more than one value for %s")
                         % (reparsed_url.query, name),
                         log.ERROR)
-                raise BackendException(u'Invalid query string')
+                raise BackendException('Invalid query string')
             if name not in MultiBackend.__knownQueryParameters:
-                log.Log(_(u"MultiBackend: Invalid query string %s: unknown parameter %s")
+                log.Log(_("MultiBackend: Invalid query string %s: unknown parameter %s")
                         % (reparsed_url.query, name),
                         log.ERROR)
-                raise BackendException(u'Invalid query string')
+                raise BackendException('Invalid query string')
 
             queryDict[name] = valueList[0]
         return queryDict
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
@@ -146,83 +143,81 @@
         #  {
         #   "url": "file:///path/to/dir"
         #  }
         # ]
 
         queryParams = MultiBackend.get_query_params(parsed_url)
 
-        if u'mode' in queryParams:
-            self.__mode = queryParams[u'mode']
+        if 'mode' in queryParams:
+            self.__mode = queryParams['mode']
 
-        if u'onfail' in queryParams:
-            self.__onfail_mode = queryParams[u'onfail']
+        if 'onfail' in queryParams:
+            self.__onfail_mode = queryParams['onfail']
 
         if self.__mode not in MultiBackend.__mode_allowedSet:
-            log.Log(_(u"MultiBackend: illegal value for %s: %s")
-                    % (u'mode', self.__mode), log.ERROR)
-            raise BackendException(u"MultiBackend: invalid mode value")
+            log.Log(_("MultiBackend: illegal value for %s: %s")
+                    % ('mode', self.__mode), log.ERROR)
+            raise BackendException("MultiBackend: invalid mode value")
 
         if self.__onfail_mode not in MultiBackend.__onfail_mode_allowedSet:
-            log.Log(_(u"MultiBackend: illegal value for %s: %s")
-                    % (u'onfail', self.__onfail_mode), log.ERROR)
-            raise BackendException(u"MultiBackend: invalid onfail value")
+            log.Log(_("MultiBackend: illegal value for %s: %s")
+                    % ('onfail', self.__onfail_mode), log.ERROR)
+            raise BackendException("MultiBackend: invalid onfail value")
 
-        if u'subpath' in queryParams:
-            self.__subpath = queryParams[u'subpath']
+        if 'subpath' in queryParams:
+            self.__subpath = queryParams['subpath']
 
         try:
             with open(parsed_url.path) as f:
                 configs = json.load(f)
         except IOError as e:
-            log.Log(_(u"MultiBackend: Url %s")
+            log.Log(_("MultiBackend: Url %s")
                     % (parsed_url.strip_auth()),
                     log.ERROR)
 
-            log.Log(_(u"MultiBackend: Could not load config file %s: %s ")
+            log.Log(_("MultiBackend: Could not load config file %s: %s ")
                     % (parsed_url.path, e),
                     log.ERROR)
-            raise BackendException(u'Could not load config file')
+            raise BackendException('Could not load config file')
 
         for config in configs:
-            url = config[u'url'] + self.__subpath
-            if sys.version_info.major == 2:
-                url = url.encode(u'utf-8')
-            log.Log(_(u"MultiBackend: use store %s")
-                    % (url),
+            url = config['url'] + self.__subpath
+            log.Log(_("MultiBackend: use store %s")
+                    % url,
                     log.INFO)
-            if u'env' in config:
-                for env in config[u'env']:
-                    log.Log(_(u"MultiBackend: set env %s = %s")
-                            % (env[u'name'], env[u'value']),
+            if 'env' in config:
+                for env in config['env']:
+                    log.Log(_("MultiBackend: set env %s = %s")
+                            % (env['name'], env['value']),
                             log.INFO)
-                    os.environ[env[u'name']] = env[u'value']
+                    os.environ[env['name']] = env['value']
 
             store = duplicity.backend.get_backend(url)
             self.__stores.append(store)
 
             # Prefix affinity
-            if u'prefixes' in config:
-                if self.__mode == u'stripe':
-                    raise BackendException(u"Multibackend: stripe mode not supported with prefix affinity.")
-                for prefix in config[u'prefixes']:
-                    log.Log(_(u"Multibackend: register affinity for prefix %s")
+            if 'prefixes' in config:
+                if self.__mode == 'stripe':
+                    raise BackendException("Multibackend: stripe mode not supported with prefix affinity.")
+                for prefix in config['prefixes']:
+                    log.Log(_("Multibackend: register affinity for prefix %s")
                             % prefix, log.INFO)
                     if prefix in self.__affinities:
                         self.__affinities[prefix].append(store)
                     else:
                         self.__affinities[prefix] = [store]
 
             # store_list = store.list()
             # log.Log(_("MultiBackend: at init, store %s has %s files")
             #         % (url, len(store_list)),
             #         log.INFO)
 
     def _eligible_stores(self, filename):
         if self.__affinities:
-            matching_prefixes = [k for k in list(self.__affinities.keys()) if util.fsdecode(filename).startswith(k)]
+            matching_prefixes = [k for k in list(self.__affinities.keys()) if os.fsdecode(filename).startswith(k)]
             matching_stores = {store for prefix in matching_prefixes for store in self.__affinities[prefix]}
             if matching_stores:
                 # Distinct stores with matching prefix
                 return list(matching_stores)
 
         # No affinity rule or no matching store for that prefix
         return self.__stores
@@ -231,55 +226,55 @@
         # Store an indication of whether any of these passed
         passed = False
 
         # Eligibile stores for this action
         stores = self._eligible_stores(remote_filename)
 
         # Mirror mode always starts at zero
-        if self.__mode == u'mirror':
+        if self.__mode == 'mirror':
             self.__write_cursor = 0
 
         first = self.__write_cursor
         while True:
             store = stores[self.__write_cursor]
             try:
                 next = self.__write_cursor + 1  # pylint: disable=redefined-builtin
-                if (next > len(stores) - 1):
+                if next > len(stores) - 1:
                     next = 0
-                log.Log(_(u"MultiBackend: _put: write to store #%s (%s)")
+                log.Log(_("MultiBackend: _put: write to store #%s (%s)")
                         % (self.__write_cursor, store.backend.parsed_url.strip_auth()),
                         log.DEBUG)
                 store.put(source_path, remote_filename)
                 passed = True
                 self.__write_cursor = next
                 # No matter what, if we loop around, break this loop
                 if next == 0:
                     break
                 # If in stripe mode, don't continue to the next
-                if self.__mode == u'stripe':
+                if self.__mode == 'stripe':
                     break
             except Exception as e:
-                log.Log(_(u"MultiBackend: failed to write to store #%s (%s), try #%s, Exception: %s")
+                log.Log(_("MultiBackend: failed to write to store #%s (%s), try #%s, Exception: %s")
                         % (self.__write_cursor, store.backend.parsed_url.strip_auth(), next, e),
                         log.INFO)
                 self.__write_cursor = next
 
                 # If we consider write failure as abort, abort
-                if self.__onfail_mode == u'abort':
-                    log.Log(_(u"MultiBackend: failed to write %s. Aborting process.")
-                            % (source_path),
+                if self.__onfail_mode == 'abort':
+                    log.Log(_("MultiBackend: failed to write %s. Aborting process.")
+                            % source_path,
                             log.ERROR)
-                    raise BackendException(u"failed to write")
+                    raise BackendException("failed to write")
 
                 # If we've looped around, and none of them passed, fail
                 if (self.__write_cursor == first) and not passed:
-                    log.Log(_(u"MultiBackend: failed to write %s. Tried all backing stores and none succeeded")
-                            % (source_path),
+                    log.Log(_("MultiBackend: failed to write %s. Tried all backing stores and none succeeded")
+                            % source_path,
                             log.ERROR)
-                    raise BackendException(u"failed to write")
+                    raise BackendException("failed to write")
 
     def _get(self, remote_filename, local_path):
         # since the backend operations will be retried, we can't
         # simply try to get from the store, if not found, move to the
         # next store (since each failure will be retried n times
         # before finally giving up).  So we need to get the list first
         # before we try to fetch
@@ -287,39 +282,38 @@
         stores = self._eligible_stores(remote_filename)
 
         for s in stores:
             flist = s.list()
             if remote_filename in flist:
                 s.get(remote_filename, local_path)
                 return
-            log.Log(_(u"MultiBackend: failed to get %s to %s from %s")
+            log.Log(_("MultiBackend: failed to get %s to %s from %s")
                     % (remote_filename, local_path, s.backend.parsed_url.strip_auth()),
                     log.INFO)
-        log.Log(_(u"MultiBackend: failed to get %s. Tried all backing stores and none succeeded")
-                % (remote_filename),
+        log.Log(_("MultiBackend: failed to get %s. Tried all backing stores and none succeeded")
+                % remote_filename,
                 log.ERROR)
-        raise BackendException(u"failed to get")
+        raise BackendException("failed to get")
 
     def _list(self):
         lists = []
         for s in self.__stores:
-            config.are_errors_fatal[u'list'] = (False, [])
+            config.are_errors_fatal['list'] = (False, [])
             l = s.list()
-            log.Notice(_(u"MultiBackend: %s: %d files")
+            log.Notice(_("MultiBackend: %s: %d files")
                        % (s.backend.parsed_url.strip_auth(), len(l)))
             if len(l) == 0 and duplicity.backend._last_exception:
-                log.Warn(_(u"Exception during list of %s: %s"
-                           % (s.backend.parsed_url.strip_auth(),
-                              util.uexc(duplicity.backend._last_exception))))
+                log.Warn(_(f"Exception during list of {s.backend.parsed_url.strip_auth()}: "
+                           f"{util.uexc(duplicity.backend._last_exception)}"))
                 duplicity.backend._last_exception = None
             lists.append(l)
         # combine the lists into a single flat list w/o duplicates via set:
         result = list({item for sublist in lists for item in sublist})
-        log.Log(_(u"MultiBackend: combined list: %s")
-                % (result),
+        log.Log(_("MultiBackend: combined list: %s")
+                % result,
                 log.DEBUG)
         return result
 
     def _delete(self, filename):
         # Store an indication on whether any passed
         passed = False
 
@@ -330,25 +324,25 @@
         # next store (since each failure will be retried n times
         # before finally giving up).  So we need to get the list first
         # before we try to delete
         # ENHANCEME: maintain a cached list for each store
         for s in stores:
             flist = s.list()
             if filename in flist:
-                if hasattr(s.backend, u'_delete_list'):
+                if hasattr(s.backend, '_delete_list'):
                     s._do_delete_list([filename, ])
-                elif hasattr(s.backend, u'_delete'):
+                elif hasattr(s.backend, '_delete'):
                     s._do_delete(filename)
                 passed = True
                 # In stripe mode, only one item will have the file
-                if self.__mode == u'stripe':
+                if self.__mode == 'stripe':
                     return
         if not passed:
-            log.Log(_(u"MultiBackend: failed to delete %s. Tried all backing stores and none succeeded")
-                    % (filename),
+            log.Log(_("MultiBackend: failed to delete %s. Tried all backing stores and none succeeded")
+                    % filename,
                     log.ERROR)
 
     def _delete_list(self, filenames):
         # Store an indication on whether any passed
         passed = False
 
         stores = self.__stores
@@ -358,36 +352,36 @@
         # next store (since each failure will be retried n times
         # before finally giving up).  So we need to get the list first
         # before we try to delete
         # ENHANCEME: maintain a cached list for each store
         for s in stores:
             flist = s.list()
             cleaned = [f for f in filenames if f in flist]
-            if hasattr(s.backend, u'_delete_list'):
+            if hasattr(s.backend, '_delete_list'):
                 s._do_delete_list(cleaned)
-            elif hasattr(s.backend, u'_delete'):
+            elif hasattr(s.backend, '_delete'):
                 for filename in cleaned:
                     s._do_delete(filename)
             passed = True
             # In stripe mode, only one item will have the file
-            if self.__mode == u'stripe':
+            if self.__mode == 'stripe':
                 return
         if not passed:
-            log.Log(_(u"MultiBackend: failed to delete %s. Tried all backing stores and none succeeded")
-                    % (filenames),
+            log.Log(_("MultiBackend: failed to delete %s. Tried all backing stores and none succeeded")
+                    % filenames,
                     log.ERROR)
 
     def pre_process_download(self, filename):
         for store in self.__stores:
-            if hasattr(store.backend, u'pre_process_download'):
+            if hasattr(store.backend, 'pre_process_download'):
                 store.backend.pre_process_download(filename)
 
     def pre_process_download_batch(self, filenames):
         set_files = set(filenames)
         for store in self.__stores:
-            if hasattr(store.backend, u'pre_process_download_batch'):
+            if hasattr(store.backend, 'pre_process_download_batch'):
                 store_files_to_download = set_files.intersection(store.list())
                 if len(store_files_to_download) > 0:
                     store.backend.pre_process_download_batch(store_files_to_download)
 
 
-duplicity.backend.register_backend(u'multi', MultiBackend)
+duplicity.backend.register_backend('multi', MultiBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/dpbxbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/dpbxbackend.py`

 * *Files 8% similar despite different names*

```diff
@@ -21,31 +21,29 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from __future__ import division
-from future import standard_library
-standard_library.install_aliases()
-from builtins import input
-from builtins import str
+
 import io
 import os
 import re
 import sys
 import time
 import traceback
-import urllib.request  # pylint: disable=import-error
-import urllib.parse  # pylint: disable=import-error
-import urllib.error  # pylint: disable=import-error
-
-from duplicity import log, config
+import urllib.error
+import urllib.parse
+import urllib.request
+
+from duplicity import (
+    log,
+    config,
+)
 from duplicity import progress
 from duplicity.errors import BackendException
 from requests.exceptions import ConnectionError  # pylint: disable=redefined-builtin
 import duplicity.backend
 
 # This is chunk size for upload using Dpbx chumked API v2. It doesn't
 # make sense to make it much large since Dpbx SDK uses connection pool
@@ -57,145 +55,153 @@
 # Download internal buffer size. Files are downloaded using one request.
 DPBX_DOWNLOAD_BUF_SIZE = 512 * 1024
 
 DPBX_AUTORENAMED_FILE_RE = re.compile(r' \([0-9]+\)\.[^\.]+$')
 
 
 def log_exception(e):
-    log.Error(u'Exception [%s]:' % (e,))
+    log.Error(f'Exception [{e}]:')
     f = io.StringIO()
     traceback.print_exc(file=f)
     f.seek(0)
     for s in f.readlines():
-        log.Error(u'| ' + s.rstrip())
+        log.Error(f"| {s.rstrip()}")
     f.close()
 
 
 def command(login_required=True):  # pylint: disable=unused-argument
-    u"""a decorator for handling authentication and exceptions"""
+    """a decorator for handling authentication and exceptions"""
+
     def decorate(f):
         def wrapper(self, *args):
             try:
                 return f(self, *args)
             except ApiError as e:
                 log_exception(e)
-                raise BackendException(u'dpbx api error "%s"' % (e,))
+                raise BackendException(f'dpbx api error "{e}"')
             except Exception as e:
                 log_exception(e)
-                log.Error(u'dpbx code error "%s"' % (e,), log.ErrorCode.backend_code_error)
+                log.Error(f'dpbx code error "{e}"', log.ErrorCode.backend_code_error)
                 raise
 
         wrapper.__doc__ = f.__doc__
         return wrapper
+
     return decorate
 
 
 class DPBXBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using Dr*pB*x service"""
+    """Connect to remote store using Dr*pB*x service"""
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         global Dropbox
         global AuthError, BadInputError, ApiError
         global UploadSessionCursor, CommitInfo
         global WriteMode, GetMetadataError
         global DeleteError, UploadSessionLookupError
         global ListFolderError
         global DropboxOAuth2FlowNoRedirect
         try:
             from dropbox import Dropbox
-            from dropbox.exceptions import AuthError, BadInputError, ApiError
-            from dropbox.files import (UploadSessionCursor, CommitInfo,
-                                       WriteMode, GetMetadataError,
-                                       DeleteError, UploadSessionLookupError,
-                                       ListFolderError)
+            from dropbox.exceptions import (
+                AuthError,
+                BadInputError,
+                ApiError,
+            )
+            from dropbox.files import (
+                UploadSessionCursor,
+                CommitInfo,
+                WriteMode,
+                GetMetadataError,
+                DeleteError,
+                UploadSessionLookupError,
+                ListFolderError,
+            )
             from dropbox.oauth import DropboxOAuth2FlowNoRedirect
         except ImportError as e:
-            raise BackendException(u"""\
-This backend requires the dropbox package version 6.9.0
+            raise BackendException(f"""This backend requires the dropbox package version 6.9.0
 To install use "sudo pip install dropbox==6.9.0"
-Exception: %s""" % str(e))
+Exception: {str(e)}""")
 
         self.api_account = None
         self.api_client = None
         self.auth_flow = None
 
         self.login()
 
     def user_authenticated(self):
         try:
             account = self.api_client.users_get_current_account()
-            log.Debug(u"User authenticated as ,%s" % account)
+            log.Debug(f"User authenticated as ,{account}")
             return True
-        except:
-            log.Debug(u'User not authenticated')
+        except Exception as e:
+            log.Debug('User not authenticated')
             return False
 
     def load_access_token(self):
-        return os.environ.get(u'DPBX_ACCESS_TOKEN', None)
+        return os.environ.get('DPBX_ACCESS_TOKEN', None)
 
     def save_access_token(self, access_token):
-        raise BackendException(u'dpbx: Please set DPBX_ACCESS_TOKEN=\"%s\" environment variable' %
-                               access_token)
+        raise BackendException(f'dpbx: Please set DPBX_ACCESS_TOKEN="{access_token}" environment variable')
 
     def obtain_access_token(self):
-        log.Info(u"dpbx: trying to obtain access token")
-        for env_var in [u'DPBX_APP_KEY', u'DPBX_APP_SECRET']:
+        log.Info("dpbx: trying to obtain access token")
+        for env_var in ['DPBX_APP_KEY', 'DPBX_APP_SECRET']:
             if env_var not in os.environ:
-                raise BackendException(u'dpbx: %s environment variable not set' % env_var)
+                raise BackendException(f'dpbx: {env_var} environment variable not set')
 
-        app_key = os.environ[u'DPBX_APP_KEY']
-        app_secret = os.environ[u'DPBX_APP_SECRET']
+        app_key = os.environ['DPBX_APP_KEY']
+        app_secret = os.environ['DPBX_APP_SECRET']
 
         if not sys.stdout.isatty() or not sys.stdin.isatty():
-            log.FatalError(u'dpbx error: cannot interact, but need human attention',
+            log.FatalError('dpbx error: cannot interact, but need human attention',
                            log.ErrorCode.backend_command_error)
 
         auth_flow = DropboxOAuth2FlowNoRedirect(app_key, app_secret)
-        log.Debug(u'dpbx,auth_flow.start()')
+        log.Debug('dpbx,auth_flow.start()')
         authorize_url = auth_flow.start()
         print()
-        print(u'-' * 72)
-        print(u"1. Go to: " + authorize_url)
-        print(u"2. Click \"Allow\" (you might have to log in first).")
-        print(u"3. Copy the authorization code.")
-        print(u'-' * 72)
-        auth_code = input(u"Enter the authorization code here: ").strip()
+        print('-' * 72)
+        print(f"1. Go to: {authorize_url}")
+        print("2. Click \"Allow\" (you might have to log in first).")
+        print("3. Copy the authorization code.")
+        print('-' * 72)
+        auth_code = input("Enter the authorization code here: ").strip()
         try:
-            log.Debug(u'dpbx,auth_flow.finish(%s)' % auth_code)
+            log.Debug(f'dpbx,auth_flow.finish({auth_code})')
             authresult = auth_flow.finish(auth_code)
         except Exception as e:
-            raise BackendException(u'dpbx: Unable to obtain access token: %s' % e)
-        log.Info(u"dpbx: Authentication successfull")
+            raise BackendException(f'dpbx: Unable to obtain access token: {e}')
+        log.Info("dpbx: Authentication successfull")
         self.save_access_token(authresult.access_token)
 
     def login(self):
         if self.load_access_token() is None:
             self.obtain_access_token()
 
         self.api_client = Dropbox(self.load_access_token())
         self.api_account = None
         try:
-            log.Debug(u'dpbx,users_get_current_account([token])')
+            log.Debug('dpbx,users_get_current_account([token])')
             self.api_account = self.api_client.users_get_current_account()
-            log.Debug(u"dpbx,%s" % self.api_account)
+            log.Debug(f"dpbx,{self.api_account}")
 
         except (BadInputError, AuthError) as e:
-            log.Debug(u'dpbx,exception: %s' % e)
-            log.Info(u"dpbx: Authentication failed. Trying to obtain new access token")
+            log.Debug(f'dpbx,exception: {e}')
+            log.Info("dpbx: Authentication failed. Trying to obtain new access token")
 
             self.obtain_access_token()
 
             # We're assuming obtain_access_token will throw exception.
             # So this line should not be reached
-            raise BackendException(u"dpbx: Please update DPBX_ACCESS_TOKEN and try again")
+            raise BackendException("dpbx: Please update DPBX_ACCESS_TOKEN and try again")
 
-        log.Info(u"dpbx: Successfully authenticated as %s" %
-                 self.api_account.name.display_name)
+        log.Info(f"dpbx: Successfully authenticated as {self.api_account.name.display_name}")
 
     def _error_code(self, operation, e):  # pylint: disable=unused-argument
         if isinstance(e, ApiError):
             err = e.error
 
             if isinstance(err, GetMetadataError) and err.is_path():
                 if err.get_path().is_not_found():
@@ -203,66 +209,63 @@
             elif isinstance(err, DeleteError) and err.is_path_lookup():
                 lookup = e.error.get_path_lookup()
                 if lookup.is_not_found():
                     return log.ErrorCode.backend_not_found
 
     @command()
     def _put(self, source_path, remote_filename):
-        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip(u'/'))
-        remote_path = u'/' + os.path.join(remote_dir, remote_filename.decode()).rstrip()
+        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip('/'))
+        remote_path = f"/{os.path.join(remote_dir, remote_filename.decode()).rstrip()}"
 
         file_size = os.path.getsize(source_path.name)
         progress.report_transfer(0, file_size)
 
         if file_size < DPBX_UPLOAD_CHUNK_SIZE:
             # Upload whole file at once to avoid extra server request
             res_metadata = self.put_file_small(source_path, remote_path)
         else:
             res_metadata = self.put_file_chunked(source_path, remote_path)
 
         # A few sanity checks
         if res_metadata.path_display != remote_path:
-            raise BackendException(u'dpbx: result path mismatch: %s (expected: %s)' %
-                                   (res_metadata.path_display, remote_path))
+            raise BackendException(f'dpbx: result path mismatch: {res_metadata.path_display} (expected: {remote_path})')
         if res_metadata.size != file_size:
-            raise BackendException(u'dpbx: result size mismatch: %s (expected: %s)' %
-                                   (res_metadata.size, file_size))
+            raise BackendException(f'dpbx: result size mismatch: {res_metadata.size} (expected: {file_size})')
 
     def put_file_small(self, source_path, remote_path):
         if not self.user_authenticated():
             self.login()
 
         file_size = os.path.getsize(source_path.name)
-        f = source_path.open(u'rb')
+        f = source_path.open('rb')
         try:
-            log.Debug(u'dpbx,files_upload(%s, [%d bytes])' % (remote_path, file_size))
+            log.Debug(f'dpbx,files_upload({remote_path}, [{int(file_size)} bytes])')
 
             res_metadata = self.api_client.files_upload(f.read(), remote_path,
                                                         mode=WriteMode.overwrite,
                                                         autorename=False,
                                                         client_modified=None,
                                                         mute=True)
-            log.Debug(u'dpbx,files_upload(): %s' % res_metadata)
+            log.Debug(f'dpbx,files_upload(): {res_metadata}')
             progress.report_transfer(file_size, file_size)
             return res_metadata
         finally:
             f.close()
 
     def put_file_chunked(self, source_path, remote_path):
         if not self.user_authenticated():
             self.login()
 
         file_size = os.path.getsize(source_path.name)
-        f = source_path.open(u'rb')
+        f = source_path.open('rb')
         try:
             buf = f.read(DPBX_UPLOAD_CHUNK_SIZE)
-            log.Debug(u'dpbx,files_upload_session_start([%d bytes]), total: %d' %
-                      (len(buf), file_size))
+            log.Debug(f'dpbx,files_upload_session_start([{len(buf)} bytes]), total: {int(file_size)}')
             upload_sid = self.api_client.files_upload_session_start(buf)
-            log.Debug(u'dpbx,files_upload_session_start(): %s' % upload_sid)
+            log.Debug(f'dpbx,files_upload_session_start(): {upload_sid}')
             upload_cursor = UploadSessionCursor(upload_sid.session_id, f.tell())
             commit_info = CommitInfo(remote_path, mode=WriteMode.overwrite,
                                      autorename=False, client_modified=None,
                                      mute=True)
             res_metadata = None
             progress.report_transfer(f.tell(), file_size)
 
@@ -290,196 +293,193 @@
                     # reset temporary status variables
                     requested_offset = None
                     current_chunk_size = DPBX_UPLOAD_CHUNK_SIZE
                     retry_number = config.num_retries
 
                     if not is_eof:
                         assert len(buf) != 0
-                        log.Debug(u'dpbx,files_upload_sesssion_append([%d bytes], offset=%d)' %
-                                  (len(buf), upload_cursor.offset))
+                        log.Debug(f'dpbx,files_upload_sesssion_append([{len(buf)} bytes], '
+                                  f'offset={int(upload_cursor.offset)})')
                         self.api_client.files_upload_session_append(buf,
                                                                     upload_cursor.session_id,
                                                                     upload_cursor.offset)
                     else:
-                        log.Debug(u'dpbx,files_upload_sesssion_finish([%d bytes], offset=%d)' %
-                                  (len(buf), upload_cursor.offset))
+                        log.Debug(f'dpbx,files_upload_sesssion_finish([{len(buf)} bytes], '
+                                  f'offset={int(upload_cursor.offset)})')
                         res_metadata = self.api_client.files_upload_session_finish(buf,
                                                                                    upload_cursor,
                                                                                    commit_info)
 
                     upload_cursor.offset = f.tell()
-                    log.Debug(u'progress: %d of %d' % (upload_cursor.offset,
-                                                       file_size))
+                    log.Debug(f'progress: {int(upload_cursor.offset)} of {int(file_size)}')
                     progress.report_transfer(upload_cursor.offset, file_size)
                 except ApiError as e:
                     error = e.error
                     if isinstance(error, UploadSessionLookupError) and error.is_incorrect_offset():
                         # Server reports that we should send another chunk.
                         # Most likely this is caused by network error during
                         # previous upload attempt. In such case we'll get
                         # expected offset from server and it's enough to just
                         # seek() and retry again
                         new_offset = error.get_incorrect_offset().correct_offset
-                        log.Debug(u'dpbx,files_upload_session_append: incorrect offset: %d (expected: %s)' %
-                                  (upload_cursor.offset, new_offset))
+                        log.Debug(f'dpbx,files_upload_session_append: incorrect offset: {int(upload_cursor.offset)} '
+                                  f'(expected: {new_offset})')
                         if requested_offset is not None:
                             # chunk failed even after seek attempt. Something
                             # strange and no safe way to recover
-                            raise BackendException(u"dpbx: unable to chunk upload")
+                            raise BackendException("dpbx: unable to chunk upload")
                         else:
                             # will seek and retry
                             requested_offset = new_offset
                         continue
                     raise
                 except ConnectionError as e:
-                    log.Debug(u'dpbx,files_upload_session_append: %s' % e)
+                    log.Debug(f'dpbx,files_upload_session_append: {e}')
 
                     retry_number -= 1
 
                     if not self.user_authenticated():
                         self.login()
 
                     if retry_number == 0:
                         raise
 
                     # We don't know for sure, was partial upload successful or
                     # not. So it's better to retry smaller amount to avoid extra
                     # reupload
-                    log.Info(u'dpbx: sleeping a bit before chunk retry')
+                    log.Info('dpbx: sleeping a bit before chunk retry')
                     time.sleep(30)
                     current_chunk_size = DPBX_UPLOAD_CHUNK_SIZE / 5
                     requested_offset = None
                     continue
 
             if f.tell() != file_size:
-                raise BackendException(u'dpbx: something wrong')
+                raise BackendException('dpbx: something wrong')
 
-            log.Debug(u'dpbx,files_upload_sesssion_finish(): %s' % res_metadata)
+            log.Debug(f'dpbx,files_upload_sesssion_finish(): {res_metadata}')
             progress.report_transfer(f.tell(), file_size)
 
             return res_metadata
 
         finally:
             f.close()
 
     @command()
     def _get(self, remote_filename, local_path):
         if not self.user_authenticated():
             self.login()
 
-        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip(u'/'))
-        remote_path = u'/' + os.path.join(remote_dir, remote_filename.decode()).rstrip()
+        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip('/'))
+        remote_path = f"/{os.path.join(remote_dir, remote_filename.decode()).rstrip()}"
 
-        log.Debug(u'dpbx,files_download(%s)' % remote_path)
+        log.Debug(f'dpbx,files_download({remote_path})')
         res_metadata, http_fd = self.api_client.files_download(remote_path)
-        log.Debug(u'dpbx,files_download(%s): %s, %s' % (remote_path, res_metadata,
-                                                        http_fd))
+        log.Debug(f'dpbx,files_download({remote_path}): {res_metadata}, {http_fd}')
         file_size = res_metadata.size
         to_fd = None
         progress.report_transfer(0, file_size)
         try:
-            to_fd = local_path.open(u'wb')
+            to_fd = local_path.open('wb')
             for c in http_fd.iter_content(DPBX_DOWNLOAD_BUF_SIZE):
                 to_fd.write(c)
                 progress.report_transfer(to_fd.tell(), file_size)
 
         finally:
             if to_fd:
                 to_fd.close()
             http_fd.close()
 
         # It's different from _query() check because we're not querying metadata
         # again. Since this check is free, it's better to have it here
         local_size = os.path.getsize(local_path.name)
         if local_size != file_size:
-            raise BackendException(u"dpbx: wrong file size: %d (expected: %d)" %
-                                   (local_size, file_size))
+            raise BackendException(f"dpbx: wrong file size: {int(local_size)} (expected: {int(file_size)})")
 
         local_path.setdata()
 
     @command()
     def _list(self):
         # Do a long listing to avoid connection reset
         if not self.user_authenticated():
             self.login()
-        remote_dir = u'/' + urllib.parse.unquote(self.parsed_url.path.lstrip(u'/')).rstrip()
+        remote_dir = f"/{urllib.parse.unquote(self.parsed_url.path.lstrip('/')).rstrip()}"
 
-        log.Debug(u'dpbx.files_list_folder(%s)' % remote_dir)
+        log.Debug(f'dpbx.files_list_folder({remote_dir})')
         res = []
         try:
             resp = self.api_client.files_list_folder(remote_dir)
-            log.Debug(u'dpbx.list(%s): %s' % (remote_dir, resp))
+            log.Debug(f'dpbx.list({remote_dir}): {resp}')
 
             while True:
                 res.extend([entry.name for entry in resp.entries])
                 if not resp.has_more:
                     break
                 resp = self.api_client.files_list_folder_continue(resp.cursor)
         except ApiError as e:
             if (isinstance(e.error, ListFolderError) and e.error.is_path() and
                     e.error.get_path().is_not_found()):
-                log.Debug(u'dpbx.list(%s): ignore missing folder (%s)' % (remote_dir, e))
+                log.Debug(f'dpbx.list({remote_dir}): ignore missing folder ({e})')
             else:
                 raise
 
         # Warn users of old version dpbx about automatically renamed files
         self.check_renamed_files(res)
 
         return res
 
     @command()
     def _delete(self, filename):
         if not self.user_authenticated():
             self.login()
 
-        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip(u'/'))
-        remote_path = u'/' + os.path.join(remote_dir, filename.decode()).rstrip()
+        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip('/'))
+        remote_path = f"/{os.path.join(remote_dir, filename.decode()).rstrip()}"
 
-        log.Debug(u'dpbx.files_delete(%s)' % remote_path)
+        log.Debug(f'dpbx.files_delete({remote_path})')
         self.api_client.files_delete(remote_path)
 
         # files_permanently_delete seems to be better for backup purpose
         # but it's only available for Business accounts
         # self.api_client.files_permanently_delete(remote_path)
 
     @command()
     def _close(self):
-        u"""close backend session? no! just "flush" the data"""
-        log.Debug(u'dpbx.close():')
+        """close backend session? no! just "flush" the data"""
+        log.Debug('dpbx.close():')
 
     @command()
     def _query(self, filename):
         if not self.user_authenticated():
             self.login()
-        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip(u'/'))
-        remote_path = u'/' + os.path.join(remote_dir, filename.decode()).rstrip()
+        remote_dir = urllib.parse.unquote(self.parsed_url.path.lstrip('/'))
+        remote_path = f"/{os.path.join(remote_dir, filename.decode()).rstrip()}"
 
-        log.Debug(u'dpbx.files_get_metadata(%s)' % remote_path)
+        log.Debug(f'dpbx.files_get_metadata({remote_path})')
         info = self.api_client.files_get_metadata(remote_path)
-        log.Debug(u'dpbx.files_get_metadata(%s): %s' % (remote_path, info))
-        return {u'size': info.size}
+        log.Debug(f'dpbx.files_get_metadata({remote_path}): {info}')
+        return {'size': info.size}
 
     def check_renamed_files(self, file_list):
         if not self.user_authenticated():
             self.login()
         bad_list = [x for x in file_list if DPBX_AUTORENAMED_FILE_RE.search(x) is not None]
         if len(bad_list) == 0:
             return
-        log.Warn(u'-' * 72)
-        log.Warn(u'Warning! It looks like there are automatically renamed files on backend')
-        log.Warn(u'They were probably created when using older version of duplicity.')
-        log.Warn(u'')
-        log.Warn(u'Please check your backup consistency. Most likely you will need to choose')
-        log.Warn(u'largest file from duplicity-* (number).gpg and remove brackets from its name.')
-        log.Warn(u'')
-        log.Warn(u'These files are not managed by duplicity at all and will not be')
-        log.Warn(u'removed/rotated automatically.')
-        log.Warn(u'')
-        log.Warn(u'Affected files:')
+        log.Warn('-' * 72)
+        log.Warn('Warning! It looks like there are automatically renamed files on backend')
+        log.Warn('They were probably created when using older version of duplicity.')
+        log.Warn('')
+        log.Warn('Please check your backup consistency. Most likely you will need to choose')
+        log.Warn('largest file from duplicity-* (number).gpg and remove brackets from its name.')
+        log.Warn('')
+        log.Warn('These files are not managed by duplicity at all and will not be')
+        log.Warn('removed/rotated automatically.')
+        log.Warn('')
+        log.Warn('Affected files:')
         for x in bad_list:
-            log.Warn(u'\t%s' % x)
-        log.Warn(u'')
-        log.Warn(u'In any case it\'s better to create full backup.')
-        log.Warn(u'-' * 72)
+            log.Warn(f'\t{x}')
+        log.Warn('')
+        log.Warn('In any case it\'s better to create full backup.')
+        log.Warn('-' * 72)
 
 
-duplicity.backend.register_backend(u"dpbx", DPBXBackend)
+duplicity.backend.register_backend("dpbx", DPBXBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/boxbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/boxbackend.py`

 * *Files 7% similar despite different names*

```diff
@@ -14,104 +14,104 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
 
 import os
 
 import duplicity.backend
-from boxsdk import Client, JWTAuth
 from duplicity.errors import BackendException
-from future import standard_library
-
-standard_library.install_aliases()
 
 
 class BoxBackend(duplicity.backend.Backend):
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
+        from boxsdk import (
+            Client,
+            JWTAuth,
+        )
+
         self._client = self.get_box_client(parsed_url)
         self._folder = (
             parsed_url.path[1:]
-            if parsed_url.path[0] == u'/'
+            if parsed_url.path[0] == '/'
             else parsed_url.path
         )
 
         self._file_to_metadata_map = {}
         self._folder_id = self.get_id_from_path(self._folder)
         if self._folder_id is None:
             self._folder_id = self.makedirs(self._folder)
 
     def get_box_client(self, parsed_url):
         try:
             config_path = os.path.expanduser(
-                parsed_url.query_args[u'config'][0]
+                parsed_url.query_args['config'][0]
             )
             return Client(JWTAuth.from_settings_file(config_path))
         except Exception as e:
-            config_path = os.environ.get(u'BOX_CONFIG_PATH')
+            config_path = os.environ.get('BOX_CONFIG_PATH')
             if config_path is not None:
                 try:
                     return Client(JWTAuth.from_settings_file(config_path))
                 except Exception as e:
-                    raise BackendException(u'box config file is not found.')
+                    raise BackendException('box config file is not found.')
 
             raise BackendException(
-                u'box config file is not specified or not found.'
+                'box config file is not specified or not found.'
             )
 
     def _put(self, source_path, remote_filename):
-        u"""Uploads file to the specified remote folder
+        """Uploads file to the specified remote folder
         (tries to delete it first to make sure the new one can be uploaded)"""
 
         try:
             self.delete(remote_filename.decode())
         except Exception:
             pass
         self.upload(
             local_file=source_path.get_canonical().decode(),
             remote_file=remote_filename.decode(),
         )
 
     def _get(self, remote_filename, local_path):
-        u'Downloads file from the specified remote path'
+        """Downloads file from the specified remote path"""
 
         self.download(
             remote_file=remote_filename.decode(),
             local_file=local_path.name.decode(),
         )
 
     def _list(self):
-        u'Lists files in the specified remote path'
+        """Lists files in the specified remote path"""
 
         return self.folder_contents()
 
     def _delete(self, filename):
-        u'Deletes file from the specified remote path'
+        """Deletes file from the specified remote path"""
 
         self.delete(remote_file=filename.decode())
 
     def _query_list(self, filename_list):
-        u'Query metadata for a list of file'
+        """Query metadata for a list of file"""
         return {
             filename: self._file_to_metadata_map.get(
-                filename.decode(), {u'size': -1}
+                filename.decode(), {'size': -1}
             )
             for filename in filename_list
         }
 
-    def get_id_from_path(self, remote_path, parent_id=u'0'):
-        u'Get the folder or file id from its path'
+    def get_id_from_path(self, remote_path, parent_id='0'):
+        """Get the folder or file id from its path"""
         path_items = [
-            x.strip() for x in remote_path.split(u'/') if x.strip() != u''
+            x.strip() for x in remote_path.split('/') if x.strip() != ''
         ]
         head = path_items[0]
         tail = path_items[1:]
 
         while True:
             selected_item_id = None
             for item in self._client.folder(folder_id=parent_id).get_items():
@@ -127,36 +127,36 @@
             parent_id = selected_item_id
             head = tail[0]
             tail = tail[1:]
 
         return None
 
     def get_file_id_from_filename(self, remote_filename):
-        u'Get the fild id by its file name'
+        """Get the fild id by its file name"""
         file = self._file_to_metadata_map.get(remote_filename)
 
         if file is not None:
-            return file[u'id']
+            return file['id']
 
         file_id = self.get_id_from_path(
             remote_filename, parent_id=self._folder_id
         )
         file = self._client.file(file_id).get()
         self._file_to_metadata_map[file.name] = {
-            u'id': file.id,
-            u'size': file.size,
+            'id': file.id,
+            'size': file.size,
         }
         return file_id
 
     def makedirs(self, remote_path):
-        u'Create folder(s) in a path if necessary'
+        """Create folder(s) in a path if necessary"""
         path_items = [
-            x.strip() for x in remote_path.split(u'/') if x.strip() != u''
+            x.strip() for x in remote_path.split('/') if x.strip() != ''
         ]
-        parent_id = u'0'
+        parent_id = '0'
 
         start_folder_id = None
         while len(path_items) > 0:
             selected_item_id = None
             for item in self._client.folder(folder_id=parent_id).get_items():
                 if item.name == path_items[0]:
                     selected_item_id = item.id
@@ -176,47 +176,47 @@
                     item
                 )
                 parent_id = subfolder.id
 
         return parent_id
 
     def folder_contents(self):
-        u'Lists files of a remote box path'
+        """Lists files of a remote box path"""
 
         items = [
             x
             for x in self._client.folder(folder_id=self._folder_id).get_items(
-                fields=[u'id', u'name', u'size']
+                fields=['id', 'name', 'size']
             )
-            if x.type == u'file'
+            if x.type == 'file'
         ]
 
         self._file_to_metadata_map.update(
-            {x.name: {u'id': x.id, u'size': x.size} for x in items}
+            {x.name: {'id': x.id, 'size': x.size} for x in items}
         )
 
         return [x.name for x in items]
 
     def upload(self, remote_file, local_file):
-        u'Upload local file to the box folder'
+        """Upload local file to the box folder"""
         new_file = self._client.folder(self._folder_id).upload(
             file_path=local_file, file_name=remote_file
         )
 
         self._file_to_metadata_map[new_file.name] = {
-            u'id': new_file.id,
-            u'size': new_file.size,
+            'id': new_file.id,
+            'size': new_file.size,
         }
 
     def download(self, remote_file, local_file):
-        u'Download file in box folder'
+        """Download file in box folder"""
         file_id = self.get_file_id_from_filename(remote_file)
-        with open(local_file, u'wb') as fp:
+        with open(local_file, 'wb') as fp:
             self._client.file(file_id).download_to(fp)
 
     def delete(self, remote_file):
-        u'Delete file in box folder'
+        """Delete file in box folder"""
         file_id = self.get_file_id_from_filename(remote_file)
         self._client.file(file_id).delete()
 
 
-duplicity.backend.register_backend(u'box', BoxBackend)
+duplicity.backend.register_backend('box', BoxBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/cfbackend.py` & `duplicity-2.0.0rc0/duplicity/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
-# Copyright 2013 Kenneth Loafman
+# Copyright 2002 Ben Escoto <ben@emerose.org>
+# Copyright 2007 Kenneth Loafman <kenneth@loafman.com>
 #
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
 # under the terms of the GNU General Public License as published by the
 # Free Software Foundation; either version 2 of the License, or (at your
 # option) any later version.
@@ -14,17 +15,12 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-import duplicity.backend
-from duplicity import config
+import gettext
 
-if (config.cf_backend and
-        config.cf_backend.lower().strip() == u'pyrax'):
-    from ._cf_pyrax import PyraxBackend as CFBackend
-else:
-    from ._cf_cloudfiles import CloudFilesBackend as CFBackend
+__version__ = '2.0.0rc0'
 
-duplicity.backend.register_backend(u"cf+http", CFBackend)
+gettext.install('duplicity', names=['ngettext'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/webdavbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/webdavbackend.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,42 +17,42 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from future import standard_library
-standard_library.install_aliases()
-from builtins import str
-from builtins import range
 
 import base64
 import http.client
 import os
 import re
 import shutil
-import urllib.request  # pylint: disable=import-error
-import urllib.parse  # pylint: disable=import-error
-import urllib.error  # pylint: disable=import-error
+import urllib.error
+import urllib.parse
+import urllib.request
 import xml.dom.minidom
 
 import duplicity.backend
 from duplicity import config
 from duplicity import log
 from duplicity import util
-from duplicity.errors import BackendException, FatalBackendException
+from duplicity.errors import (
+    BackendException,
+    FatalBackendException,
+)
 
 
 class CustomMethodRequest(urllib.request.Request):
-    u"""
+    """
     This request subclass allows explicit specification of
     the HTTP request method. Basic urllib.request.Request class
     chooses GET or POST depending on self.has_data()
     """
+
     def __init__(self, method, *args, **kwargs):
         self.method = method
         urllib.request.Request.__init__(self, *args, **kwargs)
 
     def get_method(self):
         return self.method
 
@@ -60,435 +60,409 @@
 class VerifiedHTTPSConnection(http.client.HTTPSConnection):
     def __init__(self, *args, **kwargs):
         try:
             global socket, ssl
             import socket
             import ssl
         except ImportError:
-            raise FatalBackendException(_(u"Missing socket or ssl python modules."))
+            raise FatalBackendException(_("Missing socket or ssl python modules."))
 
         http.client.HTTPSConnection.__init__(self, *args, **kwargs)
 
         self.cacert_file = config.ssl_cacert_file
-        self.cacert_candidates = [u"~/.duplicity/cacert.pem",
-                                  u"~/duplicity_cacert.pem",
-                                  u"/etc/duplicity/cacert.pem"]
+        self.cacert_candidates = ["~/.duplicity/cacert.pem",
+                                  "~/duplicity_cacert.pem",
+                                  "/etc/duplicity/cacert.pem"]
         # if no cacert file was given search default locations
         if not self.cacert_file:
             for path in self.cacert_candidates:
                 path = os.path.expanduser(path)
-                if (os.path.isfile(path)):
+                if os.path.isfile(path):
                     self.cacert_file = path
                     break
 
         # check if file is accessible (libssl errors are not very detailed)
         if self.cacert_file and not os.access(self.cacert_file, os.R_OK):
-            raise FatalBackendException(_(u"Cacert database file '%s' is not readable.") %
+            raise FatalBackendException(_("Cacert database file '%s' is not readable.") %
                                         self.cacert_file)
 
     def connect(self):
         # create new socket
         sock = socket.create_connection((self.host, self.port),
                                         self.timeout)
         if self._tunnel_host:
             self.sock = sock
             self.tunnel()
 
-        # python 2.7.9+ supports default system certs now
-        if u"create_default_context" in dir(ssl):
-            context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH,
-                                                 cafile=self.cacert_file,
-                                                 capath=config.ssl_cacert_path)
-            self.sock = context.wrap_socket(sock, server_hostname=self.host)
-        # the legacy way needing a cert file
-        else:
-            if config.ssl_cacert_path:
-                raise FatalBackendException(
-                    _(u"Option '--ssl-cacert-path' is not supported "
-                      u"with python 2.7.8 and below."))
-
-            if not self.cacert_file:
-                raise FatalBackendException(_(u"""\
-For certificate verification with python 2.7.8 or earlier a cacert database
-file is needed in one of these locations: %s
-Hints:
-Consult the man page, chapter 'SSL Certificate Verification'.
-Consider using the options --ssl-cacert-file, --ssl-no-check-certificate .""") %
-                                            u", ".join(self.cacert_candidates))
-
-            # wrap the socket in ssl using verification
-            self.sock = ssl.wrap_socket(sock,
-                                        cert_reqs=ssl.CERT_REQUIRED,
-                                        ca_certs=self.cacert_file,
-                                        )
+        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH,
+                                             cafile=self.cacert_file,
+                                             capath=config.ssl_cacert_path)
+        self.sock = context.wrap_socket(sock, server_hostname=self.host)
 
     def request(self, *args, **kwargs):  # pylint: disable=method-hidden
         try:
             return http.client.HTTPSConnection.request(self, *args, **kwargs)
         except ssl.SSLError as e:
             # encapsulate ssl errors
-            raise BackendException(u"SSL failed: %s" % util.uexc(e),
+            raise BackendException(f"SSL failed: {util.uexc(e)}",
                                    log.ErrorCode.backend_error)
 
 
 class WebDAVBackend(duplicity.backend.Backend):
-    u"""Backend for accessing a WebDAV repository.
+    """Backend for accessing a WebDAV repository.
 
     webdav backend contributed in 2006 by Jesper Zedlitz <jesper@zedlitz.de>
     """
 
-    u"""
+    """
     Request just the names.
     """
-    listbody = u'<?xml version="1.0"?><D:propfind xmlns:D="DAV:"><D:prop><D:resourcetype/></D:prop></D:propfind>'
+    listbody = '<?xml version="1.0"?><D:propfind xmlns:D="DAV:"><D:prop><D:resourcetype/></D:prop></D:propfind>'
+
+    """Connect to remote store using WebDAV Protocol"""
 
-    u"""Connect to remote store using WebDAV Protocol"""
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
-        self.headers = {u'Connection': u'keep-alive'}
+        self.headers = {'Connection': 'keep-alive',
+                        'Content-Type': 'application/octet-stream'}
         if config.webdav_headers:
             try:
                 self.headers = util.merge_dicts(self.headers,
                                                 util.csv_args_to_dict(config.webdav_headers))
             except IndexError as e:
-                log.FatalError(u"--webdav-headers value has an odd number of arguments.  Must be paired.")
+                log.FatalError("--webdav-headers value has an odd number of arguments.  Must be paired.")
             except SyntaxError as e:
-                log.FatalError(u"--webdav-headers value has bad syntax.  Check quoting pairs.")
+                log.FatalError("--webdav-headers value has bad syntax.  Check quoting pairs.")
             except Exception as e:
-                log.FatalErrof(u"--webdav-headers value caused error: %s" % e)
+                log.FatalErrof(f"--webdav-headers value caused error: {e}")
 
         self.parsed_url = parsed_url
         self.digest_challenge = None
         self.digest_auth_handler = None
 
         self.username = parsed_url.username
         self.password = self.get_password()
         self.directory = self.sanitize_path(parsed_url.path)
 
-        log.Info(_(u"Using WebDAV host %s port %s") % (parsed_url.hostname,
-                                                       parsed_url.port))
-        log.Info(_(u"Using WebDAV directory %s") % (self.directory,))
+        log.Info(_("Using WebDAV host %s port %s") % (parsed_url.hostname,
+                                                      parsed_url.port))
+        log.Info(_("Using WebDAV directory %s") % (self.directory,))
 
         self.conn = None
 
     def sanitize_path(self, path):
         if path:
-            foldpath = re.compile(u'/+')
-            return foldpath.sub(u'/', path + u'/')
+            foldpath = re.compile('/+')
+            return foldpath.sub('/', f"{path}/")
         else:
-            return u'/'
+            return '/'
 
     def getText(self, nodelist):
-        rc = u""
+        rc = ""
         for node in nodelist:
             if node.nodeType == node.TEXT_NODE:
                 rc = rc + node.data
         return rc
 
     def _retry_cleanup(self):
         self.connect(forced=True)
 
     def connect(self, forced=False):
-        u"""
+        """
         Connect or re-connect to the server, updates self.conn
         # reconnect on errors as a precaution, there are errors e.g.
         # "[Errno 32] Broken pipe" or SSl errors that render the connection unusable
         """
         if not forced and self.conn \
                 and self.conn.host == self.parsed_url.hostname:
             return
 
-        log.Info(_(u"WebDAV create connection on '%s'") % (self.parsed_url.hostname))
+        log.Info(_("WebDAV create connection on '%s'") % self.parsed_url.hostname)
         self._close()
         # http schemes needed for redirect urls from servers
-        if self.parsed_url.scheme in [u'webdav', u'http']:
+        if self.parsed_url.scheme in ['webdav', 'http']:
             self.conn = http.client.HTTPConnection(self.parsed_url.hostname, self.parsed_url.port)
-        elif self.parsed_url.scheme in [u'webdavs', u'https']:
+        elif self.parsed_url.scheme in ['webdavs', 'https']:
             if config.ssl_no_check_certificate:
                 self.conn = http.client.HTTPSConnection(self.parsed_url.hostname, self.parsed_url.port)
             else:
                 self.conn = VerifiedHTTPSConnection(self.parsed_url.hostname, self.parsed_url.port)
         else:
-            raise FatalBackendException(_(u"WebDAV Unknown URI scheme: %s") % (self.parsed_url.scheme))
+            raise FatalBackendException(_("WebDAV Unknown URI scheme: %s") % self.parsed_url.scheme)
 
     def _close(self):
         if self.conn:
             self.conn.close()
 
     def request(self, method, path, data=None, redirected=0):
-        u"""
+        """
         Wraps the connection.request method to retry once if authentication is
         required
         """
         self._close()  # or we get previous request's data or exception
         self.connect()
 
-        quoted_path = urllib.parse.quote(path, u"/:~")
+        quoted_path = urllib.parse.quote(path, "/:~")
 
         if self.digest_challenge is not None:
-            self.headers[u'Authorization'] = self.get_digest_authorization(path)
+            self.headers['Authorization'] = self.get_digest_authorization(path)
 
-        log.Info(_(u"WebDAV %s %s request with headers: %s ") % (method, quoted_path, self.headers))
-        log.Info(_(u"WebDAV data length: %s ") % len(str(data)))
+        log.Info(_("WebDAV %s %s request with headers: %s ") % (method, quoted_path, self.headers))
+        log.Info(_("WebDAV data length: %s ") % len(str(data)))
         self.conn.request(method, quoted_path, data, self.headers)
         response = self.conn.getresponse()
-        log.Info(_(u"WebDAV response status %s with reason '%s'.") % (response.status, response.reason))
+        log.Info(_("WebDAV response status %s with reason '%s'.") % (response.status, response.reason))
         # resolve redirects and reset url on listing requests (they usually come before everything else)
-        if response.status in [301, 302] and method == u'PROPFIND':
-            redirect_url = response.getheader(u'location', None)
+        if response.status in [301, 302] and method == 'PROPFIND':
+            redirect_url = response.getheader('location', None)
             response.close()
             if redirect_url:
-                log.Notice(_(u"WebDAV redirect to: %s ") % urllib.parse.unquote(redirect_url))
+                log.Notice(_("WebDAV redirect to: %s ") % urllib.parse.unquote(redirect_url))
                 if redirected > 10:
-                    raise FatalBackendException(_(u"WebDAV redirected 10 times. Giving up."))
+                    raise FatalBackendException(_("WebDAV redirected 10 times. Giving up."))
                 self.parsed_url = duplicity.backend.ParsedUrl(redirect_url)
                 self.directory = self.sanitize_path(self.parsed_url.path)
                 return self.request(method, self.directory, data, redirected + 1)
             else:
-                raise FatalBackendException(_(u"WebDAV missing location header in redirect response."))
+                raise FatalBackendException(_("WebDAV missing location header in redirect response."))
         elif response.status == 401:
             response.read()
             response.close()
-            self.headers[u'Authorization'] = self.get_authorization(response, quoted_path)
-            log.Info(_(u"WebDAV retry request with authentification headers."))
-            log.Info(_(u"WebDAV %s %s request2 with headers: %s ") % (method, quoted_path, self.headers))
-            log.Info(_(u"WebDAV data length: %s ") % len(str(data)))
+            self.headers['Authorization'] = self.get_authorization(response, quoted_path)
+            log.Info(_("WebDAV retry request with authentification headers."))
+            log.Info(_("WebDAV %s %s request2 with headers: %s ") % (method, quoted_path, self.headers))
+            log.Info(_("WebDAV data length: %s ") % len(str(data)))
             self.conn.request(method, quoted_path, data, self.headers)
             response = self.conn.getresponse()
-            log.Info(_(u"WebDAV response2 status %s with reason '%s'.") % (response.status, response.reason))
+            log.Info(_("WebDAV response2 status %s with reason '%s'.") % (response.status, response.reason))
 
         return response
 
     def get_authorization(self, response, path):
-        u"""
+        """
         Fetches the auth header based on the requested method (basic or digest)
         """
         try:
-            auth_hdr = response.getheader(u'www-authenticate', u'')
-            token, challenge = auth_hdr.split(u' ', 1)
+            auth_hdr = response.getheader('www-authenticate', '')
+            token, challenge = auth_hdr.split(' ', 1)
         except ValueError:
             return None
-        if token.split(u',')[0].lower() == u'negotiate':
+        if token.split(',')[0].lower() == 'negotiate':
             try:
                 return self.get_kerberos_authorization()
             except ImportError:
-                log.Warn(_(u"python-kerberos needed to use kerberos \
+                log.Warn(_("python-kerberos needed to use kerberos \
                           authorization, falling back to basic auth."))
                 return self.get_basic_authorization()
             except Exception as e:
-                log.Warn(_(u"Kerberos authorization failed: %s.\
+                log.Warn(_("Kerberos authorization failed: %s.\
                           Falling back to basic auth.") % e)
                 return self.get_basic_authorization()
-        elif token.lower() == u'basic':
+        elif token.lower() == 'basic':
             return self.get_basic_authorization()
         else:
             self.digest_challenge = self.parse_digest_challenge(challenge)
             return self.get_digest_authorization(path)
 
     def parse_digest_challenge(self, challenge_string):
         return urllib.request.parse_keqv_list(urllib.request.parse_http_list(challenge_string))
 
     def get_kerberos_authorization(self):
         import kerberos  # pylint: disable=import-error
-        _, ctx = kerberos.authGSSClientInit(u"HTTP@%s" % self.conn.host)
-        kerberos.authGSSClientStep(ctx, u"")
+        _, ctx = kerberos.authGSSClientInit(f"HTTP@{self.conn.host}")
+        kerberos.authGSSClientStep(ctx, "")
         tgt = kerberos.authGSSClientResponse(ctx)
-        return u'Negotiate %s' % tgt
+        return f'Negotiate {tgt}'
 
     def get_basic_authorization(self):
-        u"""
+        """
         Returns the basic auth header
         """
-        auth_string = u'%s:%s' % (self.username, self.password)
-        return u'Basic %s' % base64.b64encode(auth_string.encode()).strip().decode()
+        auth_string = f'{self.username}:{self.password}'
+        return f'Basic {base64.b64encode(auth_string.encode()).strip().decode()}'
 
     def get_digest_authorization(self, path):
-        u"""
+        """
         Returns the digest auth header
         """
         u = self.parsed_url
         if self.digest_auth_handler is None:
             pw_manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()
             pw_manager.add_password(None, self.conn.host, self.username, self.password)
             self.digest_auth_handler = urllib.request.HTTPDigestAuthHandler(pw_manager)
 
         # building a dummy request that gets never sent,
         # needed for call to auth_handler.get_authorization
-        scheme = u.scheme == u'webdavs' and u'https' or u'http'
-        hostname = u.port and u"%s:%s" % (u.hostname, u.port) or u.hostname
-        dummy_url = u"%s://%s%s" % (scheme, hostname, path)
+        scheme = u.scheme == 'webdavs' and 'https' or 'http'
+        hostname = u.port and f"{u.hostname}:{u.port}" or u.hostname
+        dummy_url = f"{scheme}://{hostname}{path}"
         dummy_req = CustomMethodRequest(self.conn._method, dummy_url)
         auth_string = self.digest_auth_handler.get_authorization(dummy_req,
                                                                  self.digest_challenge)
-        return u'Digest %s' % auth_string
+        return f'Digest {auth_string}'
 
     def _list(self):
         response = None
         try:
-            self.headers[u'Depth'] = u"1"
-            response = self.request(u"PROPFIND", self.directory, self.listbody)
-            del self.headers[u'Depth']
+            self.headers['Depth'] = "1"
+            response = self.request("PROPFIND", self.directory, self.listbody)
+            del self.headers['Depth']
             # if the target collection does not exist, create it.
             if response.status == 404:
                 response.close()  # otherwise next request fails with ResponseNotReady
                 self.makedir()
                 # just created an empty folder, so return empty
                 return []
             elif response.status in [200, 207]:
                 document = response.read()
                 response.close()
             else:
                 status = response.status
                 reason = response.reason
                 response.close()
-                raise BackendException(u"Bad status code %s reason %s." % (status, reason))
+                raise BackendException(f"Bad status code {status} reason {reason}.")
 
-            log.Debug(u"%s" % (document,))
+            log.Debug(f"{document}")
             dom = xml.dom.minidom.parseString(document)
             result = []
-            for href in dom.getElementsByTagNameNS(u'*', u'href'):
+            for href in dom.getElementsByTagNameNS('*', 'href'):
                 filename = self.taste_href(href)
                 if filename:
                     result.append(filename)
             return result
         except Exception as e:
             raise e
         finally:
             if response:
                 response.close()
 
     def makedir(self):
-        u"""Make (nested) directories on the server."""
-        dirs = self.directory.split(u"/")
+        """Make (nested) directories on the server."""
+        dirs = self.directory.split("/")
         # url causes directory to start with /, but it might be given
         # with or without trailing / (which is required)
-        if dirs[-1] == u'':
+        if dirs[-1] == '':
             dirs = dirs[0:-1]
         for i in range(1, len(dirs)):
-            d = u"/".join(dirs[0:i + 1]) + u"/"
+            d = f"{'/'.join(dirs[0:i + 1])}/"
 
-            self.headers[u'Depth'] = u"1"
-            response = self.request(u"PROPFIND", d)
-            del self.headers[u'Depth']
+            self.headers['Depth'] = "1"
+            response = self.request("PROPFIND", d)
+            del self.headers['Depth']
 
-            log.Info(u"Checking existence dir %s: %d" % (d, response.status))
+            log.Info(f"Checking existence dir {d}: {int(response.status)}")
 
             if response.status == 404:
-                log.Info(_(u"Creating missing directory %s") % d)
+                log.Info(_("Creating missing directory %s") % d)
 
-                res = self.request(u"MKCOL", d)
+                res = self.request("MKCOL", d)
                 if res.status != 201:
-                    raise BackendException(_(u"WebDAV MKCOL %s failed: %s %s") %
+                    raise BackendException(_("WebDAV MKCOL %s failed: %s %s") %
                                            (d, res.status, res.reason))
 
     def taste_href(self, href):
-        u"""
+        """
         Internal helper to taste the given href node and, if
         it is a duplicity file, collect it as a result file.
 
         @return: A matching filename, or None if the href did not match.
         """
         raw_filename = self.getText(href.childNodes).strip()
         parsed_url = urllib.parse.urlparse(urllib.parse.unquote(raw_filename))
         filename = parsed_url.path
-        log.Debug(_(u"WebDAV path decoding and translation: "
-                  u"%s -> %s") % (raw_filename, filename))
+        log.Debug(_("WebDAV path decoding and translation: "
+                    "%s -> %s") % (raw_filename, filename))
 
         # at least one WebDAV server returns files in the form
         # of full URL:s. this may or may not be
         # according to the standard, but regardless we
         # feel we want to bail out if the hostname
         # does not match until someone has looked into
         # what the WebDAV protocol mandages.
         if parsed_url.hostname is not None \
-           and not (parsed_url.hostname == self.parsed_url.hostname):
-            m = u"Received filename was in the form of a "\
-                u"full url, but the hostname (%s) did "\
-                u"not match that of the webdav backend "\
-                u"url (%s) - aborting as a conservative "\
-                u"safety measure. If this happens to you, "\
-                u"please report the problem"\
-                u"" % (parsed_url.hostname,
-                       self.parsed_url.hostname)
+                and not (parsed_url.hostname == self.parsed_url.hostname):
+            m = f"Received filename was in the form of a full url, but the hostname ({parsed_url.hostname}) " \
+                f"did not match that of the webdav backend url ({self.parsed_url.hostname}) - " \
+                f"aborting as a conservative safety measure. If this happens to you, please report the problem"
             raise BackendException(m)
 
         if filename.startswith(self.directory):
-            filename = filename.replace(self.directory, u'', 1)
+            filename = filename.replace(self.directory, '', 1)
             return filename
         else:
             return None
 
     def _get(self, remote_filename, local_path):
-        url = self.directory + util.fsdecode(remote_filename)
+        url = self.directory + os.fsdecode(remote_filename)
         response = None
         try:
-            target_file = local_path.open(u"wb")
-            response = self.request(u"GET", url)
+            target_file = local_path.open("wb")
+            response = self.request("GET", url)
             if response.status == 200:
                 # data=response.read()
                 shutil.copyfileobj(response, target_file)
                 # import hashlib
                 # log.Info("WebDAV GOT %s bytes with md5=%s" %
                 # (len(data),hashlib.md5(data).hexdigest()) )
                 assert not target_file.close()
                 response.close()
             else:
                 status = response.status
                 reason = response.reason
                 response.close()
-                raise BackendException(_(u"WebDAV GET Bad status code %s reason %s.") %
+                raise BackendException(_("WebDAV GET Bad status code %s reason %s.") %
                                        (status, reason))
         except Exception as e:
             raise e
         finally:
             if response:
                 response.close()
 
     def _put(self, source_path, remote_filename):
-        url = self.directory + util.fsdecode(remote_filename)
+        url = self.directory + os.fsdecode(remote_filename)
         response = None
         try:
-            source_file = source_path.open(u"rb")
-            response = self.request(u"PUT", url, source_file.read())
+            source_file = source_path.open("rb")
+            response = self.request("PUT", url, source_file.read())
             # 200 is returned if a file is overwritten during restarting
             if response.status in [200, 201, 204]:
                 response.read()
                 response.close()
             else:
                 status = response.status
                 reason = response.reason
                 response.close()
-                raise BackendException(_(u"WebDAV PUT Bad status code %s reason %s.") %
+                raise BackendException(_("WebDAV PUT Bad status code %s reason %s.") %
                                        (status, reason))
         except Exception as e:
             raise e
         finally:
             if response:
                 response.close()
 
     def _delete(self, filename):
-        url = self.directory + util.fsdecode(filename)
+        url = self.directory + os.fsdecode(filename)
         response = None
         try:
-            response = self.request(u"DELETE", url)
+            response = self.request("DELETE", url)
             if response.status in [200, 204]:
                 response.read()
                 response.close()
             else:
                 status = response.status
                 reason = response.reason
                 response.close()
-                raise BackendException(_(u"WebDAV DEL Bad status code %s reason %s.") %
+                raise BackendException(_("WebDAV DEL Bad status code %s reason %s.") %
                                        (status, reason))
         except Exception as e:
             raise e
         finally:
             if response:
                 response.close()
 
 
-duplicity.backend.register_backend(u"http", WebDAVBackend)
-duplicity.backend.register_backend(u"https", WebDAVBackend)
-duplicity.backend.register_backend(u"webdav", WebDAVBackend)
-duplicity.backend.register_backend(u"webdavs", WebDAVBackend)
-duplicity.backend.uses_netloc.extend([u'http', u'https', u'webdav', u'webdavs'])
+duplicity.backend.register_backend("http", WebDAVBackend)
+duplicity.backend.register_backend("https", WebDAVBackend)
+duplicity.backend.register_backend("webdav", WebDAVBackend)
+duplicity.backend.register_backend("webdavs", WebDAVBackend)
+duplicity.backend.uses_netloc.extend(['http', 'https', 'webdav', 'webdavs'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/megav3backend.py` & `duplicity-2.0.0rc0/duplicity/backends/megav3backend.py`

 * *Files 13% similar despite different names*

```diff
@@ -14,267 +14,256 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
 
 import os
 import re
 import subprocess
 
 import duplicity.backend
-from duplicity import util
 from duplicity.errors import BackendException
-from future import standard_library
-
-standard_library.install_aliases()
 
 
 class Megav3Backend(duplicity.backend.Backend):
-    u"""Backend for MEGA.nz cloud storage, only one that works for accounts created since Nov. 2018
+    """Backend for MEGA.nz cloud storage, only one that works for accounts created since Nov. 2018
     See https://github.com/megous/megatools/issues/411 for more details
 
     This MEGA backend resorts to official tools (MEGAcmd) as available at https://mega.nz/cmd
     MEGAcmd works through a single binary called "mega-cmd", which keeps state (for example,
     persisting a session). Multiple "mega-*" shell wrappers (ie. "mega-ls") exist as the user
     interface to "mega-cmd" and MEGA API
     The full MEGAcmd User Guide can be found in the software's GitHub page below :
     https://github.com/meganz/MEGAcmd/blob/master/UserGuide.md"""
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # Sanity check : ensure all the necessary "MEGAcmd" binaries exist
-        self._check_binary_exists(u'mega-cmd')
-        self._check_binary_exists(u'mega-exec')
-        self._check_binary_exists(u'mega-help')
-        self._check_binary_exists(u'mega-get')
-        self._check_binary_exists(u'mega-login')
-        self._check_binary_exists(u'mega-logout')
-        self._check_binary_exists(u'mega-ls')
-        self._check_binary_exists(u'mega-mkdir')
-        self._check_binary_exists(u'mega-put')
-        self._check_binary_exists(u'mega-rm')
-        self._check_binary_exists(u'mega-whoami')
+        self._check_binary_exists('mega-cmd')
+        self._check_binary_exists('mega-exec')
+        self._check_binary_exists('mega-help')
+        self._check_binary_exists('mega-get')
+        self._check_binary_exists('mega-login')
+        self._check_binary_exists('mega-logout')
+        self._check_binary_exists('mega-ls')
+        self._check_binary_exists('mega-mkdir')
+        self._check_binary_exists('mega-put')
+        self._check_binary_exists('mega-rm')
+        self._check_binary_exists('mega-whoami')
 
         # "MEGAcmd" does not use a config file, however it is handy to keep one (with the old ".megarc" format) to
         # securely store the username and password
         self._hostname = parsed_url.hostname
         if parsed_url.username is None:
-            self._megarc = os.getenv(u'HOME') + u'/.megav3rc'
+            self._megarc = f"{os.getenv('HOME')}/.megav3rc"
             try:
-                conf_file = open(self._megarc, u"r")
+                conf_file = open(self._megarc, "r")
             except Exception as e:
                 raise BackendException(
-                    u"No password provided in URL and MEGA configuration "
-                    u"file for duplicity does not exist as '%s'"
-                    % (self._megarc,)
+                    f"No password provided in URL and MEGA configuration file for "
+                    f"duplicity does not exist as '{self._megarc}'"
                 )
 
             myvars = {}
             for line in conf_file:
-                name, var = line.partition(u"=")[::2]
+                name, var = line.partition("=")[::2]
                 myvars[name.strip()] = str(var.strip())
             conf_file.close()
-            self._username = myvars[u"Username"]
-            self._password = myvars[u"Password"]
+            self._username = myvars["Username"]
+            self._password = myvars["Password"]
 
         else:
             self._username = parsed_url.username
             self._password = parsed_url.password
 
-        no_logout_option = parsed_url.query_args.get(u'no_logout', [])
+        no_logout_option = parsed_url.query_args.get('no_logout', [])
         self._no_logout = (len(no_logout_option) > 0) and (
-            no_logout_option[0].lower() in [u'1', u'yes', u'true']
+            no_logout_option[0].lower() in ['1', 'yes', 'true']
         )
 
         self.ensure_mega_cmd_running()
 
         # Remote folder ("MEGAcmd" no longer shows "Root/" at the top of the hierarchy)
-        self._folder = u'/' + parsed_url.path[1:]
+        self._folder = f"/{parsed_url.path[1:]}"
 
         # Only create the remote folder if it doesn't exist yet
         self.mega_login()
-        cmd = [u'mega-ls', self._folder]
+        cmd = ['mega-ls', self._folder]
         try:
             self.subprocess_popen(cmd)
         except Exception as e:
             self._makedir(self._folder)
 
     def _check_binary_exists(self, cmd):
-        u'Checks that a specified command exists in the running user command path'
+        """Checks that a specified command exists in the running user command path"""
 
         try:
             # Ignore the output, as we only need the return code
-            subprocess.check_output([u'which', cmd])
+            subprocess.check_output(['which', cmd])
         except Exception as e:
             raise BackendException(
-                u"Command '%s' not found, make sure 'MEGAcmd' tools (https://mega.nz/cmd) is "
-                u"properly installed and in the running user command path"
-                % (cmd,)
+                f"Command '{cmd}' not found, make sure 'MEGAcmd' tools (https://mega.nz/cmd) is properly installed "
+                f"and in the running user command path"
             )
 
     def ensure_mega_cmd_running(self):
-        u'Trigger any mega command to ensure mega-cmd server is running'
+        """Trigger any mega command to ensure mega-cmd server is running"""
         try:
             subprocess.run(
-                u"mega-help",
+                "mega-help",
                 stdout=subprocess.DEVNULL,
                 stderr=subprocess.DEVNULL,
             ).check_returncode()
         except Exception:
-            raise BackendException(u'Cannot execute mega command')
+            raise BackendException('Cannot execute mega command')
 
     def _makedir(self, path):
-        u'Creates a remote directory (recursively if necessary)'
+        """Creates a remote directory (recursively if necessary)"""
 
         self.mega_login()
-        cmd = [u'mega-mkdir', u'-p', path]
+        cmd = ['mega-mkdir', '-p', path]
         try:
             self.subprocess_popen(cmd)
         except Exception as e:
             error_str = str(e)
-            if u"Folder already exists" in error_str:
+            if "Folder already exists" in error_str:
                 raise BackendException(
-                    u"Folder '%s' could not be created on MEGA because it already exists. "
-                    u"Use another path or remove the folder in MEGA manually"
-                    % (path,)
+                    f"Folder '{path}' could not be created on MEGA because it already exists. "
+                    f"Use another path or remove the folder in MEGA manually"
                 )
             else:
                 raise BackendException(
-                    u"Folder '%s' could not be created, reason : '%s'"
-                    % (path, e)
+                    f"Folder '{path}' could not be created, reason : '{e}'"
                 )
 
     def _put(self, source_path, remote_filename):
-        u"""Uploads file to the specified remote folder (tries to delete it first to make
+        """Uploads file to the specified remote folder (tries to delete it first to make
         sure the new one can be uploaded)"""
 
         try:
             self.delete(remote_filename.decode())
         except Exception:
             pass
         self.upload(
             local_file=source_path.get_canonical().decode(),
             remote_file=remote_filename.decode(),
         )
 
     def _get(self, remote_filename, local_path):
-        u'Downloads file from the specified remote path'
+        """Downloads file from the specified remote path"""
 
         self.download(
             remote_file=remote_filename.decode(),
             local_file=local_path.name.decode(),
         )
 
     def _list(self):
-        u'Lists files in the specified remote path'
+        """Lists files in the specified remote path"""
 
         return self.folder_contents(files_only=True)
 
     def _delete(self, filename):
-        u'Deletes file from the specified remote path'
+        """Deletes file from the specified remote path"""
 
         self.delete(remote_file=filename.decode())
 
     def _close(self):
-        u'Function called when backend is done being used'
+        """Function called when backend is done being used"""
 
         if not self._no_logout:
-            cmd = [u'mega-logout']
+            cmd = ['mega-logout']
             self.subprocess_popen(cmd)
 
-        cmd = [u'mega-exec', u'exit']
+        cmd = ['mega-exec', 'exit']
         self.subprocess_popen(cmd)
 
     def mega_login(self):
-        u"""Helper function to check existing session exists"""
+        """Helper function to check existing session exists"""
 
         # Abort if command doesn't return in a reasonable time (somehow "mega-session" sometimes
         # doesn't return), and create session if one doesn't exist yet
         try:
             result = subprocess.run(
-                u'mega-whoami',
+                'mega-whoami',
                 timeout=30,
                 capture_output=True,
             )
             result.check_returncode()
-            current_username = result.stdout.decode().split(u':')[-1].strip()
+            current_username = result.stdout.decode().split(':')[-1].strip()
             if current_username != self._username:
-                raise Exception(u"Username is not match")
+                raise Exception("Username is not match")
         except subprocess.TimeoutExpired:
             self._close()
             raise BackendException(
-                u"Timed out while trying to determine if a MEGA session exists"
+                "Timed out while trying to determine if a MEGA session exists"
             )
         except Exception as e:
             if self._password is None:
                 self._password = self.get_password()
 
-            cmd = [u'mega-login', self._username, self._password]
+            cmd = ['mega-login', self._username, self._password]
             try:
                 subprocess.run(
                     cmd,
                     stderr=subprocess.DEVNULL,
                 ).check_returncode()
             except Exception as e:
                 self._close()
                 raise BackendException(
-                    u"Could not log in to MEGA, error : '%s'" % (e,)
+                    f"Could not log in to MEGA, error : '{e}'"
                 )
 
     def folder_contents(self, files_only=False):
-        u'Lists contents of a remote MEGA path, optionally ignoring subdirectories'
+        """Lists contents of a remote MEGA path, optionally ignoring subdirectories"""
 
-        cmd = [u'mega-ls', u'-l', self._folder]
+        cmd = ['mega-ls', '-l', self._folder]
 
         self.mega_login()
         files = subprocess.check_output(cmd)
-        files = files.decode().split(u'\n')
+        files = files.decode().split('\n')
 
         # Optionally ignore directories
         if files_only:
-            files = [f.split()[5] for f in files if re.search(u'^-', f)]
+            files = [f.split()[5] for f in files if re.search('^-', f)]
 
         return files
 
     def download(self, remote_file, local_file):
-        u'Downloads a file from a remote MEGA path'
+        """Downloads a file from a remote MEGA path"""
 
-        cmd = [u'mega-get', self._folder + u'/' + remote_file, local_file]
+        cmd = ['mega-get', f"{self._folder}/{remote_file}", local_file]
         self.mega_login()
         self.subprocess_popen(cmd)
 
     def upload(self, local_file, remote_file):
-        u'Uploads a file to a remote MEGA path'
+        """Uploads a file to a remote MEGA path"""
 
-        cmd = [u'mega-put', local_file, self._folder + u'/' + remote_file]
+        cmd = ['mega-put', local_file, f"{self._folder}/{remote_file}"]
         self.mega_login()
         try:
             self.subprocess_popen(cmd)
         except Exception as e:
             error_str = str(e)
-            if u"Reached storage quota" in error_str:
+            if "Reached storage quota" in error_str:
                 raise BackendException(
-                    u"MEGA account over quota, could not write file : '%s' . "
-                    u"Upgrade your storage at https://mega.nz/pro or remove some data."
-                    % (remote_file,)
+                    f"MEGA account over quota, could not write file : '{remote_file}' . "
+                    f"Upgrade your storage at https://mega.nz/pro or remove some data."
                 )
             else:
                 raise BackendException(
-                    u"Failed writing file '%s' to MEGA, reason : '%s'"
-                    % (remote_file, e)
+                    f"Failed writing file '{remote_file}' to MEGA, reason : '{e}'"
                 )
 
     def delete(self, remote_file):
-        u'Deletes a file from a remote MEGA path'
+        """Deletes a file from a remote MEGA path"""
 
-        cmd = [u'mega-rm', u'-f', self._folder + u'/' + remote_file]
+        cmd = ['mega-rm', '-f', f"{self._folder}/{remote_file}"]
         self.mega_login()
         self.subprocess_popen(cmd)
 
 
-duplicity.backend.register_backend(u'megav3', Megav3Backend)
-duplicity.backend.uses_netloc.extend([u'megav3'])
+duplicity.backend.register_backend('megav3', Megav3Backend)
+duplicity.backend.uses_netloc.extend(['megav3'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/hubicbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/hubicbackend.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,55 +14,53 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
 import os
 
+import duplicity.backend
 from duplicity import log
 from duplicity import util
 from duplicity.errors import BackendException
-import duplicity.backend
-
 from ._cf_pyrax import PyraxBackend
 
 
 class HubicBackend(PyraxBackend):
-    u"""
+    """
     Backend for Hubic using Pyrax
     """
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         try:
             import pyrax
         except ImportError as e:
-            raise BackendException(u"""\
-Hubic backend requires the pyrax library available from Rackspace.
-Exception: %s""" % str(e))
+            raise BackendException(f"""Hubic backend requires the pyrax library available from Rackspace.
+Exception: {str(e)}""")
 
         # Inform Pyrax that we're talking to Hubic
-        pyrax.set_setting(u"identity_type", u"duplicity.backends.pyrax_identity.hubic.HubicIdentity")
+        pyrax.set_setting("identity_type", "duplicity.backends.pyrax_identity.hubic.HubicIdentity")
 
-        CREDENTIALS_FILE = os.path.expanduser(u"~/.hubic_credentials")
+        CREDENTIALS_FILE = os.path.expanduser("~/.hubic_credentials")
         if os.path.exists(CREDENTIALS_FILE):
             try:
                 pyrax.set_credential_file(CREDENTIALS_FILE)
             except Exception as e:
-                log.FatalError(u"Connection failed, please check your credentials: %s %s"
-                               % (e.__class__.__name__, util.uexc(e)),
+                log.FatalError(f"Connection failed, please check your credentials: "
+                               f"{e.__class__.__name__} {util.uexc(e)}",
                                log.ErrorCode.connection_failed)
 
         else:
-            raise BackendException(u"No ~/.hubic_credentials file found.")
+            raise BackendException("No ~/.hubic_credentials file found.")
 
-        container = parsed_url.path.lstrip(u'/')
+        container = parsed_url.path.lstrip('/')
 
         self.client_exc = pyrax.exceptions.ClientException
         self.nso_exc = pyrax.exceptions.NoSuchObject
         self.container = pyrax.cloudfiles.create_container(container)
 
 
-duplicity.backend.register_backend(u"cf+hubic", HubicBackend)
+duplicity.backend.register_backend("cf+hubic", HubicBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/lftpbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/lftpbackend.py`

 * *Files 10% similar despite different names*

```diff
@@ -20,217 +20,197 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from future import standard_library
-standard_library.install_aliases()
 
 import os
 import os.path
 import re
-import urllib.request  # pylint: disable=import-error
-import urllib.parse  # pylint: disable=import-error
-import urllib.error  # pylint: disable=import-error
+import urllib.error
+import urllib.parse
+import urllib.request
+
 try:
     from shlex import quote as cmd_quote
 except ImportError:
     from pipes import quote as cmd_quote
 
 import duplicity.backend
 from duplicity import config
 from duplicity import log
 from duplicity import tempdir
-from duplicity import util
 
 
 class LFTPBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using File Transfer Protocol"""
+    """Connect to remote store using File Transfer Protocol"""
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # we expect an output
         try:
-            p = os.popen(u"lftp --version")
+            p = os.popen("lftp --version")
             fout = p.read()
             ret = p.close()
         except Exception:
             pass
         # there is no output if lftp not found
         if not fout:
-            log.FatalError(u"LFTP not found:  Please install LFTP.",
+            log.FatalError("LFTP not found:  Please install LFTP.",
                            log.ErrorCode.ftps_lftp_missing)
 
         # version is the second word of the second part of the first line
-        version = fout.split(u'\n')[0].split(u' | ')[1].split()[1]
-        log.Notice(u"LFTP version is %s" % version)
+        version = fout.split('\n')[0].split(' | ')[1].split()[1]
+        log.Notice(f"LFTP version is {version}")
 
         self.parsed_url = parsed_url
 
-        self.scheme = duplicity.backend.strip_prefix(parsed_url.scheme, u'lftp').lower()
-        self.scheme = re.sub(u'^webdav', u'http', self.scheme)
-        self.url_string = self.scheme + u'://' + parsed_url.hostname
+        self.scheme = duplicity.backend.strip_prefix(parsed_url.scheme, 'lftp').lower()
+        self.scheme = re.sub('^webdav', 'http', self.scheme)
+        self.url_string = f"{self.scheme}://{parsed_url.hostname}"
         if parsed_url.port:
-            self.url_string += u":%s" % parsed_url.port
+            self.url_string += f":{parsed_url.port}"
 
-        self.remote_path = re.sub(u'^/', u'', parsed_url.path)
+        self.remote_path = re.sub('^/', '', parsed_url.path)
 
         # Fix up an empty remote path
         if len(self.remote_path) == 0:
-            self.remote_path = u'/'
+            self.remote_path = '/'
 
         # Use an explicit directory name.
-        if self.remote_path[-1] != u'/':
-            self.remote_path += u'/'
+        if self.remote_path[-1] != '/':
+            self.remote_path += '/'
 
-        self.authflag = u''
+        self.authflag = ''
         if self.parsed_url.username:
             self.username = self.parsed_url.username
             self.password = self.get_password()
-            self.authflag = u"-u '%s,%s'" % (self.username, self.password)
+            self.authflag = f"-u '{self.username},{self.password}'"
 
-        if config.ftp_connection == u'regular':
-            self.conn_opt = u'off'
+        if config.ftp_connection == 'regular':
+            self.conn_opt = 'off'
         else:
-            self.conn_opt = u'on'
+            self.conn_opt = 'on'
 
         # check for cacert file if https
         self.cacert_file = config.ssl_cacert_file
-        if self.scheme == u'https' and not config.ssl_no_check_certificate:
-            cacert_candidates = [u"~/.duplicity/cacert.pem",
-                                 u"~/duplicity_cacert.pem",
-                                 u"/etc/duplicity/cacert.pem"]
+        if self.scheme == 'https' and not config.ssl_no_check_certificate:
+            cacert_candidates = ["~/.duplicity/cacert.pem",
+                                 "~/duplicity_cacert.pem",
+                                 "/etc/duplicity/cacert.pem"]
             # look for a default cacert file
             if not self.cacert_file:
                 for path in cacert_candidates:
                     path = os.path.expanduser(path)
-                    if (os.path.isfile(path)):
+                    if os.path.isfile(path):
                         self.cacert_file = path
                         break
 
         # save config into a reusable temp file
         self.tempfd, self.tempname = tempdir.default().mkstemp()
-        self.tempfile = os.fdopen(self.tempfd, u"w")
-        self.tempfile.write(u"set ssl:verify-certificate " +
-                            (u"false" if config.ssl_no_check_certificate else u"true") + u"\n")
+        self.tempfile = os.fdopen(self.tempfd, "w")
+        self.tempfile.write("set ssl:verify-certificate " +
+                            ("false" if config.ssl_no_check_certificate else "true") + "\n")
         if self.cacert_file:
-            self.tempfile.write(u"set ssl:ca-file " + cmd_quote(self.cacert_file) + u"\n")
+            self.tempfile.write(f"set ssl:ca-file {cmd_quote(self.cacert_file)}\n")
         if config.ssl_cacert_path:
-            self.tempfile.write(u"set ssl:ca-path " + cmd_quote(config.ssl_cacert_path) + u"\n")
-        if self.parsed_url.scheme == u'ftps':
-            self.tempfile.write(u"set ftp:ssl-allow true\n")
-            self.tempfile.write(u"set ftp:ssl-protect-data true\n")
-            self.tempfile.write(u"set ftp:ssl-protect-list true\n")
-        elif self.parsed_url.scheme == u'ftpes':
-            self.tempfile.write(u"set ftp:ssl-force on\n")
-            self.tempfile.write(u"set ftp:ssl-protect-data on\n")
-            self.tempfile.write(u"set ftp:ssl-protect-list on\n")
+            self.tempfile.write(f"set ssl:ca-path {cmd_quote(config.ssl_cacert_path)}\n")
+        if self.parsed_url.scheme == 'ftps':
+            self.tempfile.write("set ftp:ssl-allow true\n")
+            self.tempfile.write("set ftp:ssl-protect-data true\n")
+            self.tempfile.write("set ftp:ssl-protect-list true\n")
+        elif self.parsed_url.scheme == 'ftpes':
+            self.tempfile.write("set ftp:ssl-force on\n")
+            self.tempfile.write("set ftp:ssl-protect-data on\n")
+            self.tempfile.write("set ftp:ssl-protect-list on\n")
         else:
-            self.tempfile.write(u"set ftp:ssl-allow false\n")
-        self.tempfile.write(u"set http:use-propfind true\n")
-        self.tempfile.write(u"set net:timeout %s\n" % config.timeout)
-        self.tempfile.write(u"set net:max-retries %s\n" % config.num_retries)
-        self.tempfile.write(u"set ftp:passive-mode %s\n" % self.conn_opt)
+            self.tempfile.write("set ftp:ssl-allow false\n")
+        self.tempfile.write("set http:use-propfind true\n")
+        self.tempfile.write(f"set net:timeout {config.timeout}\n")
+        self.tempfile.write(f"set net:max-retries {config.num_retries}\n")
+        self.tempfile.write(f"set ftp:passive-mode {self.conn_opt}\n")
         if log.getverbosity() >= log.DEBUG:
-            self.tempfile.write(u"debug\n")
-        if self.parsed_url.scheme == u'ftpes':
-            self.tempfile.write(u"open %s %s\n" % (self.authflag, self.url_string.replace(u'ftpes', u'ftp')))
+            self.tempfile.write("debug\n")
+        if self.parsed_url.scheme == 'ftpes':
+            self.tempfile.write(f"open {self.authflag} {self.url_string.replace('ftpes', 'ftp')}\n")
         else:
-            self.tempfile.write(u"open %s %s\n" % (self.authflag, self.url_string))
+            self.tempfile.write(f"open {self.authflag} {self.url_string}\n")
         self.tempfile.close()
         # print settings in debug mode
         if log.getverbosity() >= log.DEBUG:
-            f = open(self.tempname, u'r')
-            log.Debug(u"SETTINGS: \n"
-                      u"%s" % f.read())
+            f = open(self.tempname, 'r')
+            log.Debug(f"SETTINGS: \n{f.read()}")
 
     def _put(self, source_path, remote_filename):
         if isinstance(remote_filename, b"".__class__):
-            remote_filename = util.fsdecode(remote_filename)
-        commandline = u"lftp -c \"source %s; mkdir -p %s; put %s -o %s\"" % (
-            self.tempname,
-            cmd_quote(self.remote_path),
-            cmd_quote(source_path.uc_name),
-            cmd_quote(self.remote_path) + util.fsdecode(remote_filename)
-        )
-        log.Debug(u"CMD: %s" % commandline)
+            remote_filename = os.fsdecode(remote_filename)
+        commandline = f"lftp -c \"source {self.tempname}; mkdir -p {cmd_quote(self.remote_path)}; " \
+                      f"put {cmd_quote(source_path.uc_name)} " \
+                      f"-o {cmd_quote(self.remote_path) + os.fsdecode(remote_filename)}\""
+        log.Debug(f"CMD: {commandline}")
         s, l, e = self.subprocess_popen(commandline)
-        log.Debug(u"STATUS: %s" % s)
-        log.Debug(u"STDERR:\n"
-                  u"%s" % (e))
-        log.Debug(u"STDOUT:\n"
-                  u"%s" % (l))
+        log.Debug(f"STATUS: {s}")
+        log.Debug(f"STDERR:\n{e}")
+        log.Debug(f"STDOUT:\n{l}")
 
     def _get(self, remote_filename, local_path):
         if isinstance(remote_filename, b"".__class__):
-            remote_filename = util.fsdecode(remote_filename)
-        commandline = u"lftp -c \"source %s; get %s -o %s\"" % (
-            cmd_quote(self.tempname),
-            cmd_quote(self.remote_path) + remote_filename,
-            cmd_quote(local_path.uc_name)
-        )
-        log.Debug(u"CMD: %s" % commandline)
+            remote_filename = os.fsdecode(remote_filename)
+        commandline = f"lftp -c \"source {cmd_quote(self.tempname)}; " \
+                      f"get {cmd_quote(self.remote_path) + remote_filename} " \
+                      f"-o {cmd_quote(local_path.uc_name)}\""
+        log.Debug(f"CMD: {commandline}")
         _, l, e = self.subprocess_popen(commandline)
-        log.Debug(u"STDERR:\n"
-                  u"%s" % (e))
-        log.Debug(u"STDOUT:\n"
-                  u"%s" % (l))
+        log.Debug(f"STDERR:\n{e}")
+        log.Debug(f"STDOUT:\n{l}")
 
     def _list(self):
         # Do a long listing to avoid connection reset
         # remote_dir = urllib.unquote(self.parsed_url.path.lstrip('/')).rstrip()
         remote_dir = urllib.parse.unquote(self.parsed_url.path)
         # print remote_dir
         quoted_path = cmd_quote(self.remote_path)
         # failing to cd into the folder might be because it was not created already
-        commandline = u"lftp -c \"source %s; ( cd %s && ls ) || ( mkdir -p %s && cd %s && ls )\"" % (
-            cmd_quote(self.tempname),
-            quoted_path, quoted_path, quoted_path
-        )
-        log.Debug(u"CMD: %s" % commandline)
+        commandline = f"lftp -c \"source {cmd_quote(self.tempname)}; ( cd {quoted_path} && ls ) || " \
+                      f"( mkdir -p {quoted_path} && cd {quoted_path} && ls )\""
+        log.Debug(f"CMD: {commandline}")
         _, l, e = self.subprocess_popen(commandline)
-        log.Debug(u"STDERR:\n"
-                  u"%s" % (e))
-        log.Debug(u"STDOUT:\n"
-                  u"%s" % (l))
+        log.Debug(f"STDERR:\n{e}")
+        log.Debug(f"STDOUT:\n{l}")
 
         # Look for our files as the last element of a long list line
-        return [util.fsencode(x.split()[-1]) for x in l.split(u'\n') if x]
+        return [os.fsencode(x.split()[-1]) for x in l.split('\n') if x]
 
     def _delete(self, filename):
-        commandline = u"lftp -c \"source %s; cd %s; rm %s\"" % (
-            cmd_quote(self.tempname),
-            cmd_quote(self.remote_path),
-            cmd_quote(util.fsdecode(filename))
-        )
-        log.Debug(u"CMD: %s" % commandline)
+        commandline = f"lftp -c \"source {cmd_quote(self.tempname)}; cd {cmd_quote(self.remote_path)}; " \
+                      f"rm {cmd_quote(os.fsdecode(filename))}\""
+        log.Debug(f"CMD: {commandline}")
         _, l, e = self.subprocess_popen(commandline)
-        log.Debug(u"STDERR:\n"
-                  u"%s" % (e))
-        log.Debug(u"STDOUT:\n"
-                  u"%s" % (l))
-
-
-duplicity.backend.register_backend(u"ftp", LFTPBackend)
-duplicity.backend.register_backend(u"ftps", LFTPBackend)
-duplicity.backend.register_backend(u"fish", LFTPBackend)
-duplicity.backend.register_backend(u"ftpes", LFTPBackend)
-
-duplicity.backend.register_backend(u"lftp+ftp", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+ftps", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+fish", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+ftpes", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+sftp", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+webdav", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+webdavs", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+http", LFTPBackend)
-duplicity.backend.register_backend(u"lftp+https", LFTPBackend)
-
-duplicity.backend.uses_netloc.extend([u'ftp', u'ftps', u'fish', u'ftpes',
-                                      u'lftp+ftp', u'lftp+ftps',
-                                      u'lftp+fish', u'lftp+ftpes',
-                                      u'lftp+sftp',
-                                      u'lftp+webdav', u'lftp+webdavs',
-                                      u'lftp+http', u'lftp+https']
+        log.Debug(f"STDERR:\n{e}")
+        log.Debug(f"STDOUT:\n{l}")
+
+
+duplicity.backend.register_backend("ftp", LFTPBackend)
+duplicity.backend.register_backend("ftps", LFTPBackend)
+duplicity.backend.register_backend("fish", LFTPBackend)
+duplicity.backend.register_backend("ftpes", LFTPBackend)
+
+duplicity.backend.register_backend("lftp+ftp", LFTPBackend)
+duplicity.backend.register_backend("lftp+ftps", LFTPBackend)
+duplicity.backend.register_backend("lftp+fish", LFTPBackend)
+duplicity.backend.register_backend("lftp+ftpes", LFTPBackend)
+duplicity.backend.register_backend("lftp+sftp", LFTPBackend)
+duplicity.backend.register_backend("lftp+webdav", LFTPBackend)
+duplicity.backend.register_backend("lftp+webdavs", LFTPBackend)
+duplicity.backend.register_backend("lftp+http", LFTPBackend)
+duplicity.backend.register_backend("lftp+https", LFTPBackend)
+
+duplicity.backend.uses_netloc.extend(['ftp', 'ftps', 'fish', 'ftpes',
+                                      'lftp+ftp', 'lftp+ftps',
+                                      'lftp+fish', 'lftp+ftpes',
+                                      'lftp+sftp',
+                                      'lftp+webdav', 'lftp+webdavs',
+                                      'lftp+http', 'lftp+https']
                                      )
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/rsyncbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/rsyncbackend.py`

 * *Files 10% similar despite different names*

```diff
@@ -15,155 +15,158 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-from builtins import map
+
 import os
 import re
 import tempfile
 
 import duplicity.backend
+from duplicity import (
+    config,
+    tempdir,
+    util,
+)
 from duplicity.errors import InvalidBackendURL
-from duplicity import config, tempdir, util
 
 
 class RsyncBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using rsync
+    """Connect to remote store using rsync
 
     rsync backend contributed by Sebastian Wilhelmi <seppi@seppi.de>
     rsyncd auth, alternate port support
     Copyright 2010 by Edgar Soldin <edgar.soldin@web.de>
     """
+
     def __init__(self, parsed_url):
-        u"""rsyncBackend initializer"""
+        """rsyncBackend initializer"""
         duplicity.backend.Backend.__init__(self, parsed_url)
-        u"""
+        """
         rsyncd module url: rsync://[user:password@]host[:port]::[/]modname/path
                       Note: 3.0.7 is picky about syntax use either 'rsync://' or '::'
                       cmd: rsync [--port=port] host::modname/path
         -or-
         rsync via ssh/rsh url: rsync://user@host[:port]://some_absolute_path
              -or-              rsync://user@host[:port]:/some_relative_path
                           cmd: rsync -e 'ssh [-p=port]' [user@]host:[/]path
         """
         host = parsed_url.hostname
-        port = u""
+        port = ""
         # RSYNC_RSH from calling shell might conflict with our settings
-        if u'RSYNC_RSH' in os.environ:
-            del os.environ[u'RSYNC_RSH']
+        if 'RSYNC_RSH' in os.environ:
+            del os.environ['RSYNC_RSH']
         if self.over_rsyncd():
             # its a module path
             (path, port) = self.get_rsync_path()
-            self.url_string = u"%s::%s" % (host, path.lstrip(u'/:'))
+            self.url_string = f"{host}::{path.lstrip('/:')}"
             if port:
-                port = u" --port=%s" % port
+                port = f" --port={port}"
         else:
-            host_string = host + u":" if host else u""
-            if parsed_url.path.startswith(u"//"):
+            host_string = f"{host}:" if host else ""
+            if parsed_url.path.startswith("//"):
                 # its an absolute path
-                self.url_string = u"%s/%s" % (host_string, parsed_url.path.lstrip(u'/'))
+                self.url_string = f"{host_string}/{parsed_url.path.lstrip('/')}"
             else:
                 # its a relative path
-                self.url_string = u"%s%s" % (host_string, parsed_url.path.lstrip(u'/'))
+                self.url_string = f"{host_string}{parsed_url.path.lstrip('/')}"
             if parsed_url.port:
-                port = u"-p %s" % parsed_url.port
+                port = f"-p {parsed_url.port}"
         # add trailing slash if missing
-        if self.url_string[-1] != u'/':
-            self.url_string += u'/'
+        if self.url_string[-1] != '/':
+            self.url_string += '/'
         # user?
         if parsed_url.username:
             if self.over_rsyncd():
-                os.environ[u'USER'] = parsed_url.username
+                os.environ['USER'] = parsed_url.username
             else:
-                self.url_string = parsed_url.username + u"@" + self.url_string
+                self.url_string = f"{parsed_url.username}@{self.url_string}"
         # password?, don't ask if none was given
         self.use_getpass = False
         password = self.get_password()
         if password:
-            os.environ[u'RSYNC_PASSWORD'] = password
+            os.environ['RSYNC_PASSWORD'] = password
         if self.over_rsyncd():
             portOption = port
         else:
-            portOption = u"-e 'ssh %s -oBatchMode=yes %s'" % (port, config.ssh_options)
+            portOption = f"-e 'ssh {port} -oBatchMode=yes {config.ssh_options}'"
         rsyncOptions = config.rsync_options
         # build cmd
-        self.cmd = u"rsync %s %s" % (portOption, rsyncOptions)
+        self.cmd = f"rsync {portOption} {rsyncOptions}"
 
     def over_rsyncd(self):
         url = self.parsed_url.url_string
-        if re.search(u'::[^:]*$', url):
+        if re.search('::[^:]*$', url):
             return True
         else:
             return False
 
     def get_rsync_path(self):
         url = self.parsed_url.url_string
         m = re.search(r"(:\d+|)?::([^:]*)$", url)
         if m:
-            return m.group(2), m.group(1).lstrip(u':')
-        raise InvalidBackendURL(u"Could not determine rsync path: %s"
-                                u"" % self.munge_password(url))
+            return m.group(2), m.group(1).lstrip(':')
+        raise InvalidBackendURL(f"Could not determine rsync path: {self.munge_password(url)}")
 
     def _put(self, source_path, remote_filename):
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         remote_path = os.path.join(self.url_string, remote_filename)
-        commandline = u"%s %s %s" % (self.cmd, source_path.uc_name, remote_path)
+        commandline = f"{self.cmd} {source_path.uc_name} {remote_path}"
         self.subprocess_popen(commandline)
 
     def _get(self, remote_filename, local_path):
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         remote_path = os.path.join(self.url_string, remote_filename)
-        commandline = u"%s %s %s" % (self.cmd, remote_path, local_path.uc_name)
+        commandline = f"{self.cmd} {remote_path} {local_path.uc_name}"
         self.subprocess_popen(commandline)
 
     def _list(self):
         def split(str):  # pylint: disable=redefined-builtin
             line = str.split()
-            if len(line) > 4 and line[4] != u'.':
+            if len(line) > 4 and line[4] != '.':
                 return line[4]
             else:
                 return None
-        commandline = u"%s %s" % (self.cmd, self.url_string)
+
+        commandline = f"{self.cmd} {self.url_string}"
         result, stdout, stderr = self.subprocess_popen(commandline)
-        return [util.fsencode(x) for x in map(split, stdout.split(u'\n')) if x]
+        return [os.fsencode(x) for x in map(split, stdout.split('\n')) if x]
 
     def _delete_list(self, filename_list):
         delete_list = filename_list
         dont_delete_list = []
         for file in self._list():
             if file in delete_list:
                 delete_list.remove(file)
             else:
                 dont_delete_list.append(file)
 
         dir = tempfile.mkdtemp()  # pylint: disable=redefined-builtin
         exclude, exclude_name = tempdir.default().mkstemp_file()
         to_delete = [exclude_name]
         for file in dont_delete_list:
-            file = util.fsdecode(file)
+            file = os.fsdecode(file)
             path = os.path.join(dir, file)
             to_delete.append(path)
             try:
-                f = open(path, u'w')
+                f = open(path, 'w')
             except IsADirectoryError:
                 print(file, file=exclude)
                 continue
             print(file, file=exclude)
             f.close()
         exclude.close()
-        commandline = (u"%s --recursive --delete --exclude-from=%s %s/ %s" %
-                       (self.cmd, exclude_name, dir, self.url_string))
+        commandline = f"{self.cmd} --recursive --delete --exclude-from={exclude_name} {dir}/ {self.url_string}"
         self.subprocess_popen(commandline)
         for file in to_delete:
             try:
                 util.ignore_missing(os.unlink, file)
             except IsADirectoryError:
                 pass
         os.rmdir(dir)
 
 
-duplicity.backend.register_backend(u"rsync", RsyncBackend)
-duplicity.backend.uses_netloc.extend([u'rsync'])
+duplicity.backend.register_backend("rsync", RsyncBackend)
+duplicity.backend.uses_netloc.extend(['rsync'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/ncftpbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/ncftpbackend.py`

 * *Files 11% similar despite different names*

```diff
@@ -15,117 +15,112 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from future import standard_library
-standard_library.install_aliases()
 import os.path
-import urllib.request  # pylint: disable=import-error
-import urllib.parse  # pylint: disable=import-error
-import urllib.error  # pylint: disable=import-error
 import re
+import urllib.error
+import urllib.parse
+import urllib.request
 
 import duplicity.backend
 from duplicity import config
 from duplicity import log
 from duplicity import tempdir
-from duplicity import util
 
 
 class NCFTPBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using File Transfer Protocol"""
+    """Connect to remote store using File Transfer Protocol"""
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # we expect an error return, so go low-level and ignore it
         try:
-            p = os.popen(u"ncftpls -v")
+            p = os.popen("ncftpls -v")
             fout = p.read()
             ret = p.close()
         except Exception:
             pass
         # the expected error is 8 in the high-byte and some output
         if ret != 0x0800 or not fout:
-            log.FatalError(u"NcFTP not found:  Please install NcFTP version 3.1.9 or later",
+            log.FatalError("NcFTP not found:  Please install NcFTP version 3.1.9 or later",
                            log.ErrorCode.ftp_ncftp_missing)
 
         # version is the second word of the first line
-        version = fout.split(u'\n')[0].split()[1]
-        if version < u"3.1.9":
-            log.FatalError(u"NcFTP too old:  Duplicity requires NcFTP version 3.1.9,"
-                           u"3.2.1 or later.  Version 3.2.0 will not work properly.",
+        version = fout.split('\n')[0].split()[1]
+        if version < "3.1.9":
+            log.FatalError("NcFTP too old:  Duplicity requires NcFTP version 3.1.9,"
+                           "3.2.1 or later.  Version 3.2.0 will not work properly.",
                            log.ErrorCode.ftp_ncftp_too_old)
-        elif version == u"3.2.0":
-            log.Warn(u"NcFTP (ncftpput) version 3.2.0 may fail with duplicity.\n"
-                     u"see: http://www.ncftpd.com/ncftp/doc/changelog.html\n"
-                     u"If you have trouble, please upgrade to 3.2.1 or later",
+        elif version == "3.2.0":
+            log.Warn("NcFTP (ncftpput) version 3.2.0 may fail with duplicity.\n"
+                     "see: http://www.ncftpd.com/ncftp/doc/changelog.html\n"
+                     "If you have trouble, please upgrade to 3.2.1 or later",
                      log.WarningCode.ftp_ncftp_v320)
-        log.Notice(u"NcFTP version is %s" % version)
+        log.Notice(f"NcFTP version is {version}")
 
         self.parsed_url = parsed_url
 
         self.url_string = duplicity.backend.strip_auth_from_url(self.parsed_url)
 
         # strip ncftp+ prefix
-        self.url_string = duplicity.backend.strip_prefix(self.url_string, u'ncftp')
+        self.url_string = duplicity.backend.strip_prefix(self.url_string, 'ncftp')
 
         # This squelches the "file not found" result from ncftpls when
         # the ftp backend looks for a collection that does not exist.
         # version 3.2.2 has error code 5, 1280 is some legacy value
-        self.popen_breaks[u'ncftpls'] = [5, 1280]
+        self.popen_breaks['ncftpls'] = [5, 1280]
 
         # Use an explicit directory name.
-        if self.url_string[-1] != u'/':
-            self.url_string += u'/'
+        if self.url_string[-1] != '/':
+            self.url_string += '/'
 
         self.password = self.get_password()
 
-        if config.ftp_connection == u'regular':
-            self.conn_opt = u'-E'
+        if config.ftp_connection == 'regular':
+            self.conn_opt = '-E'
         else:
-            self.conn_opt = u'-F'
+            self.conn_opt = '-F'
 
         self.tempfd, self.tempname = tempdir.default().mkstemp()
-        self.tempfile = os.fdopen(self.tempfd, u"w")
-        self.tempfile.write(u"host %s\n" % self.parsed_url.hostname)
-        self.tempfile.write(u"user %s\n" % self.parsed_url.username)
-        self.tempfile.write(u"pass %s\n" % self.password)
+        self.tempfile = os.fdopen(self.tempfd, "w")
+        self.tempfile.write(f"host {self.parsed_url.hostname}\n")
+        self.tempfile.write(f"user {self.parsed_url.username}\n")
+        self.tempfile.write(f"pass {self.password}\n")
         self.tempfile.close()
-        self.flags = u"-f %s %s -t %s -o useCLNT=0,useHELP_SITE=0 " % \
-            (self.tempname, self.conn_opt, config.timeout)
+        self.flags = f"-f {self.tempname} {self.conn_opt} -t {config.timeout} -o useCLNT=0,useHELP_SITE=0 "
         if parsed_url.port is not None and parsed_url.port != 21:
-            self.flags += u" -P '%s'" % (parsed_url.port)
+            self.flags += f" -P '{parsed_url.port}'"
 
     def _put(self, source_path, remote_filename):
-        remote_filename = util.fsdecode(remote_filename)
-        remote_path = os.path.join(urllib.parse.unquote(re.sub(u'^/', u'', self.parsed_url.path)),
+        remote_filename = os.fsdecode(remote_filename)
+        remote_path = os.path.join(urllib.parse.unquote(re.sub('^/', '', self.parsed_url.path)),
                                    remote_filename).rstrip()
-        commandline = u"ncftpput %s -m -V -C '%s' '%s'" % \
-            (self.flags, source_path.uc_name, remote_path)
+        commandline = f"ncftpput {self.flags} -m -V -C '{source_path.uc_name}' '{remote_path}'"
         self.subprocess_popen(commandline)
 
     def _get(self, remote_filename, local_path):
-        remote_filename = util.fsdecode(remote_filename)
-        remote_path = os.path.join(urllib.parse.unquote(re.sub(u'^/', u'', self.parsed_url.path)),
+        remote_filename = os.fsdecode(remote_filename)
+        remote_path = os.path.join(urllib.parse.unquote(re.sub('^/', '', self.parsed_url.path)),
                                    remote_filename).rstrip()
-        commandline = u"ncftpget %s -V -C '%s' '%s' '%s'" % \
-            (self.flags, self.parsed_url.hostname, remote_path.lstrip(u'/'), local_path.uc_name)
+        commandline = f"ncftpget {self.flags} -V -C '{self.parsed_url.hostname}' " \
+                      f"'{remote_path.lstrip('/')}' '{local_path.uc_name}'"
         self.subprocess_popen(commandline)
 
     def _list(self):
         # Do a long listing to avoid connection reset
-        commandline = u"ncftpls %s -l '%s'" % (self.flags, self.url_string)
+        commandline = f"ncftpls {self.flags} -l '{self.url_string}'"
         _, l, _ = self.subprocess_popen(commandline)
         # Look for our files as the last element of a long list line
-        return [util.fsencode(x.split()[-1]) for x in l.split(u'\n') if x and not x.startswith(u"total ")]
+        return [os.fsencode(x.split()[-1]) for x in l.split('\n') if x and not x.startswith("total ")]
 
     def _delete(self, filename):
-        commandline = u"ncftpls %s -l -X 'DELE %s' '%s'" % \
-            (self.flags, filename, self.url_string)
+        commandline = f"ncftpls {self.flags} -l -X 'DELE {filename}' '{self.url_string}'"
         self.subprocess_popen(commandline)
 
 
-duplicity.backend.register_backend(u"ncftp+ftp", NCFTPBackend)
-duplicity.backend.uses_netloc.extend([u'ncftp+ftp'])
+duplicity.backend.register_backend("ncftp+ftp", NCFTPBackend)
+duplicity.backend.uses_netloc.extend(['ncftp+ftp'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/mediafirebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/mediafirebackend.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,39 +14,36 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""MediaFire Duplicity Backend"""
-
-from builtins import str
+"""MediaFire Duplicity Backend"""
 
 import os
 
 import duplicity.backend
-from duplicity import util
 from duplicity.errors import BackendException
 
-DUPLICITY_APP_ID = u'45593'
+DUPLICITY_APP_ID = '45593'
 
 
 class MediafireBackend(duplicity.backend.Backend):
-    u"""Use this backend when saving to MediaFire
+    """Use this backend when saving to MediaFire
 
     URLs look like mf:/root/folder.
     """
+
     def __init__(self, parsed_url):
         try:
             import mediafire.client
         except ImportError as e:
-            raise BackendException(u"""\
-Mediafire backend requires the mediafire library.
-Exception: %s""" % str(e))
+            raise BackendException(f"""Mediafire backend requires the mediafire library.
+Exception: {str(e)}""")
 
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         mediafire_email = parsed_url.username
         mediafire_password = self.get_password()
 
         self._file_res = mediafire.client.File
@@ -56,86 +53,85 @@
 
         self.client = mediafire.client.MediaFireClient()
         self.client.login(app_id=DUPLICITY_APP_ID,
                           email=mediafire_email,
                           password=mediafire_password)
 
         # //username:password@host/path/to/folder -> path/to/folder
-        uri = u'mf:///' + parsed_url.path.split(u'/', 3)[3]
+        uri = f"mf:///{parsed_url.path.split('/', 3)[3]}"
 
         # Create folder if it does not exist and make sure it is private
         # See MediaFire Account Settings /Security and Privacy / Share Link
         # to set "Inherit from parent folder"
         try:
             folder = self.client.get_resource_by_uri(uri)
             if not isinstance(folder, self._folder_res):
-                raise BackendException(u"target_url already exists "
-                                       u"and is not a folder")
+                raise BackendException("target_url already exists "
+                                       "and is not a folder")
         except mediafire.client.ResourceNotFoundError:
             # force folder to be private
             folder = self.client.create_folder(uri, recursive=True)
-            self.client.update_folder_metadata(uri, privacy=u'private')
+            self.client.update_folder_metadata(uri, privacy='private')
 
         self.folder = folder
 
     def _put(self, source_path, remote_filename=None):
-        u"""Upload file"""
+        """Upload file"""
         # Use source file name if remote one is not defined
         if remote_filename is None:
             remote_filename = os.path.basename(source_path.name)
 
         uri = self._build_uri(remote_filename)
 
         with self.client.upload_session():
-            self.client.upload_file(source_path.open(u'rb'), uri)
+            self.client.upload_file(source_path.open('rb'), uri)
 
     def _get(self, filename, local_path):
-        u"""Download file"""
+        """Download file"""
         uri = self._build_uri(filename)
         try:
-            self.client.download_file(uri, local_path.open(u'wb'))
+            self.client.download_file(uri, local_path.open('wb'))
         except self._downloaderror_exc as ex:
             raise BackendException(ex)
 
     def _list(self):
-        u"""List files in backup directory"""
+        """List files in backup directory"""
         uri = self._build_uri()
         filenames = []
         for item in self.client.get_folder_contents_iter(uri):
             if not isinstance(item, self._file_res):
                 continue
 
-            filenames.append(item[u'filename'].encode(u'utf-8'))
+            filenames.append(item['filename'].encode('utf-8'))
 
         return filenames
 
     def _delete(self, filename):
-        u"""Delete single file"""
+        """Delete single file"""
         uri = self._build_uri(filename)
         self.client.delete_file(uri, purge=config.mf_purge)
 
     def _delete_list(self, filename_list):
-        u"""Delete list of files"""
+        """Delete list of files"""
         for filename in filename_list:
             self._delete(filename)
 
     def _query(self, filename):
-        u"""Stat the remote file"""
+        """Stat the remote file"""
         uri = self._build_uri(filename)
 
         try:
             resource = self.client.get_resource_by_uri(uri)
-            size = int(resource[u'size'])
+            size = int(resource['size'])
         except self._notfound_exc:
             size = -1
 
-        return {u'size': size}
+        return {'size': size}
 
-    def _build_uri(self, filename=u''):
-        u"""Build relative URI"""
+    def _build_uri(self, filename=''):
+        """Build relative URI"""
         return (
-            u'mf:' + self.folder[u"folderkey"] +
-            (u'/' + util.fsdecode(filename))
+            f"mf:{self.folder['folderkey']}/{os.fsdecode(filename)}"
         )
 
 
-duplicity.backend.register_backend(u"mf", MediafireBackend)
+duplicity.backend.register_backend("mf", MediafireBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/s3_boto_backend.py` & `duplicity-2.0.0rc0/testing/unit/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,12 +1,10 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
-# Copyright 2002 Ben Escoto <ben@emerose.org>
-# Copyright 2007 Kenneth Loafman <kenneth@loafman.com>
-# Copyright 2011 Henrique Carvalho Alves <hcarvalhoalves@gmail.com>
+# Copyright 2012 Canonical Ltd
 #
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
 # under the terms of the GNU General Public License as published by the
 # Free Software Foundation; either version 2 of the License, or (at your
 # option) any later version.
@@ -16,18 +14,13 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-import duplicity.backend
-from duplicity import config
 
-if config.s3_use_multiprocessing:
-    from ._boto_multi import BotoBackend
-else:
-    from ._boto_single import BotoBackend
+from .. import DuplicityTestCase
 
-duplicity.backend.register_backend(u"boto+gs", BotoBackend)
-# s3 is also implemented by the newer boto3 backend now
-duplicity.backend.register_backend(u"boto+s3", BotoBackend)
+
+class UnitTestCase(DuplicityTestCase):
+    pass
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/hsibackend.py` & `duplicity-2.0.0rc0/duplicity/backends/tahoebackend.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,69 +1,79 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
-# Copyright 2002 Ben Escoto <ben@emerose.org>
-# Copyright 2007 Kenneth Loafman <kenneth@loafman.com>
+# Copyright 2008 Francois Deppierraz
 #
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
 # under the terms of the GNU General Public License as published by the
-# Free Software Foundation; either version 2 of the License, or (at your
+# Free Software Foundation; either version 3 of the License, or (at your
 # option) any later version.
 #
 # Duplicity is distributed in the hope that it will be useful, but
 # WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import range
 import os
+
 import duplicity.backend
-from duplicity import util
+from duplicity import log
 
-hsi_command = u"hsi"
 
+class TAHOEBackend(duplicity.backend.Backend):
+    """
+    Backend for the Tahoe file system
+    """
 
-class HSIBackend(duplicity.backend.Backend):
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
-        self.host_string = parsed_url.hostname
-        self.remote_dir = parsed_url.path
-        if self.remote_dir:
-            self.remote_prefix = self.remote_dir + u"/"
+
+        url = parsed_url.path.strip('/').split('/')
+
+        self.alias = url[0]
+
+        if len(url) > 1:
+            self.directory = "/".join(url[1:])
         else:
-            self.remote_prefix = u""
+            self.directory = ""
+
+        log.Debug(f"tahoe: {url} -> {self.alias}:{self.directory}")
+
+    def get_remote_path(self, filename=None):
+        if filename is None:
+            if self.directory != "":
+                return f"{self.alias}:{self.directory}"
+            else:
+                return f"{self.alias}:"
+
+        if isinstance(filename, b"".__class__):
+            filename = os.fsdecode(filename)
+        if self.directory != "":
+            return f"{self.alias}:{self.directory}/{filename}"
+        else:
+            return f"{self.alias}:{filename}"
+
+    def run(self, *args):
+        cmd = " ".join(args)
+        _, output, _ = self.subprocess_popen(cmd)
+        return output
 
     def _put(self, source_path, remote_filename):
-        if isinstance(remote_filename, b"".__class__):
-            remote_filename = util.fsdecode(remote_filename)
-        commandline = u'%s "put %s : %s%s"' % (hsi_command, source_path.uc_name, self.remote_prefix, remote_filename)
-        self.subprocess_popen(commandline)
+        self.run("tahoe", "cp", source_path.uc_name, self.get_remote_path(remote_filename))
 
     def _get(self, remote_filename, local_path):
-        if isinstance(remote_filename, b"".__class__):
-            remote_filename = util.fsdecode(remote_filename)
-        commandline = u'%s "get %s : %s%s"' % (hsi_command, local_path.uc_name, self.remote_prefix, remote_filename)
-        self.subprocess_popen(commandline)
+        self.run("tahoe", "cp", self.get_remote_path(remote_filename), local_path.uc_name)
 
     def _list(self):
-        commandline = u'%s "ls -l %s"' % (hsi_command, self.remote_dir)
-        l = self.subprocess_popen(commandline)[2]
-        l = l.split(os.linesep.encode())[3:]
-        for i in range(0, len(l)):
-            if l[i]:
-                l[i] = l[i].split()[-1]
-        return [util.fsencode(x) for x in l if x]
+        output = self.run("tahoe", "ls", self.get_remote_path())
+        return [os.fsencode(x) for x in output.split('\n') if x]
 
     def _delete(self, filename):
-        if isinstance(filename, b"".__class__):
-            filename = util.fsdecode(filename)
-        commandline = u'%s "rm %s%s"' % (hsi_command, self.remote_prefix, filename)
-        self.subprocess_popen(commandline)
+        self.run("tahoe", "rm", self.get_remote_path(filename))
 
 
-duplicity.backend.register_backend(u"hsi", HSIBackend)
-duplicity.backend.uses_netloc.extend([u'hsi'])
+duplicity.backend.register_backend("tahoe", TAHOEBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/_boto_multi.py` & `duplicity-2.0.0rc0/duplicity/backends/s3_boto3_backend.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
 # Copyright 2002 Ben Escoto <ben@emerose.org>
 # Copyright 2007 Kenneth Loafman <kenneth@loafman.com>
-# Copyright 2011 Henrique Carvalho Alves <hcarvalhoalves@gmail.com>
+# Copyright 2019 Carl A. Adams <carlalex@overlords.com>
 #
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
 # under the terms of the GNU General Public License as published by the
 # Free Software Foundation; either version 2 of the License, or (at your
 # option) any later version.
@@ -16,233 +16,237 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import division
-from future import standard_library
-standard_library.install_aliases()
-from builtins import range
-
-import os
-import psutil
-import queue
-import socket
-import sys
-import threading
-import time
-import traceback
-
+import duplicity.backend
 from duplicity import config
+from duplicity import file_naming
 from duplicity import log
 from duplicity import progress
-from duplicity.errors import *  # pylint: disable=unused-wildcard-import
-from duplicity.filechunkio import FileChunkIO
-
-from ._boto_single import BotoBackend as BotoSingleBackend
-from ._boto_single import get_connection
-
-BOTO_MIN_VERSION = u"2.1.1"
+from duplicity.errors import (
+    FatalBackendException,
+    BackendException,
+)
+
+
+# Note: current gaps with the old boto backend include:
+#       - Glacier restore to S3 not implemented. Should this
+#         be done here? Or is that out of scope. My current opinion
+#         is that it is out of scope, and the manpage reflects this.
+#         It can take days, so waiting seems like it's not ideal.
+#         "Thaw" isn't currently a generic concept that the core asks
+#         of back-ends. Perhaps that is worth exploring.  The older
+#         boto backend appeared  to attempt this restore in the code,
+#         but the man page indicated that restores should be done out
+#         of band. If implemented,  We should add the the following
+#         new features:
+#              - when restoring from glacier or deep archive, specify TTL.
+#              - allow user to specify how fast to restore (impacts cost).
 
-# Multiprocessing is not supported on *BSD
-if sys.platform not in (u'darwin', u'linux2'):
-    from multiprocessing import dummy as multiprocessing
-    log.Debug(u'Multiprocessing is not supported on %s, will use threads instead.' % sys.platform)
-else:
-    import multiprocessing
-
-
-class ConsumerThread(threading.Thread):
-    u"""
-    A background thread that collects all written bytes from all
-    the pool workers, and reports it to the progress module.
-    Wakes up every second to check for termination
+class S3Boto3Backend(duplicity.backend.Backend):
     """
-    def __init__(self, queue, total):
-        super(ConsumerThread, self).__init__()
-        self.daemon = True
-        self.finish = False
-        self.progress = {}
-        self.queue = queue
-        self.total = total
-
-    def run(self):
-        wait = True
-        while not self.finish:
-            try:
-                args = self.queue.get(wait, 1)
-                self.progress[args[0]] = args[1]
-                wait = False
-            except queue.Empty as e:
-                progress.report_transfer(sum(self.progress.values()), self.total)
-                wait = True
-                pass
-
-
-class BotoBackend(BotoSingleBackend):
-    u"""
     Backend for Amazon's Simple Storage System, (aka Amazon S3), though
-    the use of the boto module, (http://code.google.com/p/boto/).
-
-    To make use of this backend you must set aws_access_key_id
-    and aws_secret_access_key in your ~/.boto or /etc/boto.cfg
-    with your Amazon Web Services key id and secret respectively.
-    Alternatively you can export the environment variables
-    AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.
+    the use of the boto3 module. (See
+    https://boto3.amazonaws.com/v1/documentation/api/latest/index.html
+    for information on boto3.)
+
+    Pursuant to Amazon's announced deprecation of path style S3 access,
+    this backend only supports virtual host style bucket URIs.
+    See the man page for full details.
+
+    To make use of this backend, you must provide AWS credentials.
+    This may be done in several ways: through the environment variables
+    AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY, by the
+    ~/.aws/credentials file, by the ~/.aws/config file,
+    or by using the boto2 style ~/.boto or /etc/boto.cfg files.
     """
 
     def __init__(self, parsed_url):
-        BotoSingleBackend.__init__(self, parsed_url)
+        duplicity.backend.Backend.__init__(self, parsed_url)
+
+        # This folds the null prefix and all null parts, which means that:
+        #  //MyBucket/ and //MyBucket are equivalent.
+        #  //MyBucket//My///My/Prefix/ and //MyBucket/My/Prefix are equivalent.
+        url_path_parts = [x for x in parsed_url.path.split('/') if x != '']
+        if url_path_parts:
+            self.bucket_name = url_path_parts.pop(0)
+        else:
+            raise BackendException('S3 requires a bucket name.')
+
+        if url_path_parts:
+            self.key_prefix = f"{'/'.join(url_path_parts)}/"
+        else:
+            self.key_prefix = ''
+
+        self.parsed_url = parsed_url
+        self.straight_url = duplicity.backend.strip_auth_from_url(parsed_url)
+        self.s3 = None
+        self.bucket = None
+        self.tracker = UploadProgressTracker()
+
+    def reset_connection(self):
+        import boto3
+        import botocore
+        from botocore.exceptions import ClientError
+
+        self.bucket = None
+        self.s3 = boto3.resource('s3', region_name=config.s3_region_name,
+                                 use_ssl=(not config.s3_unencrypted_connection),
+                                 endpoint_url=config.s3_endpoint_url)
+
         try:
-            import boto
-        except ImportError:
-            raise
-        self._setup_pool()
-
-    def _setup_pool(self):
-        number_of_procs = config.s3_multipart_max_procs
-
-        if getattr(self, u'_pool', False):
-            log.Debug(u"A process pool already exists. Destroying previous pool.")
-            self._pool.terminate()  # pylint:disable=access-member-before-definition
-            self._pool.join()  # pylint:disable=access-member-before-definition
-            self._pool = None
-
-        log.Debug(u"Setting multipart boto backend process pool to %d processes" % number_of_procs)
-
-        self._pool = multiprocessing.Pool(processes=number_of_procs)
-
-    def _close(self):
-        BotoSingleBackend._close(self)
-        log.Debug(u"Closing pool")
-        self._pool.terminate()
-        self._pool.join()
-
-    def upload(self, filename, key, headers=None):
-        import boto  # pylint: disable=import-error
-
-        chunk_size = config.s3_multipart_chunk_size
-
-        # Check minimum chunk size for S3
-        if chunk_size < config.s3_multipart_minimum_chunk_size:
-            log.Warn(u"Minimum chunk size is %d, but %d specified." % (
-                config.s3_multipart_minimum_chunk_size, chunk_size))
-            chunk_size = config.s3_multipart_minimum_chunk_size
-
-        # Decide in how many chunks to upload
-        bytes = os.path.getsize(filename)  # pylint: disable=redefined-builtin
-        if bytes < chunk_size:
-            chunks = 1
+            self.s3.meta.client.head_bucket(Bucket=self.bucket_name)
+        except botocore.exceptions.ClientError as bce:
+            error_code = bce.response['Error']['Code']
+            if error_code == '404':
+                raise FatalBackendException(f'S3 bucket "{self.bucket_name}" does not exist',
+                                            code=log.ErrorCode.backend_not_found)
+            else:
+                raise
+
+        self.bucket = self.s3.Bucket(self.bucket_name)  # only set if bucket is thought to exist.
+
+    def _put(self, local_source_path, remote_filename):
+        from boto3.s3.transfer import TransferConfig
+
+        if not self.s3:
+            self.reset_connection()
+
+        # files that should not in glacier and deep_archive, to allow smooth operation
+        if config.short_filenames:
+            glacier_exceptions = [
+                file_naming.full_manifest_re_short,
+                file_naming.inc_manifest_re_short,
+                file_naming.full_sig_re_short,
+                file_naming.new_sig_re_short
+            ]
+        else:
+            glacier_exceptions = [
+                file_naming.full_manifest_re,
+                file_naming.inc_manifest_re,
+                file_naming.full_sig_re,
+                file_naming.new_sig_re
+            ]
+
+        def is_glacier_exception(filename):
+            return any([x.match(filename) for x in glacier_exceptions])
+
+        if config.s3_use_rrs:
+            storage_class = 'REDUCED_REDUNDANCY'
+        elif config.s3_use_ia:
+            storage_class = 'STANDARD_IA'
+        elif config.s3_use_onezone_ia:
+            storage_class = 'ONEZONE_IA'
+        elif config.s3_use_glacier and not is_glacier_exception(remote_filename):
+            storage_class = 'GLACIER'
+        elif config.s3_use_glacier_ir and not is_glacier_exception(remote_filename):
+            storage_class = 'GLACIER_IR'
+        elif config.s3_use_deep_archive and not is_glacier_exception(remote_filename):
+            storage_class = 'DEEP_ARCHIVE'
         else:
-            chunks = bytes // chunk_size
-            if (bytes % chunk_size):
-                chunks += 1
-
-        log.Debug(u"Uploading %d bytes in %d chunks" % (bytes, chunks))
-
-        mp = self.bucket.initiate_multipart_upload(key.key, headers, encrypt_key=config.s3_use_sse)
-
-        # Initiate a queue to share progress data between the pool
-        # workers and a consumer thread, that will collect and report
-        queue = None
-        if config.progress:
-            manager = multiprocessing.Manager()
-            queue = manager.Queue()
-            consumer = ConsumerThread(queue, bytes)
-            consumer.start()
-        tasks = []
-        for n in range(chunks):
-            storage_uri = boto.storage_uri(self.boto_uri_str)
-            params = [self.scheme, self.parsed_url, storage_uri, self.bucket_name,
-                      mp.id, filename, n, chunk_size, config.num_retries,
-                      queue]
-            tasks.append(self._pool.apply_async(multipart_upload_worker, params))
+            storage_class = 'STANDARD'
+        extra_args = {'StorageClass': storage_class}
 
-        log.Debug(u"Waiting for the pool to finish processing %s tasks" % len(tasks))
-        while tasks:
+        if config.s3_use_sse:
+            extra_args['ServerSideEncryption'] = 'AES256'
+        elif config.s3_use_sse_kms:
+            if config.s3_kms_key_id is None:
+                raise FatalBackendException("S3 USE SSE KMS was requested, but key id not provided "
+                                            "require (--s3-kms-key-id)",
+                                            code=log.ErrorCode.s3_kms_no_id)
+            extra_args['ServerSideEncryption'] = 'aws:kms'
+            extra_args['SSEKMSKeyId'] = config.s3_kms_key_id
+            if config.s3_kms_grant:
+                extra_args['GrantFullControl'] = config.s3_kms_grant
+
+        transfer_config = TransferConfig(multipart_chunksize=config.s3_multipart_chunk_size,
+                                         multipart_threshold=config.s3_multipart_chunk_size,
+                                         max_concurrency=config.s3_multipart_max_procs)
+
+        # Should the tracker be scoped to the put or the backend?
+        # The put seems right to me, but the results look a little more correct
+        # scoped to the backend.  This brings up questions about knowing when
+        # it's proper for it to be reset.
+        # tracker = UploadProgressTracker() # Scope the tracker to the put()
+        tracker = self.tracker
+
+        remote_filename = util.fsdecode(remote_filename)
+        key = self.key_prefix + remote_filename
+
+        log.Info(f"Uploading {self.straight_url}/{remote_filename} to {storage_class} Storage")
+        self.s3.Object(self.bucket.name, key).upload_file(local_source_path.uc_name,
+                                                          Callback=tracker.progress_cb,
+                                                          Config=transfer_config,
+                                                          ExtraArgs=extra_args)
+
+    def _get(self, remote_filename, local_path):
+        if not self.s3:
+            self.reset_connection()
+
+        remote_filename = os.fsdecode(remote_filename)
+        key = self.key_prefix + remote_filename
+        self.s3.Object(self.bucket.name, key).download_file(local_path.uc_name)
+
+    def _list(self):
+        if not self.s3:
+            self.reset_connection()
+
+        filename_list = []
+        for obj in self.bucket.objects.filter(Prefix=self.key_prefix):
             try:
-                tasks[0].wait(timeout=config.s3_multipart_max_timeout)
-                if tasks[0].ready():
-                    if tasks[0].successful():
-                        del tasks[0]
-                    else:
-                        log.Debug(u"Part upload not successful, aborting multipart upload.")
-                        self._setup_pool()
-                        break
-                else:
-                    raise multiprocessing.TimeoutError
-            except multiprocessing.TimeoutError:
-                log.Debug(u"%s tasks did not finish by the specified timeout,"
-                          u"aborting multipart upload and resetting pool." % len(tasks))
-                self._setup_pool()
-                break
-
-        log.Debug(u"Done waiting for the pool to finish processing")
-
-        # Terminate the consumer thread, if any
-        if config.progress:
-            consumer.finish = True
-            consumer.join()
-
-        if len(tasks) > 0 or len(mp.get_all_parts()) < chunks:
-            mp.cancel_upload()
-            raise BackendException(u"Multipart upload failed. Aborted.")
-
-        return mp.complete_upload()
-
-
-def multipart_upload_worker(scheme, parsed_url, storage_uri, bucket_name, multipart_id,
-                            filename, offset, bytes, num_retries, queue):  # pylint: disable=redefined-builtin
-    u"""
-    Worker method for uploading a file chunk to S3 using multipart upload.
-    Note that the file chunk is read into memory, so it's important to keep
-    this number reasonably small.
-    """
+                filename = obj.key.replace(self.key_prefix, '', 1)
+                filename_list.append(os.fsencode(filename))
+                log.Debug(f"Listed {self.straight_url}/{filename}")
+            except AttributeError:
+                pass
+        return filename_list
 
-    def _upload_callback(uploaded, total):
-        worker_name = multiprocessing.current_process().name
-        log.Debug(u"%s: Uploaded %s/%s bytes" % (worker_name, uploaded, total))
-        if queue is not None:
-            queue.put([offset, uploaded])  # Push data to the consumer thread
-
-    def _upload(num_retries):
-        worker_name = multiprocessing.current_process().name
-        log.Debug(u"%s: Uploading chunk %d" % (worker_name, offset + 1))
-        try:
-            conn = get_connection(scheme, parsed_url, storage_uri)
-            bucket = conn.lookup(bucket_name)
+    def _delete(self, remote_filename):
+        if not self.s3:
+            self.reset_connection()
+
+        remote_filename = os.fsdecode(remote_filename)
+        key = self.key_prefix + remote_filename
+        self.s3.Object(self.bucket.name, key).delete()
+
+    def _query(self, remote_filename):
+        if not self.s3:
+            self.reset_connection()
 
-            for mp in bucket.list_multipart_uploads():
-                if mp.id == multipart_id:
-                    with FileChunkIO(filename, u'r', offset=offset * bytes, bytes=bytes) as fd:
-                        start = time.time()
-                        try:
-                            mp.upload_part_from_file(fd, offset + 1, cb=_upload_callback,
-                                                     num_cb=max(2, 8 * bytes / (1024 * 1024))
-                                                     )  # Max num of callbacks = 8 times x megabyte
-                        except socket.gaierror as ex:
-                            log.Warn(ex.strerror)
-                        end = time.time()
-                        log.Debug((u"{name}: Uploaded chunk {chunk} "
-                                   u"at roughly {speed} bytes/second").format(name=worker_name,
-                                                                              chunk=offset + 1,
-                                                                              speed=(bytes /
-                                                                                     max(1, abs(end - start)))))
-                    break
-            conn.close()
-            conn = None
-            bucket = None
-            del conn
-        except Exception as e:
-            traceback.print_exc()
-            if num_retries:
-                log.Debug(u"%s: Upload of chunk %d failed. Retrying %d more times..." % (
-                    worker_name, offset + 1, num_retries - 1))
-                return _upload(num_retries - 1)
-            log.Debug(u"%s: Upload of chunk %d failed. Aborting..." % (
-                worker_name, offset + 1))
-            raise e
-        log.Debug(u"%s: Upload of chunk %d complete" % (worker_name, offset + 1))
+        import botocore
 
-    return _upload(num_retries)
+        remote_filename = os.fsdecode(remote_filename)
+        key = self.key_prefix + remote_filename
+        content_length = -1
+        try:
+            s3_obj = self.s3.Object(self.bucket.name, key)
+            s3_obj.load()
+            content_length = s3_obj.content_length
+        except botocore.exceptions.ClientError as bce:
+            if bce.response['Error']['Code'] == '404':
+                pass
+            else:
+                raise
+        return {'size': content_length}
+
+
+class UploadProgressTracker(object):
+    def __init__(self):
+        self.total_bytes = 0
+
+    def progress_cb(self, fresh_byte_count):
+        self.total_bytes += fresh_byte_count
+        progress.report_transfer(self.total_bytes, 0)  # second arg appears to be unused
+        # It would seem to me that summing progress should be the callers job,
+        # and backends should just toss bytes written numbers over the fence.
+        # But, the progress bar doesn't work in a reasonable way when we do
+        # that. (This would also eliminate the need for this class to hold
+        # the scoped rolling total.)
+        # progress.report_transfer(fresh_byte_count, 0)
+
+
+duplicity.backend.register_backend("boto3+s3", S3Boto3Backend)
+# make boto3 the default s3 backend
+duplicity.backend.register_backend("s3", S3Boto3Backend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/par2backend.py` & `duplicity-2.0.0rc0/duplicity/backends/par2backend.py`

 * *Files 19% similar despite different names*

```diff
@@ -16,27 +16,28 @@
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 import os
 import re
+
 from duplicity import backend
-from duplicity.errors import BackendException
-from duplicity import log
 from duplicity import config
-from duplicity import util
+from duplicity import log
+from duplicity.errors import BackendException
 
 
 class Par2Backend(backend.Backend):
-    u"""This backend wrap around other backends and create Par2 recovery files
+    """This backend wrap around other backends and create Par2 recovery files
     before the file and the Par2 files are transfered with the wrapped backend.
 
     If a received file is corrupt it will try to repair it on the fly.
     """
+
     def __init__(self, parsed_url):
         backend.Backend.__init__(self, parsed_url)
 
         self.parsed_url = parsed_url
         try:
             self.redundancy = config.par2_redundancy
         except AttributeError:
@@ -44,83 +45,82 @@
 
         try:
             self.volumes = config.par2_volumes
         except AttributeError:
             self.volumes = 1
 
         try:
-            self.common_options = config.par2_options + u" -q -q"
+            self.common_options = f"{config.par2_options} -q -q"
         except AttributeError:
-            self.common_options = u"-q -q"
+            self.common_options = "-q -q"
 
         self.wrapped_backend = backend.get_backend_object(parsed_url.url_string)
 
-        for attr in [u'_get', u'_put', u'_list', u'_delete', u'_delete_list',
-                     u'_query', u'_query_list', u'_retry_cleanup', u'_error_code',
-                     u'_move', u'_close']:
+        for attr in ['_get', '_put', '_list', '_delete', '_delete_list',
+                     '_query', '_query_list', '_retry_cleanup', '_error_code',
+                     '_move', '_close']:
             if hasattr(self.wrapped_backend, attr):
                 setattr(self, attr, getattr(self, attr[1:]))
 
         # always declare _delete_list support because _delete queries file
         # list for every call
         self._delete_list = self.delete_list
 
     def transfer(self, method, source_path, remote_filename):
-        u"""create Par2 files and transfer the given file and the Par2 files
+        """create Par2 files and transfer the given file and the Par2 files
         with the wrapped backend.
 
         Par2 must run on the real filename or it would restore the
         temp-filename later on. So first of all create a tempdir and symlink
         the soure_path with remote_filename into this.
         """
         par2temp = source_path.get_temp_in_same_dir()
         par2temp.mkdir()
         source_symlink = par2temp.append(remote_filename)
         source_target = source_path.get_canonical()
         if not os.path.isabs(source_target):
-            source_target = os.path.join(util.fsencode(os.getcwd()), source_target)
+            source_target = os.path.join(os.fsencode(os.getcwd()), source_target)
         os.symlink(source_target, source_symlink.get_canonical())
         source_symlink.setdata()
 
-        log.Info(u"Create Par2 recovery files")
-        par2create = u'par2 c -r%d -n%d %s "%s"' % (self.redundancy, self.volumes,
-                                                    self.common_options,
-                                                    util.fsdecode(source_symlink.get_canonical()))
+        log.Info("Create Par2 recovery files")
+        par2create = f'par2 c -r{int(self.redundancy)} -n{int(self.volumes)} {self.common_options} ' \
+                     f'"{os.fsdecode(source_symlink.get_canonical())}"'
         returncode, out, err = self.subprocess_popen(par2create)
 
         if returncode:
-            log.Warn(u"Failed to create par2 file with requested options, retrying with -n1")
-            par2create = u'par2 c -r%d -n1 %s "%s"' % (self.redundancy, self.common_options,
-                                                       util.fsdecode(source_symlink.get_canonical()))
+            log.Warn("Failed to create par2 file with requested options, retrying with -n1")
+            par2create = f'par2 c -r{int(self.redundancy)} -n1 {self.common_options} ' \
+                         f'"{os.fsdecode(source_symlink.get_canonical())}"'
             returncode, out, err = self.subprocess_popen(par2create)
             if not returncode:
-                log.Warn(u"Successfully created par2 file with -n1")
+                log.Warn("Successfully created par2 file with -n1")
 
         source_symlink.delete()
         files_to_transfer = []
         if not returncode:
             for file in par2temp.listdir():
                 files_to_transfer.append(par2temp.append(file))
         else:
-            log.Error(u"FAILED to create par2 file with returncode %d" % returncode)
+            log.Error(f"FAILED to create par2 file with returncode {int(returncode)}")
 
         method(source_path, remote_filename)
         for file in files_to_transfer:
             method(file, file.get_filename())
 
         par2temp.deltree()
 
     def put(self, local, remote):
         self.transfer(self.wrapped_backend._put, local, remote)
 
     def move(self, local, remote):
         self.transfer(self.wrapped_backend._move, local, remote)
 
     def get(self, remote_filename, local_path):
-        u"""transfer remote_filename and the related .par2 file into
+        """transfer remote_filename and the related .par2 file into
         a temp-dir. remote_filename will be renamed into local_path before
         finishing.
 
         If "par2 verify" detect an error transfer the Par2-volumes into the
         temp-dir and try to repair.
         """
 
@@ -130,86 +130,84 @@
 
         self.wrapped_backend._get(remote_filename, local_path_temp)
 
         try:
             par2file = par2temp.append(remote_filename + b'.par2')
             self.wrapped_backend._get(par2file.get_filename(), par2file)
 
-            par2verify = u'par2 v %s %s "%s"' % (self.common_options,
-                                                 util.fsdecode(par2file.get_canonical()),
-                                                 util.fsdecode(local_path_temp.get_canonical()))
+            par2verify = f'par2 v {self.common_options} {os.fsdecode(par2file.get_canonical())} ' \
+                         f'"{os.fsdecode(local_path_temp.get_canonical())}"'
             returncode, out, err = self.subprocess_popen(par2verify)
 
             if returncode:
-                log.Warn(u"File is corrupt. Try to repair %s" % remote_filename)
-                c = re.compile(u'%s\\.vol[\\d+]*\\.par2' % remote_filename.decode())
-                par2volumes = [f for f in self.wrapped_backend._list() if c.match(util.fsdecode(f))]
+                log.Warn(f"File is corrupt. Try to repair {remote_filename}")
+                c = re.compile(f'{remote_filename.decode()}\\.vol[\\d+]*\\.par2')
+                par2volumes = [f for f in self.wrapped_backend._list() if c.match(os.fsdecode(f))]
 
                 for filename in par2volumes:
                     file = par2temp.append(filename)
                     self.wrapped_backend._get(filename, file)
 
-                par2repair = u'par2 r %s %s "%s"' % (self.common_options,
-                                                     util.fsdecode(par2file.get_canonical()),
-                                                     util.fsdecode(local_path_temp.get_canonical()))
+                par2repair = f'par2 r {self.common_options} {os.fsdecode(par2file.get_canonical())} ' \
+                             f'"{os.fsdecode(local_path_temp.get_canonical())}"'
                 returncode, out, err = self.subprocess_popen(par2repair)
 
                 if returncode:
-                    log.Error(u"Failed to repair %s" % remote_filename)
+                    log.Error(f"Failed to repair {remote_filename}")
                 else:
-                    log.Warn(u"Repair successful %s" % remote_filename)
+                    log.Warn(f"Repair successful {remote_filename}")
         except BackendException:
             # par2 file not available
             pass
         finally:
             local_path_temp.rename(local_path)
             par2temp.deltree()
 
     def delete(self, filename):
-        u"""delete given filename and its .par2 files
+        """delete given filename and its .par2 files
         """
         self.wrapped_backend._delete(filename)
 
         remote_list = self.unfiltered_list()
 
-        c = re.compile(u'%s(?:\\.vol[\\d+]*)?\\.par2' % util.fsdecode(filename))
+        c = re.compile(f'{os.fsdecode(filename)}(?:\\.vol[\\d+]*)?\\.par2')
         for remote_filename in remote_list:
-            if c.match(util.fsdecode(remote_filename)):
-                self.wrapped_backend._delete(util.fsencode(remote_filename))
+            if c.match(os.fsdecode(remote_filename)):
+                self.wrapped_backend._delete(os.fsencode(remote_filename))
 
     def delete_list(self, filename_list):
-        u"""delete given filename_list and all .par2 files that belong to them
+        """delete given filename_list and all .par2 files that belong to them
         """
         remote_list = self.unfiltered_list()
 
         for filename in filename_list[:]:
-            c = re.compile(u'%s(?:\\.vol[\\d+]*)?\\.par2' % util.fsdecode(filename))
+            c = re.compile(f'{os.fsdecode(filename)}(?:\\.vol[\\d+]*)?\\.par2')
             for remote_filename in remote_list:
-                if c.match(util.fsdecode(remote_filename)):
+                if c.match(os.fsdecode(remote_filename)):
                     # insert here to make sure par2 files will be removed first
                     filename_list.insert(0, remote_filename)
 
-        if hasattr(self.wrapped_backend, u'_delete_list'):
+        if hasattr(self.wrapped_backend, '_delete_list'):
             return self.wrapped_backend._delete_list(filename_list)
         else:
             for filename in filename_list:
                 self.wrapped_backend._delete(filename)
 
     def list(self):
-        u"""
+        """
         Return list of filenames (byte strings) present in backend
 
         Files ending with ".par2" will be excluded from the list.
         """
         remote_list = self.wrapped_backend._list()
 
-        c = re.compile(u'(?!.*\\.par2$)')
+        c = re.compile('(?!.*\\.par2$)')
         filtered_list = []
         for filename in remote_list:
-            if c.match(util.fsdecode(filename)):
+            if c.match(os.fsdecode(filename)):
                 filtered_list.append(filename)
         return filtered_list
 
     def unfiltered_list(self):
         return self.wrapped_backend._list()
 
     def retry_cleanup(self):
@@ -224,8 +222,8 @@
     def query_list(self, filename_list):
         return self.wrapped_backend._query(filename_list)
 
     def close(self):
         self.wrapped_backend._close()
 
 
-backend.register_backend_prefix(u'par2', Par2Backend)
+backend.register_backend_prefix('par2', Par2Backend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/ssh_paramiko_backend.py` & `duplicity-2.0.0rc0/duplicity/backends/ssh_paramiko_backend.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,43 +17,37 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import division
-from builtins import input
-from builtins import oct
-from builtins import zip
 
 import errno
 import getpass
 import logging
 import os
 import re
 import sys
 import warnings
-
 from binascii import hexlify
 
 import duplicity.backend
-from duplicity import progress
 from duplicity import config
+from duplicity import progress
 from duplicity import util
 from duplicity.errors import BackendException
 
 global paramiko
 
-
 read_blocksize = 65635  # for doing scp retrievals, where we need to read ourselves
 
 
 class SSHParamikoBackend(duplicity.backend.Backend):
-    u"""This backend accesses files using the sftp or scp protocols.
+    """This backend accesses files using the sftp or scp protocols.
     It does not need any local client programs, but an ssh server and the sftp
     program must be installed on the remote side (or with scp, the programs
     scp, ls, mkdir, rm and a POSIX-compliant shell).
 
     Authentication keys are requested from an ssh agent if present, then
     ~/.ssh/id_rsa/dsa are tried. If -oIdentityFile=path is present in
     --ssh-options, then that file is also tried. The passphrase for any of
@@ -64,407 +58,397 @@
     Missing directories on the remote side will be created.
 
     If scp is active then all operations on the remote side require passing
     arguments through a shell, which introduces unavoidable quoting issues:
     directory and file names that contain single quotes will not work.
     This problem does not exist with sftp.
     """
+
     def __init__(self, parsed_url):
         global paramiko
 
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         self.retry_delay = 10
 
         if parsed_url.path:
             # remove first leading '/'
             self.remote_dir = re.sub(r'^/', r'', parsed_url.path, 1)
         else:
-            self.remote_dir = u'.'
+            self.remote_dir = '.'
 
         # lazily import paramiko when we need it
         # debian squeeze's paramiko is a bit old, so we silence randompool
         # depreciation warning note also: passphrased private keys work with
         # squeeze's paramiko only if done with DES, not AES
         with warnings.catch_warnings():
-            warnings.simplefilter(u"ignore")
+            warnings.simplefilter("ignore")
             try:
                 import paramiko
             except ImportError:
                 raise
 
-        class AgreedAddPolicy (paramiko.AutoAddPolicy):
-            u"""
+        class AgreedAddPolicy(paramiko.AutoAddPolicy):
+            """
             Policy for showing a yes/no prompt and adding the hostname and new
             host key to the known host file accordingly.
 
             This class simply extends the AutoAddPolicy class with a yes/no
             prompt.
             """
+
             def missing_host_key(self, client, hostname, key):
                 fp = hexlify(key.get_fingerprint())
-                fingerprint = u':'.join(str(a + b) for a, b in list(zip(fp[::2], fp[1::2])))
-                question = u"""The authenticity of host '%s' can't be established.
-%s key fingerprint is %s.
-Are you sure you want to continue connecting (yes/no)? """ % (hostname,
-                                                              key.get_name().upper(),
-                                                              fingerprint)
+                fingerprint = ':'.join(str(a + b) for a, b in list(zip(fp[::2], fp[1::2])))
+                question = f"""The authenticity of host '{hostname}' can't be established.
+{key.get_name().upper()} key fingerprint is {fingerprint}.
+Are you sure you want to continue connecting (yes/no)? """
                 while True:
                     sys.stdout.write(question)
                     choice = input().lower()
-                    if choice in [u'yes', u'y']:
+                    if choice in ['yes', 'y']:
                         paramiko.AutoAddPolicy.missing_host_key(self, client,
                                                                 hostname, key)
                         return
-                    elif choice in [u'no', u'n']:
+                    elif choice in ['no', 'n']:
                         raise AuthenticityException(hostname)
                     else:
-                        question = u"Please type 'yes' or 'no': "
+                        question = "Please type 'yes' or 'no': "
 
-        class AuthenticityException (paramiko.SSHException):
+        class AuthenticityException(paramiko.SSHException):
             def __init__(self, hostname):
                 paramiko.SSHException.__init__(self,
-                                               u'Host key verification for server %s failed.' %
-                                               hostname)
+                                               f'Host key verification for server {hostname} failed.')
 
         self.client = paramiko.SSHClient()
         self.client.set_missing_host_key_policy(AgreedAddPolicy())
 
         # paramiko uses logging with the normal python severity levels,
         # but duplicity uses both custom levels and inverted logic...*sigh*
-        self.client.set_log_channel(u"sshbackend")
-        ours = paramiko.util.get_logger(u"sshbackend")
+        self.client.set_log_channel("sshbackend")
+        ours = paramiko.util.get_logger("sshbackend")
         dest = logging.StreamHandler(sys.stderr)
-        dest.setFormatter(logging.Formatter(u'ssh: %(message)s'))
+        dest.setFormatter(logging.Formatter('ssh: %(message)s'))
         ours.addHandler(dest)
 
         # ..and the duplicity levels are neither linear,
         # nor are the names compatible with python logging,
         # eg. 'NOTICE'...WAAAAAH!
-        plevel = logging.getLogger(u"duplicity").getEffectiveLevel()
+        plevel = logging.getLogger("duplicity").getEffectiveLevel()
         if plevel <= 1:
             wanted = logging.DEBUG
         elif plevel <= 5:
             wanted = logging.INFO
         elif plevel <= 7:
             wanted = logging.WARNING
         elif plevel <= 9:
             wanted = logging.ERROR
         else:
             wanted = logging.CRITICAL
         ours.setLevel(wanted)
 
         # load user/local known_hosts files
         # paramiko is very picky wrt format and bails out on any problem...
-        global_known_hosts = u"/etc/ssh/ssh_known_hosts"
+        global_known_hosts = "/etc/ssh/ssh_known_hosts"
         m = re.search(r"""
                       ^(?:.+\s+)?
                       (?:-oGlobalKnownHostsFile=)
                       (
                           ([\"'])
                           ([^\\2]+)
                           \\2
                           |
                           [\S]+
                       )
                       """,
                       config.ssh_options, re.VERBOSE)
-        if (m is not None):
+        if m is not None:
             global_known_hosts = m.group(3) if m.group(3) else m.group(1)
         try:
             if os.path.isfile(global_known_hosts):
                 self.client.load_system_host_keys(global_known_hosts)
         except Exception as e:
             raise BackendException(f"could not load {global_known_hosts}, maybe corrupt?")
 
-        user_known_hosts = os.path.expanduser(u"~/.ssh/known_hosts")
+        user_known_hosts = os.path.expanduser("~/.ssh/known_hosts")
         m = re.search(r"""
                       ^(?:.+\s+)?
                       (?:-oUserKnownHostsFile=)
                       (
                           ([\"'])
                           ([^\\2]+)
                           \\2
                           |
                           [\S]+
                       )
                       """,
                       config.ssh_options, re.VERBOSE)
-        if (m is not None):
+        if m is not None:
             user_known_hosts = m.group(3) if m.group(3) else m.group(1)
         try:
             # use load_host_keys() to signal it's writable to paramiko
             # load if file exists or add filename to create it if needed
             if os.path.isfile(user_known_hosts):
                 self.client.load_host_keys(user_known_hosts)
             else:
                 self.client._host_keys_filename = user_known_hosts
         except Exception as e:
             raise BackendException(f"could not load {user_known_hosts}, maybe corrupt?")
 
-        u""" the next block reorganizes all host parameters into a
+        """ the next block reorganizes all host parameters into a
         dictionary like SSHConfig does. this dictionary 'self.config'
         becomes the authorative source for these values from here on.
         rationale is that it is easiest to deal wrt overwriting multiple
         values from ssh_config file. (ede 03/2012)
         """
-        self.config = {u'hostname': parsed_url.hostname}
+        self.config = {'hostname': parsed_url.hostname}
         # get system host config entries
-        self.config.update(self.gethostconfig(u'/etc/ssh/ssh_config',
+        self.config.update(self.gethostconfig('/etc/ssh/ssh_config',
                                               parsed_url.hostname))
         # update with user's config file
-        self.config.update(self.gethostconfig(u'~/.ssh/config',
+        self.config.update(self.gethostconfig('~/.ssh/config',
                                               parsed_url.hostname))
         # update with url values
         # username from url
         if parsed_url.username:
-            self.config.update({u'user': parsed_url.username})
+            self.config.update({'user': parsed_url.username})
         # username from input
-        if u'user' not in self.config:
-            self.config.update({u'user': getpass.getuser()})
+        if 'user' not in self.config:
+            self.config.update({'user': getpass.getuser()})
         # port from url
         if parsed_url.port:
-            self.config.update({u'port': parsed_url.port})
+            self.config.update({'port': parsed_url.port})
         # ensure there is deafult 22 or an int value
-        if u'port' in self.config:
-            self.config.update({u'port': int(self.config[u'port'])})
+        if 'port' in self.config:
+            self.config.update({'port': int(self.config['port'])})
         else:
-            self.config.update({u'port': 22})
+            self.config.update({'port': 22})
         # parse ssh options for alternative ssh private key, identity file
         m = re.search(r"""
                       ^(?:.+\s+)?
                       (?:-oIdentityFile=|-i\s+)
                       (([\"'])
                       (
                           [^\\2]+)\\2
                           |
                           [\S]+
                       )
                       """,
                       config.ssh_options, re.VERBOSE)
-        if (m is not None):
+        if m is not None:
             keyfilename = m.group(3) if m.group(3) else m.group(1)
-            self.config[u'identityfile'] = keyfilename.strip(u'\'\"')
+            self.config['identityfile'] = keyfilename.strip('\'\"')
         # ensure ~ is expanded and identity exists in dictionary
-        if u'identityfile' in self.config:
-            if not isinstance(self.config[u'identityfile'], list):
+        if 'identityfile' in self.config:
+            if not isinstance(self.config['identityfile'], list):
                 # Paramiko 1.9.0 and earlier do not support multiple
                 # identity files when parsing config files and always
                 # return a string; later versions always return a list,
                 # even if there is only one file given.
                 #
                 # All recent versions seem to support *using* multiple
                 # identity files, though, so to make things easier, we
                 # simply always use a list.
-                self.config[u'identityfile'] = [self.config[u'identityfile']]
+                self.config['identityfile'] = [self.config['identityfile']]
 
-            self.config[u'identityfile'] = [
-                os.path.expanduser(i) for i in self.config[u'identityfile']]
+            self.config['identityfile'] = [
+                os.path.expanduser(i) for i in self.config['identityfile']]
         else:
-            self.config[u'identityfile'] = None
+            self.config['identityfile'] = None
 
         # get password, enable prompt if askpass is set
         self.use_getpass = config.ssh_askpass
         # set url values for beautiful login prompt
-        parsed_url.username = self.config[u'user']
-        parsed_url.hostname = self.config[u'hostname']
+        parsed_url.username = self.config['user']
+        parsed_url.hostname = self.config['hostname']
         password = self.get_password()
 
         try:
-            self.client.connect(hostname=self.config[u'hostname'],
-                                port=self.config[u'port'],
-                                username=self.config[u'user'],
+            self.client.connect(hostname=self.config['hostname'],
+                                port=self.config['port'],
+                                username=self.config['user'],
                                 password=password,
                                 allow_agent=True,
                                 look_for_keys=True,
-                                key_filename=self.config[u'identityfile'])
+                                key_filename=self.config['identityfile'])
         except Exception as e:
-            raise BackendException(u"ssh connection to %s@%s:%d failed: %s" % (
-                self.config[u'user'],
-                self.config[u'hostname'],
-                self.config[u'port'], e))
-        self.client.get_transport().set_keepalive((int)(config.timeout / 2))
+            raise BackendException(f"ssh connection to "
+                                   f"{self.config['user']}@{self.config['hostname']}:{int(self.config['port'])} "
+                                   f"failed: {e}")
+        self.client.get_transport().set_keepalive(int(config.timeout / 2))
 
         self.scheme = duplicity.backend.strip_prefix(parsed_url.scheme,
-                                                     u'paramiko')
-        self.use_scp = (self.scheme == u'scp')
+                                                     'paramiko')
+        self.use_scp = (self.scheme == 'scp')
 
         # scp or sftp?
-        if (self.use_scp):
+        if self.use_scp:
             # sanity-check the directory name
-            if (re.search(u"'", self.remote_dir)):
-                raise BackendException(u"cannot handle directory names with single quotes with scp")
+            if re.search("'", self.remote_dir):
+                raise BackendException("cannot handle directory names with single quotes with scp")
 
             # make directory if needed
-            self.runremote(u"mkdir -p '%s'" % (self.remote_dir,), False, u"scp mkdir ")
+            self.runremote(f"mkdir -p '{self.remote_dir}'", False, "scp mkdir ")
         else:
             try:
                 self.sftp = self.client.open_sftp()
             except Exception as e:
-                raise BackendException(u"sftp negotiation failed: %s" % e)
+                raise BackendException(f"sftp negotiation failed: {e}")
 
             # move to the appropriate directory, possibly after creating it and its parents
             dirs = self.remote_dir.split(os.sep)
             if len(dirs) > 0:
-                if dirs[0] == u'':
-                    dirs[0] = u'/'
+                if dirs[0] == '':
+                    dirs[0] = '/'
                 for d in dirs:
-                    if (d == u''):
+                    if d == '':
                         continue
                     try:
                         attrs = self.sftp.stat(d)
                     except IOError as e:
                         if e.errno == errno.ENOENT:
                             try:
                                 self.sftp.mkdir(d)
                             except Exception as e:
-                                raise BackendException(u"sftp mkdir %s failed: %s" %
-                                                       (self.sftp.normalize(u".") + u"/" + d, e))
+                                raise BackendException(f"sftp mkdir {self.sftp.normalize('.')}/{d} failed: {e}")
                         else:
-                            raise BackendException(u"sftp stat %s failed: %s" %
-                                                   (self.sftp.normalize(u".") + u"/" + d, e))
+                            raise BackendException(f"sftp stat {self.sftp.normalize('.')}/{d} failed: {e}")
                     try:
                         self.sftp.chdir(d)
                     except Exception as e:
-                        raise BackendException(u"sftp chdir to %s failed: %s" %
-                                               (self.sftp.normalize(u".") + u"/" + d, e))
+                        raise BackendException(f"sftp chdir to {self.sftp.normalize('.')}/{d} failed: {e}")
 
     def _put(self, source_path, remote_filename):
         # remote_filename is a byte object, not str or unicode
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         if self.use_scp:
-            f = open(source_path.name, u'rb')
+            f = open(source_path.name, 'rb')
             try:
                 chan = self.client.get_transport().open_session()
                 chan.settimeout(config.timeout)
                 # scp in sink mode uses the arg as base directory
-                chan.exec_command(u"scp -t '%s'" % self.remote_dir)
+                chan.exec_command(f"scp -t '{self.remote_dir}'")
             except Exception as e:
-                raise BackendException(u"scp execution failed: %s" % e)
+                raise BackendException(f"scp execution failed: {e}")
             # scp protocol: one 0x0 after startup, one after the Create meta,
             # one after saving if there's a problem: 0x1 or 0x02 and some error
             # text
             response = chan.recv(1)
-            if (response != b"\0"):
+            if response != b"\0":
                 raise BackendException(b"scp remote error: %b" % chan.recv(-1))
             fstat = os.stat(source_path.name)
-            chan.send(u'C%s %d %s\n' % (oct(fstat.st_mode)[-4:], fstat.st_size,
-                                        remote_filename))
+            chan.send(f'C{oct(fstat.st_mode)[-4:]} {int(fstat.st_size)} {remote_filename}\n')
             response = chan.recv(1)
-            if (response != b"\0"):
+            if response != b"\0":
                 raise BackendException(b"scp remote error: %b" % chan.recv(-1))
             file_pos = 0
             file_size = fstat.st_size
             while file_pos < file_size:
                 chan.sendall(f.read(16384))
                 file_pos = f.tell()
                 progress.report_transfer(file_pos, file_size)
             chan.sendall(b'\0')
             f.close()
             response = chan.recv(1)
-            if (response != b"\0"):
-                raise BackendException(u"scp remote error: %s" % chan.recv(-1))
+            if response != b"\0":
+                raise BackendException(f"scp remote error: {chan.recv(-1)}")
             chan.close()
         else:
             self.sftp.put(source_path.name, remote_filename, callback=progress.report_transfer)
 
     def _get(self, remote_filename, local_path):
         # remote_filename is a byte object, not str or unicode
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         if self.use_scp:
             try:
                 chan = self.client.get_transport().open_session()
                 chan.settimeout(config.timeout)
-                chan.exec_command(u"scp -f '%s/%s'" % (self.remote_dir,
-                                                       remote_filename))
+                chan.exec_command(f"scp -f '{self.remote_dir}/{remote_filename}'")
             except Exception as e:
-                raise BackendException(u"scp execution failed: %s" % e)
+                raise BackendException(f"scp execution failed: {e}")
 
-            chan.send(u'\0')  # overall ready indicator
+            chan.send('\0')  # overall ready indicator
             msg = chan.recv(-1)
             if isinstance(msg, bytes):  # make msg into str
                 msg = msg.decode()
             m = re.match(r"C([0-7]{4})\s+(\d+)\s+(\S.*)$", msg)
-            if (m is None or m.group(3) != remote_filename):
-                raise BackendException(u"scp get %s failed: incorrect response '%s'" %
-                                       (remote_filename, msg))
+            if m is None or m.group(3) != remote_filename:
+                raise BackendException(f"scp get {remote_filename} failed: incorrect response '{msg}'")
             chan.recv(1)  # dispose of the newline trailing the C message
 
             size = int(m.group(2))
             togo = size
-            f = open(local_path.name, u'wb')
-            chan.send(u'\0')  # ready for data
+            f = open(local_path.name, 'wb')
+            chan.send('\0')  # ready for data
             try:
                 while togo > 0:
                     if togo > read_blocksize:
                         blocksize = read_blocksize
                     else:
                         blocksize = togo
                     buff = chan.recv(blocksize)
                     f.write(buff)
                     togo -= len(buff)
             except Exception as e:
-                raise BackendException(u"scp get %s failed: %s" % (remote_filename, e))
+                raise BackendException(f"scp get {remote_filename} failed: {e}")
 
             msg = chan.recv(1)  # check the final status
             if msg != b'\0':
-                raise BackendException(u"scp get %s failed: %s" % (remote_filename,
-                                                                   chan.recv(-1)))
+                raise BackendException(f"scp get {remote_filename} failed: {chan.recv(-1)}")
             f.close()
-            chan.send(u'\0')  # send final done indicator
+            chan.send('\0')  # send final done indicator
             chan.close()
         else:
             self.sftp.get(remote_filename, local_path.name)
 
     def _list(self):
         # In scp mode unavoidable quoting issues will make this fail if the
         # directory name contains single quotes.
         if self.use_scp:
-            output = self.runremote(u"ls -1 '%s'" % self.remote_dir, False,
-                                    u"scp dir listing ")
+            output = self.runremote(f"ls -1 '{self.remote_dir}'", False,
+                                    "scp dir listing ")
             return output.splitlines()
         else:
             return self.sftp.listdir()
 
     def _delete(self, filename):
         # filename is a byte object, not str or unicode
-        filename = util.fsdecode(filename)
+        filename = os.fsdecode(filename)
         # In scp mode unavoidable quoting issues will cause failures if
         # filenames containing single quotes are encountered.
         if self.use_scp:
-            self.runremote(u"rm '%s/%s'" % (self.remote_dir, filename), False,
-                           u"scp rm ")
+            self.runremote(f"rm '{self.remote_dir}/{filename}'", False,
+                           "scp rm ")
         else:
             self.sftp.remove(filename)
 
-    def runremote(self, cmd, ignoreexitcode=False, errorprefix=u""):
-        u"""small convenience function that opens a shell channel, runs remote
+    def runremote(self, cmd, ignoreexitcode=False, errorprefix=""):
+        """small convenience function that opens a shell channel, runs remote
         command and returns stdout of command. throws an exception if exit
         code!=0 and not ignored"""
         try:
             ch_in, ch_out, ch_err = self.client.exec_command(cmd, -1, config.timeout)
             output = ch_out.read(-1)
             return output
         except Exception as e:
             if not ignoreexitcode:
-                raise BackendException(u"%sfailed: %s \n %s" % (
-                    errorprefix, cmd, util.uexc(e)))
+                raise BackendException(f"{errorprefix}failed: {cmd} \n {util.uexc(e)}")
 
     def gethostconfig(self, file, host):
         file = os.path.expanduser(file)
         if not os.path.isfile(file):
             return {}
 
         sshconfig = paramiko.SSHConfig()
         try:
             sshconfig.parse(open(file))
         except Exception as e:
-            raise BackendException(u"could not load '%s', maybe corrupt?" % (file))
+            raise BackendException(f"could not load '{file}', maybe corrupt?")
 
         return sshconfig.lookup(host)
 
 
-duplicity.backend.register_backend(u"sftp", SSHParamikoBackend)
-duplicity.backend.register_backend(u"scp", SSHParamikoBackend)
-duplicity.backend.register_backend(u"paramiko+sftp", SSHParamikoBackend)
-duplicity.backend.register_backend(u"paramiko+scp", SSHParamikoBackend)
-duplicity.backend.uses_netloc.extend([u'sftp', u'scp', u'paramiko+sftp', u'paramiko+scp'])
+duplicity.backend.register_backend("sftp", SSHParamikoBackend)
+duplicity.backend.register_backend("scp", SSHParamikoBackend)
+duplicity.backend.register_backend("paramiko+sftp", SSHParamikoBackend)
+duplicity.backend.register_backend("paramiko+scp", SSHParamikoBackend)
+duplicity.backend.uses_netloc.extend(['sftp', 'scp', 'paramiko+sftp', 'paramiko+scp'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/pcabackend.py` & `duplicity-2.0.0rc0/duplicity/backends/pcabackend.py`

 * *Files 14% similar despite different names*

```diff
@@ -15,264 +15,259 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
 import os
+import time
 
 import duplicity.backend
 from duplicity import log
-from duplicity import util
 from duplicity.errors import BackendException
-import time
 
 
 class PCABackend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for OVH PCA
     """
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         try:
             from swiftclient import Connection
             from swiftclient import ClientException
         except ImportError as e:
-            raise BackendException(u"""\
-PCA backend requires the python-swiftclient library.
-Exception: %s""" % str(e))
+            raise BackendException(f"""PCA backend requires the python-swiftclient library.
+Exception: {str(e)}""")
 
         self.resp_exc = ClientException
         self.conn_cls = Connection
         conn_kwargs = {}
 
         # if the user has already authenticated
-        if u'PCA_PREAUTHURL' in os.environ and u'PCA_PREAUTHTOKEN' in os.environ:
-            conn_kwargs[u'preauthurl'] = os.environ[u'PCA_PREAUTHURL']
-            conn_kwargs[u'preauthtoken'] = os.environ[u'PCA_PREAUTHTOKEN']
+        if 'PCA_PREAUTHURL' in os.environ and 'PCA_PREAUTHTOKEN' in os.environ:
+            conn_kwargs['preauthurl'] = os.environ['PCA_PREAUTHURL']
+            conn_kwargs['preauthtoken'] = os.environ['PCA_PREAUTHTOKEN']
 
         else:
-            if u'PCA_USERNAME' not in os.environ:
-                raise BackendException(u'PCA_USERNAME environment variable '
-                                       u'not set.')
-
-            if u'PCA_PASSWORD' not in os.environ:
-                raise BackendException(u'PCA_PASSWORD environment variable '
-                                       u'not set.')
-
-            if u'PCA_AUTHURL' not in os.environ:
-                raise BackendException(u'PCA_AUTHURL environment variable '
-                                       u'not set.')
-
-            conn_kwargs[u'user'] = os.environ[u'PCA_USERNAME']
-            conn_kwargs[u'key'] = os.environ[u'PCA_PASSWORD']
-            conn_kwargs[u'authurl'] = os.environ[u'PCA_AUTHURL']
+            if 'PCA_USERNAME' not in os.environ:
+                raise BackendException('PCA_USERNAME environment variable '
+                                       'not set.')
+
+            if 'PCA_PASSWORD' not in os.environ:
+                raise BackendException('PCA_PASSWORD environment variable '
+                                       'not set.')
+
+            if 'PCA_AUTHURL' not in os.environ:
+                raise BackendException('PCA_AUTHURL environment variable '
+                                       'not set.')
+
+            conn_kwargs['user'] = os.environ['PCA_USERNAME']
+            conn_kwargs['key'] = os.environ['PCA_PASSWORD']
+            conn_kwargs['authurl'] = os.environ['PCA_AUTHURL']
 
         os_options = {}
 
-        if u'PCA_AUTHVERSION' in os.environ:
-            conn_kwargs[u'auth_version'] = os.environ[u'PCA_AUTHVERSION']
-            if os.environ[u'PCA_AUTHVERSION'] == u'3':
-                if u'PCA_USER_DOMAIN_NAME' in os.environ:
-                    os_options.update({u'user_domain_name': os.environ[u'PCA_USER_DOMAIN_NAME']})
-                if u'PCA_USER_DOMAIN_ID' in os.environ:
-                    os_options.update({u'user_domain_id': os.environ[u'PCA_USER_DOMAIN_ID']})
-                if u'PCA_PROJECT_DOMAIN_NAME' in os.environ:
-                    os_options.update({u'project_domain_name': os.environ[u'PCA_PROJECT_DOMAIN_NAME']})
-                if u'PCA_PROJECT_DOMAIN_ID' in os.environ:
-                    os_options.update({u'project_domain_id': os.environ[u'PCA_PROJECT_DOMAIN_ID']})
-                if u'PCA_TENANTNAME' in os.environ:
-                    os_options.update({u'tenant_name': os.environ[u'PCA_TENANTNAME']})
-                if u'PCA_ENDPOINT_TYPE' in os.environ:
-                    os_options.update({u'endpoint_type': os.environ[u'PCA_ENDPOINT_TYPE']})
-                if u'PCA_USERID' in os.environ:
-                    os_options.update({u'user_id': os.environ[u'PCA_USERID']})
-                if u'PCA_TENANTID' in os.environ:
-                    os_options.update({u'tenant_id': os.environ[u'PCA_TENANTID']})
-                if u'PCA_REGIONNAME' in os.environ:
-                    os_options.update({u'region_name': os.environ[u'PCA_REGIONNAME']})
+        if 'PCA_AUTHVERSION' in os.environ:
+            conn_kwargs['auth_version'] = os.environ['PCA_AUTHVERSION']
+            if os.environ['PCA_AUTHVERSION'] == '3':
+                if 'PCA_USER_DOMAIN_NAME' in os.environ:
+                    os_options.update({'user_domain_name': os.environ['PCA_USER_DOMAIN_NAME']})
+                if 'PCA_USER_DOMAIN_ID' in os.environ:
+                    os_options.update({'user_domain_id': os.environ['PCA_USER_DOMAIN_ID']})
+                if 'PCA_PROJECT_DOMAIN_NAME' in os.environ:
+                    os_options.update({'project_domain_name': os.environ['PCA_PROJECT_DOMAIN_NAME']})
+                if 'PCA_PROJECT_DOMAIN_ID' in os.environ:
+                    os_options.update({'project_domain_id': os.environ['PCA_PROJECT_DOMAIN_ID']})
+                if 'PCA_TENANTNAME' in os.environ:
+                    os_options.update({'tenant_name': os.environ['PCA_TENANTNAME']})
+                if 'PCA_ENDPOINT_TYPE' in os.environ:
+                    os_options.update({'endpoint_type': os.environ['PCA_ENDPOINT_TYPE']})
+                if 'PCA_USERID' in os.environ:
+                    os_options.update({'user_id': os.environ['PCA_USERID']})
+                if 'PCA_TENANTID' in os.environ:
+                    os_options.update({'tenant_id': os.environ['PCA_TENANTID']})
+                if 'PCA_REGIONNAME' in os.environ:
+                    os_options.update({'region_name': os.environ['PCA_REGIONNAME']})
 
         else:
-            conn_kwargs[u'auth_version'] = u'2'
-        if u'PCA_TENANTNAME' in os.environ:
-            conn_kwargs[u'tenant_name'] = os.environ[u'PCA_TENANTNAME']
-        if u'PCA_REGIONNAME' in os.environ:
-            os_options.update({u'region_name': os.environ[u'PCA_REGIONNAME']})
+            conn_kwargs['auth_version'] = '2'
+        if 'PCA_TENANTNAME' in os.environ:
+            conn_kwargs['tenant_name'] = os.environ['PCA_TENANTNAME']
+        if 'PCA_REGIONNAME' in os.environ:
+            os_options.update({'region_name': os.environ['PCA_REGIONNAME']})
 
-        conn_kwargs[u'os_options'] = os_options
-        conn_kwargs[u'retries'] = 0
+        conn_kwargs['os_options'] = os_options
+        conn_kwargs['retries'] = 0
 
         self.conn_kwargs = conn_kwargs
 
         # This folds the null prefix and all null parts, which means that:
         #  //MyContainer/ and //MyContainer are equivalent.
         #  //MyContainer//My/Prefix/ and //MyContainer/My/Prefix are equivalent.
-        url_parts = [x for x in parsed_url.path.split(u'/') if x != u'']
+        url_parts = [x for x in parsed_url.path.split('/') if x != '']
 
         self.container = url_parts.pop(0)
         if url_parts:
-            self.prefix = u'%s/' % u'/'.join(url_parts)
+            self.prefix = f"{'/'.join(url_parts)}/"
         else:
-            self.prefix = u''
+            self.prefix = ''
 
-        policy = u'PCA'
-        policy_header = u'X-Storage-Policy'
+        policy = 'PCA'
+        policy_header = 'X-Storage-Policy'
 
         container_metadata = None
         try:
             self.conn = Connection(**self.conn_kwargs)
             container_metadata = self.conn.head_container(self.container)
         except ClientException:
             pass
         except Exception as e:
-            log.FatalError(u"Connection failed: %s %s"
-                           % (e.__class__.__name__, str(e)),
+            log.FatalError(f"Connection failed: {e.__class__.__name__} {str(e)}",
                            log.ErrorCode.connection_failed)
 
         if container_metadata is None:
-            log.Info(u"Creating container %s" % self.container)
+            log.Info(f"Creating container {self.container}")
             try:
                 headers = dict([[policy_header, policy]])
                 self.conn.put_container(self.container, headers=headers)
             except Exception as e:
-                log.FatalError(u"Container creation failed: %s %s"
-                               % (e.__class__.__name__, str(e)),
+                log.FatalError(f"Container creation failed: {e.__class__.__name__} {str(e)}",
                                log.ErrorCode.connection_failed)
         elif policy and container_metadata[policy_header.lower()] != policy:
-            log.FatalError(u"Container '%s' exists but its storage policy is '%s' not '%s'."
-                           % (self.container, container_metadata[policy_header.lower()], policy))
+            log.FatalError(f"Container '{self.container}' exists but its storage policy is "
+                           f"'{container_metadata[policy_header.lower()]}' not '{policy}'.")
 
     def _error_code(self, operation, e):  # pylint: disable= unused-argument
         if isinstance(e, self.resp_exc):
             if e.http_status == 404:
                 return log.ErrorCode.backend_not_found
 
     def _put(self, source_path, remote_filename):
-        self.conn.put_object(self.container, self.prefix + util.fsdecode(remote_filename),
-                             open(util.fsdecode(source_path.name), u'rb'))
+        self.conn.put_object(self.container, self.prefix + os.fsdecode(remote_filename),
+                             open(os.fsdecode(source_path.name), 'rb'))
 
     def _get(self, remote_filename, local_path):
-        body = self.unseal(self.prefix + util.fsdecode(remote_filename))
+        body = self.unseal(os.fsdecode(remote_filename))
         if body:
-            with open(util.fsdecode(local_path.name), u'wb') as f:
+            with open(os.fsdecode(local_path.name), 'wb') as f:
                 for chunk in body:
                     f.write(chunk)
 
     def __list_objs(self, ffilter=None):
         # full_listing should be set to True but a bug in python-swiftclient
         # doesn't forward query_string in this case...
         # bypass here using a patched copy (with query_string) from swiftclient code
         rv = self.conn.get_container(self.container, full_listing=False,
-                                     path=self.prefix, query_string=u'policy_extra=true')
+                                     path=self.prefix, query_string='policy_extra=true')
         listing = rv[1]
         while listing:
-            marker = listing[-1][u'name']
-            version_marker = listing[-1].get(u'version_id')
+            marker = listing[-1]['name']
+            version_marker = listing[-1].get('version_id')
             listing = self.conn.get_container(self.container, marker=marker, version_marker=version_marker,
                                               full_listing=False, path=self.prefix,
-                                              query_string=u'policy_extra=true')[1]
+                                              query_string='policy_extra=true')[1]
             if listing:
                 rv[1].extend(listing)
         if ffilter is not None:
             return list(filter(ffilter, rv[1]))
         return rv[1]
 
     def _list(self):
-        return [util.fsencode(o[u'name'][len(self.prefix):]) for o in self.__list_objs()]
+        return [os.fsencode(o['name'][len(self.prefix):]) for o in self.__list_objs()]
 
     def _delete(self, filename):
-        self.conn.delete_object(self.container, self.prefix + util.fsdecode(filename))
+        self.conn.delete_object(self.container, self.prefix + os.fsdecode(filename))
 
     def _query(self, filename):
-        sobject = self.conn.head_object(self.container, self.prefix + util.fsdecode(filename))
-        return {u'size': int(sobject[u'content-length'])}
+        sobject = self.conn.head_object(self.container, self.prefix + os.fsdecode(filename))
+        return {'size': int(sobject['content-length'])}
 
     def unseal(self, remote_filename):
         try:
             _, body = self.conn.get_object(self.container, remote_filename,
                                            resp_chunk_size=1024)
-            log.Info(u"File %s was successfully unsealed." % remote_filename)
+            log.Info(f"File {remote_filename} was successfully unsealed.")
             return body
         except self.resp_exc as e:
             # The object is sealed but being released.
             if e.http_status == 429:
                 # The retry-after header contains the remaining duration before
                 # the unsealing operation completes.
-                duration = int(e.http_response_headers[u'Retry-After'])
+                duration = int(e.http_response_headers['Retry-After'])
                 m, s = divmod(duration, 60)
                 h, m = divmod(m, 60)
-                eta = u"%dh%02dm%02ds" % (h, m, s)
-                log.Info(u"File %s is being unsealed, operation ETA is %s." %
-                         (remote_filename, eta))
+                eta = f"{int(h)}h{int(m):02}m{int(s):02}s"
+                log.Info(f"File {remote_filename} is being unsealed, operation ETA is {eta}.")
             else:
-                log.FatalError(u"Connection failed: %s %s" % (e.__class__.__name__, str(e)),
+                log.FatalError(f"Connection failed: {e.__class__.__name__} {str(e)}",
                                log.ErrorCode.connection_failed)
         return None
 
     def pre_process_download_batch(self, remote_filenames):
-        u"""
+        """
         This is called before downloading volumes from this backend
         by main engine. For PCA, volumes passed as argument need to be unsealed.
         This method is blocking, showing a status at regular interval
         """
         retry_interval = 60  # status will be shown every 60s
         # remote_filenames are bytes string
-        u_remote_filenames = list(map(util.fsdecode, remote_filenames))
-        objs = self.__list_objs(ffilter=lambda x: util.fsdecode(x[u'name'])
+        u_remote_filenames = list(map(os.fsdecode, remote_filenames))
+        objs = self.__list_objs(ffilter=lambda x: util.fsdecode(x['name'])
                                 in [self.prefix + s for s in u_remote_filenames])
         # first step: retrieve pca seal status for all required volumes
         # and launch unseal for all sealed files
         one_object_not_unsealed = False
         for o in objs:
-            filename = util.fsdecode(o[u'name'])
+            filename = os.fsdecode(o['name'])
             # see ovh documentation for policy_retrieval_state definition
-            policy_retrieval_state = o[u'policy_retrieval_state']
-            log.Info(u"Volume %s. State : %s. " % (filename, policy_retrieval_state))
-            if policy_retrieval_state == u'sealed':
-                log.Notice(u"Launching unseal of volume %s." % filename)
-                self.unseal(o[u'name'])
+            policy_retrieval_state = o['policy_retrieval_state']
+            log.Info(f"Volume {filename}. State : {policy_retrieval_state}. ")
+            if policy_retrieval_state == 'sealed':
+                log.Notice(f"Launching unseal of volume {filename}.")
+                self.unseal(o['name'])
                 one_object_not_unsealed = True
-            elif policy_retrieval_state == u"unsealing":
+            elif policy_retrieval_state == "unsealing":
                 one_object_not_unsealed = True
         # second step: display estimated time for last volume unseal
         # and loop until all volumes are unsealed
         while one_object_not_unsealed:
             one_object_not_unsealed = self.unseal_status(u_remote_filenames)
             time.sleep(retry_interval)
             # might be a good idea to show a progress bar here...
         else:
-            log.Notice(u"All volumes to download are unsealed.")
+            log.Notice("All volumes to download are unsealed.")
 
     def unseal_status(self, u_remote_filenames):
-        u"""
+        """
         Shows unsealing status for input volumes
         """
         one_object_not_unsealed = False
-        objs = self.__list_objs(ffilter=lambda x: util.fsdecode(x[u'name'])
+        objs = self.__list_objs(ffilter=lambda x: os.fsdecode(x['name'])
                                 in [self.prefix + s for s in u_remote_filenames])
         max_duration = 0
         for o in objs:
-            policy_retrieval_state = o[u'policy_retrieval_state']
-            filename = util.fsdecode(o[u'name'])
-            if policy_retrieval_state == u'sealed':
-                log.Notice(u"Error: volume is still in sealed state : %s." % filename)
-                log.Notice(u"Launching unseal of volume %s." % filename)
-                self.unseal(o[u'name'])
+            policy_retrieval_state = o['policy_retrieval_state']
+            filename = os.fsdecode(o['name'])
+            if policy_retrieval_state == 'sealed':
+                log.Notice(f"Error: volume is still in sealed state : {filename}.")
+                log.Notice(f"Launching unseal of volume {filename}.")
+                self.unseal(o['name'])
                 one_object_not_unsealed = True
-            elif policy_retrieval_state == u"unsealing":
-                duration = int(o[u'policy_retrieval_delay'])
-                log.Info(u"%s available in %d seconds." % (filename, duration))
+            elif policy_retrieval_state == "unsealing":
+                duration = int(o['policy_retrieval_delay'])
+                log.Info(f"{filename} available in {int(duration)} seconds.")
                 if duration > max_duration:
                     max_duration = duration
                 one_object_not_unsealed = True
 
         m, s = divmod(max_duration, 60)
         h, m = divmod(m, 60)
-        max_duration_eta = u"%dh%02dm%02ds" % (h, m, s)
-        log.Notice(u"Need to wait %s before all volumes are unsealed." % max_duration_eta)
+        max_duration_eta = f"{int(h)}h{int(m):02}m{int(s):02}s"
+        log.Notice(f"Need to wait {max_duration_eta} before all volumes are unsealed.")
         return one_object_not_unsealed
 
 
-duplicity.backend.register_backend(u"pca", PCABackend)
+duplicity.backend.register_backend("pca", PCABackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/jottacloudbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/jottacloudbackend.py`

 * *Files 8% similar despite different names*

```diff
@@ -21,136 +21,139 @@
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 # stdlib
 import logging
 import posixpath
 
+import duplicity.backend
 # import duplicity stuff
 from duplicity import log
 from duplicity.errors import BackendException
-import duplicity.backend
 
 
 def get_jotta_device(jfs):
     jottadev = None
     for j in jfs.devices:  # find Jotta/Shared folder
-        if j.name == u'Jotta':
+        if j.name == 'Jotta':
             jottadev = j
     return jottadev
 
 
 def get_root_dir(jfs):
     jottadev = get_jotta_device(jfs)
-    root_dir = jottadev.mountPoints[u'Archive']
+    root_dir = jottadev.mountPoints['Archive']
     return root_dir
 
 
 def set_jottalib_logging_level(log_level):
-    logger = logging.getLogger(u'jottalib')
+    logger = logging.getLogger('jottalib')
     logger.setLevel(getattr(logging, log_level))
 
 
 def set_jottalib_log_handlers(handlers):
-    logger = logging.getLogger(u'jottalib')
+    logger = logging.getLogger('jottalib')
     for handler in handlers:
         logger.addHandler(handler)
 
 
 def get_duplicity_log_level():
-    u""" Get the current duplicity log level as a stdlib-compatible logging level"""
+    """ Get the current duplicity log level as a stdlib-compatible logging level"""
     duplicity_log_level = log.LevelName(log.getverbosity())
 
     # notice is a duplicity-specific logging level not supported by stdlib
-    if duplicity_log_level == u'NOTICE':
-        duplicity_log_level = u'INFO'
+    if duplicity_log_level == 'NOTICE':
+        duplicity_log_level = 'INFO'
 
     return duplicity_log_level
 
 
 class JottaCloudBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using JottaCloud API"""
+    """Connect to remote store using JottaCloud API"""
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # Import JottaCloud libraries.
         try:
             from jottalib import JFS
-            from jottalib.JFS import JFSNotFoundError, JFSIncompleteFile
+            from jottalib.JFS import (
+                JFSNotFoundError,
+                JFSIncompleteFile,
+            )
         except ImportError:
-            raise BackendException(u'JottaCloud backend requires jottalib'
-                                   u' (see https://pypi.python.org/pypi/jottalib).')
+            raise BackendException('JottaCloud backend requires jottalib'
+                                   ' (see https://pypi.python.org/pypi/jottalib).')
 
         # Set jottalib loggers to the same verbosity as duplicity
         duplicity_log_level = get_duplicity_log_level()
         set_jottalib_logging_level(duplicity_log_level)
 
         # Ensure jottalib and duplicity log to the same handlers
         set_jottalib_log_handlers(log._logger.handlers)
 
         # Will fetch jottacloud auth from environment or .netrc
         self.client = JFS.JFS()
 
-        self.folder = self.get_or_create_directory(parsed_url.path.lstrip(u'/'))
-        log.Debug(u"Jottacloud folder for duplicity: %r" % self.folder.path)
+        self.folder = self.get_or_create_directory(parsed_url.path.lstrip('/'))
+        log.Debug(f"Jottacloud folder for duplicity: {self.folder.path!r}")
 
     def get_or_create_directory(self, directory_name):
         root_directory = get_root_dir(self.client)
         full_path = posixpath.join(root_directory.path, directory_name)
         try:
             return self.client.getObject(full_path)
         except JFSNotFoundError:
             return root_directory.mkdir(directory_name)
 
     def _put(self, source_path, remote_filename):
         # - Upload one file
         # - Retried if an exception is thrown
         resp = self.folder.up(source_path.open(), remote_filename)
-        log.Debug(u'jottacloud.put(%s,%s): %s' % (source_path.name, remote_filename, resp))
+        log.Debug(f'jottacloud.put({source_path.name},{remote_filename}): {resp}')
 
     def _get(self, remote_filename, local_path):
         # - Get one file
         # - Retried if an exception is thrown
         remote_file = self.client.getObject(posixpath.join(self.folder.path, remote_filename))
-        log.Debug(u'jottacloud.get(%s,%s): %s' % (remote_filename, local_path.name, remote_file))
-        with open(local_path.name, u'wb') as to_file:
+        log.Debug(f'jottacloud.get({remote_filename},{local_path.name}): {remote_file}')
+        with open(local_path.name, 'wb') as to_file:
             for chunk in remote_file.stream():
                 to_file.write(chunk)
 
     def _list(self):
         # - List all files in the backend
         # - Return a list of filenames
         # - Retried if an exception is thrown
         return list([f.name for f in self.folder.files()  # pylint: disable=no-value-for-parameter
-                     if not f.is_deleted() and f.state != u'INCOMPLETE'])
+                     if not f.is_deleted() and f.state != 'INCOMPLETE'])
 
     def _delete(self, filename):
         # - Delete one file
         # - Retried if an exception is thrown
         remote_path = posixpath.join(self.folder.path, filename)
         remote_file = self.client.getObject(remote_path)
-        log.Debug(u'jottacloud.delete deleting: %s (%s)' % (remote_file, type(remote_file)))
+        log.Debug(f'jottacloud.delete deleting: {remote_file} ({type(remote_file)})')
         remote_file.delete()
 
     def _query(self, filename):
-        u"""Get size of filename"""
+        """Get size of filename"""
         #  - Query metadata of one file
         #  - Return a dict with a 'size' key, and a file size value (-1 for not found)
         #  - Retried if an exception is thrown
-        log.Info(u'Querying size of %s' % filename)
+        log.Info(f'Querying size of {filename}')
         remote_path = posixpath.join(self.folder.path, filename)
         try:
             remote_file = self.client.getObject(remote_path)
         except JFSNotFoundError:
-            return {u'size': -1}
+            return {'size': -1}
         return {
-            u'size': remote_file.size,
+            'size': remote_file.size,
         }
 
     def _close(self):
         # - If your backend needs to clean up after itself, do that here.
         pass
 
 
-duplicity.backend.register_backend(u"jottacloud", JottaCloudBackend)
-u""" jottacloud is a Norwegian backup company """
+duplicity.backend.register_backend("jottacloud", JottaCloudBackend)
+""" jottacloud is a Norwegian backup company """
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/pyrax_identity/hubic.py` & `duplicity-2.0.0rc0/duplicity/backends/pyrax_identity/hubic.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,280 +1,270 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
 # Copyright (c) 2014 Gu1
 # Licensed under the MIT license
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import str
 
 import configparser
 import os
 import re
 import time
-import urllib.parse  # pylint: disable=import-error
+import urllib.parse
 
-from requests.compat import quote, quote_plus
+from requests.compat import (
+    quote,
+    quote_plus,
+)
 import requests
 
 try:
     import pyrax
-    from pyrax.base_identity import BaseIdentity, Service
+    from pyrax.base_identity import (
+        BaseIdentity,
+        Service,
+    )
     import pyrax.exceptions as exc
 except ImportError as e:
-    raise BackendException(u"""\
-Hubic backend requires the pyrax library available from Rackspace.
-Exception: %s""" % str(e))
-
-OAUTH_ENDPOINT = u"https://api.hubic.com/oauth/"
-API_ENDPOINT = u"https://api.hubic.com/1.0/"
-TOKENS_FILE = os.path.expanduser(u"~/.hubic_tokens")
+    raise BackendException(f"""Hubic backend requires the pyrax library available from Rackspace.
+Exception: {str(e)}""")
+
+OAUTH_ENDPOINT = "https://api.hubic.com/oauth/"
+API_ENDPOINT = "https://api.hubic.com/1.0/"
+TOKENS_FILE = os.path.expanduser("~/.hubic_tokens")
 
 
 class BearerTokenAuth(requests.auth.AuthBase):
     def __init__(self, token):
         self.token = token
 
     def __call__(self, req):
-        req.headers[u'Authorization'] = u'Bearer ' + self.token
+        req.headers['Authorization'] = f"Bearer {self.token}"
         return req
 
 
 class HubicIdentity(BaseIdentity):
-    def __init__(self, **kwargs):
-        super(HubicIdentity, self).__init__(self, **kwargs)
-
     def _get_auth_endpoint(self):
-        return u""
+        return ""
 
     def set_credentials(self, email, password, client_id,
                         client_secret, redirect_uri,
                         authenticate=False):
-        u"""Sets the username and password directly."""
+        """Sets the username and password directly."""
         self._email = email
         self._password = password
         self._client_id = client_id
         self.tenant_id = client_id
         self._client_secret = client_secret
         self._redirect_uri = redirect_uri
         if authenticate:
             self.authenticate()
 
     def _read_credential_file(self, cfg):
-        u"""
+        """
         Parses the credential file with Rackspace-specific labels.
         """
-        self._email = cfg.get(u"hubic", u"email")
-        self._password = cfg.get(u"hubic", u"password")
-        self._client_id = cfg.get(u"hubic", u"client_id")
+        self._email = cfg.get("hubic", "email")
+        self._password = cfg.get("hubic", "password")
+        self._client_id = cfg.get("hubic", "client_id")
         self.tenant_id = self._client_id
-        self._client_secret = cfg.get(u"hubic", u"client_secret")
-        self._redirect_uri = cfg.get(u"hubic", u"redirect_uri")
+        self._client_secret = cfg.get("hubic", "client_secret")
+        self._redirect_uri = cfg.get("hubic", "redirect_uri")
 
     def _parse_error(self, resp):
-        if u'location' not in resp.headers:
+        if 'location' not in resp.headers:
             return None
-        query = urllib.parse.urlsplit(resp.headers[u'location']).query
+        query = urllib.parse.urlsplit(resp.headers['location']).query
         qs = dict(urllib.parse.parse_qsl(query))
-        return {u'error': qs[u'error'], u'error_description': qs[u'error_description']}
+        return {'error': qs['error'], 'error_description': qs['error_description']}
 
     def _get_access_token(self, code):
         r = requests.post(
-            OAUTH_ENDPOINT + u'token/',
+            f"{OAUTH_ENDPOINT}token/",
             data={
-                u'code': code,
-                u'redirect_uri': self._redirect_uri,
-                u'grant_type': u'authorization_code',
+                'code': code,
+                'redirect_uri': self._redirect_uri,
+                'grant_type': 'authorization_code',
             },
             auth=(self._client_id, self._client_secret)
         )
         if r.status_code != 200:
             try:
                 err = r.json()
-                err[u'code'] = r.status_code
-            except:
+                err['code'] = r.status_code
+            except Exception as e:
                 err = {}
 
-            raise exc.AuthenticationFailed(u"Unable to get oauth access token, "
-                                           u"wrong client_id or client_secret ? (%s)" %
-                                           str(err))
+            raise exc.AuthenticationFailed(f"Unable to get oauth access token, wrong client_id or client_secret ? "
+                                           f"({str(err)})")
 
         oauth_token = r.json()
 
         config = configparser.ConfigParser()
         config.read(TOKENS_FILE)
 
-        if not config.has_section(u"hubic"):
-            config.add_section(u"hubic")
+        if not config.has_section("hubic"):
+            config.add_section("hubic")
 
-        if oauth_token[u'access_token'] is not None:
-            config.set(u"hubic", u"access_token", oauth_token[u'access_token'])
-            with open(TOKENS_FILE, u'wb') as configfile:
+        if oauth_token['access_token'] is not None:
+            config.set("hubic", "access_token", oauth_token['access_token'])
+            with open(TOKENS_FILE, 'wb') as configfile:
                 config.write(configfile)
         else:
             raise exc.AuthenticationFailed(
-                u"Unable to get oauth access token, wrong client_id or client_secret ? (%s)" %
-                str(err))
+                f"Unable to get oauth access token, wrong client_id or client_secret ? ({str(err)})")
 
-        if oauth_token[u'refresh_token'] is not None:
-            config.set(u"hubic", u"refresh_token", oauth_token[u'refresh_token'])
-            with open(TOKENS_FILE, u'wb') as configfile:
+        if oauth_token['refresh_token'] is not None:
+            config.set("hubic", "refresh_token", oauth_token['refresh_token'])
+            with open(TOKENS_FILE, 'wb') as configfile:
                 config.write(configfile)
         else:
-            raise exc.AuthenticationFailed(u"Unable to get the refresh token.")
+            raise exc.AuthenticationFailed("Unable to get the refresh token.")
 
         # removing username and password from .hubic_tokens
-        if config.has_option(u"hubic", u"email"):
-            config.remove_option(u"hubic", u"email")
-            with open(TOKENS_FILE, u'wb') as configfile:
+        if config.has_option("hubic", "email"):
+            config.remove_option("hubic", "email")
+            with open(TOKENS_FILE, 'wb') as configfile:
                 config.write(configfile)
-            print(u"username has been removed from the .hubic_tokens file sent to the CE.")
-        if config.has_option(u"hubic", u"password"):
-            config.remove_option(u"hubic", u"password")
-            with open(TOKENS_FILE, u'wb') as configfile:
+            print("username has been removed from the .hubic_tokens file sent to the CE.")
+        if config.has_option("hubic", "password"):
+            config.remove_option("hubic", "password")
+            with open(TOKENS_FILE, 'wb') as configfile:
                 config.write(configfile)
-            print(u"password has been removed from the .hubic_tokens file sent to the CE.")
+            print("password has been removed from the .hubic_tokens file sent to the CE.")
 
         return oauth_token
 
     def _refresh_access_token(self):
 
         config = configparser.ConfigParser()
         config.read(TOKENS_FILE)
-        refresh_token = config.get(u"hubic", u"refresh_token")
+        refresh_token = config.get("hubic", "refresh_token")
 
         if refresh_token is None:
-            raise exc.AuthenticationFailed(u"refresh_token is null. Not acquiered before ?")
+            raise exc.AuthenticationFailed("refresh_token is null. Not acquiered before ?")
 
         success = False
         max_retries = 20
         retries = 0
         sleep_time = 30
         max_sleep_time = 3600
 
         while retries < max_retries and not success:
             r = requests.post(
-                OAUTH_ENDPOINT + u'token/',
+                f"{OAUTH_ENDPOINT}token/",
                 data={
-                    u'refresh_token': refresh_token,
-                    u'grant_type': u'refresh_token',
+                    'refresh_token': refresh_token,
+                    'grant_type': 'refresh_token',
                 },
                 auth=(self._client_id, self._client_secret)
             )
             if r.status_code != 200:
                 if r.status_code == 509:
-                    print(u"status_code 509: attempt #", retries, u" failed")
+                    print("status_code 509: attempt #", retries, " failed")
                     retries += 1
                     time.sleep(sleep_time)
                     sleep_time = sleep_time * 2
                     if sleep_time > max_sleep_time:
                         sleep_time = max_sleep_time
                 else:
                     try:
                         err = r.json()
-                        err[u'code'] = r.status_code
-                    except:
+                        err['code'] = r.status_code
+                    except Exception as e:
                         err = {}
 
                     raise exc.AuthenticationFailed(
-                        u"Unable to get oauth access token, wrong client_id or client_secret ? (%s)" %
-                        str(err))
+                        f"Unable to get oauth access token, wrong client_id or client_secret ? ({str(err)})")
             else:
                 success = True
 
         if not success:
             raise exc.AuthenticationFailed(
-                u"All the attempts failed to get the refresh token: "
-                u"status_code = 509: Bandwidth Limit Exceeded")
+                "All the attempts failed to get the refresh token: "
+                "status_code = 509: Bandwidth Limit Exceeded")
 
         oauth_token = r.json()
 
-        if oauth_token[u'access_token'] is not None:
+        if oauth_token['access_token'] is not None:
             return oauth_token
         else:
-            raise exc.AuthenticationFailed(u"Unable to get oauth access token from json")
+            raise exc.AuthenticationFailed("Unable to get oauth access token from json")
 
     def authenticate(self):
         config = configparser.ConfigParser()
         config.read(TOKENS_FILE)
 
-        if config.has_option(u"hubic", u"refresh_token"):
+        if config.has_option("hubic", "refresh_token"):
             oauth_token = self._refresh_access_token()
         else:
             r = requests.get(
-                OAUTH_ENDPOINT + u'auth/?client_id={0}&redirect_uri={1}'
-                u'&scope=credentials.r,account.r&response_type=code&state={2}'.format(
-                    quote(self._client_id),
-                    quote_plus(self._redirect_uri),
-                    pyrax.utils.random_ascii()  # csrf ? wut ?..
-                ),
-                allow_redirects=False
-            )
+                OAUTH_ENDPOINT +
+                f'auth/?client_id={quote(self._client_id)}&redirect_uri={quote_plus(self._redirect_uri)}'
+                f'&scope=credentials.r,account.r&response_type=code&state={pyrax.utils.random_ascii()}',
+                allow_redirects=False)
             if r.status_code != 200:
-                raise exc.AuthenticationFailed(u"Incorrect/unauthorized "
-                                               u"client_id (%s)" % str(self._parse_error(r)))
+                raise exc.AuthenticationFailed(f"Incorrect/unauthorized client_id ({str(self._parse_error(r))})")
 
             try:
                 from lxml import html as lxml_html
             except ImportError:
                 lxml_html = None
 
             if lxml_html:
-                oauth = lxml_html.document_fromstring(r.content).xpath(u'//input[@name="oauth"]')
+                oauth = lxml_html.document_fromstring(r.content).xpath('//input[@name="oauth"]')
                 oauth = oauth[0].value if oauth else None
             else:
                 oauth = re.search(
                     r'<input\s+[^>]*name=[\'"]?oauth[\'"]?\s+[^>]*value=[\'"]?(\d+)[\'"]?>',
                     r.content)
                 oauth = oauth.group(1) if oauth else None
 
             if not oauth:
-                raise exc.AuthenticationFailed(u"Unable to get oauth_id from authorization page")
+                raise exc.AuthenticationFailed("Unable to get oauth_id from authorization page")
 
             if self._email is None or self._password is None:
-                raise exc.AuthenticationFailed(u"Cannot retrieve email and/or password. "
-                                               u"Please run expresslane-hubic-setup.sh")
+                raise exc.AuthenticationFailed("Cannot retrieve email and/or password. "
+                                               "Please run expresslane-hubic-setup.sh")
 
             r = requests.post(
-                OAUTH_ENDPOINT + u'auth/',
+                f"{OAUTH_ENDPOINT}auth/",
                 data={
-                    u'action': u'accepted',
-                    u'oauth': oauth,
-                    u'login': self._email,
-                    u'user_pwd': self._password,
-                    u'account': u'r',
-                    u'credentials': u'r',
+                    'action': 'accepted',
+                    'oauth': oauth,
+                    'login': self._email,
+                    'user_pwd': self._password,
+                    'account': 'r',
+                    'credentials': 'r',
 
                 },
                 allow_redirects=False
             )
 
             try:
-                query = urllib.parse.urlsplit(r.headers[u'location']).query
-                code = dict(urllib.parse.parse_qsl(query))[u'code']
-            except:
-                raise exc.AuthenticationFailed(u"Unable to authorize client_id, "
-                                               u"invalid login/password ?")
+                query = urllib.parse.urlsplit(r.headers['location']).query
+                code = dict(urllib.parse.parse_qsl(query))['code']
+            except Exception as e:
+                raise exc.AuthenticationFailed("Unable to authorize client_id, "
+                                               "invalid login/password ?")
 
             oauth_token = self._get_access_token(code)
 
-        if oauth_token[u'token_type'].lower() != u'bearer':
-            raise exc.AuthenticationFailed(u"Unsupported access token type")
+        if oauth_token['token_type'].lower() != 'bearer':
+            raise exc.AuthenticationFailed("Unsupported access token type")
 
         r = requests.get(
-            API_ENDPOINT + u'account/credentials',
-            auth=BearerTokenAuth(oauth_token[u'access_token']),
+            f"{API_ENDPOINT}account/credentials",
+            auth=BearerTokenAuth(oauth_token['access_token']),
         )
 
         swift_token = r.json()
         self.authenticated = True
-        self.token = swift_token[u'token']
-        self.expires = swift_token[u'expires']
-        self.services[u'object_store'] = Service(self, {
-            u'name': u'HubiC',
-            u'type': u'cloudfiles',
-            u'endpoints': [
-                {u'public_url': swift_token[u'endpoint']}
+        self.token = swift_token['token']
+        self.expires = swift_token['expires']
+        self.services['object_store'] = Service(self, {
+            'name': 'HubiC',
+            'type': 'cloudfiles',
+            'endpoints': [
+                {'public_url': swift_token['endpoint']}
             ]
         })
         self.username = self.password = None
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/pyrax_identity/__init__.py` & `duplicity-2.0.0rc0/duplicity/backends/pyrax_identity/__init__.py`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/imapbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/imapbackend.py`

 * *Files 10% similar despite different names*

```diff
@@ -16,267 +16,261 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from future import standard_library
-standard_library.install_aliases()
-from builtins import input
 
 import email
 import email.encoders
 import email.mime.multipart
 import getpass
 import imaplib
 import os
 import re
 import socket
-import sys
 import time
 
 from email.parser import Parser
+
 try:
-    from email.policy import default  # pylint: disable=import-error
-except:
+    from email.policy import default
+except Exception as e:
     pass
 
 # TODO: should probably change use of socket.sslerror instead of doing this
-if sys.version_info.major >= 3:
-    import ssl
-    socket.sslerror = ssl.SSLError
+import ssl
+
+socket.sslerror = ssl.SSLError
 
 from duplicity import config
-from duplicity import log
 from duplicity.errors import *  # pylint: disable=unused-wildcard-import
 import duplicity.backend
 
 
 class ImapBackend(duplicity.backend.Backend):
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
-        log.Debug(u"I'm %s (scheme %s) connecting to %s as %s" %
-                  (self.__class__.__name__, parsed_url.scheme, parsed_url.hostname, parsed_url.username))
+        log.Debug(f"I'm {self.__class__.__name__} (scheme {parsed_url.scheme}) connecting to "
+                  f"{parsed_url.hostname} as {parsed_url.username}")
 
         #  Store url for reconnection on error
         self.url = parsed_url
 
         #  Set the username
-        if (parsed_url.username is None):
-            username = eval(input(u'Enter account userid: '))
+        if parsed_url.username is None:
+            username = eval(input('Enter account userid: '))
         else:
             username = parsed_url.username
 
         #  Set the password
-        if (not parsed_url.password):
-            if u'IMAP_PASSWORD' in os.environ:
-                password = os.environ.get(u'IMAP_PASSWORD')
+        if not parsed_url.password:
+            if 'IMAP_PASSWORD' in os.environ:
+                password = os.environ.get('IMAP_PASSWORD')
             else:
-                password = getpass.getpass(u"Enter account password: ")
+                password = getpass.getpass("Enter account password: ")
         else:
             password = parsed_url.password
 
         self.username = username
         self.password = password
         self.resetConnection()
 
     def resetConnection(self):
         parsed_url = self.url
         try:
-            imap_server = os.environ[u'IMAP_SERVER']
+            imap_server = os.environ['IMAP_SERVER']
         except KeyError:
             imap_server = parsed_url.hostname
 
         #  Try to close the connection cleanly
         try:
             self.conn.close()  # pylint:disable=access-member-before-definition
         except Exception:
             pass
 
-        if (parsed_url.scheme == u"imap"):
+        if parsed_url.scheme == "imap":
             cl = imaplib.IMAP4
             self.conn = cl(imap_server, 143)
-        elif (parsed_url.scheme == u"imaps"):
+        elif parsed_url.scheme == "imaps":
             cl = imaplib.IMAP4_SSL
             self.conn = cl(imap_server, 993)
 
-        log.Debug(u"Type of imap class: %s" % (cl.__name__))
+        log.Debug(f"Type of imap class: {cl.__name__}")
         self.remote_dir = re.sub(r'^/', r'', parsed_url.path, 1)
 
         #  Login
-        if (not config.imap_full_address):
+        if not config.imap_full_address:
             self.conn.login(self.username, self.password)
             self.conn.select(config.imap_mailbox)
-            log.Info(u"IMAP connected")
+            log.Info("IMAP connected")
         else:
-            self.conn.login(self.username + u"@" + parsed_url.hostname, self.password)
+            self.conn.login(f"{self.username}@{parsed_url.hostname}", self.password)
             self.conn.select(config.imap_mailbox)
-            log.Info(u"IMAP connected")
+            log.Info("IMAP connected")
 
     def prepareBody(self, f, rname):
         mp = email.mime.multipart.MIMEMultipart()
 
         # I am going to use the remote_dir as the From address so that
         # multiple archives can be stored in an IMAP account and can be
         # accessed separately
-        mp[u"From"] = self.remote_dir
-        mp[u"Subject"] = rname.decode()
+        mp["From"] = self.remote_dir
+        mp["Subject"] = rname.decode()
 
-        a = email.mime.multipart.MIMEBase(u"application", u"binary")
+        a = email.mime.multipart.MIMEBase("application", "binary")
         a.set_payload(f.read())
 
         email.encoders.encode_base64(a)
 
         mp.attach(a)
 
         return mp.as_string()
 
     def _put(self, source_path, remote_filename):
-        f = source_path.open(u"rb")
+        f = source_path.open("rb")
         allowedTimeout = config.timeout
-        if (allowedTimeout == 0):
+        if allowedTimeout == 0:
             # Allow a total timeout of 1 day
             allowedTimeout = 2880
         while allowedTimeout > 0:
             try:
                 self.conn.select(remote_filename)
                 body = self.prepareBody(f, remote_filename)
                 # If we don't select the IMAP folder before
                 # append, the message goes into the INBOX.
                 self.conn.select(config.imap_mailbox)
                 self.conn.append(config.imap_mailbox, None, None, body.encode())
                 break
             except (imaplib.IMAP4.abort, socket.error, socket.sslerror):
                 allowedTimeout -= 1
-                log.Info(u"Error saving '%s', retrying in 30s " % remote_filename)
+                log.Info(f"Error saving '{remote_filename}', retrying in 30s ")
                 time.sleep(30)
                 while allowedTimeout > 0:
                     try:
                         self.resetConnection()
                         break
                     except (imaplib.IMAP4.abort, socket.error, socket.sslerror):
                         allowedTimeout -= 1
-                        log.Info(u"Error reconnecting, retrying in 30s ")
+                        log.Info("Error reconnecting, retrying in 30s ")
                         time.sleep(30)
 
-        log.Info(u"IMAP mail with '%s' subject stored" % remote_filename)
+        log.Info(f"IMAP mail with '{remote_filename}' subject stored")
 
     def _get(self, remote_filename, local_path):
         allowedTimeout = config.timeout
-        if (allowedTimeout == 0):
+        if allowedTimeout == 0:
             # Allow a total timeout of 1 day
             allowedTimeout = 2880
         while allowedTimeout > 0:
             try:
                 self.conn.select(config.imap_mailbox)
-                (result, flist) = self.conn.search(None, u'Subject', remote_filename)
-                if result != u"OK":
+                (result, flist) = self.conn.search(None, 'Subject', remote_filename)
+                if result != "OK":
                     raise Exception(flist[0])
 
                 # check if there is any result
-                if flist[0] == u'':
-                    raise Exception(u"no mail with subject %s")
+                if flist[0] == '':
+                    raise Exception("no mail with subject %s")
 
-                (result, flist) = self.conn.fetch(flist[0], u"(RFC822)")
+                (result, flist) = self.conn.fetch(flist[0], "(RFC822)")
 
-                if result != u"OK":
+                if result != "OK":
                     raise Exception(flist[0])
                 rawbody = flist[0][1]
 
                 p = Parser()
 
                 m = p.parsestr(rawbody.decode())
 
                 mp = m.get_payload(0)
 
                 body = mp.get_payload(decode=True)
                 break
             except (imaplib.IMAP4.abort, socket.error, socket.sslerror):
                 allowedTimeout -= 1
-                log.Info(u"Error loading '%s', retrying in 30s " % remote_filename)
+                log.Info(f"Error loading '{remote_filename}', retrying in 30s ")
                 time.sleep(30)
                 while allowedTimeout > 0:
                     try:
                         self.resetConnection()
                         break
                     except (imaplib.IMAP4.abort, socket.error, socket.sslerror):
                         allowedTimeout -= 1
-                        log.Info(u"Error reconnecting, retrying in 30s ")
+                        log.Info("Error reconnecting, retrying in 30s ")
                         time.sleep(30)
 
-        tfile = local_path.open(u"wb")
+        tfile = local_path.open("wb")
         tfile.write(body)
         tfile.close()
         local_path.setdata()
-        log.Info(u"IMAP mail with '%s' subject fetched" % remote_filename)
+        log.Info(f"IMAP mail with '{remote_filename}' subject fetched")
 
     def _list(self):
         ret = []
         (result, flist) = self.conn.select(config.imap_mailbox)
-        if result != u"OK":
+        if result != "OK":
             raise BackendException(flist[0])
 
         # Going to find all the archives which have remote_dir in the From
         # address
 
         # Search returns an error if you haven't selected an IMAP folder.
-        (result, flist) = self.conn.search(None, u'FROM', self.remote_dir)
-        if result != u"OK":
+        (result, flist) = self.conn.search(None, 'FROM', self.remote_dir)
+        if result != "OK":
             raise Exception(flist[0])
         if flist[0] == b'':
             return ret
         nums = flist[0].strip().split(b" ")
         set = b"%s:%s" % (nums[0], nums[-1])  # pylint: disable=redefined-builtin
-        (result, flist) = self.conn.fetch(set, u"(BODY[HEADER])")
-        if result != u"OK":
+        (result, flist) = self.conn.fetch(set, "(BODY[HEADER])")
+        if result != "OK":
             raise Exception(flist[0])
 
         for msg in flist:
-            if (len(msg) == 1):
+            if len(msg) == 1:
                 continue
-            if sys.version_info.major >= 3:
-                headers = Parser(policy=default).parsestr(msg[1].decode(u"unicode-escape"))  # noqa  # pylint: disable=unsubscriptable-object
-            else:
-                headers = Parser().parsestr(msg[1].decode(u"unicode-escape"))  # pylint: disable=unsubscriptable-object
-            subj = headers[u"subject"]
-            header_from = headers[u"from"]
+            headers = Parser(policy=default).parsestr(
+                msg[1].decode("unicode-escape"))  # noqa  # pylint: disable=unsubscriptable-object
+            subj = headers["subject"]
+            header_from = headers["from"]
 
             # Catch messages with empty headers which cause an exception.
-            if (not (header_from is None)):
-                if (re.compile(u"^" + self.remote_dir + u"$").match(header_from)):
+            if not (header_from is None):
+                if re.compile(f"^{self.remote_dir}$").match(header_from):
                     ret.append(subj)
-                    log.Info(u"IMAP flist: %s %s" % (subj, header_from))
+                    log.Info(f"IMAP flist: {subj} {header_from}")
         return ret
 
     def imapf(self, fun, *args):
         (ret, flist) = fun(*args)
-        if ret != u"OK":
+        if ret != "OK":
             raise Exception(flist[0])
         return flist
 
     def delete_single_mail(self, i):
-        self.imapf(self.conn.store, i, u"+FLAGS", u'\\DELETED')
+        self.imapf(self.conn.store, i, "+FLAGS", '\\DELETED')
 
     def expunge(self):
         flist = self.imapf(self.conn.expunge)
 
     def _delete_list(self, filename_list):
         for filename in filename_list:
-            flist = self.imapf(self.conn.search, None, u"(SUBJECT %s)" % filename)
+            flist = self.imapf(self.conn.search, None, f"(SUBJECT {filename})")
             flist = flist[0].split()
-            if len(flist) > 0 and flist[0] != u"":
+            if len(flist) > 0 and flist[0] != "":
                 self.delete_single_mail(flist[0])
-                log.Notice(u"marked %s to be deleted" % filename)
+                log.Notice(f"marked {filename} to be deleted")
         self.expunge()
-        log.Notice(u"IMAP expunged %s files" % len(filename_list))
+        log.Notice(f"IMAP expunged {len(filename_list)} files")
 
     def _close(self):
         self.conn.select(config.imap_mailbox)
         self.conn.close()
         self.conn.logout()
 
 
-duplicity.backend.register_backend(u"imap", ImapBackend)
-duplicity.backend.register_backend(u"imaps", ImapBackend)
-duplicity.backend.uses_netloc.extend([u'imap', u'imaps'])
+duplicity.backend.register_backend("imap", ImapBackend)
+duplicity.backend.register_backend("imaps", ImapBackend)
+duplicity.backend.uses_netloc.extend(['imap', 'imaps'])
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/_cf_cloudfiles.py` & `duplicity-2.0.0rc0/duplicity/backends/_cf_cloudfiles.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,63 +14,62 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
 import os
 
 import duplicity.backend
 from duplicity import log
 from duplicity import util
 from duplicity.errors import BackendException
 
 
 class CloudFilesBackend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for Rackspace's CloudFiles
     """
+
     def __init__(self, parsed_url):
+        super().__init__(parsed_url)
         try:
             from cloudfiles import Connection
             from cloudfiles.errors import ResponseError
             from cloudfiles import consts
             from cloudfiles.errors import NoSuchObject
         except ImportError as e:
-            raise BackendException(u"""\
-Cloudfiles backend requires the cloudfiles library available from Rackspace.
-Exception: %s""" % str(e))
+            raise BackendException(f"""Cloudfiles backend requires the cloudfiles library available from Rackspace.
+Exception: {str(e)}""")
 
         self.resp_exc = ResponseError
         conn_kwargs = {}
 
-        if u'CLOUDFILES_USERNAME' not in os.environ:
-            raise BackendException(u'CLOUDFILES_USERNAME environment variable'
-                                   u'not set.')
+        if 'CLOUDFILES_USERNAME' not in os.environ:
+            raise BackendException('CLOUDFILES_USERNAME environment variable'
+                                   'not set.')
 
-        if u'CLOUDFILES_APIKEY' not in os.environ:
-            raise BackendException(u'CLOUDFILES_APIKEY environment variable not set.')
+        if 'CLOUDFILES_APIKEY' not in os.environ:
+            raise BackendException('CLOUDFILES_APIKEY environment variable not set.')
 
-        conn_kwargs[u'username'] = os.environ[u'CLOUDFILES_USERNAME']
-        conn_kwargs[u'api_key'] = os.environ[u'CLOUDFILES_APIKEY']
+        conn_kwargs['username'] = os.environ['CLOUDFILES_USERNAME']
+        conn_kwargs['api_key'] = os.environ['CLOUDFILES_APIKEY']
 
-        if u'CLOUDFILES_AUTHURL' in os.environ:
-            conn_kwargs[u'authurl'] = os.environ[u'CLOUDFILES_AUTHURL']
+        if 'CLOUDFILES_AUTHURL' in os.environ:
+            conn_kwargs['authurl'] = os.environ['CLOUDFILES_AUTHURL']
         else:
-            conn_kwargs[u'authurl'] = consts.default_authurl
+            conn_kwargs['authurl'] = consts.default_authurl
 
-        container = parsed_url.path.lstrip(u'/')
+        container = parsed_url.path.lstrip('/')
 
         try:
             conn = Connection(**conn_kwargs)
         except Exception as e:
-            log.FatalError(u"Connection failed, please check your credentials: %s %s"
-                           % (e.__class__.__name__, util.uexc(e)),
+            log.FatalError(f"Connection failed, please check your credentials: {e.__class__.__name__} {util.uexc(e)}",
                            log.ErrorCode.connection_failed)
         self.container = conn.create_container(container)
 
     def _error_code(self, operation, e):  # pylint: disable=unused-argument
         if isinstance(e, NoSuchObject):
             return log.ErrorCode.backend_not_found
         elif isinstance(e, self.resp_exc):
@@ -79,15 +78,15 @@
 
     def _put(self, source_path, remote_filename):
         sobject = self.container.create_object(remote_filename)
         sobject.load_from_filename(source_path.name)
 
     def _get(self, remote_filename, local_path):
         sobject = self.container.create_object(remote_filename)
-        with open(local_path.name, u'wb') as f:
+        with open(local_path.name, 'wb') as f:
             for chunk in sobject.stream():
                 f.write(chunk)
 
     def _list(self):
         # Cloud Files will return a max of 10,000 objects.  We have
         # to make multiple requests to get them all.
         objs = self.container.list_objects()
@@ -98,8 +97,8 @@
         return keys
 
     def _delete(self, filename):
         self.container.delete_object(filename)
 
     def _query(self, filename):
         sobject = self.container.get_object(filename)
-        return {u'size': sobject.size}
+        return {'size': sobject.size}
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/_cf_pyrax.py` & `duplicity-2.0.0rc0/duplicity/backends/_cf_pyrax.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,103 +14,101 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
 import os
 
 import duplicity.backend
 from duplicity import log
 from duplicity import util
 from duplicity.errors import BackendException
 
 
 class PyraxBackend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for Rackspace's CloudFiles using Pyrax
     """
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         try:
             import pyrax
         except ImportError as e:
-            raise BackendException(u"""\
-Pyrax backend requires the pyrax library available from Rackspace.
-Exception: %s""" % str(e))
+            raise BackendException(f"""Pyrax backend requires the pyrax library available from Rackspace.
+Exception: {str(e)}""")
 
         # Inform Pyrax that we're talking to Rackspace
         # per Jesus Monzon (gsusmonzon)
-        pyrax.set_setting(u"identity_type", u"rackspace")
+        pyrax.set_setting("identity_type", "rackspace")
 
         conn_kwargs = {}
 
-        if u'CLOUDFILES_USERNAME' not in os.environ:
-            raise BackendException(u'CLOUDFILES_USERNAME environment variable'
-                                   u'not set.')
+        if 'CLOUDFILES_USERNAME' not in os.environ:
+            raise BackendException('CLOUDFILES_USERNAME environment variable'
+                                   'not set.')
 
-        if u'CLOUDFILES_APIKEY' not in os.environ:
-            raise BackendException(u'CLOUDFILES_APIKEY environment variable not set.')
+        if 'CLOUDFILES_APIKEY' not in os.environ:
+            raise BackendException('CLOUDFILES_APIKEY environment variable not set.')
 
-        conn_kwargs[u'username'] = os.environ[u'CLOUDFILES_USERNAME']
-        conn_kwargs[u'api_key'] = os.environ[u'CLOUDFILES_APIKEY']
+        conn_kwargs['username'] = os.environ['CLOUDFILES_USERNAME']
+        conn_kwargs['api_key'] = os.environ['CLOUDFILES_APIKEY']
 
-        if u'CLOUDFILES_REGION' in os.environ:
-            conn_kwargs[u'region'] = os.environ[u'CLOUDFILES_REGION']
+        if 'CLOUDFILES_REGION' in os.environ:
+            conn_kwargs['region'] = os.environ['CLOUDFILES_REGION']
 
-        container = parsed_url.path.lstrip(u'/')
+        container = parsed_url.path.lstrip('/')
 
         try:
             pyrax.set_credentials(**conn_kwargs)
         except Exception as e:
-            log.FatalError(u"Connection failed, please check your credentials: %s %s"
-                           % (e.__class__.__name__, util.uexc(e)),
+            log.FatalError(f"Connection failed, please check your credentials: {e.__class__.__name__} {util.uexc(e)}",
                            log.ErrorCode.connection_failed)
 
         self.client_exc = pyrax.exceptions.ClientException
         self.nso_exc = pyrax.exceptions.NoSuchObject
 
         # query rackspace for the specified container name
         try:
             self.container = pyrax.cloudfiles.get_container(container)
         except pyrax.exceptions.Forbidden as e:
-            log.FatalError(u"%s : %s \n" % (e.__class__.__name__, util.uexc(e)) +
-                           u"Container may exist, but access was denied.\n" +
-                           u"If this container exists, please check its X-Container-Read/Write headers.\n" +
-                           u"Otherwise, please check your credentials and permissions.",
+            log.FatalError(f"{e.__class__.__name__} : {util.uexc(e)} \n" +
+                           "Container may exist, but access was denied.\n" +
+                           "If this container exists, please check its X-Container-Read/Write headers.\n" +
+                           "Otherwise, please check your credentials and permissions.",
                            log.ErrorCode.backend_permission_denied)
         except pyrax.exceptions.NoSuchContainer as e:
             try:
                 self.container = pyrax.cloudfiles.create_container(container)
             except pyrax.exceptions.Forbidden as e:
-                log.FatalError(u"%s : %s \n" % (e.__class__.__name__, util.uexc(e)) +
-                               u"Container does not exist, but creation was denied.\n" +
-                               u"You may be using a read-only user that can view but not create containers.\n" +
-                               u"Please check your credentials and permissions.",
+                log.FatalError(f"{e.__class__.__name__} : {util.uexc(e)} \n" +
+                               "Container does not exist, but creation was denied.\n" +
+                               "You may be using a read-only user that can view but not create containers.\n" +
+                               "Please check your credentials and permissions.",
                                log.ErrorCode.backend_permission_denied)
 
     def _error_code(self, operation, e):  # pylint: disable=unused-argument
         if isinstance(e, self.nso_exc):
             return log.ErrorCode.backend_not_found
         elif isinstance(e, self.client_exc):
             if e.code == 404:
                 return log.ErrorCode.backend_not_found
-        elif hasattr(e, u'http_status'):
+        elif hasattr(e, 'http_status'):
             if e.http_status == 404:
                 return log.ErrorCode.backend_not_found
 
     def _put(self, source_path, remote_filename):
         self.container.upload_file(source_path.name, remote_filename)
 
     def _get(self, remote_filename, local_path):
         sobject = self.container.get_object(remote_filename)
-        with open(local_path.name, u'wb') as f:
+        with open(local_path.name, 'wb') as f:
             f.write(sobject.get())
 
     def _list(self):
         # Cloud Files will return a max of 10,000 objects.  We have
         # to make multiple requests to get them all.
         objs = self.container.get_object_names()
         keys = objs
@@ -120,8 +118,8 @@
         return keys
 
     def _delete(self, filename):
         self.container.delete_object(filename)
 
     def _query(self, filename):
         sobject = self.container.get_object(filename)
-        return {u'size': sobject.total_bytes}
+        return {'size': sobject.total_bytes}
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/README` & `duplicity-2.0.0rc0/duplicity/backends/README`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/sxbackend.py` & `duplicity-2.0.0rc0/duplicity/backends/sxbackend.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,43 +15,45 @@
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
 import os.path
+
 import duplicity.backend
 import duplicity.util
 
 
 class SXBackend(duplicity.backend.Backend):
-    u"""Connect to remote store using Skylable Protocol"""
+    """Connect to remote store using Skylable Protocol"""
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
         self.url_string = parsed_url.url_string
 
     def _put(self, source_path, remote_filename):
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         remote_path = os.path.join(self.url_string, remote_filename)
-        commandline = u"sxcp {0} {1}".format(source_path.uc_name, remote_path)
+        commandline = f"sxcp {source_path.uc_name} {remote_path}"
         self.subprocess_popen(commandline)
 
     def _get(self, remote_filename, local_path):
-        remote_filename = util.fsdecode(remote_filename)
+        remote_filename = os.fsdecode(remote_filename)
         remote_path = os.path.join(self.url_string, remote_filename)
-        commandline = u"sxcp {0} {1}".format(remote_path, local_path.uc_name)
+        commandline = f"sxcp {remote_path} {local_path.uc_name}"
         self.subprocess_popen(commandline)
 
     def _list(self):
         # Do a long listing to avoid connection reset
-        commandline = u"sxls {0}/".format(self.url_string)
+        commandline = f"sxls {self.url_string}/"
         _, l, _ = self.subprocess_popen(commandline)
         # Look for our files as the last element of a long list line
-        return [util.fsencode(x[x.rindex(u'/') + 1:].split()[-1]) for x in l.split(u'\n')
-                if x and not x.startswith(u"total ")]
+        return [os.fsencode(x[x.rindex('/') + 1:].split()[-1]) for x in l.split('\n')
+                if x and not x.startswith("total ")]
 
     def _delete(self, filename):
-        commandline = u"sxrm {0}/{1}".format(self.url_string, filename)
+        commandline = f"sxrm {self.url_string}/{filename}"
         self.subprocess_popen(commandline)
 
 
-duplicity.backend.register_backend(u"sx", SXBackend)
+duplicity.backend.register_backend("sx", SXBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/xorrisobackend.py` & `duplicity-2.0.0rc0/duplicity/backends/xorrisobackend.py`

 * *Files 5% similar despite different names*

```diff
@@ -26,55 +26,62 @@
 import shlex
 import subprocess
 import time
 
 from duplicity import util
 
 import duplicity.backend
-from duplicity import path, progress
-from duplicity.errors import FatalBackendException, BackendException, InvalidBackendURL
+from duplicity import (
+    path,
+    progress,
+)
+from duplicity.errors import (
+    FatalBackendException,
+    BackendException,
+    InvalidBackendURL,
+)
 
 
 class Xorriso:
-    u"""
+    """
     Wrapper around a xorriso subprocess.
     """
 
-    def __init__(self, device, xorriso_path=u"xorriso", xorriso_args=None):
+    def __init__(self, device, xorriso_path="xorriso", xorriso_args=None):
 
         self.device = device
 
         # Xorriso process
         self.proc = None
 
         # Default arguments for xorriso.
         self.xorriso_args = [
-            u"-abort_on", u"FAILURE",
-            u"-return_with", u"SORRY", u"0",
-            u"-osirrox", u"on",  # Enable copying from ISO to disk.
-            u"-calm_drive", u"off",  # Don't immediately turn off device. Increases access speed for next action.abs
-            u"-joliet", u"on",
+            "-abort_on", "FAILURE",
+            "-return_with", "SORRY", "0",
+            "-osirrox", "on",  # Enable copying from ISO to disk.
+            "-calm_drive", "off",  # Don't immediately turn off device. Increases access speed for next action.abs
+            "-joliet", "on",
         ]
 
         if xorriso_args is not None:
             self.xorriso_args.extend(xorriso_args)
 
         self.__start_subprocess(
             [xorriso_path]
             + self.xorriso_args +
             [
-                u"-dev", self.device,
-                u"-dialog", u"on",  # Enable interactive mode
+                "-dev", self.device,
+                "-dialog", "on",  # Enable interactive mode
             ]
         )
 
         stdout, stderr = self.__recv_stdout_stderr()
         self.__handle_xorriso_error(stderr)
 
-        stdout, stderr = self.__send_cmd(u"-version")  # Test connectivity to subprocess.
+        stdout, stderr = self.__send_cmd("-version")  # Test connectivity to subprocess.
 
     def __start_subprocess(self, commandline):
 
         def setNonBlocking(fd):
             flags = fcntl.fcntl(fd, fcntl.F_GETFL)
             flags = flags | os.O_NONBLOCK
             fcntl.fcntl(fd, fcntl.F_SETFL, flags)
@@ -85,15 +92,15 @@
                 stdin=subprocess.PIPE,
                 stdout=subprocess.PIPE,
                 stderr=subprocess.PIPE,
             )
 
             self.proc = p
         except FileNotFoundError as err:
-            raise FatalBackendException(u"Xorriso binary not found: {}".format(self.xorriso_cmd))
+            raise FatalBackendException(f"Xorriso binary not found: {self.xorriso_cmd}")
 
         setNonBlocking(self.proc.stdout)
         setNonBlocking(self.proc.stderr)
 
     def __send_cmd(self, *args):
 
         # Drain stdout and stderr
@@ -102,20 +109,20 @@
             pass
 
         while self.proc.stderr.readline():
             pass
 
         try:
             for arg in args:
-                self.proc.stdin.write(shlex.quote(arg).encode(u"utf-8"))
+                self.proc.stdin.write(shlex.quote(arg).encode("utf-8"))
                 self.proc.stdin.write(b" ")
             self.proc.stdin.write(b"\n")
             self.proc.stdin.flush()
         except BrokenPipeError as e:
-            raise FatalBackendException(u"BrokenPipe: lost connection to xorriso subprocess")
+            raise FatalBackendException("BrokenPipe: lost connection to xorriso subprocess")
 
         stdout, stderr = self.__recv_stdout_stderr()
 
         self.__handle_xorriso_error(stderr)
 
         return stdout, stderr
 
@@ -127,175 +134,175 @@
             if self.proc.poll() is not None:
                 # Process terminated
                 break
 
             no_input = True
 
             while True:
-                line = self.proc.stdout.readline().decode(u"utf-8").strip()
+                line = self.proc.stdout.readline().decode("utf-8").strip()
                 if line:
                     stdout.append(line)
                 else:
                     no_input = False
                     break
 
             while True:
-                line = self.proc.stderr.readline().decode(u"utf-8").strip()
+                line = self.proc.stderr.readline().decode("utf-8").strip()
                 if line:
                     stderr.append(line)
                 else:
                     no_input = False
                     break
 
-            if stderr and stderr[-1] == u"enter option and arguments :":
+            if stderr and stderr[-1] == "enter option and arguments :":
                 break
 
             if no_input:
                 time.sleep(0.1)
 
         return stdout, stderr
 
     def __handle_xorriso_error(self, stderr):
-        u"""
+        """
         Detect errors from stderr of xorriso.
         Convert the errors into exceptions.
         """
 
         lines = stderr
 
-        stderr = u"\n".join(lines)
+        stderr = "\n".join(lines)
 
-        is_fatal = u"FATAL" in stderr
-        is_failure = u"FAILURE" in stderr
+        is_fatal = "FATAL" in stderr
+        is_failure = "FAILURE" in stderr
 
         if is_fatal:
-            msg = u"\n".join(l for l in lines if u": FATAL" in l)
+            msg = "\n".join(l for l in lines if ": FATAL" in l)
             raise BackendException(msg)
         elif is_failure:
-            msg = u"\n".join(l for l in lines if u": FAILURE" in l)
+            msg = "\n".join(l for l in lines if ": FAILURE" in l)
             raise BackendException(stderr)
 
-    def ls(self, pattern=u"."):
-        u"""
+    def ls(self, pattern="."):
+        """
         List files on optical disc.
         """
 
         files = [f for f, _ in self.lsl(pattern)]
 
         return files
 
-    def lsl(self, pattern=u"."):
-        u"""
+    def lsl(self, pattern="."):
+        """
         List files on optical disc.
         """
 
-        stdout, stderr = self.__send_cmd(u"-lsl", pattern)
+        stdout, stderr = self.__send_cmd("-lsl", pattern)
 
         # Parse output of `xorriso -lsl`
         lines = stdout
 
         files = []
 
         for line in lines:
             line = line.strip()
 
             if not line:  # Skip empty lines
                 continue
 
-            parts = re.split(u'\\s+', line, maxsplit=8)
+            parts = re.split('\\s+', line, maxsplit=8)
 
             if len(parts) != 9:
                 continue
 
             mode, _, _uid, _gid, size, _month, _day, _time, filename = parts
 
-            if not filename.startswith(u"'") or not filename.endswith(u"'"):
-                raise BackendException(u"Got unexpected format from xorriso -lsl.")
+            if not filename.startswith("'") or not filename.endswith("'"):
+                raise BackendException("Got unexpected format from xorriso -lsl.")
 
             # Parse size into an integer.
             try:
                 size = int(size)
-            except:
-                raise BackendException(u"Could not parse file size.")
+            except Exception as e:
+                raise BackendException("Could not parse file size.")
 
             filename = filename[1:-1]  # strip leading and trailing `'`s
-            files.append((filename, {u'size': size}))
+            files.append((filename, {'size': size}))
 
         return files
 
     def commit(self):
-        u"""
+        """
         Commit changes and write them to the image.
         """
 
         stdout, stderr = self.__send_cmd(
-            u"-commit"
+            "-commit"
         )
 
-        if u"exceeds free space on media" in u"\n".join(stderr):
-            raise BackendException(u"Not enough free space on media.")
+        if "exceeds free space on media" in "\n".join(stderr):
+            raise BackendException("Not enough free space on media.")
 
     def end(self):
-        u"""
+        """
         Terminate the xorriso subprocess
         """
 
-        stdout, stderr = self.__send_cmd(u"-end")
+        stdout, stderr = self.__send_cmd("-end")
 
     def cp(self, files, dest):
-        u"""
+        """
         Copy file to the ISO image. Does not commit the changes yet.
         """
         assert isinstance(files, list)
 
         stdout, stderr = self.__send_cmd(
-            u"-cpr",
+            "-cpr",
             *files,
             dest,
-            u"--",
+            "--",
         )
 
-        if u"exceeds free space on media" in u"\n".join(stderr):
-            raise BackendException(u"Not enough free space on media.")
+        if "exceeds free space on media" in "\n".join(stderr):
+            raise BackendException("Not enough free space on media.")
 
     def rm(self, files):
-        u"""
+        """
         Remove a list of files from the image. Does not commit the changes yet.
         """
         assert isinstance(files, list)
 
         if not files:
             return
 
         stdout, stderr = self.__send_cmd(
-            u"-rm",
+            "-rm",
             *files,
             # Don't commit yet.
         )
 
     def extract(self, files, dest):
-        u"""
+        """
         Extract files from the ISO image.
         """
         assert isinstance(files, list)
 
         assert not os.path.exists(dest) or os.path.isfile(dest)
 
         if len(files) == 0:
             return
 
         stdout, stderr = self.__send_cmd(
-            u"-cpx",
+            "-cpx",
             *files,
             dest
         )
 
 
 class XorrisoBackend(duplicity.backend.Backend):
-    u"""Backend for writing to optical discs or ISO images using xorriso.
+    """Backend for writing to optical discs or ISO images using xorriso.
 
     Simple URLs look like `xorriso:///dev/sr0` if the backup location is at the root of the filesystem.
     or if `xorriso://dev/sr0:/path/to/a/directory/on/iso` if the backup location is in a directory.
 
     Especially for testing also an ISO file can be used: xorriso://path/to/image.iso
 
     The path to the `xorriso` executable can be specified with teh `XORRISO_PATH` environment variable.
@@ -307,101 +314,101 @@
     * XORRISO_ARGS: Arbitrary arguments to xorriso, inserted before the filesystem operations. For experts only.
     """
 
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
 
         # Path to xorriso executable.
-        xorriso_cmd = os.environ.get(u'XORRISO_PATH', default=u'xorriso')
+        xorriso_cmd = os.environ.get('XORRISO_PATH', default='xorriso')
 
         # Check if xorriso is installed.
-        if xorriso_cmd == u'xorriso':
-            if not util.which(u'xorriso'):
-                raise FatalBackendException(u"xorriso not installed")
+        if xorriso_cmd == 'xorriso':
+            if not util.which('xorriso'):
+                raise FatalBackendException("xorriso not installed")
 
         # Default arguments for xorriso.
         self.xorriso_args = []
 
-        args_pre = os.environ.get(u'XORRISO_ARGS')
+        args_pre = os.environ.get('XORRISO_ARGS')
         if args_pre is not None:
             arg_list = shlex.split(args_pre)
             self.xorriso_args.extend(arg_list)
 
-        assert_volid = os.environ.get(u'XORRISO_ASSERT_VOLID')
+        assert_volid = os.environ.get('XORRISO_ASSERT_VOLID')
         if assert_volid is not None:
-            self.xorriso_args += [u"-assert_volid", assert_volid, u"FAILURE"]
+            self.xorriso_args += ["-assert_volid", assert_volid, "FAILURE"]
 
-        speed = os.environ.get(u'XORRISO_WRITE_SPEED', default=u'min')
-        if speed in [u"min", u"max"]:
-            self.xorriso_args += [u"-speed", speed]
+        speed = os.environ.get('XORRISO_WRITE_SPEED', default='min')
+        if speed in ["min", "max"]:
+            self.xorriso_args += ["-speed", speed]
         else:
-            self.xorriso_args += [u"-speed", u"min"]
+            self.xorriso_args += ["-speed", "min"]
 
         # The URL form "file:MyFile" is not a valid duplicity target.
-        if not parsed_url.path.startswith(u'//'):
-            raise InvalidBackendURl(u"Bad xorriso:// path syntax.")
+        if not parsed_url.path.startswith('//'):
+            raise InvalidBackendURl("Bad xorriso:// path syntax.")
 
         path = parsed_url.path[2:]  # Strip '//'
 
-        parts = path.split(u":", maxsplit=1)
+        parts = path.split(":", maxsplit=1)
         if len(parts) == 2:
             self.device = parts[0]
             self.iso_path = parts[1]
         else:
             self.device = parts[0]
-            self.iso_path = u"/"
+            self.iso_path = "/"
 
-        if not self.iso_path.endswith(u"/"):
-            self.iso_path += u"/"
+        if not self.iso_path.endswith("/"):
+            self.iso_path += "/"
 
         if not os.path.exists(self.device):
-            raise InvalidBackendURL(u"Optical disc device does not exist: {}".format(self.device))
+            raise InvalidBackendURL(f"Optical disc device does not exist: {self.device}")
 
         # Start xorriso subprocess.
         self.xorriso = Xorriso(
             device=self.device,
             xorriso_path=xorriso_cmd,
             xorriso_args=self.xorriso_args
         )
 
     def _put(self, source_path, remote_filename):
-        assert not os.path.isdir(source_path.name.decode(u'utf8'))
+        assert not os.path.isdir(source_path.name.decode('utf8'))
         source_path.setdata()
         source_size = source_path.getsize()
         progress.report_transfer(0, source_size)
 
-        self.xorriso.cp([source_path.name.decode(u'utf8')], self.iso_path + remote_filename.decode(u'utf8'))
+        self.xorriso.cp([source_path.name.decode('utf8')], self.iso_path + remote_filename.decode('utf8'))
         self.xorriso.commit()
 
         progress.report_transfer(source_size, source_size)
 
     def _get(self, filename, local_path):
-        self.xorriso.extract([self.iso_path + filename.decode(u'utf8')], local_path.name.decode(u'utf8'))
+        self.xorriso.extract([self.iso_path + filename.decode('utf8')], local_path.name.decode('utf8'))
 
     def _list(self):
         files = self.xorriso.ls(pattern=self.iso_path)
         return [f.encode() for f in files]
 
     def _delete(self, filename):
-        self.xorriso.rm([self.iso_path + filename.decode(u'utf8')])
+        self.xorriso.rm([self.iso_path + filename.decode('utf8')])
 
     def _delete_list(self, filenames):
-        filenames = [self.iso_path + f.decode(u'utf8') for f in filenames]
+        filenames = [self.iso_path + f.decode('utf8') for f in filenames]
         self.xorriso.rm(filenames)
 
     def _query(self, filename):
-        filename = self.iso_path + filename.decode(u'utf8')
+        filename = self.iso_path + filename.decode('utf8')
         files = self.xorriso.lsl(filename)
 
         if len(files) == 0 or files[0][0] != filename:
             size = -1
         else:
-            size = files[0][1][u'size']
+            size = files[0][1]['size']
 
-        return {u'size': size}
+        return {'size': size}
 
     def _close(self):
         self.xorriso.commit()
         self.xorriso.end()
 
 
-duplicity.backend.register_backend(u"xorriso", XorrisoBackend)
+duplicity.backend.register_backend("xorriso", XorrisoBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backends/slatebackend.py` & `duplicity-2.0.0rc0/duplicity/backends/slatebackend.py`

 * *Files 9% similar despite different names*

```diff
@@ -14,172 +14,171 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import str
+import json
 import os
 import shutil
-import requests
-import json
 import urllib.request
 from pathlib import Path
-import time
+
+import requests
 
 import duplicity.backend
 from duplicity import log
-from duplicity import util
 from duplicity.errors import BackendException
 
 
 class SlateBackend(duplicity.backend.Backend):
-    u"""
+    """
     Backend for Slate
     """
+
     def __init__(self, parsed_url):
         duplicity.backend.Backend.__init__(self, parsed_url)
-        log.Debug(u"loading slate backend...")
-        if u'SLATE_API_KEY' not in os.environ.keys():
+        log.Debug("loading slate backend...")
+        if 'SLATE_API_KEY' not in os.environ.keys():
             raise BackendException(
-                u'''You must set an environment variable SLATE_API_KEY
+                '''You must set an environment variable SLATE_API_KEY
                 as the value of your slate API key''')
         else:
-            self.key = os.environ[u'SLATE_API_KEY']
+            self.key = os.environ['SLATE_API_KEY']
 
-        if u'SLATE_SSL_VERIFY' not in os.environ.keys():
+        if 'SLATE_SSL_VERIFY' not in os.environ.keys():
             self.verify = True
         else:
-            if u'SLATE_SSL_VERIFY' == u'0':
+            if 'SLATE_SSL_VERIFY' == '0':
                 self.verify = False
             else:
                 self.verify = True
 
-        data = json.dumps({u'data': {u'private': u'true'}})
+        data = json.dumps({'data': {'private': 'true'}})
         headers = {
-            u'Content-Type': u'application/json',
-            u'Authorization': u'Basic ' + self.key
+            'Content-Type': 'application/json',
+            'Authorization': f"Basic {self.key}"
         }
 
         response = requests.post(
-            u'https://slate.host/api/v1/get',
+            'https://slate.host/api/v1/get',
             data=data,
             headers=headers,
             verify=self.verify)
         if not response.ok:
-            raise BackendException(u"Slate backend requires a valid API key")
+            raise BackendException("Slate backend requires a valid API key")
 
-        self.slate_id = parsed_url.geturl().split(u'/')[-1]
+        self.slate_id = parsed_url.geturl().split('/')[-1]
 
     def _put(self, source_path, remote_filename):
-        data = json.dumps({u'data': {u'private': u'true'}})
+        data = json.dumps({'data': {'private': 'true'}})
         headers = {
-            u'Content-Type': u'application/json',
-            u'Authorization': u'Basic ' + self.key
+            'Content-Type': 'application/json',
+            'Authorization': f"Basic {self.key}"
         }
 
-        log.Debug(u"source_path.name: " + str(source_path.name))
-        log.Debug(u"remote_filename: " + remote_filename.decode(u"utf8"))
-        rem_filename = str(util.fsdecode(remote_filename))
-
-        src = Path(util.fsdecode(source_path.name))
-        if str(src.name).startswith(u"mktemp"):
-            log.Debug(u"copying temp file for upload")
+        log.Debug(f"source_path.name: {str(source_path.name)}")
+        log.Debug(f"remote_filename: {remote_filename.decode('utf8')}")
+        rem_filename = str(os.fsdecode(remote_filename))
+
+        src = Path(os.fsdecode(source_path.name))
+        if str(src.name).startswith("mktemp"):
+            log.Debug("copying temp file for upload")
             src = shutil.move(str(src), str(src.with_name(rem_filename)))
 
-        log.Debug(u"response")
+        log.Debug("response")
         headers = {
-            u'Authorization': u'Basic ' + self.key
+            'Authorization': f"Basic {self.key}"
         }
-        files = {rem_filename: open(str(src), u'rb')}
-        log.Debug(u"-------------------FILECHECK: " + str(files.keys()))
+        files = {rem_filename: open(str(src), 'rb')}
+        log.Debug(f"-------------------FILECHECK: {str(files.keys())}")
         response = requests.post(
-            url=u'https://uploads.slate.host/api/public/' + self.slate_id,
+            url=f"https://uploads.slate.host/api/public/{self.slate_id}",
             files=files,
             headers=headers)
-        log.Debug(u"response handled")
+        log.Debug("response handled")
 
         if not response.ok:
-            raise BackendException(u"An error occurred whilst attempting to upload a file: %s" % (response))
+            raise BackendException(f"An error occurred whilst attempting to upload a file: {response}")
         else:
-            log.Debug(u"File successfully uploaded to slate with id:" + self.slate_id)
+            log.Debug(f"File successfully uploaded to slate with id:{self.slate_id}")
 
-        if str(src).endswith(u"difftar.gpg"):
+        if str(src).endswith("difftar.gpg"):
             os.remove(str(src))
 
     def _list(self):
 
         # Checks if a specific slate has been selected, otherwise lists all slates
-        log.Debug(u"Slate ID: %s" % (self.slate_id))
-        data = json.dumps({u'data': {u'private': u'true'}})
+        log.Debug(f"Slate ID: {self.slate_id}")
+        data = json.dumps({'data': {'private': 'true'}})
         headers = {
-            u'Content-Type': u'application/json',
-            u'Authorization': u'Basic ' + self.key
+            'Content-Type': 'application/json',
+            'Authorization': f"Basic {self.key}"
         }
         response = requests.post(
-            u'https://slate.host/api/v1/get',
+            'https://slate.host/api/v1/get',
             data=data,
             headers=headers,
             verify=self.verify)
 
         if not response.ok:
-            raise BackendException(u"Slate backend requires a valid API key")
+            raise BackendException("Slate backend requires a valid API key")
 
-        slates = response.json()[u'slates']
+        slates = response.json()['slates']
         # log.Debug("SLATES:\n%s"%(slates))
         file_list = []
         for slate in slates:
-            if slate[u'id'] == self.slate_id:
-                files = slate[u'data'][u'objects']
+            if slate['id'] == self.slate_id:
+                files = slate['data']['objects']
                 for f in files:
-                    file_list.append(f[u'name'])
+                    file_list.append(f['name'])
             else:
-                log.Debug(u"Could not find slate with id: " + self.slate_id)
+                log.Debug(f"Could not find slate with id: {self.slate_id}")
 
         return file_list
 
     def _get(self, remote_filename, local_path):
         # Downloads chosen file from IPFS by parsing its cid
         found = False
-        data = json.dumps({u'data': {u'private': u'true'}})
+        data = json.dumps({'data': {'private': 'true'}})
         headers = {
-            u'Content-Type': u'application/json',
-            u'Authorization': u'Basic ' + self.key
+            'Content-Type': 'application/json',
+            'Authorization': f"Basic {self.key}"
         }
 
         response = requests.post(
-            u'https://slate.host/api/v1/get',
+            'https://slate.host/api/v1/get',
             data=data,
             headers=headers,
             verify=self.verify)
 
-        slates = response.json()[u'slates']
+        slates = response.json()['slates']
         # file_list = self._list()
 
         # if remote_filename not in file_list:
         #     raise BackendException(u"The chosen file does not exist in the chosen slate")
 
         for slate in slates:
-            if slate[u'id'] == self.slate_id:
+            if slate['id'] == self.slate_id:
                 found = True
-                for obj in slate[u'data'][u'objects']:
-                    if obj[u'name'] == remote_filename.decode(u"utf8"):
-                        cid = obj[u'url'].split(u"/")[-1]
+                for obj in slate['data']['objects']:
+                    if obj['name'] == remote_filename.decode("utf8"):
+                        cid = obj['url'].split("/")[-1]
                         break
                     else:
                         raise BackendException(
-                            u"The file '"
-                            + remote_filename.decode(u"utf8")
-                            + u"' could not be found in the specified slate")
+                            "The file '"
+                            + remote_filename.decode("utf8")
+                            + "' could not be found in the specified slate")
 
         if not found:
-            raise BackendException(u"A slate with id " + self.slate_id + u" does not exist")
+            raise BackendException(f"A slate with id {self.slate_id} does not exist")
 
         try:
-            urllib.request.urlretrieve(u'http://ipfs.io/ipfs/%s' % (cid), util.fsdecode(local_path.name))
-            log.Debug(u'Downloaded file with cid: %s' % (cid))
+            urllib.request.urlretrieve(f'http://ipfs.io/ipfs/{cid}', os.fsdecode(local_path.name))
+            log.Debug(f'Downloaded file with cid: {cid}')
         except NameError as e:
-            raise BackendException(u"Couldn't download file")
+            raise BackendException("Couldn't download file")
 
 
-duplicity.backend.register_backend(u'slate', SlateBackend)
+duplicity.backend.register_backend('slate', SlateBackend)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/dup_threading.py` & `duplicity-2.0.0rc0/duplicity/dup_threading.py`

 * *Files 23% similar despite different names*

```diff
@@ -15,87 +15,31 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Duplicity specific but otherwise generic threading interfaces and
 utilities.
 
 (Not called "threading" because we do not want to conflict with
-the standard threading module, and absolute imports require
-at least python 2.5.)
+the standard threading module.)
 """
 
-from future import standard_library
-standard_library.install_aliases()
-from builtins import object
+import _thread
 import sys
-from duplicity import errors
-
-_threading_supported = True
-
-try:
-    import _thread
-except ImportError:
-    import _dummy_thread as _thread
-    _threading_supported = False
-
-try:
-    import threading
-except ImportError:
-    import dummy_threading as threading
-    _threading_supported = False
-
-
-def threading_supported():
-    u"""
-    Returns whether threading is supported on the system we are
-    running on.
-    """
-    return _threading_supported
-
-
-def require_threading(reason=None):
-    u"""
-    Assert that threading is required for operation to continue. Raise
-    an appropriate exception if this is not the case.
+import threading
 
-    Reason specifies an optional reason why threading is required,
-    which will be used for error reporting in case threading is not
-    supported.
-    """
-    if not threading_supported():
-        if reason is None:
-            reason = u"(no reason given)"
-        raise errors.NotSupported(u"threading was needed because [%s], but "
-                                  u"is not supported by the python "
-                                  u"interpreter" % (reason,))
-
-
-def thread_module():
-    u"""
-    Returns the thread module, or dummy_thread if threading is not
-    supported.
-    """
-    return _thread
-
-
-def threading_module():
-    u"""
-    Returns the threading module, or dummy_thread if threading is not
-    supported.
-    """
-    return threading
+from duplicity import errors
 
 
 def with_lock(lock, fn):
-    u"""
+    """
     Call fn with lock acquired. Guarantee that lock is released upon
     the return of fn.
 
     Returns the value returned by fn, or raises the exception raised
     by fn.
 
     (Lock can actually be anything responding to acquire() and
@@ -106,15 +50,15 @@
     try:
         return fn()
     finally:
         lock.release()
 
 
 def interruptably_wait(cv, waitFor):
-    u"""
+    """
     cv   - The threading.Condition instance to wait on
     test - Callable returning a boolean to indicate whether
            the criteria being waited on has been satisfied.
 
     Perform a wait on a condition such that it is keyboard
     interruptable when done in the main thread. Due to Python
     limitations as of <= 2.5, lock acquisition and conditions waits
@@ -157,15 +101,15 @@
     # imply a latency penalty in the common case of a
     # notify.
     while not waitFor():
         cv.wait(0.1)
 
 
 def async_split(fn):
-    u"""
+    """
     Splits the act of calling the given function into one front-end
     part for waiting on the result, and a back-end part for performing
     the work in another thread.
 
     Returns (waiter, caller) where waiter is a function to be called
     in order to wait for the results of an asynchronous invokation of
     fn to complete, returning fn's result or propagating it's
@@ -182,57 +126,57 @@
     # We use a dictionary to track the state of the asynchronous call,
     # rather than local variables. This is to get around the way
     # closures work with respect to local variables in Python. We do
     # not care about hash lookup overhead since this is intended to be
     # used for significant amounts of work.
 
     cv = threading.Condition()
-    state = {u'done': False,
-             u'error': None,
-             u'trace': None,
-             u'value': None}
+    state = {'done': False,
+             'error': None,
+             'trace': None,
+             'value': None}
 
     def waiter():
         cv.acquire()
         try:
-            interruptably_wait(cv, lambda: state[u'done'])
+            interruptably_wait(cv, lambda: state['done'])
 
-            if state[u'error'] is None:
-                return state[u'value']
+            if state['error'] is None:
+                return state['value']
             else:
-                raise state[u'error'].with_traceback(state[u'trace'])
+                raise state['error'].with_traceback(state['trace'])
         finally:
             cv.release()
 
     def caller():
         try:
             value = fn()
 
             cv.acquire()
-            state[u'done'] = True
-            state[u'value'] = value
+            state['done'] = True
+            state['value'] = value
             cv.notify()
             cv.release()
 
-            return (True, waiter)
+            return True, waiter
         except Exception as e:
             cv.acquire()
-            state[u'done'] = True
-            state[u'error'] = e
-            state[u'trace'] = sys.exc_info()[2]
+            state['done'] = True
+            state['error'] = e
+            state['trace'] = sys.exc_info()[2]
             cv.notify()
             cv.release()
 
-            return (False, waiter)
+            return False, waiter
 
-    return (waiter, caller)
+    return waiter, caller
 
 
 class Value(object):
-    u"""
+    """
     A thread-safe container of a reference to an object (but not the
     object itself).
 
     In particular this means it is safe to:
 
       value.set(1)
 
@@ -249,61 +193,63 @@
 
     Operations such as increments are best done as:
 
       value.transform(lambda val: val + 1)
     """
 
     def __init__(self, value=None):
-        u"""
+        """
         Initialuze with the given value.
         """
         self.__value = value
 
         self.__cv = threading.Condition()
 
     def get(self):
-        u"""
+        """
         Returns the value protected by this Value.
         """
         return with_lock(self.__cv, lambda: self.__value)
 
     def set(self, value):
-        u"""
+        """
         Resets the value protected by this Value.
         """
+
         def _set():
             self.__value = value
 
         with_lock(self.__cv, _set)
 
     def transform(self, fn):
-        u"""
+        """
         Call fn with the current value as the parameter, and reset the
         value to the return value of fn.
 
         During the execution of fn, all other access to this Value is
         prevented.
 
         If fn raised an exception, the value is not reset.
 
         Returns the value returned by fn, or raises the exception
         raised by fn.
         """
+
         def _transform():
             self.__value = fn(self.__value)
             return self.__value
 
         return with_lock(self.cv, _transform)
 
     def acquire(self):
-        u"""
+        """
         Acquire this Value for mutually exclusive access. Only ever
         needed when calling code must perform operations that cannot
         be done with get(), set() or transform().
         """
         self.__cv.acquire()
 
     def release(self):
-        u"""
+        """
         Release this Value for mutually exclusive access.
         """
         self.__cv.release()
```

### Comparing `duplicity-1.2.3.dev43/duplicity/dup_main.py` & `duplicity-2.0.0rc0/duplicity/dup_main.py`

 * *Files 4% similar despite different names*

```diff
@@ -25,70 +25,58 @@
 #  http://duplicity.us
 #  or
 #  http://duplicity.gitlab.io
 # .
 # Please send mail to me or the mailing list if you find bugs or have
 # any suggestions.
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import map
-from builtins import next
-from builtins import object
-from builtins import range
 
 import copy
-import fasteners
 import os
 import platform
 import resource
+import socket
 import sys
 import time
+from datetime import datetime
+
+import fasteners
 
 from duplicity import __version__
 from duplicity import asyncscheduler
-from duplicity import commandline
+from duplicity import cli_main
+from duplicity import config
 from duplicity import diffdir
 from duplicity import dup_collections
 from duplicity import dup_temp
 from duplicity import dup_time
+from duplicity import errors
 from duplicity import file_naming
-from duplicity import config
 from duplicity import gpg
 from duplicity import log
 from duplicity import manifest
 from duplicity import patchdir
 from duplicity import path
 from duplicity import progress
 from duplicity import tempdir
 from duplicity import util
-import duplicity.errors
 from duplicity.errors import BadVolumeException
 
-import duplicity.config as config
-
-from datetime import datetime
-
 # If exit_val is not None, exit with given value at end.
 exit_val = None
 
 
 def getpass_safe(message):
-    # getpass() in Python 2.x will call str() on our prompt.  So we can't pass
-    # in non-ascii characters.
     import getpass
     import locale
-    if sys.version_info.major == 2:
-        message = message.encode(locale.getpreferredencoding(), u'replace')
     return getpass.getpass(message)
 
 
 def get_passphrase(n, action, for_signing=False):
-    u"""
+    """
     Check to make sure passphrase is indeed needed, then get
     the passphrase from environment, from gpg-agent, or user
 
     If n=3, a password is requested and verified. If n=2, the current
     password is verified. If n=1, a password is requested without
     verification for the time being.
 
@@ -101,121 +89,121 @@
     @rtype: string
     @return: passphrase
     """
 
     # First try the environment
     try:
         if for_signing:
-            return os.environ[u'SIGN_PASSPHRASE']
+            return os.environ['SIGN_PASSPHRASE']
         else:
-            return os.environ[u'PASSPHRASE']
+            return os.environ['PASSPHRASE']
     except KeyError:
         pass
 
     # check if we can reuse an already set (signing_)passphrase
     # if signing key is also an encryption key assume that the passphrase is identical
     if (for_signing and
             (config.gpg_profile.sign_key in config.gpg_profile.recipients or
              config.gpg_profile.sign_key in config.gpg_profile.hidden_recipients) and
-             u'PASSPHRASE' in os.environ):  # noqa
-        log.Notice(_(u"Reuse configured PASSPHRASE as SIGN_PASSPHRASE"))
-        return os.environ[u'PASSPHRASE']
+            'PASSPHRASE' in os.environ):  # noqa
+        log.Notice(_("Reuse configured PASSPHRASE as SIGN_PASSPHRASE"))
+        return os.environ['PASSPHRASE']
     # if one encryption key is also the signing key assume that the passphrase is identical
     if (not for_signing and
             (config.gpg_profile.sign_key in config.gpg_profile.recipients or
              config.gpg_profile.sign_key in config.gpg_profile.hidden_recipients) and
-             u'SIGN_PASSPHRASE' in os.environ):  # noqa
-        log.Notice(_(u"Reuse configured SIGN_PASSPHRASE as PASSPHRASE"))
-        return os.environ[u'SIGN_PASSPHRASE']
+            'SIGN_PASSPHRASE' in os.environ):  # noqa
+        log.Notice(_("Reuse configured SIGN_PASSPHRASE as PASSPHRASE"))
+        return os.environ['SIGN_PASSPHRASE']
 
     # Next, verify we need to ask the user
 
     # Assumptions:
     #   - encrypt-key has no passphrase
     #   - sign-key requires passphrase
     #   - gpg-agent supplies all, no user interaction
 
     # no passphrase if --no-encryption or --use-agent
     if not config.encryption or config.use_agent:
-        return u""
+        return ""
 
     # these commands don't need a password
-    elif action in [u"collection-status",
-                    u"list-current",
-                    u"remove-all-but-n-full",
-                    u"remove-all-inc-of-but-n-full",
-                    u"remove-old",
+    elif action in ["collection-status",
+                    "list-current-files",
+                    "remove-all-but-n-full",
+                    "remove-all-inc-of-but-n-full",
+                    "remove-old",
                     ]:
-        return u""
+        return ""
 
     # for a full backup, we don't need a password if
     # there is no sign_key and there are recipients
-    elif (action == u"full"
+    elif (action == "full"
           and (config.gpg_profile.recipients or config.gpg_profile.hidden_recipients)
           and (not config.gpg_profile.sign_key
                or (not config.restart and not for_signing))):
-        return u""
+        return ""
 
     # for an inc backup, we don't need a password if
     # there is no sign_key and there are recipients
-    elif (action == u"inc"
+    elif (action == "inc"
           and (config.gpg_profile.recipients or config.gpg_profile.hidden_recipients)
           and (not config.gpg_profile.sign_key
                or (not config.restart and not for_signing))):
-        return u""
+        return ""
 
     # Finally, ask the user for the passphrase
     else:
-        log.Info(_(u"PASSPHRASE variable not set, asking user."))
+        log.Info(_("PASSPHRASE variable not set, asking user."))
         use_cache = True
-        while 1:
+        while True:
             # ask the user to enter a new passphrase to avoid an infinite loop
             # if the user made a typo in the first passphrase
             if use_cache and n == 2:
                 if for_signing:
                     pass1 = config.gpg_profile.signing_passphrase
                 else:
                     pass1 = config.gpg_profile.passphrase
             else:
                 if for_signing:
                     if use_cache and config.gpg_profile.signing_passphrase:
                         pass1 = config.gpg_profile.signing_passphrase
                     else:
-                        pass1 = getpass_safe(_(u"GnuPG passphrase for signing key:") + u" ")
+                        pass1 = getpass_safe(f"{_('GnuPG passphrase for signing key:')} ")
                 else:
                     if use_cache and config.gpg_profile.passphrase:
                         pass1 = config.gpg_profile.passphrase
                     else:
-                        pass1 = getpass_safe(_(u"GnuPG passphrase for decryption:") + u" ")
+                        pass1 = getpass_safe(f"{_('GnuPG passphrase for decryption:')} ")
 
             if n == 1:
                 pass2 = pass1
             elif for_signing:
-                pass2 = getpass_safe(_(u"Retype passphrase for signing key to confirm: "))
+                pass2 = getpass_safe(_("Retype passphrase for signing key to confirm: "))
             else:
-                pass2 = getpass_safe(_(u"Retype passphrase for decryption to confirm: "))
+                pass2 = getpass_safe(_("Retype passphrase for decryption to confirm: "))
 
             if not pass1 == pass2:
-                log.Log(_(u"First and second passphrases do not match!  Please try again."),
+                log.Log(_("First and second passphrases do not match!  Please try again."),
                         log.WARNING, force_print=True)
                 use_cache = False
                 continue
 
             if not pass1 and not (config.gpg_profile.recipients or
                                   config.gpg_profile.hidden_recipients) and not for_signing:
-                log.Log(_(u"Cannot use empty passphrase with symmetric encryption!  Please try again."),
+                log.Log(_("Cannot use empty passphrase with symmetric encryption!  Please try again."),
                         log.WARNING, force_print=True)
                 use_cache = False
                 continue
 
             return pass1
 
 
 def dummy_backup(tarblock_iter):
-    u"""
+    """
     Fake writing to backend, but do go through all the source paths.
 
     @type tarblock_iter: tarblock_iter
     @param tarblock_iter: iterator for current tar block
 
     @rtype: int
     @return: constant 0 (zero)
@@ -227,15 +215,15 @@
     except StopIteration:
         pass
     log.Progress(None, diffdir.stats.SourceFileSize)
     return 0
 
 
 def restart_position_iterator(tarblock_iter):
-    u"""
+    """
     Fake writing to backend, but do go through all the source paths.
     Stop when we have processed the last file and block from the
     last backup.  Normal backup will proceed at the start of the
     next volume in the set.
 
     @type tarblock_iter: tarblock_iter
     @param tarblock_iter: iterator for current tar block
@@ -245,42 +233,42 @@
     """
     last_index = config.restart.last_index
     last_block = config.restart.last_block
     try:
         # Just spin our wheels
         iter_result = next(tarblock_iter)
         while iter_result:
-            if (tarblock_iter.previous_index == last_index):
+            if tarblock_iter.previous_index == last_index:
                 # If both the previous index and this index are done, exit now
                 # before we hit the next index, to prevent skipping its first
                 # block.
                 if not last_block and not tarblock_iter.previous_block:
                     break
                 # Only check block number if last_block is also a number
                 if (last_block and tarblock_iter.previous_block
                         and tarblock_iter.previous_block > last_block):
                     break
             if tarblock_iter.previous_index > last_index:
-                log.Warn(_(u"File %s complete in backup set.\n"
-                           u"Continuing restart on file %s.") %
+                log.Warn(_("File %s complete in backup set.\n"
+                           "Continuing restart on file %s.") %
                          (util.uindex(last_index), util.uindex(tarblock_iter.previous_index)),
                          log.ErrorCode.restart_file_not_found)
                 # We went too far! Stuff the data back into place before restarting
                 tarblock_iter.queue_index_data(iter_result)
                 break
             iter_result = next(tarblock_iter)
     except StopIteration:
-        log.Warn(_(u"File %s missing in backup set.\n"
-                   u"Continuing restart on file %s.") %
+        log.Warn(_("File %s missing in backup set.\n"
+                   "Continuing restart on file %s.") %
                  (util.uindex(last_index), util.uindex(tarblock_iter.previous_index)),
                  log.ErrorCode.restart_file_not_found)
 
 
 def write_multivol(backup_type, tarblock_iter, man_outfp, sig_outfp, backend):
-    u"""
+    """
     Encrypt volumes of tarblock_iter and write to backend
 
     backup_type should be "inc" or "full" and only matters here when
     picking the filenames.  The path_prefix will determine the names
     of the files written to backend.  Also writes manifest file.
     Returns number of bytes written.
 
@@ -292,15 +280,15 @@
     @param backend: I/O backend for selected protocol
 
     @rtype: int
     @return: bytes written
     """
 
     def get_indicies(tarblock_iter):
-        u"""Return start_index and end_index of previous volume"""
+        """Return start_index and end_index of previous volume"""
         start_index, start_block = tarblock_iter.recall_index()
         if start_index is None:
             start_index = ()
             start_block = None
         if start_block:
             start_block -= 1
         end_index, end_block = tarblock_iter.get_previous_index()
@@ -309,48 +297,49 @@
             end_block = start_block
         if end_block:
             end_block -= 1
         return start_index, start_block, end_index, end_block
 
     def validate_block(orig_size, dest_filename):
         info = backend.query_info([dest_filename])[dest_filename]
-        size = info[u'size']
+        size = info['size']
         if size is None:
             return  # error querying file
         for attempt in range(1, config.num_retries + 1):
             info = backend.query_info([dest_filename])[dest_filename]
-            size = info[u'size']
+            size = info['size']
             if size == orig_size:
                 break
             if size is None:
                 return
-            log.Notice(_(u"%s Remote filesize %d for %s does not match local size %d, retrying.") % (datetime.now(),
-                       size, util.escape(dest_filename), orig_size))
-            time.sleep(2**attempt)
+            log.Notice(_("%s Remote filesize %d for %s does not match local size %d, retrying.") % (datetime.now(),
+                                                                                                    size, util.escape(
+                dest_filename), orig_size))
+            time.sleep(2 ** attempt)
         if size != orig_size:
-            code_extra = u"%s %d %d" % (util.escape(dest_filename), orig_size, size)
-            log.FatalError(_(u"File %s was corrupted during upload.") % util.fsdecode(dest_filename),
+            code_extra = f"{util.escape(dest_filename)} {int(orig_size)} {int(size)}"
+            log.FatalError(_("File %s was corrupted during upload.") % os.fsdecode(dest_filename),
                            log.ErrorCode.volume_wrong_size, code_extra)
 
     def put(tdp, dest_filename, vol_num):
-        u"""
+        """
         Retrieve file size *before* calling backend.put(), which may (at least
         in case of the localbackend) rename the temporary file to the target
         instead of copying.
         """
         putsize = tdp.getsize()
         if config.skip_volume != vol_num:  # for testing purposes only
             backend.put(tdp, dest_filename)
         validate_block(putsize, dest_filename)
         if tdp.stat:
             tdp.delete()
         return putsize
 
     def validate_encryption_settings(backup_set, manifest):
-        u"""
+        """
         When restarting a backup, we have no way to verify that the current
         passphrase is the same as the one used for the beginning of the backup.
         This is because the local copy of the manifest is unencrypted and we
         don't need to decrypt the existing volumes on the backend.  To ensure
         that we are using the same passphrase, we manually download volume 1
         and decrypt it with the current passphrase.  We also want to confirm
         that we're using the same encryption settings (i.e. we don't switch
@@ -364,16 +353,16 @@
             # on the machine.
             return
 
         vol1_filename = file_naming.get(backup_type, 1,
                                         encrypted=config.encryption,
                                         gzipped=config.compression)
         if vol1_filename != backup_set.volume_name_dict[1]:
-            log.FatalError(_(u"Restarting backup, but current encryption "
-                             u"settings do not match original settings"),
+            log.FatalError(_("Restarting backup, but current encryption "
+                             "settings do not match original settings"),
                            log.ErrorCode.enryption_mismatch)
 
         # Settings are same, let's check passphrase itself if we are encrypted
         if config.encryption:
             fileobj = restore_get_enc_fileobj(config.backend, vol1_filename,
                                               manifest.volume_info_dict[1])
             fileobj.close()
@@ -387,18 +376,18 @@
         # restart from last known position
         mf = config.restart.last_backup.get_local_manifest()
         config.restart.checkManifest(mf)
         config.restart.setLastSaved(mf)
         if not (config.s3_use_deep_archive or config.s3_use_glacier or config.s3_use_glacier_ir):
             validate_encryption_settings(config.restart.last_backup, mf)
         else:
-            log.Warn(_(u"Skipping encryption validation due to glacier/deep storage"))
+            log.Warn(_("Skipping encryption validation due to glacier/deep storage"))
         mf.fh = man_outfp
         last_block = config.restart.last_block
-        log.Notice(_(u"Restarting after volume %s, file %s, block %s") %
+        log.Notice(_("Restarting after volume %s, file %s, block %s") %
                    (config.restart.start_vol,
                     util.uindex(config.restart.last_index),
                     config.restart.last_block))
         vol_num = config.restart.start_vol
         restart_position_iterator(tarblock_iter)
 
     at_end = 0
@@ -424,42 +413,34 @@
     async_waiters = []
 
     while not at_end:
         # set up iterator
         tarblock_iter.remember_next_index()  # keep track of start index
 
         # Create volume
-        try:
-            log.Debug(u"BACKEND: " + str(config.backend))
-        except:
-            pass
-        log.Debug(u"***CREATING VOLUME***")
-
         vol_num += 1
         dest_filename = file_naming.get(backup_type, vol_num,
                                         encrypted=config.encryption,
                                         gzipped=config.compression)
         tdp = dup_temp.new_tempduppath(file_naming.parse(dest_filename))
-        log.Debug(u"FILENAME: " + str(tdp.name))
 
         # write volume
-        log.Debug(u"***WRITING VOLUME***")
         if config.encryption:
             at_end = gpg.GPGWriteFile(tarblock_iter, tdp.name, config.gpg_profile,
                                       config.volsize)
         elif config.compression:
             at_end = gpg.GzipWriteFile(tarblock_iter, tdp.name, config.volsize)
         else:
             at_end = gpg.PlainWriteFile(tarblock_iter, tdp.name, config.volsize)
         tdp.setdata()
 
         # Add volume information to manifest
         vi = manifest.VolumeInfo()
         vi.set_info(vol_num, *get_indicies(tarblock_iter))
-        vi.set_hash(u"SHA1", gpg.get_hash(u"SHA1", tdp))
+        vi.set_hash("SHA1", gpg.get_hash("SHA1", tdp))
         mf.add_volume_info(vi)
 
         # Checkpoint after each volume so restart has a place to restart.
         # Note that until after the first volume, all files are temporary.
         if vol_num == 1:
             sig_outfp.to_partial()
             man_outfp.to_partial()
@@ -468,49 +449,49 @@
             man_outfp.flush()
 
         async_waiters.append(io_scheduler.schedule_task(lambda tdp, dest_filename,
                                                         vol_num: put(tdp, dest_filename, vol_num),
                                                         (tdp, dest_filename, vol_num)))
 
         # Log human-readable version as well as raw numbers for machine consumers
-        log.Progress(_(u'Processed volume %d') % vol_num, diffdir.stats.SourceFileSize)
+        log.Progress(_('Processed volume %d') % vol_num, diffdir.stats.SourceFileSize)
         # Snapshot (serialize) progress now as a Volume has been completed.
         # This is always the last restore point when it comes to restart a failed backup
         if config.progress:
             progress.tracker.snapshot_progress(vol_num)
 
         # for testing purposes only - assert on inc or full
-        assert config.fail_on_volume != vol_num, u"Forced assertion for testing at volume %d" % vol_num
+        assert config.fail_on_volume != vol_num, f"Forced assertion for testing at volume {int(vol_num)}"
 
     # Collect byte count from all asynchronous jobs; also implicitly waits
     # for them all to complete.
     for waiter in async_waiters:
         bytes_written += waiter()
 
     # Upload the collection summary.
     # bytes_written += write_manifest(mf, backup_type, backend)
     mf.set_files_changed_info(diffdir.stats.get_delta_entries_file())
 
     return bytes_written
 
 
 def get_man_fileobj(backup_type):
-    u"""
+    """
     Return a fileobj opened for writing, save results as manifest
 
     Save manifest in config.archive_dir_path gzipped.
     Save them on the backend encrypted as needed.
 
     @type man_type: string
     @param man_type: either "full" or "new"
 
     @rtype: fileobj
     @return: fileobj opened for writing
     """
-    assert backup_type == u"full" or backup_type == u"inc"
+    assert backup_type == "full" or backup_type == "inc"
 
     part_man_filename = file_naming.get(backup_type,
                                         manifest=True,
                                         partial=True)
     perm_man_filename = file_naming.get(backup_type,
                                         manifest=True)
     remote_man_filename = file_naming.get(backup_type,
@@ -521,27 +502,27 @@
                                       part_man_filename,
                                       perm_man_filename,
                                       remote_man_filename)
     return fh
 
 
 def get_sig_fileobj(sig_type):
-    u"""
+    """
     Return a fileobj opened for writing, save results as signature
 
     Save signatures in config.archive_dir gzipped.
     Save them on the backend encrypted as needed.
 
     @type sig_type: string
     @param sig_type: either "full-sig" or "new-sig"
 
     @rtype: fileobj
     @return: fileobj opened for writing
     """
-    assert sig_type in [u"full-sig", u"new-sig"]
+    assert sig_type in ["full-sig", "new-sig"]
 
     part_sig_filename = file_naming.get(sig_type,
                                         gzipped=False,
                                         partial=True)
     perm_sig_filename = file_naming.get(sig_type,
                                         gzipped=True)
     remote_sig_filename = file_naming.get(sig_type, encrypted=config.encryption,
@@ -552,15 +533,15 @@
                                       perm_sig_filename,
                                       remote_sig_filename,
                                       overwrite=True)
     return fh
 
 
 def full_backup(col_stats):
-    u"""
+    """
     Do full backup of directory to backend, using archive_dir_path
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
@@ -570,27 +551,27 @@
         # Fake a backup to compute total of moving bytes
         tarblock_iter = diffdir.DirFull(config.select)
         dummy_backup(tarblock_iter)
         # Store computed stats to compute progress later
         progress.tracker.set_evidence(diffdir.stats, True)
         # Reinit the config.select iterator, so
         # the core of duplicity can rescan the paths
-        commandline.set_selection()
+        cli_main.set_selection()
         progress.progress_thread = progress.LogProgressThread()
 
     if config.dry_run:
         tarblock_iter = diffdir.DirFull(config.select)
         bytes_written = dummy_backup(tarblock_iter)
         col_stats.set_values(sig_chain_warning=None)
     else:
-        sig_outfp = get_sig_fileobj(u"full-sig")
-        man_outfp = get_man_fileobj(u"full")
+        sig_outfp = get_sig_fileobj("full-sig")
+        man_outfp = get_man_fileobj("full")
         tarblock_iter = diffdir.DirFull_WriteSig(config.select,
                                                  sig_outfp)
-        bytes_written = write_multivol(u"full", tarblock_iter,
+        bytes_written = write_multivol("full", tarblock_iter,
                                        man_outfp, sig_outfp,
                                        config.backend)
 
         # close sig file, send to remote, and rename to final
         sig_outfp.close()
         sig_outfp.to_remote()
         sig_outfp.to_final()
@@ -610,83 +591,83 @@
 
         col_stats.set_values(sig_chain_warning=None)
 
     print_statistics(diffdir.stats, bytes_written)
 
 
 def check_sig_chain(col_stats):
-    u"""
+    """
     Get last signature chain for inc backup, or None if none available
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
     """
     if not col_stats.matched_chain_pair:
-        if config.incremental:
-            log.FatalError(_(u"Fatal Error: Unable to start incremental backup.  "
-                             u"Old signatures not found and incremental specified"),
+        if config.inc_explicit:
+            log.FatalError(_("Fatal Error: Unable to start incremental backup.  "
+                             "Old signatures not found and incremental specified"),
                            log.ErrorCode.inc_without_sigs)
         else:
-            log.Warn(_(u"No signatures found, switching to full backup."))
+            log.Warn(_("No signatures found, switching to full backup."))
         return None
     return col_stats.matched_chain_pair[0]
 
 
 def print_statistics(stats, bytes_written):  # pylint: disable=unused-argument
-    u"""
+    """
     If config.print_statistics, print stats after adding bytes_written
 
     @rtype: void
     @return: void
     """
     if config.print_statistics:
         diffdir.stats.TotalDestinationSizeChange = bytes_written
-        logstring = diffdir.stats.get_stats_logstring(_(u"Backup Statistics"))
+        logstring = diffdir.stats.get_stats_logstring(_("Backup Statistics"))
         log.Log(logstring, log.NOTICE, force_print=True)
 
 
 def incremental_backup(sig_chain):
-    u"""
+    """
     Do incremental backup of directory to backend, using archive_dir_path
 
     @rtype: void
     @return: void
     """
     if not config.restart:
         dup_time.setprevtime(sig_chain.end_time)
         if dup_time.curtime == dup_time.prevtime:
             time.sleep(2)
             dup_time.setcurtime()
             assert dup_time.curtime != dup_time.prevtime, \
-                u"time not moving forward at appropriate pace - system clock issues?"
+                "time not moving forward at appropriate pace - system clock issues?"
 
     if config.progress:
         progress.tracker = progress.ProgressTracker()
         # Fake a backup to compute total of moving bytes
         tarblock_iter = diffdir.DirDelta(config.select,
                                          sig_chain.get_fileobjs())
         dummy_backup(tarblock_iter)
         # Store computed stats to compute progress later
         progress.tracker.set_evidence(diffdir.stats, False)
         # Reinit the config.select iterator, so
         # the core of duplicity can rescan the paths
-        commandline.set_selection()
+        cli_main.set_selection()
         progress.progress_thread = progress.LogProgressThread()
 
     if config.dry_run:
         tarblock_iter = diffdir.DirDelta(config.select,
                                          sig_chain.get_fileobjs())
         bytes_written = dummy_backup(tarblock_iter)
     else:
-        new_sig_outfp = get_sig_fileobj(u"new-sig")
-        new_man_outfp = get_man_fileobj(u"inc")
+        new_sig_outfp = get_sig_fileobj("new-sig")
+        new_man_outfp = get_man_fileobj("inc")
         tarblock_iter = diffdir.DirDelta_WriteSig(config.select,
                                                   sig_chain.get_fileobjs(),
                                                   new_sig_outfp)
-        bytes_written = write_multivol(u"inc", tarblock_iter,
+        bytes_written = write_multivol("inc", tarblock_iter,
                                        new_man_outfp, new_sig_outfp,
                                        config.backend)
 
         # close sig file and rename to final
         new_sig_outfp.close()
         new_sig_outfp.to_remote()
         new_sig_outfp.to_final()
@@ -704,204 +685,201 @@
                                  progress.tracker.total_elapsed_seconds(),
                                  progress.tracker.speed, False)
 
     print_statistics(diffdir.stats, bytes_written)
 
 
 def list_current(col_stats):
-    u"""
+    """
     List the files current in the archive (examining signature only)
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
     """
     time = config.restore_time or dup_time.curtime
     sig_chain = col_stats.get_signature_chain_at_time(time)
     path_iter = diffdir.get_combined_path_iter(sig_chain.get_fileobjs(time))
     for path in path_iter:
-        if path.difftype != u"deleted":
-            user_info = u"%s %s" % (dup_time.timetopretty(path.getmtime()),
-                                    util.fsdecode(path.get_relative_path()))
-            log_info = u"%s %s %s" % (dup_time.timetostring(path.getmtime()),
-                                      util.escape(path.get_relative_path()),
-                                      path.type)
+        if path.difftype != "deleted":
+            user_info = f"{dup_time.timetopretty(path.getmtime())} {os.fsdecode(path.get_relative_path())}"
+            log_info = f"{dup_time.timetostring(path.getmtime())} {util.escape(path.get_relative_path())} {path.type}"
             log.Log(user_info, log.INFO, log.InfoCode.file_list,
                     log_info, True)
 
 
 def restore(col_stats):
-    u"""
+    """
     Restore archive in config.backend to config.local_path
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
     """
     if config.dry_run:
         # Only prints list of required volumes when running dry
         restore_get_patched_rop_iter(col_stats)
         return
     if not patchdir.Write_ROPaths(config.local_path,
                                   restore_get_patched_rop_iter(col_stats)):
-        if config.restore_dir:
-            log.FatalError(_(u"%s not found in archive - no files restored.")
-                           % (util.fsdecode(config.restore_dir)),
-                           log.ErrorCode.restore_dir_not_found)
+        if config.restore_path:
+            log.FatalError(_("%s not found in archive - no files restored.")
+                           % (os.fsdecode(config.restore_path)),
+                           log.ErrorCode.restore_path_not_found)
         else:
-            log.FatalError(_(u"No files found in archive - nothing restored."),
+            log.FatalError(_("No files found in archive - nothing restored."),
                            log.ErrorCode.no_restore_files)
 
 
 def restore_get_patched_rop_iter(col_stats):
-    u"""
+    """
     Return iterator of patched ROPaths of desired restore data
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
     """
-    if config.restore_dir:
-        index = tuple(config.restore_dir.split(b"/"))
+    if config.restore_path:
+        index = tuple(config.restore_path.split(b"/"))
     else:
         index = ()
     time = config.restore_time or dup_time.curtime
     backup_chain = col_stats.get_backup_chain_at_time(time)
     assert backup_chain, col_stats.all_backup_chains
     backup_setlist = backup_chain.get_sets_at_time(time)
     num_vols = 0
     for s in backup_setlist:
         num_vols += len(s)
     cur_vol = [0]
 
     def get_fileobj_iter(backup_set):
-        u"""Get file object iterator from backup_set contain given index"""
+        """Get file object iterator from backup_set contain given index"""
         manifest = backup_set.get_manifest()
         volumes = manifest.get_containing_volumes(index)
         for vol_num in volumes:
             try:
                 yield restore_get_enc_fileobj(backup_set.backend,
                                               backup_set.volume_name_dict[vol_num],
                                               manifest.volume_info_dict[vol_num])
             except BadVolumeException as e:
                 yield e
 
             cur_vol[0] += 1
-            log.Progress(_(u'Processed volume %d of %d') % (cur_vol[0], num_vols),
+            log.Progress(_('Processed volume %d of %d') % (cur_vol[0], num_vols),
                          cur_vol[0], num_vols)
 
-    if hasattr(config.backend, u'pre_process_download_batch') or config.dry_run:
+    if hasattr(config.backend, 'pre_process_download_batch') or config.dry_run:
         file_names = []
         for backup_set in backup_setlist:
             manifest = backup_set.get_manifest()
             volumes = manifest.get_containing_volumes(index)
             for vol_num in volumes:
                 file_names.append(backup_set.volume_name_dict[vol_num])
         if config.dry_run:
-            log.Notice(u"Required volumes to restore:\n\t" +
-                       u'\n\t'.join(file_name.decode() for file_name in file_names))
+            log.Notice("Required volumes to restore:\n\t" +
+                       '\n\t'.join(file_name.decode() for file_name in file_names))
             return None
         else:
             config.backend.pre_process_download_batch(file_names)
 
     fileobj_iters = list(map(get_fileobj_iter, backup_setlist))
     tarfiles = list(map(patchdir.TarFile_FromFileobjs, fileobj_iters))
     return patchdir.tarfiles2rop_iter(tarfiles, index)
 
 
 def restore_get_enc_fileobj(backend, filename, volume_info):
-    u"""
+    """
     Return plaintext fileobj from encrypted filename on backend
 
     If volume_info is set, the hash of the file will be checked,
     assuming some hash is available.  Also, if config.sign_key is
     set, a fatal error will be raised if file not signed by sign_key.
 
     with --ignore-errors set continue on hash mismatch
 
     """
     for n in range(1, config.num_retries + 1):
-        u""" get the remote file """
+        """ get the remote file """
         parseresults = file_naming.parse(filename)
         tdp = dup_temp.new_tempduppath(parseresults)
         backend.get(filename, tdp)
 
-        u""" verify hash of the remote file """
+        """ verify hash of the remote file """
         verified, hash_pair, calculated_hash = restore_check_hash(volume_info, tdp)
         if verified:
             break
         else:
-            error_msg = u"%s\n %s\n %s\n %s\n" % (
-                _(u"Invalid data - %s hash mismatch for file:") %
+            error_msg = "%s\n %s\n %s\n %s\n" % (
+                _("Invalid data - %s hash mismatch for file:") %
                 hash_pair[0],
-                util.fsdecode(filename),
-                _(u"Calculated hash: %s") % calculated_hash,
-                _(u"Manifest hash: %s") % hash_pair[1]
+                os.fsdecode(filename),
+                _("Calculated hash: %s") % calculated_hash,
+                _("Manifest hash: %s") % hash_pair[1]
             )
             log.Error(error_msg, code=log.ErrorCode.mismatched_hash)
     else:
         if config.ignore_errors:
-            exc = duplicity.errors.BadVolumeException(u"Hash mismatch for: %s" % util.fsdecode(filename))
-            log.Warn(_(u"IGNORED_ERROR: Warning: ignoring error as requested: %s: %s")
+            exc = duplicity.errors.BadVolumeException(f"Hash mismatch for: {os.fsdecode(filename)}")
+            log.Warn(_("IGNORED_ERROR: Warning: ignoring error as requested: %s: %s")
                      % (exc.__class__.__name__, util.uexc(exc)))
         else:
             log.FatalError(error_msg, code=log.ErrorCode.mismatched_hash)
 
-    fileobj = tdp.filtered_open_with_delete(u"rb")
+    fileobj = tdp.filtered_open_with_delete("rb")
     if parseresults.encrypted and config.gpg_profile.sign_key:
         restore_add_sig_check(fileobj)
     return fileobj
 
 
 def restore_check_hash(volume_info, vol_path):
-    u"""
+    """
     Check the hash of vol_path path against data in volume_info
 
     @rtype: boolean
     @return: true (verified) / false (failed)
     """
     hash_pair = volume_info.get_best_hash()
     if hash_pair:
         calculated_hash = gpg.get_hash(hash_pair[0], vol_path)
         if calculated_hash != hash_pair[1]:
             return False, hash_pair, calculated_hash
-    u""" reached here, verification passed """
+    """ reached here, verification passed """
     return True, hash_pair, calculated_hash
 
 
 def restore_add_sig_check(fileobj):
-    u"""
+    """
     Require signature when closing fileobj matches sig in gpg_profile
 
     @rtype: void
     @return: void
     """
     assert (isinstance(fileobj, dup_temp.FileobjHooked) and
             isinstance(fileobj.fileobj, gpg.GPGFile)), fileobj
 
     def check_signature():
-        u"""Thunk run when closing volume file"""
+        """Thunk run when closing volume file"""
         actual_sig = fileobj.fileobj.get_signature()
-        actual_sig = u"None" if actual_sig is None else actual_sig
+        actual_sig = "None" if actual_sig is None else actual_sig
         sign_key = config.gpg_profile.sign_key
-        sign_key = u"None" if sign_key is None else sign_key
+        sign_key = "None" if sign_key is None else sign_key
         ofs = -min(len(actual_sig), len(sign_key))
         if actual_sig[ofs:] != sign_key[ofs:]:
-            log.FatalError(_(u"Volume was signed by key %s, not %s") %
+            log.FatalError(_("Volume was signed by key %s, not %s") %
                            (actual_sig[ofs:], sign_key[ofs:]),
                            log.ErrorCode.unsigned_volume)
 
     fileobj.addhook(check_signature)
 
 
 def verify(col_stats):
-    u"""
+    """
     Verify files, logging differences
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
@@ -917,54 +895,54 @@
         if not current_path:
             current_path = path.ROPath(backup_ropath.index)
         if not backup_ropath.compare_verbose(current_path, config.compare_data):
             diff_count += 1
         total_count += 1
     # Unfortunately, ngettext doesn't handle multiple number variables, so we
     # split up the string.
-    log.Notice(_(u"Verify complete: %s, %s.") %
-               (_(u"%d file(s) compared") % total_count,
-                _(u"%d difference(s) found") % diff_count))
+    log.Notice(_("Verify complete: %s, %s.") %
+               (_("%d file(s) compared") % total_count,
+                _("%d difference(s) found") % diff_count))
     if diff_count >= 1:
         exit_val = 1
 
 
 def cleanup(col_stats):
-    u"""
+    """
     Delete the extraneous files in the current backend
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
     """
     ext_local, ext_remote = col_stats.get_extraneous()
     extraneous = ext_local + ext_remote
     if not extraneous:
-        log.Warn(_(u"No extraneous files found, nothing deleted in cleanup."))
+        log.Warn(_("No extraneous files found, nothing deleted in cleanup."))
         return
 
-    filestr = u"\n".join(map(util.fsdecode, extraneous))
+    filestr = "\n".join(map(os.fsdecode, extraneous))
     if config.force:
-        log.Notice(_(u"Deleting these file(s) from backend:") + u"\n" + filestr)
+        log.Notice(f"{_('Deleting these file(s) from backend:')}\n{filestr}")
         if not config.dry_run:
             col_stats.backend.delete(ext_remote)
             for fn in ext_local:
                 try:
                     config.archive_dir_path.append(fn).delete()
                 except Exception:
                     pass
     else:
-        log.Notice(_(u"Found the following file(s) to delete:") + u"\n" + filestr + u"\n" +
-                   _(u"Run duplicity again with the --force option to actually delete."))
+        log.Notice(_("Found the following file(s) to delete:") + "\n" + filestr + "\n" +
+                   _("Run duplicity again with the --force option to actually delete."))
 
 
 def remove_all_but_n_full(col_stats):
-    u"""
+    """
     Remove backup files older than the last n full backups.
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
@@ -973,224 +951,108 @@
 
     config.remove_time = col_stats.get_nth_last_full_backup_time(config.keep_chains)
 
     remove_old(col_stats)
 
 
 def remove_old(col_stats):
-    u"""
+    """
     Remove backup files older than config.remove_time from backend
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
     """
     assert config.remove_time is not None
 
     def set_times_str(setlist):
-        u"""Return string listing times of sets in setlist"""
-        return u"\n".join([dup_time.timetopretty(s.get_time()) for s in setlist])
+        """Return string listing times of sets in setlist"""
+        return "\n".join([dup_time.timetopretty(s.get_time()) for s in setlist])
 
     def chain_times_str(chainlist):
-        u"""Return string listing times of chains in chainlist"""
-        return u"\n".join([dup_time.timetopretty(s.end_time) for s in chainlist])
+        """Return string listing times of chains in chainlist"""
+        return "\n".join([dup_time.timetopretty(s.end_time) for s in chainlist])
 
     req_list = col_stats.get_older_than_required(config.remove_time)
     if req_list:
-        log.Warn(u"%s\n%s\n%s" %
-                 (_(u"There are backup set(s) at time(s):"),
+        log.Warn("%s\n%s\n%s" %
+                 (_("There are backup set(s) at time(s):"),
                   set_times_str(req_list),
-                  _(u"Which can't be deleted because newer sets depend on them.")))
+                  _("Which can't be deleted because newer sets depend on them.")))
 
     if (col_stats.matched_chain_pair and
             col_stats.matched_chain_pair[1].end_time < config.remove_time):
-        log.Warn(_(u"Current active backup chain is older than specified time.  "
-                   u"However, it will not be deleted.  To remove all your backups, "
-                   u"manually purge the repository."))
+        log.Warn(_("Current active backup chain is older than specified time.  "
+                   "However, it will not be deleted.  To remove all your backups, "
+                   "manually purge the repository."))
 
     chainlist = col_stats.get_chains_older_than(config.remove_time)
 
-    if config.remove_all_inc_of_but_n_full_mode:
+    if config.action == "remove-all-inc-of-but-n-full":
         # ignore chains without incremental backups:
         chainlist = list(x for x in chainlist if
                          (isinstance(x, dup_collections.SignatureChain) and x.inclist) or
                          (isinstance(x, dup_collections.BackupChain) and x.incset_list))
 
     if not chainlist:
-        log.Notice(_(u"No old backup sets found, nothing deleted."))
+        log.Notice(_("No old backup sets found, nothing deleted."))
         return
     if config.force:
-        log.Notice(_(u"Deleting backup chain(s) at time:") +
-                   u"\n" + chain_times_str(chainlist))
+        log.Notice(_("Deleting backup chain(s) at time:") +
+                   "\n" + chain_times_str(chainlist))
         # Add signature files too, since they won't be needed anymore
         chainlist += col_stats.get_signature_chains_older_than(config.remove_time)
         chainlist.reverse()  # save oldest for last
         for chain in chainlist:
-            # if remove_all_inc_of_but_n_full_mode mode, remove only
+            # if action is remove_all_inc_of_but_n_full, remove only
             # incrementals one and not full
-            if config.remove_all_inc_of_but_n_full_mode:
+            if config.action == "remove-all-inc-of-but-n-full":
                 if isinstance(chain, dup_collections.SignatureChain):
-                    chain_desc = _(u"Deleting any incremental signature chain rooted at %s")
+                    chain_desc = _("Deleting any incremental signature chain rooted at %s")
                 else:
-                    chain_desc = _(u"Deleting any incremental backup chain rooted at %s")
+                    chain_desc = _("Deleting any incremental backup chain rooted at %s")
             else:
                 if isinstance(chain, dup_collections.SignatureChain):
-                    chain_desc = _(u"Deleting complete signature chain %s")
+                    chain_desc = _("Deleting complete signature chain %s")
                 else:
-                    chain_desc = _(u"Deleting complete backup chain %s")
+                    chain_desc = _("Deleting complete backup chain %s")
             log.Notice(chain_desc % dup_time.timetopretty(chain.end_time))
             if not config.dry_run:
-                chain.delete(keep_full=config.remove_all_inc_of_but_n_full_mode)
+                chain.delete(keep_full=(config.action == "remove-all-inc-of-but-n-full"))
         col_stats.set_values(sig_chain_warning=None)
     else:
-        log.Notice(_(u"Found old backup chain(s) at the following time:") +
-                   u"\n" + chain_times_str(chainlist) + u"\n" +
-                   _(u"Rerun command with --force option to actually delete."))
-
-
-def replicate():
-    u"""
-    Replicate backup files from one remote to another, possibly encrypting or adding parity.
-
-    @rtype: void
-    @return: void
-    """
-    action = u"replicate"
-    time = config.restore_time or dup_time.curtime
-    src_stats = dup_collections.CollectionsStatus(config.src_backend, None, action).set_values(sig_chain_warning=None)
-    tgt_stats = dup_collections.CollectionsStatus(config.backend, None, action).set_values(sig_chain_warning=None)
-
-    src_list = config.src_backend.list()
-    tgt_list = config.backend.list()
-
-    src_chainlist = src_stats.get_signature_chains(local=False, filelist=src_list)[0]
-    tgt_chainlist = tgt_stats.get_signature_chains(local=False, filelist=tgt_list)[0]
-    src_chainlist = sorted(src_chainlist, key=lambda chain: chain.start_time)
-    tgt_chainlist = sorted(tgt_chainlist, key=lambda chain: chain.start_time)
-    if not src_chainlist:
-        log.Notice(_(u"No old backup sets found."))
-        return
-    for src_chain in src_chainlist:
-        try:
-            tgt_chain = list([chain for chain in tgt_chainlist if chain.start_time == src_chain.start_time])[0]
-        except IndexError:
-            tgt_chain = None
-
-        tgt_sigs = list(map(file_naming.parse, tgt_chain.get_filenames())) if tgt_chain else []
-        for src_sig_filename in src_chain.get_filenames():
-            src_sig = file_naming.parse(src_sig_filename)
-            if not (src_sig.time or src_sig.end_time) < time:
-                continue
-            try:
-                tgt_sigs.remove(src_sig)
-                log.Info(_(u"Signature %s already replicated") % (src_sig_filename,))
-                continue
-            except ValueError:
-                pass
-            if src_sig.type == u'new-sig':
-                dup_time.setprevtime(src_sig.start_time)
-            dup_time.setcurtime(src_sig.time or src_sig.end_time)
-            log.Notice(_(u"Replicating %s.") % (src_sig_filename,))
-            fileobj = config.src_backend.get_fileobj_read(src_sig_filename)
-            filename = file_naming.get(src_sig.type, encrypted=config.encryption, gzipped=config.compression)
-            tdp = dup_temp.new_tempduppath(file_naming.parse(filename))
-            tmpobj = tdp.filtered_open(mode=u'wb')
-            util.copyfileobj(fileobj, tmpobj)  # decrypt, compress, (re)-encrypt
-            fileobj.close()
-            tmpobj.close()
-            config.backend.put(tdp, filename)
-            tdp.delete()
-
-    src_chainlist = src_stats.get_backup_chains(filename_list=src_list)[0]
-    tgt_chainlist = tgt_stats.get_backup_chains(filename_list=tgt_list)[0]
-    src_chainlist = sorted(src_chainlist, key=lambda chain: chain.start_time)
-    tgt_chainlist = sorted(tgt_chainlist, key=lambda chain: chain.start_time)
-    for src_chain in src_chainlist:
-        try:
-            tgt_chain = list([chain for chain in tgt_chainlist if chain.start_time == src_chain.start_time])[0]
-        except IndexError:
-            tgt_chain = None
-
-        tgt_sets = tgt_chain.get_all_sets() if tgt_chain else []
-        for src_set in src_chain.get_all_sets():
-            if not src_set.get_time() < time:
-                continue
-            try:
-                tgt_sets.remove(src_set)
-                log.Info(_(u"Backupset %s already replicated") % (src_set.remote_manifest_name,))
-                continue
-            except ValueError:
-                pass
-            if src_set.type == u'inc':
-                dup_time.setprevtime(src_set.start_time)
-            dup_time.setcurtime(src_set.get_time())
-            rmf = src_set.get_remote_manifest()
-            mf_filename = file_naming.get(src_set.type, manifest=True)
-            mf_tdp = dup_temp.new_tempduppath(file_naming.parse(mf_filename))
-            mf = manifest.Manifest(fh=mf_tdp.filtered_open(mode=u'wb'))
-            for i, filename in list(src_set.volume_name_dict.items()):
-                log.Notice(_(u"Replicating %s.") % (filename,))
-                fileobj = restore_get_enc_fileobj(config.src_backend, filename, rmf.volume_info_dict[i])
-                filename = file_naming.get(src_set.type, i, encrypted=config.encryption, gzipped=config.compression)
-                tdp = dup_temp.new_tempduppath(file_naming.parse(filename))
-                tmpobj = tdp.filtered_open(mode=u'wb')
-                util.copyfileobj(fileobj, tmpobj)  # decrypt, compress, (re)-encrypt
-                fileobj.close()
-                tmpobj.close()
-                config.backend.put(tdp, filename)
-
-                vi = copy.copy(rmf.volume_info_dict[i])
-                vi.set_hash(u"SHA1", gpg.get_hash(u"SHA1", tdp))
-                mf.add_volume_info(vi)
-
-                tdp.delete()
-
-            mf.fh.close()
-            # incremental GPG writes hang on close, so do any encryption here at once
-            mf_fileobj = mf_tdp.filtered_open_with_delete(mode=u'rb')
-            mf_final_filename = file_naming.get(src_set.type,
-                                                manifest=True,
-                                                encrypted=config.encryption,
-                                                gzipped=config.compression)
-            mf_final_tdp = dup_temp.new_tempduppath(file_naming.parse(mf_final_filename))
-            mf_final_fileobj = mf_final_tdp.filtered_open(mode=u'wb')
-            util.copyfileobj(mf_fileobj, mf_final_fileobj)  # compress, encrypt
-            mf_fileobj.close()
-            mf_final_fileobj.close()
-            config.backend.put(mf_final_tdp, mf_final_filename)
-            mf_final_tdp.delete()
-
-    config.src_backend.close()
-    config.backend.close()
+        log.Notice(_("Found old backup chain(s) at the following time:") +
+                   "\n" + chain_times_str(chainlist) + "\n" +
+                   _("Rerun command with --force option to actually delete."))
 
 
 def sync_archive(col_stats):
-    u"""
+    """
     Synchronize local archive manifest file and sig chains to remote archives.
     Copy missing files from remote to local as needed to make sure the local
     archive is synchronized to remote storage.
 
     @rtype: void
     @return: void
     """
     suffixes = [b".g", b".gpg", b".z", b".gz", b".part"]
 
     def is_needed(filename):
-        u"""Indicates if the metadata file should be synced.
+        """Indicates if the metadata file should be synced.
 
         In full sync mode, or if there's a collection misbehavior, all files
         are needed.
 
         Otherwise, only the metadata for the target chain needs sync.
         """
-        if config.metadata_sync_mode == u"full":
+        if config.metadata_sync_mode == "full":
             return True
-        assert config.metadata_sync_mode == u"partial"
+        assert config.metadata_sync_mode == "partial"
         parsed = file_naming.parse(filename)
         try:
             target_chain = col_stats.get_backup_chain_at_time(
                 config.restore_time or dup_time.curtime)
         except dup_collections.CollectionsError:
             # With zero or multiple chains at this time, do a full sync
             return True
@@ -1200,15 +1062,15 @@
             start_time = parsed.start_time
             end_time = parsed.end_time
 
         return end_time >= target_chain.start_time and \
             start_time <= target_chain.end_time
 
     def get_metafiles(filelist):
-        u"""
+        """
         Return metafiles of interest from the file list.
         Files of interest are:
           sigtar - signature files
           manifest - signature files
           duplicity partial versions of the above
         Files excluded are:
           non-duplicity files
@@ -1221,108 +1083,109 @@
         need_passphrase = False
         for fn in filelist:
             pr = file_naming.parse(fn)
             if not pr:
                 continue
             if pr.encrypted:
                 need_passphrase = True
-            if pr.type in [u"full-sig", u"new-sig"] or pr.manifest:
+            if pr.type in ["full-sig", "new-sig"] or pr.manifest:
                 base, ext = os.path.splitext(fn)
                 if ext not in suffixes:
                     base = fn
                 if pr.partial:
                     partials[base] = fn
                 else:
                     metafiles[base] = fn
         return metafiles, partials, need_passphrase
 
     def copy_raw(src_iter, filename):
-        u"""
+        """
         Copy data from src_iter to file at fn
         """
-        file = open(filename, u"wb")
+        file = open(filename, "wb")
         while True:
             try:
                 data = src_iter.__next__().data
             except StopIteration:
                 break
             file.write(data)
         file.close()
 
     def resolve_basename(fn):
-        u"""
+        """
         @return: (parsedresult, local_name, remote_name)
         """
         pr = file_naming.parse(fn)
 
         base, ext = os.path.splitext(fn)
         if ext not in suffixes:
             base = fn
 
         suffix = file_naming.get_suffix(False, not pr.manifest)
         loc_name = base + suffix
 
-        return (pr, loc_name, fn)
+        return pr, loc_name, fn
 
     def remove_local(fn):
         del_name = config.archive_dir_path.append(fn).name
 
-        log.Notice(_(u"Deleting local %s (not authoritative at backend).") %
-                   util.fsdecode(del_name))
+        log.Notice(_("Deleting local %s (not authoritative at backend).") %
+                   os.fsdecode(del_name))
         try:
             util.ignore_missing(os.unlink, del_name)
         except Exception as e:
-            log.Warn(_(u"Unable to delete %s: %s") % (util.fsdecode(del_name),
-                                                      util.uexc(e)))
+            log.Warn(_("Unable to delete %s: %s") % (os.fsdecode(del_name),
+                                                     util.uexc(e)))
 
     def copy_to_local(fn):
-        u"""
+        """
         Copy remote file fn to local cache.
         """
+
         class Block(object):
-            u"""
+            """
             Data block to return from SrcIter
             """
 
             def __init__(self, data):
                 self.data = data
 
         class SrcIter(object):
-            u"""
+            """
             Iterate over source and return Block of data.
             """
 
             def __init__(self, fileobj):
                 self.fileobj = fileobj
 
             def __next__(self):
                 try:
                     res = Block(self.fileobj.read(self.get_read_size()))
                 except Exception as e:
-                    if hasattr(self.fileobj, u'name'):
+                    if hasattr(self.fileobj, 'name'):
                         name = self.fileobj.name
                         # name may be a path
-                        if hasattr(name, u'name'):
+                        if hasattr(name, 'name'):
                             name = name.name
                     else:
                         name = None
-                    log.FatalError(_(u"Failed to read %s: %s") % (util.fsdecode(fn), util.uexc(e)),
+                    log.FatalError(_("Failed to read %s: %s") % (os.fsdecode(fn), util.uexc(e)),
                                    log.ErrorCode.generic)
                 if not res.data:
                     self.fileobj.close()
                     raise StopIteration
                 return res
 
             def get_read_size(self):
                 return 128 * 1024
 
             def get_footer(self):
                 return b""
 
-        log.Notice(_(u"Copying %s to local cache.") % util.fsdecode(fn))
+        log.Notice(_("Copying %s to local cache.") % os.fsdecode(fn))
 
         pr, loc_name, rem_name = resolve_basename(fn)
 
         fileobj = config.backend.get_fileobj_read(fn)
         src_iter = SrcIter(fileobj)
         tdp = dup_temp.new_tempduppath(file_naming.parse(loc_name))
         if pr.manifest:
@@ -1362,41 +1225,41 @@
         # delete final versions of partial files because if we have both, it
         # means the write of the final version got interrupted.
         if key not in remote_keys or key in local_partials:
             local_spurious.append(local_metafiles[key])
 
     # finally finish the process
     if not local_missing and not local_spurious:
-        log.Notice(_(u"Local and Remote metadata are synchronized, no sync needed."))
+        log.Notice(_("Local and Remote metadata are synchronized, no sync needed."))
     else:
         local_missing.sort()
         local_spurious.sort()
         if not config.dry_run:
-            log.Notice(_(u"Synchronizing remote metadata to local cache..."))
+            log.Notice(_("Synchronizing remote metadata to local cache..."))
             if local_missing and (rem_needpass or loc_needpass):
                 # password for the --encrypt-key
-                config.gpg_profile.passphrase = get_passphrase(1, u"sync")
+                config.gpg_profile.passphrase = get_passphrase(1, "sync")
             for fn in local_spurious:
                 remove_local(fn)
-            if hasattr(config.backend, u'pre_process_download_batch'):
+            if hasattr(config.backend, 'pre_process_download_batch'):
                 config.backend.pre_process_download_batch(local_missing)
             for fn in local_missing:
                 copy_to_local(fn)
             col_stats.set_values()
         else:
             if local_missing:
-                log.Notice(_(u"Sync would copy the following from remote to local:") +
-                           u"\n" + u"\n".join(map(util.fsdecode, local_missing)))
+                log.Notice(_("Sync would copy the following from remote to local:") +
+                           "\n" + "\n".join(map(os.fsdecode, local_missing)))
             if local_spurious:
-                log.Notice(_(u"Sync would remove the following spurious local files:") +
-                           u"\n" + u"\n".join(map(util.fsdecode, local_spurious)))
+                log.Notice(_("Sync would remove the following spurious local files:") +
+                           "\n" + "\n".join(map(os.fsdecode, local_spurious)))
 
 
 def check_last_manifest(col_stats):
-    u"""
+    """
     Check consistency and hostname/directory of last manifest
 
     @type col_stats: CollectionStatus object
     @param col_stats: collection status
 
     @rtype: void
     @return: void
@@ -1405,79 +1268,78 @@
     last_backup_set = col_stats.all_backup_chains[-1].get_last()
     # check remote manifest only if we can decrypt it (see #1729796)
     check_remote = not config.encryption or config.gpg_profile.passphrase
     last_backup_set.check_manifests(check_remote=check_remote)
 
 
 def check_resources(action):
-    u"""
+    """
     Check for sufficient resources:
     - temp space for volume build
     - enough max open files
     Put out fatal error if not sufficient to run
 
     @type action: string
     @param action: action in progress
 
     @rtype: void
     @return: void
     """
-    if action in [u"full", u"inc", u"restore"]:
+    if action in ["full", "inc", "restore"]:
         # Make sure we have enough resouces to run
         # First check disk space in temp area.
         tempfile, tempname = tempdir.default().mkstemp()
         os.close(tempfile)
         # strip off the temp dir and file
         tempfs = os.path.sep.join(tempname.split(os.path.sep)[:-2])
         try:
             stats = os.statvfs(tempfs)
         except Exception:
-            log.FatalError(_(u"Unable to get free space on temp."),
+            log.FatalError(_("Unable to get free space on temp."),
                            log.ErrorCode.get_freespace_failed)
         # Calculate space we need for at least 2 volumes of full or inc
         # plus about 30% of one volume for the signature files.
         freespace = stats.f_frsize * stats.f_bavail
         needspace = (((config.async_concurrency + 1) * config.volsize) +
                      int(0.30 * config.volsize))
         if freespace < needspace:
-            log.FatalError(_(u"Temp space has %d available, backup needs approx %d.") %
+            log.FatalError(_("Temp space has %d available, backup needs approx %d.") %
                            (freespace, needspace), log.ErrorCode.not_enough_freespace)
         else:
-            log.Info(_(u"Temp has %d available, backup will use approx %d.") %
+            log.Info(_("Temp has %d available, backup will use approx %d.") %
                      (freespace, needspace))
 
         # Some environments like Cygwin run with an artificially
         # low value for max open files.  Check for safe number.
         try:
             soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)
         except resource.error:
-            log.FatalError(_(u"Unable to get max open files."),
+            log.FatalError(_("Unable to get max open files."),
                            log.ErrorCode.get_ulimit_failed)
         maxopen = min([l for l in (soft, hard) if l > -1])
         if maxopen < 1024:
-            log.FatalError(_(u"Max open files of %s is too low, should be >= 1024.\n"
-                             u"Use 'ulimit -n 1024' or higher to correct.\n") % (maxopen,),
+            log.FatalError(_("Max open files of %s is too low, should be >= 1024.\n"
+                             "Use 'ulimit -n 1024' or higher to correct.\n") % (maxopen,),
                            log.ErrorCode.maxopen_too_low)
 
 
 def log_startup_parms(verbosity=log.INFO):
-    u"""
+    """
     log Python, duplicity, and system versions
     """
-    log.Log(u'=' * 80, verbosity)
-    log.Log(u"duplicity %s" % __version__, verbosity)
-    u_args = (util.fsdecode(arg) for arg in sys.argv)
-    log.Log(u"Args: %s" % u' '.join(u_args), verbosity)
-    log.Log(u' '.join(platform.uname()), verbosity)
-    log.Log(u"%s %s" % (sys.executable or sys.platform, sys.version), verbosity)
-    log.Log(u'=' * 80, verbosity)
+    log.Log('=' * 80, verbosity)
+    log.Log(f"duplicity {__version__}", verbosity)
+    log.Log(f"Args: {' '.join([os.fsdecode(arg) for arg in sys.argv])}", verbosity)
+    log.Log(' '.join(platform.uname()), verbosity)
+    log.Log(f"{sys.executable or sys.platform} {sys.version}", verbosity)
+    log.Log('=' * 80, verbosity)
 
 
 class Restart(object):
-    u"""
+    """
     Class to aid in restart of inc or full backup.
     Instance in config.restart if restart in progress.
     """
 
     def __init__(self, last_backup):
         self.type = None
         self.start_time = None
@@ -1486,65 +1348,65 @@
         self.last_index = None
         self.last_block = None
         self.last_backup = last_backup
         self.setParms(last_backup)
 
     def setParms(self, last_backup):
         if last_backup.time:
-            self.type = u"full"
+            self.type = "full"
             self.time = last_backup.time
         else:
-            self.type = u"inc"
+            self.type = "inc"
             self.end_time = last_backup.end_time
             self.start_time = last_backup.start_time
         # We start one volume back in case we weren't able to finish writing
         # the most recent block.  Actually checking if we did (via hash) would
         # involve downloading the block.  Easier to just redo one block.
         self.start_vol = max(len(last_backup) - 1, 0)
 
     def checkManifest(self, mf):
         mf_len = len(mf.volume_info_dict)
         if (mf_len != self.start_vol) or not (mf_len and self.start_vol):
             if self.start_vol == 0:
                 # upload of 1st vol failed, clean and restart
-                log.Notice(_(u"RESTART: The first volume failed to upload before termination.\n"
-                             u"         Restart is impossible...starting backup from beginning."))
+                log.Notice(_("RESTART: The first volume failed to upload before termination.\n"
+                             "         Restart is impossible...starting backup from beginning."))
                 self.last_backup.delete()
                 os.execve(sys.argv[0], sys.argv, os.environ)
             elif mf_len - self.start_vol > 0:
                 # upload of N vols failed, fix manifest and restart
-                log.Notice(_(u"RESTART: Volumes %d to %d failed to upload before termination.\n"
-                             u"         Restarting backup at volume %d.") %
+                log.Notice(_("RESTART: Volumes %d to %d failed to upload before termination.\n"
+                             "         Restarting backup at volume %d.") %
                            (self.start_vol + 1, mf_len, self.start_vol + 1))
                 for vol in range(self.start_vol + 1, mf_len + 1):
                     mf.del_volume_info(vol)
             else:
                 # this is an 'impossible' state, remove last partial and restart
-                log.Notice(_(u"RESTART: Impossible backup state: manifest has %d vols, remote has %d vols.\n"
-                             u"         Restart is impossible ... duplicity will clean off the last partial\n"
-                             u"         backup then restart the backup from the beginning.") %
+                log.Notice(_("RESTART: Impossible backup state: manifest has %d vols, remote has %d vols.\n"
+                             "         Restart is impossible ... duplicity will clean off the last partial\n"
+                             "         backup then restart the backup from the beginning.") %
                            (mf_len, self.start_vol))
                 self.last_backup.delete()
                 os.execve(sys.argv[0], sys.argv, os.environ)
 
     def setLastSaved(self, mf):
         vi = mf.volume_info_dict[self.start_vol]
         self.last_index = vi.end_index
         self.last_block = vi.end_block or 0
 
 
 def main():
-    u"""
+    """
     Start/end here
     """
     # per bug https://bugs.launchpad.net/duplicity/+bug/931175
     # duplicity crashes when PYTHONOPTIMIZE is set, so check
     # and refuse to run if it is set.
-    if u'PYTHONOPTIMIZE' in os.environ:
-        log.FatalError(_(u"""
+    if 'PYTHONOPTIMIZE' in os.environ:
+        log.FatalError(_("""\
 PYTHONOPTIMIZE in the environment causes duplicity to fail to
 recognize its own backups.  Please remove PYTHONOPTIMIZE from
 the environment and rerun the backup.
 
 See https://bugs.launchpad.net/duplicity/+bug/931175
 """), log.ErrorCode.pythonoptimize_set)
 
@@ -1555,134 +1417,130 @@
         os.setuid(os.geteuid())
         os.setgid(os.getegid())
 
     # set the current time strings (make it available for command line processing)
     dup_time.setcurtime()
 
     # determine what action we're performing and process command line
-    action = commandline.ProcessCommandLine(sys.argv[1:])
+    action = cli_main.process_command_line(sys.argv[1:])
 
     config.lockpath = os.path.join(config.archive_dir_path.name, b"lockfile")
     config.lockfile = fasteners.process_lock.InterProcessLock(config.lockpath)
-    log.Debug(_(u"Acquiring lockfile %s") % config.lockpath)
+    log.Debug(_("Acquiring lockfile %s") % os.fsdecode(config.lockpath))
     if not config.lockfile.acquire(blocking=False):
         log.FatalError(
-            u"Another duplicity instance is already running with this archive directory\n",
+            "Another duplicity instance is already running with this archive directory\n",
             log.ErrorCode.user_error)
         log.shutdown()
         sys.exit(2)
 
+    # log some status info
+    log_startup_parms(log.INFO)
+
     try:
         do_backup(action)
-
     finally:
         util.release_lockfile()
 
 
 def do_backup(action):
     # set the current time strings again now that we have time separator
     if config.current_time:
         dup_time.setcurtime(config.current_time)
     else:
         dup_time.setcurtime()
 
-    # log some debugging status info
-    log_startup_parms(log.INFO)
-
     # check for disk space and available file handles
     check_resources(action)
 
     # get current collection status
     col_stats = dup_collections.CollectionsStatus(config.backend,
                                                   config.archive_dir_path,
                                                   action).set_values()
 
     # check archive synch with remote, fix if needed
-    if action not in [u"collection-status",
-                      u"remove-all-but-n-full",
-                      u"remove-all-inc-of-but-n-full",
-                      u"remove-old",
-                      u"replicate",
+    if action not in ["collection-status",
+                      "remove-all-but-n-full",
+                      "remove-all-inc-of-but-n-full",
+                      "remove-old",
                       ]:
         sync_archive(col_stats)
 
     while True:
         # if we have to clean up the last partial, then col_stats are invalidated
         # and we have to start the process all over again until clean.
-        if action in [u"full", u"inc", u"cleanup"]:
+        if action in ["full", "inc", "cleanup"]:
             last_full_chain = col_stats.get_last_backup_chain()
             if not last_full_chain:
                 break
             last_backup = last_full_chain.get_last()
             if last_backup.partial:
-                if action in [u"full", u"inc"]:
+                if action in ["full", "inc"]:
                     # set restart parms from last_backup info
                     config.restart = Restart(last_backup)
                     # (possibly) reset action
                     action = config.restart.type
                     # reset the time strings
-                    if action == u"full":
+                    if action == "full":
                         dup_time.setcurtime(config.restart.time)
                     else:
                         dup_time.setcurtime(config.restart.end_time)
                         dup_time.setprevtime(config.restart.start_time)
                     # log it -- main restart heavy lifting is done in write_multivol
-                    log.Notice(_(u"Last %s backup left a partial set, restarting." % action))
+                    log.Notice(_(f"Last {action} backup left a partial set, restarting."))
                     break
                 else:
                     # remove last partial backup and get new collection status
-                    log.Notice(_(u"Cleaning up previous partial %s backup set, restarting." % action))
+                    log.Notice(_(f"Cleaning up previous partial {action} backup set, restarting."))
                     last_backup.delete()
                     col_stats = dup_collections.CollectionsStatus(config.backend,
                                                                   config.archive_dir_path,
                                                                   action).set_values()
                     continue
             break
         break
 
     # OK, now we have a stable collection
     last_full_time = col_stats.get_last_full_backup_time()
     if last_full_time > 0:
-        log.Notice(_(u"Last full backup date:") + u" " + dup_time.timetopretty(last_full_time))
+        log.Notice(f"{_('Last full backup date:')} {dup_time.timetopretty(last_full_time)}")
     else:
-        log.Notice(_(u"Last full backup date: none"))
-    if not config.restart and action == u"inc" and config.full_force_time is not None and \
-       last_full_time < config.full_force_time:
-        log.Notice(_(u"Last full backup is too old, forcing full backup"))
-        action = u"full"
+        log.Notice(_("Last full backup date: none"))
+    if not config.restart and action == "inc" and config.full_if_older_than is not None and \
+            last_full_time < config.full_if_older_than:
+        log.Notice(_("Last full backup is too old, forcing full backup"))
+        action = "full"
     log.PrintCollectionStatus(col_stats)
 
     # get the passphrase if we need to based on action/options
     config.gpg_profile.passphrase = get_passphrase(1, action)
 
-    if action == u"restore":
+    if action == "restore":
         restore(col_stats)
-    elif action == u"verify":
+    elif action == "verify":
         verify(col_stats)
-    elif action == u"list-current":
+    elif action == "list-current-files":
         list_current(col_stats)
-    elif action == u"collection-status":
+    elif action == "collection-status":
         if config.show_changes_in_set is not None:
             log.PrintCollectionChangesInSet(col_stats, config.show_changes_in_set, True)
         elif not config.file_changed:
             log.PrintCollectionStatus(col_stats, True)
         else:
             log.PrintCollectionFileChangedStatus(col_stats, config.file_changed, True)
-    elif action == u"cleanup":
+    elif action == "cleanup":
         cleanup(col_stats)
-    elif action == u"remove-old":
+    elif action == "remove-older-than":
         remove_old(col_stats)
-    elif action == u"remove-all-but-n-full" or action == u"remove-all-inc-of-but-n-full":
+    elif action == "remove-all-but-n-full" or action == "remove-all-inc-of-but-n-full":
         remove_all_but_n_full(col_stats)
-    elif action == u"sync":
+    elif action == "sync":
         sync_archive(col_stats)
-    elif action == u"replicate":
-        replicate()
     else:
-        assert action == u"inc" or action == u"full", action
+        assert action == "inc" or action == "full", action
         # the passphrase for full and inc is used by --sign-key
         # the sign key can have a different passphrase than the encrypt
         # key, therefore request a passphrase
         if config.gpg_profile.sign_key:
             config.gpg_profile.signing_passphrase = get_passphrase(1, action, True)
 
         # if there are no recipients (no --encrypt-key), it must be a
@@ -1692,29 +1550,30 @@
             # a limitation in the GPG implementation does not allow for
             # inputting different passphrases, this affects symmetric+sign.
             # Allow an empty passphrase for the key though to allow a non-empty
             # symmetric key
             if (config.gpg_profile.signing_passphrase and
                     config.gpg_profile.passphrase != config.gpg_profile.signing_passphrase):
                 log.FatalError(_(
-                    u"When using symmetric encryption, the signing passphrase "
-                    u"must equal the encryption passphrase."),
+                    "When using symmetric encryption, the signing passphrase "
+                    "must equal the encryption passphrase."),
                     log.ErrorCode.user_error)
 
-        if action == u"full":
+        if action == "full":
             full_backup(col_stats)
         else:  # attempt incremental
             sig_chain = check_sig_chain(col_stats)
             # action == "inc" was requested, but no full backup is available
             if not sig_chain:
                 full_backup(col_stats)
             else:
                 if not config.restart:
                     # only ask for a passphrase if there was a previous backup
                     if col_stats.all_backup_chains:
                         config.gpg_profile.passphrase = get_passphrase(1, action)
                         check_last_manifest(col_stats)  # not needed for full backups
                 incremental_backup(sig_chain)
+
     config.backend.close()
     log.shutdown()
     if exit_val is not None:
         sys.exit(exit_val)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/backend.py` & `duplicity-2.0.0rc0/duplicity/backend.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,53 +15,44 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Provides a common interface to all backends and certain sevices
 intended to be used by the backends themselves.
 """
 
-from future import standard_library
-standard_library.install_aliases()
-from builtins import str
-from builtins import range
-from builtins import object
-
 import errno
+import getpass
 import os
+import re
+import socket
 import sys
 import time
-import re
-import getpass
-import re
-import urllib.request  # pylint: disable=import-error
-import urllib.parse  # pylint: disable=import-error
-import urllib.error  # pylint: disable=import-error
+import urllib.error
+import urllib.parse
+import urllib.request
 
+import duplicity.backends
+from duplicity import config
 from duplicity import dup_temp
 from duplicity import file_naming
-from duplicity import config
 from duplicity import log
 from duplicity import path
 from duplicity import util
-
-from duplicity.util import exception_traceback
-
 from duplicity.errors import BackendException
-from duplicity.errors import FatalBackendException
-from duplicity.errors import TemporaryLoadException
 from duplicity.errors import ConflictingScheme
+from duplicity.errors import FatalBackendException
 from duplicity.errors import InvalidBackendURL
+from duplicity.errors import TemporaryLoadException
 from duplicity.errors import UnsupportedBackendScheme
-
-import duplicity.backends
+from duplicity.util import exception_traceback
 
 _backends = {}
 _backend_prefixes = {}
 _last_exception = None
 
 # These URL schemes have a backend with a notion of an RFC "network location".
 # The 'file' and 's3+http' schemes should not be in this list.
@@ -74,173 +65,167 @@
 # schemes anyway.  So we keep our own here for our own use.
 #
 # NOTE: this is filled by the respective backends during registering
 uses_netloc = []
 
 
 def import_backends():
-    u"""
+    """
     Import files in the duplicity/backends directory where
     the filename ends in 'backend.py' and ignore the rest.
 
     @rtype: void
     @return: void
     """
     path = duplicity.backends.__path__[0]
-    assert path.endswith(u"duplicity/backends"), duplicity.backends.__path__
+    assert path.endswith("duplicity/backends"), duplicity.backends.__path__
 
-    files = os.listdir(path)
-    files.sort()
+    files = sorted(os.listdir(path))
     for fn in files:
-        if fn.endswith(u"backend.py"):
+        if fn.endswith("backend.py"):
             fn = fn[:-3]
-            imp = u"duplicity.backends.%s" % (fn,)
+            imp = f"duplicity.backends.{fn}"
             try:
                 __import__(imp)
-                res = u"Succeeded"
+                res = "Succeeded"
             except Exception:
-                res = u"Failed: " + str(sys.exc_info()[1])
-            log.Log(_(u"Import of %s %s") % (imp, res), log.INFO)
+                res = f"Failed: {str(sys.exc_info()[1])}"
+            log.Log(_("Import of %s %s") % (imp, res), log.INFO)
         else:
             continue
 
 
 def register_backend(scheme, backend_factory):
-    u"""
+    """
     Register a given backend factory responsible for URL:s with the
     given scheme.
 
     The backend must be a callable which, when called with a URL as
     the single parameter, returns an object implementing the backend
     protocol (i.e., a subclass of Backend).
 
     Typically the callable will be the Backend subclass itself.
 
     This function is not thread-safe and is intended to be called
     during module importation or start-up.
     """
     global _backends
 
-    assert callable(backend_factory), u"backend factory must be callable"
+    assert callable(backend_factory), "backend factory must be callable"
 
     if scheme in _backends:
-        raise ConflictingScheme(u"the scheme %s already has a backend "
-                                u"associated with it"
-                                u"" % (scheme,))
+        raise ConflictingScheme(f"the scheme {scheme} already has a backend associated with it")
 
     _backends[scheme] = backend_factory
 
 
 def register_backend_prefix(scheme, backend_factory):
-    u"""
+    """
     Register a given backend factory responsible for URL:s with the
     given scheme prefix.
 
     The backend must be a callable which, when called with a URL as
     the single parameter, returns an object implementing the backend
     protocol (i.e., a subclass of Backend).
 
     Typically the callable will be the Backend subclass itself.
 
     This function is not thread-safe and is intended to be called
     during module importation or start-up.
     """
     global _backend_prefixes
 
-    assert callable(backend_factory), u"backend factory must be callable"
+    assert callable(backend_factory), "backend factory must be callable"
 
     if scheme in _backend_prefixes:
-        raise ConflictingScheme(u"the prefix %s already has a backend "
-                                u"associated with it"
-                                u"" % (scheme,))
+        raise ConflictingScheme(f"the prefix {scheme} already has a backend associated with it")
 
     _backend_prefixes[scheme] = backend_factory
 
 
 def strip_prefix(url_string, prefix_scheme):
-    u"""
+    """
     strip the prefix from a string e.g. par2+ftp://... -> ftp://...
     """
-    return re.sub(r'(?i)^' + re.escape(prefix_scheme) + r'\+', r'', url_string)
+    return re.sub(f"(?i)^{re.escape(prefix_scheme)}\\+", r'', url_string)
 
 
 def is_backend_url(url_string):
-    u"""
+    """
     @return Whether the given string looks like a backend URL.
     """
     pu = ParsedUrl(url_string)
 
     # Be verbose to actually return True/False rather than string.
     if pu.scheme:
         return True
     else:
         return False
 
 
 def get_backend_object(url_string):
-    u"""
+    """
     Find the right backend class instance for the given URL, or return None
     if the given string looks like a local path rather than a URL.
 
     Raise InvalidBackendURL if the URL is not a valid URL.
     """
     if not is_backend_url(url_string):
         return None
 
     global _backends, _backend_prefixes
 
     pu = ParsedUrl(url_string)
-    assert pu.scheme, u"should be a backend url according to is_backend_url"
+    assert pu.scheme, "should be a backend url according to is_backend_url"
 
     factory = None
 
     for prefix in _backend_prefixes:
-        if url_string.startswith(prefix + u'+'):
+        if url_string.startswith(f"{prefix}+"):
             factory = _backend_prefixes[prefix]
             pu = ParsedUrl(strip_prefix(url_string, prefix))
             break
 
     if factory is None:
         if pu.scheme not in _backends:
             raise UnsupportedBackendScheme(url_string)
         else:
             factory = _backends[pu.scheme]
 
     try:
         return factory(pu)
     except ImportError:
-        raise BackendException(_(u"Could not initialize backend: %s") % str(sys.exc_info()[1]))
+        raise BackendException(_("Could not initialize backend: %s") % str(sys.exc_info()[1]))
 
 
 def get_backend(url_string):
-    u"""
+    """
     Instantiate a backend suitable for the given URL, or return None
     if the given string looks like a local path rather than a URL.
 
     Raise InvalidBackendURL if the URL is not a valid URL.
     """
-    if config.use_gio:
-        url_string = u'gio+' + url_string
     obj = get_backend_object(url_string)
     if obj:
         obj = BackendWrapper(obj)
     return obj
 
 
 class ParsedUrl(object):
-    u"""
+    """
     Parse the given URL as a duplicity backend URL.
 
     Returns the data of a parsed URL with the same names as that of
     the standard urlparse.urlparse() except that all values have been
     resolved rather than deferred.  There are no get_* members.  This
     makes sure that the URL parsing errors are detected early.
 
     Raise InvalidBackendURL on invalid URL's
     """
+
     def __init__(self, url_string):
         self.url_string = url_string
 
         # Python < 2.6.5 still examine urlparse.uses_netlock when parsing urls,
         # so stuff our custom list in there before we parse.
         urllib.parse.uses_netloc = uses_netloc
 
@@ -248,127 +233,123 @@
         # all the properties in the URL deferred or lazy.  This means that
         # problems don't get detected till called.  We'll try to trap those
         # problems here, so they will be caught early.
 
         try:
             pu = urllib.parse.urlparse(url_string)
         except Exception:
-            raise InvalidBackendURL(u"Syntax error in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error in: {url_string}")
 
         try:
             self.scheme = pu.scheme
         except Exception:
-            raise InvalidBackendURL(u"Syntax error (scheme) in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error (scheme) in: {url_string}")
 
         try:
             self.netloc = pu.netloc
         except Exception:
-            raise InvalidBackendURL(u"Syntax error (netloc) in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error (netloc) in: {url_string}")
 
         try:
             self.path = pu.path
             if self.path:
                 self.path = urllib.parse.unquote(self.path)
         except Exception:
-            raise InvalidBackendURL(u"Syntax error (path) in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error (path) in: {url_string}")
 
         try:
             self.username = pu.username
         except Exception:
-            raise InvalidBackendURL(u"Syntax error (username) in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error (username) in: {url_string}")
         if self.username:
             self.username = urllib.parse.unquote(pu.username)
         else:
             self.username = None
 
         try:
             self.password = pu.password
         except Exception:
-            raise InvalidBackendURL(u"Syntax error (password) in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error (password) in: {url_string}")
         if self.password:
             self.password = urllib.parse.unquote(self.password)
         else:
             self.password = None
 
         try:
             self.hostname = pu.hostname
         except Exception:
-            raise InvalidBackendURL(u"Syntax error (hostname) in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error (hostname) in: {url_string}")
 
         try:
             self.query = pu.query
         except Exception:
-            raise InvalidBackendURL(u"Syntax error (query) in: %s" % url_string)
+            raise InvalidBackendURL(f"Syntax error (query) in: {url_string}")
         if self.query:
             self.query_args = urllib.parse.parse_qs(self.query)
         else:
             self.query = None
             self.query_args = {}
 
         # init to None, overwrite with actual value on success
         self.port = None
         try:
             self.port = pu.port
-        except Exception:  # not raised in python2.7, just returns None
-            # TODO: remove after dropping python 2.7 support
-            if self.scheme in [u'rclone']:
+        except Exception:  # just returns None
+            if self.scheme in ['rclone']:
                 pass
             # old style rsync://host::[/]dest, are still valid, though they contain no port
-            elif not (u'rsync' in self.scheme and re.search(u'::[^:]*$', self.url_string)):
-                raise InvalidBackendURL(u"Syntax error (port) in: %s A%s B%s C%s" %
-                                        (url_string, (u'rsync' in self.scheme),
-                                         re.search(u'::[^:]+$', self.netloc), self.netloc))
+            elif not ('rsync' in self.scheme and re.search('::[^:]*$', self.url_string)):
+                raise InvalidBackendURL(f"Syntax error (port) in: {url_string} A{'rsync' in self.scheme} "
+                                        f"B{re.search('::[^:]+$', self.netloc)} C{self.netloc}")
 
         # Our URL system uses two slashes more than urlparse's does when using
         # non-netloc URLs.  And we want to make sure that if urlparse assuming
         # a netloc where we don't want one, that we correct it.
         if self.scheme not in uses_netloc:
             if self.netloc:
-                self.path = u'//' + self.netloc + self.path
-                self.netloc = u''
+                self.path = f"//{self.netloc}{self.path}"
+                self.netloc = ''
                 self.hostname = None
-            elif not self.path.startswith(u'//') and self.path.startswith(u'/'):
-                self.path = u'//' + self.path
+            elif not self.path.startswith('//') and self.path.startswith('/'):
+                self.path = f"//{self.path}"
 
         # This happens for implicit local paths.
         if not self.scheme:
             return
 
         # Our backends do not handle implicit hosts.
         if self.scheme in uses_netloc and not self.hostname:
-            raise InvalidBackendURL(u"Missing hostname in a backend URL which "
-                                    u"requires an explicit hostname: %s"
-                                    u"" % (url_string))
+            raise InvalidBackendURL(f"Missing hostname in a backend URL which requires an "
+                                    f"explicit hostname: {url_string}")
 
         # Our backends do not handle implicit relative paths.
-        if self.scheme not in uses_netloc and not self.path.startswith(u'//'):
-            raise InvalidBackendURL(u"missing // - relative paths not supported "
-                                    u"for scheme %s: %s"
-                                    u"" % (self.scheme, url_string))
+        if self.scheme not in uses_netloc and not self.path.startswith('//'):
+            raise InvalidBackendURL(f"missing // - relative paths not supported for "
+                                    f"scheme {self.scheme}: {url_string}")
 
     def geturl(self):
         return self.url_string
 
     def strip_auth(self):
         return duplicity.backend.strip_auth_from_url(self)
 
 
 def strip_auth_from_url(parsed_url):
-    u"""Return a URL from a urlparse object without a username or password."""
+    """Return a URL from a urlparse object without a username or password."""
 
-    clean_url = re.sub(u'^([^:/]+://)(.*@)?(.*)', r'\1\3', parsed_url.geturl())
+    clean_url = re.sub('^([^:/]+://)(.*@)?(.*)', r'\1\3', parsed_url.geturl())
     return clean_url
 
 
 def _get_code_from_exception(backend, operation, e):
     if isinstance(e, BackendException) and e.code != log.ErrorCode.backend_error:
         return e.code
-    elif hasattr(backend, u'_error_code'):
+    elif hasattr(backend, '_error_code'):
         return backend._error_code(operation, e) or log.ErrorCode.backend_error
-    elif hasattr(e, u'errno'):
+    elif hasattr(e, 'errno'):
         # A few backends return such errors (local, paramiko, etc)
         if e.errno == errno.EACCES:
             return log.ErrorCode.backend_permission_denied
         elif e.errno == errno.ENOENT:
             return log.ErrorCode.backend_not_found
         elif e.errno == errno.ENOSPC:
             return log.ErrorCode.backend_no_space
@@ -396,337 +377,343 @@
                 except Exception as e:
                     _last_exception = e
                     if not errors_fatal:
                         # backend wants to report and ignore errors
                         return errors_default
                     else:
                         # retry on anything else
-                        log.Debug(_(u"Backtrace of previous error: %s")
+                        log.Debug(_("Backtrace of previous error: %s")
                                   % exception_traceback())
                         at_end = n == config.num_retries
                         code = _get_code_from_exception(self.backend, operation, e)
                         if code == log.ErrorCode.backend_not_found:
                             # If we tried to do something, but the file just isn't there,
                             # no need to retry.
                             at_end = True
                         if at_end and fatal:
                             def make_filename(f):
                                 if isinstance(f, path.ROPath):
                                     return util.escape(f.uc_name)
                                 else:
                                     return util.escape(f)
-                            extra = u' '.join([operation] + [make_filename(x) for x in args
-                                                             if (x and isinstance(x, str))])
-                            log.FatalError(_(u"Giving up after %s attempts. %s: %s")
+
+                            extra = ' '.join([operation] + [make_filename(x) for x in args
+                                                            if (x and isinstance(x, str))])
+                            log.FatalError(_("Giving up after %s attempts. %s: %s")
                                            % (n, e.__class__.__name__,
                                               util.uexc(e)), code=code, extra=extra)
                         else:
-                            log.Warn(_(u"Attempt of %s Nr. %s failed. %s: %s")
+                            log.Warn(_("Attempt of %s Nr. %s failed. %s: %s")
                                      % (fn.__name__, n, e.__class__.__name__, util.uexc(e)))
                         if not at_end:
                             if isinstance(e, TemporaryLoadException):
                                 time.sleep(3 * config.backend_retry_delay)  # wait longer before trying again
                             else:
                                 time.sleep(config.backend_retry_delay)  # wait a bit before trying again
-                            if hasattr(self.backend, u'_retry_cleanup'):
+                            if hasattr(self.backend, '_retry_cleanup'):
                                 self.backend._retry_cleanup()
 
         return inner_retry
+
     return outer_retry
 
 
 class Backend(object):
-    u"""
+    """
     See README in backends directory for information on how to write a backend.
     """
+
     def __init__(self, parsed_url):
         self.parsed_url = parsed_url
 
-    u""" use getpass by default, inherited backends may overwrite this behaviour """
+    """ use getpass by default, inherited backends may overwrite this behaviour """
     use_getpass = True
 
     def get_password(self):
-        u"""
+        """
         Return a password for authentication purposes. The password
         will be obtained from the backend URL, the environment, by
         asking the user, or by some other method. When applicable, the
         result will be cached for future invocations.
         """
         if self.parsed_url.password:
             return self.parsed_url.password
 
         try:
-            password = os.environ[u'FTP_PASSWORD']
+            password = os.environ['FTP_PASSWORD']
         except KeyError:
             if self.use_getpass:
-                password = getpass.getpass(u"Password for '%s@%s': " %
-                                           (self.parsed_url.username, self.parsed_url.hostname))
-                os.environ[u'FTP_PASSWORD'] = password
+                password = getpass.getpass(f"Password for '{self.parsed_url.username}@{self.parsed_url.hostname}': ")
+                os.environ['FTP_PASSWORD'] = password
             else:
                 password = None
         return password
 
     def munge_password(self, commandline):
-        u"""
+        """
         Remove password from commandline by substituting the password
         found in the URL, if any, with a generic place-holder.
 
         This is intended for display purposes only, and it is not
         guaranteed that the results are correct (i.e., more than just
         the ':password@' may be substituted.
         """
         if self.parsed_url.password:
             return re.sub(r'(:([^\s:/@]+)@([^\s@]+))', r':*****@\3', commandline)
         else:
             return commandline
 
     def __subprocess_popen(self, args):
-        u"""
+        """
         For internal use.
         Execute the given command line, interpreted as a shell command.
         Returns int Exitcode, string StdOut, string StdErr
         """
-        from subprocess import Popen, PIPE
+        from subprocess import (
+            Popen,
+            PIPE,
+        )
 
         args[0] = util.which(args[0])
         p = Popen(args, stdout=PIPE, stderr=PIPE, universal_newlines=True)
         stdout, stderr = p.communicate()
 
         return p.returncode, stdout, stderr
 
-    u""" a dictionary for breaking exceptions, syntax is
+    """ a dictionary for breaking exceptions, syntax is
         { 'command' : [ code1, code2 ], ... } see ftpbackend for an example """
     popen_breaks = {}
 
     def subprocess_popen(self, commandline):
-        u"""
+        """
         Execute the given command line with error check.
         Returns int Exitcode, string StdOut, string StdErr
 
         Raise a BackendException on failure.
         """
         import shlex
 
         if isinstance(commandline, (list, tuple)):
-            logstr = u' '.join(commandline)
+            logstr = ' '.join(commandline)
             args = commandline
         else:
             logstr = commandline
             args = shlex.split(commandline)
 
         logstr = self.munge_password(logstr)
-        log.Info(_(u"Reading results of '%s'") % logstr)
+        log.Info(_("Reading results of '%s'") % logstr)
 
         result, stdout, stderr = self.__subprocess_popen(args)
         if result != 0:
             try:
                 ignores = self.popen_breaks[args[0]]
                 ignores.index(result)
-                u""" ignore a predefined set of error codes """
-                return 0, u'', u''
+                """ ignore a predefined set of error codes """
+                return 0, '', ''
             except (KeyError, ValueError):
-                raise BackendException(u"Error running '%s': returned %d, with output:\n%s" %
-                                       (logstr, result, stdout + u'\n' + stderr + u'\n'))
+                raise BackendException("Error running '%s': returned %d, with output:\n%s" %
+                                       (logstr, result, f"{stdout}\n{stderr}\n"))
         return result, stdout, stderr
 
 
 class BackendWrapper(object):
-    u"""
+    """
     Represents a generic duplicity backend, capable of storing and
     retrieving files.
     """
 
     def __init__(self, backend):
         self.backend = backend
 
     def __do_put(self, source_path, remote_filename):
-        if hasattr(self.backend, u'_put'):
-            log.Info(_(u"Writing %s") % util.fsdecode(remote_filename))
+        if hasattr(self.backend, '_put'):
+            log.Info(_("Writing %s") % os.fsdecode(remote_filename))
             self.backend._put(source_path, remote_filename)
         else:
             raise NotImplementedError()
 
-    @retry(u'put', fatal=True)
+    @retry('put', fatal=True)
     def put(self, source_path, remote_filename=None):
-        u"""
+        """
         Transfer source_path (Path object) to remote_filename (string)
 
         If remote_filename is None, get the filename from the last
         path component of pathname.
         """
         if not remote_filename:
             remote_filename = source_path.get_filename()
         self.__do_put(source_path, remote_filename)
 
-    @retry(u'move', fatal=True)
+    @retry('move', fatal=True)
     def move(self, source_path, remote_filename=None):
-        u"""
+        """
         Move source_path (Path object) to remote_filename (string)
 
         Same as put(), but unlinks source_path in the process.  This allows the
         local backend to do this more efficiently using rename.
         """
         if not remote_filename:
             remote_filename = source_path.get_filename()
-        if hasattr(self.backend, u'_move'):
+        if hasattr(self.backend, '_move'):
             if self.backend._move(source_path, remote_filename) is not False:
                 source_path.setdata()
                 return
         self.__do_put(source_path, remote_filename)
         source_path.delete()
 
-    @retry(u'get', fatal=True)
+    @retry('get', fatal=True)
     def get(self, remote_filename, local_path):
-        u"""Retrieve remote_filename and place in local_path"""
-        if hasattr(self.backend, u'_get'):
+        """Retrieve remote_filename and place in local_path"""
+        if hasattr(self.backend, '_get'):
             self.backend._get(remote_filename, local_path)
             local_path.setdata()
             if not local_path.exists():
-                raise BackendException(_(u"File %s not found locally after get "
-                                         u"from backend") % local_path.uc_name)
+                raise BackendException(_("File %s not found locally after get "
+                                         "from backend") % local_path.uc_name)
         else:
             raise NotImplementedError()
 
-    @retry(u'list', fatal=True)
+    @retry('list', fatal=True)
     def list(self):
-        u"""
+        """
         Return list of filenames (byte strings) present in backend
         """
+
         def tobytes(filename):
-            u"Convert a (maybe unicode) filename to bytes"
+            """Convert a (maybe unicode) filename to bytes"""
             if isinstance(filename, str):
                 # There shouldn't be any encoding errors for files we care
                 # about, since duplicity filenames are ascii.  But user files
                 # may be in the same directory.  So just replace characters.
-                return util.fsencode(filename)
+                return os.fsencode(filename)
             else:
                 return filename
 
-        if hasattr(self.backend, u'_list'):
+        if hasattr(self.backend, '_list'):
             # Make sure that duplicity internals only ever see byte strings
             # for filenames, no matter what the backend thinks it is talking.
             return [tobytes(x) for x in self.backend._list()]
         else:
             raise NotImplementedError()
 
     def pre_process_download(self, remote_filename):
-        u"""
+        """
         Manages remote access before downloading files
         (unseal data in cold storage for instance)
         """
-        if hasattr(self.backend, u'pre_process_download'):
+        if hasattr(self.backend, 'pre_process_download'):
             return self.backend.pre_process_download(remote_filename)
 
     def pre_process_download_batch(self, remote_filenames):
-        u"""
+        """
         Manages remote access before downloading files
         (unseal data in cold storage for instance)
         """
-        if hasattr(self.backend, u'pre_process_download_batch'):
+        if hasattr(self.backend, 'pre_process_download_batch'):
             return self.backend.pre_process_download_batch(remote_filenames)
 
     def delete(self, filename_list):
-        u"""
+        """
         Delete each filename in filename_list, in order if possible.
         """
         assert not isinstance(filename_list, bytes)
-        if hasattr(self.backend, u'_delete_list'):
+        if hasattr(self.backend, '_delete_list'):
             self._do_delete_list(filename_list)
-        elif hasattr(self.backend, u'_delete'):
+        elif hasattr(self.backend, '_delete'):
             for filename in filename_list:
                 self._do_delete(filename)
         else:
             raise NotImplementedError()
 
-    @retry(u'delete', fatal=False)
+    @retry('delete', fatal=False)
     def _do_delete_list(self, filename_list):
         while filename_list:
             sublist = filename_list[:100]
             self.backend._delete_list(sublist)
             filename_list = filename_list[100:]
 
-    @retry(u'delete', fatal=False)
+    @retry('delete', fatal=False)
     def _do_delete(self, filename):
         self.backend._delete(filename)
 
     # Should never cause FatalError.
     # Returns a dictionary of dictionaries.  The outer dictionary maps
     # filenames to metadata dictionaries.  Supported metadata are:
     #
     # 'size': if >= 0, size of file
     #         if -1, file is not found
     #         if None, error querying file
     #
     # Returned dictionary is guaranteed to contain a metadata dictionary for
     # each filename, and all metadata are guaranteed to be present.
     def query_info(self, filename_list):
-        u"""
+        """
         Return metadata about each filename in filename_list
         """
         info = {}
-        if hasattr(self.backend, u'_query_list'):
+        if hasattr(self.backend, '_query_list'):
             info = self._do_query_list(filename_list)
             if info is None:
                 info = {}
-        elif hasattr(self.backend, u'_query'):
+        elif hasattr(self.backend, '_query'):
             for filename in filename_list:
                 info[filename] = self._do_query(filename)
 
         # Fill out any missing entries (may happen if backend has no support
         # or its query_list support is lazy)
         for filename in filename_list:
             if filename not in info or info[filename] is None:
                 info[filename] = {}
-            for metadata in [u'size']:
+            for metadata in ['size']:
                 info[filename].setdefault(metadata, None)
 
         return info
 
-    @retry(u'query', fatal=False)
+    @retry('query', fatal=False)
     def _do_query_list(self, filename_list):
         info = self.backend._query_list(filename_list)
         if info is None:
             info = {}
         return info
 
-    @retry(u'query', fatal=False)
+    @retry('query', fatal=False)
     def _do_query(self, filename):
         try:
             return self.backend._query(filename)
         except Exception as e:
-            code = _get_code_from_exception(self.backend, u'query', e)
+            code = _get_code_from_exception(self.backend, 'query', e)
             if code == log.ErrorCode.backend_not_found:
-                return {u'size': -1}
+                return {'size': -1}
             else:
                 raise e
 
     def close(self):
-        u"""
+        """
         Close the backend, releasing any resources held and
         invalidating any file objects obtained from the backend.
         """
-        if hasattr(self.backend, u'_close'):
+        if hasattr(self.backend, '_close'):
             self.backend._close()
 
     def get_fileobj_read(self, filename, parseresults=None):
-        u"""
+        """
         Return fileobject opened for reading of filename on backend
 
         The file will be downloaded first into a temp file.  When the
         returned fileobj is closed, the temp file will be deleted.
         """
         if not parseresults:
             parseresults = file_naming.parse(filename)
-            assert parseresults, u"Filename not correctly parsed"
+            assert parseresults, "Filename not correctly parsed"
         tdp = dup_temp.new_tempduppath(parseresults)
         self.get(filename, tdp)
         tdp.setdata()
-        return tdp.filtered_open_with_delete(u"rb")
+        return tdp.filtered_open_with_delete("rb")
 
     def get_data(self, filename, parseresults=None):
-        u"""
+        """
         Retrieve a file from backend, process it, return contents.
         """
         fin = self.get_fileobj_read(filename, parseresults)
         buf = fin.read()
         assert not fin.close()
         return buf
```

### Comparing `duplicity-1.2.3.dev43/duplicity/config.py` & `duplicity-2.0.0rc0/duplicity/config.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,26 +15,39 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Store global configuration information"""
+"""Store global configuration information"""
 
 import os
-import sys
 import socket
+import sys
+import time
 
 from duplicity import __version__
-
+from duplicity import gpg
 
 # The current version of duplicity
 version = __version__
 
+# The following args are set by commandline processing
+# they correspond to the args in cli_main.duplicity_commands
+count = None
+remove_time = None
+source_path = None
+source_url = None
+target_dir = None
+target_url = None
+
+# action to take
+action = None
+
 # Prefix for all files (appended before type-specific prefixes)
 file_prefix = b""
 
 # Prefix for manifest files only
 file_prefix_manifest = b""
 
 # Prefix for archive files only
@@ -60,58 +73,61 @@
 # For testing -- set current time
 current_time = None
 
 # Set to the Path of the archive directory (the directory which
 # contains the signatures and manifests of the relevent backup
 # collection), and for checkpoint state between volumes.
 # NOTE: this gets expanded in duplicity.commandline
-os.environ[u"XDG_CACHE_HOME"] = os.getenv(u"XDG_CACHE_HOME", os.path.expanduser(u"~/.cache"))
-archive_dir = os.path.expandvars(u"$XDG_CACHE_HOME/duplicity")
+os.environ["XDG_CACHE_HOME"] = os.getenv("XDG_CACHE_HOME", os.path.expanduser("~/.cache"))
+archive_dir = os.path.expandvars("$XDG_CACHE_HOME/duplicity")
 archive_dir_path = None
 
 # config dir for future use
-os.environ[u"XDG_CONFIG_HOME"] = os.getenv(u"XDG_CONFIG_HOME", os.path.expanduser(u"~/.config"))
-config_dir = os.path.expandvars(u"$XDG_CONFIG_HOME/duplicity")
+os.environ["XDG_CONFIG_HOME"] = os.getenv("XDG_CONFIG_HOME", os.path.expanduser("~/.config"))
+config_dir = os.path.expandvars("$XDG_CONFIG_HOME/duplicity")
+config_dir_path = None
 
 # Restores will try to bring back the state as of the following time.
 # If it is None, default to current time.
 restore_time = None
 
 # If set, restore only the subdirectory or file specified, not the
 # whole root.
-restore_dir = None
+restore_path = None
 
 # The backend representing the remote side
 backend = None
 
 # Are errors fatal (set for retry decorator in backend.py)
 # See example of use in multibackend.py _list()
 # Do not use in normal cases!
 are_errors_fatal = {
-    u'delete': (True, None),
-    u'get': (True, None),
-    u'list': (True, None),
-    u'move': (True, None),
-    u'put': (True, None),
-    u'query': (True, None),
+    'delete': (True, None),
+    'get': (True, None),
+    'list': (True, None),
+    'move': (True, None),
+    'put': (True, None),
+    'query': (True, None),
 }
 
-# If set, the Select object which iterates paths in the local
-# source directory.
+# Select object which iterates paths in the local source dir.
 select = None
+select_opts = []
+select_files = []
 
+# gpg binary to use
 gpg_binary = None
 
+# Options to pass to gpg
+gpg_options = ''
+
 # Set to GPGProfile that will be used to compress/uncompress encrypted
 # files.  Replaces encryption_keys, sign_key, and passphrase settings.
 gpg_profile = None
 
-# Options to pass to gpg
-gpg_options = u''
-
 # Maximum file blocksize
 max_blocksize = 2048
 
 # If true, filelists and directory statistics will be split on
 # nulls instead of newlines.
 null_separator = None
 
@@ -120,82 +136,68 @@
 
 # True if Pydev debugger should be activated
 pydevd = False
 
 # Character used like the ":" in time strings like
 # 2002-08-06T04:22:00-07:00.  The colon isn't good for filenames on
 # windows machines.
-time_separator = u":"
+time_separator = ":"
 
 # Global lockfile used to manage concurrency
-lockpath = u""
 lockfile = None
+lockpath = ""
 
 # If this is true, only warn and don't raise fatal error when backup
 # source directory doesn't match previous backup source directory.
-allow_source_mismatch = None
-
-# If set, abort if cannot do an incremental backup.  Otherwise if
-# signatures not found, default to full.
-incremental = None
+allow_source_mismatch = False
 
 # If set, print the statistics after every backup session
 print_statistics = True
 
-# If set, use short (< 30 char) filenames for all the remote files.
-short_filenames = False
-
 # If set, forces a full backup if the last full backup is older than
 # the time specified
-full_force_time = None
+full_if_older_than = None
 
 # Used to confirm certain destructive operations like deleting old files.
 force = None
 
-# If set, signifies time in seconds before which backup files should
-# be deleted.
-remove_time = None
-
 # If set, signifies the number of backups chains to keep when performing
 # a remove-all-but-n-full.
 keep_chains = None
 
-# If set, signifies that remove-all-but-n-full in progress
-remove_all_but_n_full_mode = None
-
-# If set, signifies that remove-all-inc-of-but-n-full in progress (variant of remove-all-but-n-full)
-remove_all_inc_of_but_n_full_mode = None
-
 # Don't actually do anything, but still report what would be done
 dry_run = False
 
-# If set to false, then do not encrypt files on remote system
-encryption = True
-
-# If set to false, then do not compress files on remote system
+# Compress files on remote system?
 compression = True
 
+# Encrypt files on remote system?
+encryption = True
+
 # volume size. default 200M
 volsize = 200 * 1024 * 1024
 
+# file copy blocksize
+copy_blocksize = 128 * 1024
+
 # after this volume, we will switch to multipart upload
 mp_factor = 1.1
-mp_segment_size = mp_factor * volsize
+mp_segment_size = int(mp_factor * volsize)
 
 # Working directory for the tempfile module. Defaults to /tmp on most systems.
 temproot = None
 
 # network timeout value
 timeout = 30
 
 # FTP data connection type
-ftp_connection = u'passive'
+ftp_connection = 'passive'
 
 # Header options for Webdav
-webdav_headers = u""
+webdav_headers = ""
 
 # Asynchronous put/get concurrency limit
 # (default of 0 disables asynchronicity).
 async_concurrency = 0
 
 # Whether to use "new-style" subdomain addressing for S3 buckets. Such
 # use is not backwards-compatible with upper-case buckets, or buckets
@@ -207,15 +209,15 @@
 s3_european_buckets = False
 
 # File owner uid keeps number from tar file. Like same option in GNU tar.
 numeric_owner = False
 
 # Do no restore the uid/gid when finished, useful if you're restoring
 # data without having root privileges or Unix users support
-do_not_restore_ownership = False
+restore_ownership = True
 
 # Whether to use plain HTTP (without SSL) to send data to S3
 # See <https://bugs.launchpad.net/duplicity/+bug/433970>.
 s3_unencrypted_connection = False
 
 # Whether to use S3 Reduced Redudancy Storage
 s3_use_rrs = False
@@ -231,45 +233,35 @@
 
 # Whether to use S3 Glacier Deep Archive Storage
 s3_use_deep_archive = False
 
 # Whether to use S3 One Zone Infrequent Access Storage
 s3_use_onezone_ia = False
 
-# True if we should use boto multiprocessing version
-s3_use_multiprocessing = False
-
 # Chunk size used for S3 multipart uploads.The number of parallel uploads to
 # S3 be given by chunk size / volume size. Use this to maximize the use of
 # your bandwidth. Defaults to 25MB
 s3_multipart_chunk_size = 20 * 1024 * 1024
 
 # Minimum chunk size accepted by S3
 s3_multipart_minimum_chunk_size = 5 * 1024 * 1024
 
 # Maximum number of processes to use while doing a multipart upload to S3
 s3_multipart_max_procs = 4
 
-# Maximum time to wait for a part to finish when doig a multipart upload to S3
-s3_multipart_max_timeout = None
-
-# Use server side encryption in s3
-s3_use_sse = False
-
 # Use server side kms encryption in s3
-s3_use_sse_kms = False
 s3_kms_key_id = None
 s3_kms_grant = None
 
 # region and endpoint of s3
 s3_region_name = None
 s3_endpoint_url = None
 
 # Which storage policy to use for Swift containers
-swift_storage_policy = u""
+swift_storage_policy = ""
 
 # The largest size upload supported in a single put call for azure
 azure_max_single_put_size = None
 
 # The size of the blocks put to azure blob storage if bigger than azure_max_single_put_size
 azure_max_block_size = None
 
@@ -282,48 +274,45 @@
 # Whether to use the full email address as the user name when
 # logging into an imap server. If false just the user name
 # part of the email address is used.
 imap_full_address = False
 
 # Name of the imap folder where we want to store backups.
 # Can be changed with a command line argument.
-imap_mailbox = u"INBOX"
+imap_mailbox = "INBOX"
 
 # Sync partial metadata by default
-metadata_sync_mode = u"partial"
-
-# Whether the old filename format is in effect.
-old_filenames = False
+metadata_sync_mode = "partial"
 
 # Wheter to specify --use-agent in GnuPG options
 use_agent = False
 
-# ssh commands to use, used by ssh_pexpect (defaults to sftp, scp)
+# ssh duplicity_commands to use, used by ssh_pexpect (defaults to sftp, scp)
 scp_command = None
 sftp_command = None
 
 # default to batch mode using public-key encryption
 ssh_askpass = False
 
 # user added ssh options
-ssh_options = u""
+ssh_options = ""
 
 # default cf backend is pyrax
-cf_backend = u"pyrax"
+cf_backend = "pyrax"
 
 # default to fully deleting files in b2
 b2_hide_files = False
 
 # HTTPS ssl options (currently only webdav, lftp)
 ssl_cacert_file = None
 ssl_cacert_path = None
 ssl_no_check_certificate = False
 
 # user added rsync options
-rsync_options = u""
+rsync_options = ""
 
 # will be a Restart object if restarting
 restart = None
 
 # used in testing only - raises exception after volume
 fail_on_volume = 0
 
@@ -354,42 +343,42 @@
 # 3 seconds
 progress_rate = 3
 
 # Level of Redundancy in % for Par2 files
 par2_redundancy = 10
 
 # Verbatim par2 other options
-par2_options = u""
+par2_options = ""
 
 # Number of par2 volumes
 par2_volumes = 1
 
-# Whether to enable gio backend
-use_gio = False
-
 # If set, log the chnages is the set instead of the normal collection status
 show_changes_in_set = None
 
 # If set, collect only the file status, not the whole root.
 file_changed = None
 
-# If set, skip collecting the files_changed list in statistics, nullifies --file-changed
-no_files_changed = False
+# If set collect the files_changed list in statistics
+files_changed = True
 
 # delay (in seconds) before next operation after failure
 backend_retry_delay = 30
 
 # option for mediafire to purge files on delete instead of sending to trash
 mf_purge = False
 
 # Fake root directory path for iDrived backend
-fakeroot = None
+idr_fakeroot = None
 
 # whether to check remote manifest (requires private key)
 check_remote = True
 
+# whether 'inc` is explicit or not
+inc_explicit = True
+
 # default filesystem encoding
-# In Python 2 it seems that sys.getfilesystemencoding() will normally return
-# 'utf-8' or some other sane encoding, but will sometimes fail and return
+# It seems that sys.getfilesystemencoding() will normally return
+# 'utf-8' or some other sane encoding, but will sometimes fail and returns
 # either 'ascii' or None.  Both are bogus, so default to 'utf-8' if it does.
 fsencoding = sys.getfilesystemencoding()
-fsencoding = fsencoding if fsencoding not in [u'ascii', u'ANSI_X3.4-1968', None] else u'utf-8'
+fsencoding = fsencoding if fsencoding not in ['ascii', 'ANSI_X3.4-1968', None] else 'utf-8'
```

### Comparing `duplicity-1.2.3.dev43/duplicity/globmatch.py` & `duplicity-2.0.0rc0/duplicity/globmatch.py`

 * *Files 11% similar despite different names*

```diff
@@ -21,47 +21,42 @@
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 #
 # All functions in this module only accept unicode. Any byte strings should
 # be converted to unicode before sending them into this.
 
 import re
 
-from builtins import map
-from builtins import range
-from builtins import str
-
 
 class GlobbingError(Exception):
-    u"""Something has gone wrong when parsing a glob string"""
+    """Something has gone wrong when parsing a glob string"""
     pass
 
 
 class FilePrefixError(GlobbingError):
-    u"""Signals that a specified file doesn't start with correct prefix"""
+    """Signals that a specified file doesn't start with correct prefix"""
     pass
 
 
 def _glob_get_prefix_regexs(glob_str):
-    u"""Return list of regexps equivalent to prefixes of glob_str"""
+    """Return list of regexps equivalent to prefixes of glob_str"""
     # Internal. Used by glob_get_sf.
-    glob_parts = glob_str.split(u"/")
-    if u"" in glob_parts[1:-1]:
+    glob_parts = glob_str.split("/")
+    if "" in glob_parts[1:-1]:
         # "" OK if comes first or last, as in /foo/
-        raise GlobbingError(u"Consecutive '/'s found in globbing string " +
-                            glob_str)
+        raise GlobbingError(f"Consecutive '/'s found in globbing string {glob_str}")
 
-    prefixes = [u"/".join(glob_parts[:i + 1]) for i in range(len(glob_parts))]
+    prefixes = ["/".join(glob_parts[:i + 1]) for i in range(len(glob_parts))]
     # we must make exception for root "/", only dir to end in slash
-    if prefixes[0] == u"":
-        prefixes[0] = u"/"
+    if prefixes[0] == "":
+        prefixes[0] = "/"
     return list(map(glob_to_regex, prefixes))
 
 
 def select_fn_from_glob(glob_str, include, ignore_case=False):
-    u"""Return a function test_fn(path) which
+    """Return a function test_fn(path) which
     tests whether path matches glob, as per the Unix shell rules, taking as
     arguments a path, a glob string and include (0 indicating that the glob
     string is an exclude glob and 1 indicating that it is an include glob,
     returning:
 
     0 - if the file should be excluded
     1 - if the file should be included
@@ -81,18 +76,18 @@
     things similar to this.
 
     Note: including a folder implicitly includes everything within it.
     """
     assert isinstance(glob_str, str)
     glob_ends_w_slash = False
 
-    if glob_str == u"/":
+    if glob_str == "/":
         # If the glob string is '/', it implicitly includes everything
-        glob_str = u"/**"
-    elif glob_str[-1] == u"/":
+        glob_str = "/**"
+    elif glob_str[-1] == "/":
         glob_ends_w_slash = True
         # Remove trailing / from directory name (unless that is the entire
         # string)
         glob_str = glob_str[:-1]
 
     flags = 0
     if ignore_case:
@@ -104,38 +99,37 @@
     # Resulting regular expression is:
     # ^ string must be at the beginning of path
     # string translated into regex
     # ($|/) nothing must follow except for the end of the string, newline or /
     # Note that the "/" at the end of the regex means that it will match
     # if the glob matches a parent folders of path, i.e. including a folder
     # includes everything within it.
-    glob_comp_re = re_comp(u"^%s($|/)" % glob_to_regex(glob_str))
+    glob_comp_re = re_comp(f"^{glob_to_regex(glob_str)}($|/)")
 
     if glob_ends_w_slash:
         # Creates a version of glob_comp_re that does not match folder contents
         # This can be used later to check that an exact match is actually a
         # folder, rather than a file.
-        glob_comp_re_exact = re_comp(u"^%s($)" % glob_to_regex(glob_str))
+        glob_comp_re_exact = re_comp(f"^{glob_to_regex(glob_str)}($)")
 
-    if glob_str.find(u"**") != -1:
+    if glob_str.find("**") != -1:
         # glob_str has a ** in it
-        glob_str = glob_str[:glob_str.find(u"**") + 2]  # truncate after **
+        glob_str = glob_str[:glob_str.find("**") + 2]  # truncate after **
 
     # Below regex is translates to:
     # ^ string must be at the beginning of path
     # the regexs corresponding to the parent directories of glob_str
     # $ nothing must follow except for the end of the string or newline
-    scan_comp_re = re_comp(u"^(%s)$" %
-                           u"|".join(_glob_get_prefix_regexs(glob_str)))
+    scan_comp_re = re_comp(f"^({'|'.join(_glob_get_prefix_regexs(glob_str))})$")
 
     def test_fn(path):
-        assert not path.uc_name[-1] == u"/" or path.uc_name == u"/", \
-            u"path.name should never end in '/' during normal operation for " \
-            u"normal paths (except '/' alone)\n" \
-            u"path.name here is " + path.uc_name + u" and glob is " + glob_str
+        assert not path.uc_name[-1] == "/" or path.uc_name == "/", \
+            "path.name should never end in '/' during normal operation for " \
+            "normal paths (except '/' alone)\n" \
+            "path.name here is " + path.uc_name + " and glob is " + glob_str
 
         if glob_comp_re.match(path.uc_name):
             # Path matches glob, or is contained within a matching folder
             if not glob_ends_w_slash:
                 return include
             else:
                 # Glob ended with a /, so we need to check any exact match was
@@ -157,52 +151,52 @@
         else:
             return None
 
     return test_fn
 
 
 def glob_to_regex(pat):
-    u"""Returned regular expression equivalent to shell glob pat
+    """Returned regular expression equivalent to shell glob pat
 
     Currently only the ?, *, [], and ** expressions are supported.
     Ranges like [a-z] are currently unsupported.  There is no
     way to quote these special characters.
 
     This function taken with minor modifications from efnmatch.py
     by Donovan Baarda.
 
     """
     # Internal. Used by glob_get_sf, glob_get_prefix_res and unit tests.
 
     assert isinstance(pat, str)
 
-    i, n, res = 0, len(pat), u''
+    i, n, res = 0, len(pat), ''
     while i < n:
         c, s = pat[i], pat[i:i + 2]
         i = i + 1
-        if s == u'**':
-            res = res + u'.*'
+        if s == '**':
+            res = f"{res}.*"
             i = i + 1
-        elif c == u'*':
-            res = res + u'[^/]*'
-        elif c == u'?':
-            res = res + u'[^/]'
-        elif c == u'[':
+        elif c == '*':
+            res = f"{res}[^/]*"
+        elif c == '?':
+            res = f"{res}[^/]"
+        elif c == '[':
             j = i
-            if j < n and pat[j] in u'!^':
+            if j < n and pat[j] in '!^':
                 j = j + 1
-            if j < n and pat[j] == u']':
+            if j < n and pat[j] == ']':
                 j = j + 1
-            while j < n and pat[j] != u']':
+            while j < n and pat[j] != ']':
                 j = j + 1
             if j >= n:
-                res = res + u'\\['  # interpret the [ literally
+                res = f"{res}\\["  # interpret the [ literally
             else:
                 # Deal with inside of [..]
-                stuff = pat[i:j].replace(u'\\', u'\\\\')
+                stuff = pat[i:j].replace('\\', '\\\\')
                 i = j + 1
-                if stuff[0] in u'!^':
-                    stuff = u'^' + stuff[1:]
-                res = res + u'[' + stuff + u']'
+                if stuff[0] in '!^':
+                    stuff = f"^{stuff[1:]}"
+                res = f"{res}[{stuff}]"
         else:
             res = res + re.escape(c)
     return res
```

### Comparing `duplicity-1.2.3.dev43/duplicity/librsync.py` & `duplicity-2.0.0rc0/duplicity/librsync.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,147 +15,140 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Provides a high-level interface to some librsync functions
+"""Provides a high-level interface to some librsync functions
 
 This is a python wrapper around the lower-level _librsync module,
 which is written in C.  The goal was to use C as little as possible...
 
 """
 
-from builtins import object
-from builtins import str
-
 import array
 import os
-import sys
 
 from . import _librsync
 
-if os.environ.get(u'READTHEDOCS') == u'True':
-    import unittest.mock as mock  # pylint: disable=import-error
+if os.environ.get('READTHEDOCS') == 'True':
+    import unittest.mock as mock
     import duplicity
+
     duplicity._librsync = mock.MagicMock()
 
 blocksize = _librsync.RS_JOB_BLOCKSIZE
 
 
 class librsyncError(Exception):
-    u"""Signifies error in internal librsync processing (bad signature, etc.)
+    """Signifies error in internal librsync processing (bad signature, etc.)
 
     underlying _librsync.librsyncError's are regenerated using this
     class because the C-created exceptions are by default
     unPickleable.  There is probably a way to fix this in _librsync,
     but this scheme was easier.
 
     """
     pass
 
 
 class LikeFile(object):
-    u"""File-like object used by SigFile, DeltaFile, and PatchFile"""
-    mode = u"rb"
+    """File-like object used by SigFile, DeltaFile, and PatchFile"""
+    mode = "rb"
 
     # This will be replaced in subclasses by an object with
     # appropriate cycle() method
     maker = None
 
     def __init__(self, infile, need_seek=None):
-        u"""LikeFile initializer - zero buffers, set eofs off"""
+        """LikeFile initializer - zero buffers, set eofs off"""
         self.check_file(infile, need_seek)
         self.infile = infile
         self.closed = self.infile_closed = None
         self.inbuf = b""
-        self.outbuf = array.array(u'b')
+        self.outbuf = array.array('b')
         self.eof = self.infile_eof = None
 
     def check_file(self, file, need_seek=None):
-        u"""Raise type error if file doesn't have necessary attributes"""
-        if not hasattr(file, u"read"):
-            raise TypeError(u"Basis file must have a read() method")
-        if not hasattr(file, u"close"):
-            raise TypeError(u"Basis file must have a close() method")
-        if need_seek and not hasattr(file, u"seek"):
-            raise TypeError(u"Basis file must have a seek() method")
+        """Raise type error if file doesn't have necessary attributes"""
+        if not hasattr(file, "read"):
+            raise TypeError("Basis file must have a read() method")
+        if not hasattr(file, "close"):
+            raise TypeError("Basis file must have a close() method")
+        if need_seek and not hasattr(file, "seek"):
+            raise TypeError("Basis file must have a seek() method")
 
     def read(self, length=-1):
-        u"""Build up self.outbuf, return first length bytes"""
+        """Build up self.outbuf, return first length bytes"""
         if length == -1:
             while not self.eof:
                 self._add_to_outbuf_once()
             real_len = len(self.outbuf)
         else:
             while not self.eof and len(self.outbuf) < length:
                 self._add_to_outbuf_once()
             real_len = min(length, len(self.outbuf))
 
-        if sys.version_info.major >= 3:
-            return_val = self.outbuf[:real_len].tobytes()
-        else:
-            return_val = self.outbuf[:real_len].tostring()
+        return_val = self.outbuf[:real_len].tobytes()
         del self.outbuf[:real_len]
         return return_val
 
     def _add_to_outbuf_once(self):
-        u"""Add one cycle's worth of output to self.outbuf"""
+        """Add one cycle's worth of output to self.outbuf"""
         if not self.infile_eof:
             self._add_to_inbuf()
         try:
             self.eof, len_inbuf_read, cycle_out = self.maker.cycle(self.inbuf)
         except _librsync.librsyncError as e:
             raise librsyncError(str(e))
         self.inbuf = self.inbuf[len_inbuf_read:]
-        if sys.version_info.major >= 3:
-            self.outbuf.frombytes(cycle_out)
-        else:
-            self.outbuf.fromstring(cycle_out)
+        self.outbuf.frombytes(cycle_out)
 
     def _add_to_inbuf(self):
-        u"""Make sure len(self.inbuf) >= blocksize"""
+        """Make sure len(self.inbuf) >= blocksize"""
         assert not self.infile_eof
         while len(self.inbuf) < blocksize:
             new_in = self.infile.read(blocksize)
             if not new_in:
                 self.infile_eof = 1
                 assert not self.infile.close()
                 self.infile_closed = 1
                 break
             self.inbuf += new_in
 
     def close(self):
-        u"""Close infile"""
+        """Close infile"""
         if not self.infile_closed:
             assert not self.infile.close()
         self.closed = 1
 
 
 class SigFile(LikeFile):
-    u"""File-like object which incrementally generates a librsync signature"""
+    """File-like object which incrementally generates a librsync signature"""
+
     def __init__(self, infile, blocksize=_librsync.RS_DEFAULT_BLOCK_LEN):
-        u"""SigFile initializer - takes basis file
+        """SigFile initializer - takes basis file
 
         basis file only needs to have read() and close() methods.  It
         will be closed when we come to the end of the signature.
 
         """
         LikeFile.__init__(self, infile)
         try:
             self.maker = _librsync.new_sigmaker(blocksize)
         except _librsync.librsyncError as e:
             raise librsyncError(str(e))
 
 
 class DeltaFile(LikeFile):
-    u"""File-like object which incrementally generates a librsync delta"""
+    """File-like object which incrementally generates a librsync delta"""
+
     def __init__(self, signature, new_file):
-        u"""DeltaFile initializer - call with signature and new file
+        """DeltaFile initializer - call with signature and new file
 
         Signature can either be a string or a file with read() and
         close() methods.  New_file also only needs to have read() and
         close() methods.  It will be closed when self is closed.
 
         """
         LikeFile.__init__(self, new_file)
@@ -168,77 +161,79 @@
         try:
             self.maker = _librsync.new_deltamaker(sig_string)
         except _librsync.librsyncError as e:
             raise librsyncError(str(e))
 
 
 class PatchedFile(LikeFile):
-    u"""File-like object which applies a librsync delta incrementally"""
+    """File-like object which applies a librsync delta incrementally"""
+
     def __init__(self, basis_file, delta_file):
-        u"""PatchedFile initializer - call with basis delta
+        """PatchedFile initializer - call with basis delta
 
         Here basis_file must be a true Python file, because we may
         need to seek() around in it a lot, and this is done in C.
         delta_file only needs read() and close() methods.
 
         """
         LikeFile.__init__(self, delta_file)
         try:
             basis_file.fileno()
-        except:
-            u""" tempfile.TemporaryFile() only guarantees a true file
+        except Exception as e:
+            """ tempfile.TemporaryFile() only guarantees a true file
             object on posix platforms. on cygwin/windows a file-like
             object whose file attribute is the underlying true file
             object is returned.
             """
-            if hasattr(basis_file, u'file') and hasattr(basis_file.file, u'fileno'):
+            if hasattr(basis_file, 'file') and hasattr(basis_file.file, 'fileno'):
                 basis_file = basis_file.file
             else:
-                raise TypeError(_(u"basis_file must be a (true) file or an object whose "
-                                  u"file attribute is the underlying true file object"))
+                raise TypeError(_("basis_file must be a (true) file or an object whose "
+                                  "file attribute is the underlying true file object"))
         try:
             self.maker = _librsync.new_patchmaker(basis_file)
         except _librsync.librsyncError as e:
             raise librsyncError(str(e))
 
 
 class SigGenerator(object):
-    u"""Calculate signature.
+    """Calculate signature.
 
     Input and output is same as SigFile, but the interface is like md5
     module, not filelike object
 
     """
+
     def __init__(self, blocksize=_librsync.RS_DEFAULT_BLOCK_LEN):
-        u"""Return new signature instance"""
+        """Return new signature instance"""
         try:
             self.sig_maker = _librsync.new_sigmaker(blocksize)
         except _librsync.librsyncError as e:
             raise librsyncError(str(e))
         self.gotsig = None
         self.buffer = b""
         self.sigstring_list = []
 
     def update(self, buf):
-        u"""Add buf to data that signature will be calculated over"""
+        """Add buf to data that signature will be calculated over"""
         if self.gotsig:
-            raise librsyncError(u"SigGenerator already provided signature")
+            raise librsyncError("SigGenerator already provided signature")
         self.buffer += buf
         while len(self.buffer) >= blocksize:
             if self.process_buffer():
-                raise librsyncError(u"Premature EOF received from sig_maker")
+                raise librsyncError("Premature EOF received from sig_maker")
 
     def process_buffer(self):
-        u"""Run self.buffer through sig_maker, add to self.sig_string"""
+        """Run self.buffer through sig_maker, add to self.sig_string"""
         try:
             eof, len_buf_read, cycle_out = self.sig_maker.cycle(self.buffer)
         except _librsync.librsyncError as e:
             raise librsyncError(str(e))
         self.buffer = self.buffer[len_buf_read:]
         self.sigstring_list.append(cycle_out)
         return eof
 
     def getsig(self):
-        u"""Return signature over given data"""
+        """Return signature over given data"""
         while not self.process_buffer():
             pass  # keep running until eof
         return b''.join(self.sigstring_list)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/errors.py` & `duplicity-2.0.0rc0/duplicity/errors.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,86 +15,88 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Error/exception classes that do not fit naturally anywhere else.
 """
 
 from duplicity import log
 
 
 class DuplicityError(Exception):
     pass
 
 
 class UserError(DuplicityError):
-    u"""
+    """
     Subclasses use this in their inheritance hierarchy to signal that
     the error is a user generated one, and that it is therefore
     typically unsuitable to display a full stack trace.
     """
     pass
 
 
 class NotSupported(DuplicityError):
-    u"""
+    """
     Exception raised when an action cannot be completed because some
     particular feature is not supported by the environment.
     """
     pass
 
 
 class ConflictingScheme(DuplicityError):
-    u"""
+    """
     Raised to indicate an attempt was made to register a backend for a
     scheme for which there is already a backend registered.
     """
     pass
 
 
 class InvalidBackendURL(UserError):
-    u"""
+    """
     Raised to indicate a URL was not a valid backend URL.
     """
     pass
 
 
 class UnsupportedBackendScheme(InvalidBackendURL, UserError):
-    u"""
+    """
     Raised to indicate that a backend URL was parsed successfully as a
     URL, but was not supported.
     """
+
     def __init__(self, url):
         InvalidBackendURL.__init__(self,
-                                   (u"scheme not supported in url: %s" % (url,)))
+                                   f"scheme not supported in url: {url}")
         self.url = url
 
 
 class BackendException(DuplicityError):
-    u"""
+    """
     Raised to indicate a backend specific problem.
     """
+
     def __init__(self, msg, code=log.ErrorCode.backend_error):
-        super(BackendException, self).__init__(msg)
+        super().__init__(msg)
         self.code = code
 
 
 class FatalBackendException(BackendException):
-    u"""
+    """
     Raised to indicate a backend failed fatally.
     """
     pass
 
 
 class TemporaryLoadException(BackendException):
-    u"""
+    """
     Raised to indicate a temporary issue on the backend.
     Duplicity should back off for a bit and try again.
     """
     pass
 
 
 class BadVolumeException(DuplicityError):
```

### Comparing `duplicity-1.2.3.dev43/duplicity/tempdir.py` & `duplicity-2.0.0rc0/duplicity/tempdir.py`

 * *Files 8% similar despite different names*

```diff
@@ -15,26 +15,21 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Provides temporary file handling cenetered around a single top-level
 securely created temporary directory.
 
 The public interface of this module is thread-safe.
 """
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import object
-
 import os
 import platform
 import subprocess
 import tempfile
 import threading
 
 from duplicity import config
@@ -47,15 +42,15 @@
 _defaultInstance = None
 # backup the initial tmp dir path because we will force tempfile
 # later to use our generated _defaultInstance.dir() as temproot
 _initialSystemTempRoot = tempfile.gettempdir()
 
 
 def default():
-    u"""
+    """
     Obtain the global default instance of TemporaryDirectory, creating
     it first if necessary. Failures are propagated to caller. Most
     callers are expected to use this function rather than
     instantiating TemporaryDirectory directly, unless they explicitly
     desdire to have their "own" directory for some reason.
 
     This function is thread-safe.
@@ -71,15 +66,15 @@
             tempfile.tempdir = _defaultInstance.dir()
         return _defaultInstance
     finally:
         _defaultLock.release()
 
 
 class TemporaryDirectory(object):
-    u"""
+    """
     A temporary directory.
 
     An instance of this class is backed by a directory in the file
     system created securely by the use of tempfile.mkdtemp(). Said
     instance can be used to obtain unique filenames inside of this
     directory for cases where mktemp()-like semantics is desired, or
     (recommended) an fd,filename pair for mkstemp()-like semantics.
@@ -116,27 +111,29 @@
 
     In addition, since cleanup is in the form of deletion based on a
     list of filenames, completely independently of whether someone
     else already deleted the file, there exists a race here as
     well. The impact should however be limited to the removal of an
     'attackers' file.
     """
+
     def __init__(self, temproot=None):
-        u"""
+        """
         Create a new TemporaryDirectory backed by a unique and
         securely created file system directory.
 
         tempbase - The temp root directory, or None to use system
         default (recommended).
         """
+
         def defaults_to_tmp(path):
-            u'''Determine if path point to a MAcOS system tmp'''
+            """Determine if path point to a MAcOS system tmp"""
             sys_temps = [
-                os.path.realpath(u"/tmp"),
-                os.path.realpath(u"/var/tmp"),
+                os.path.realpath("/tmp"),
+                os.path.realpath("/var/tmp"),
             ]
 
             user_temp = os.path.realpath(path)
             for sys_temp in sys_temps:
                 if user_temp.startswith(sys_temp):
                     return True
             return False
@@ -144,151 +141,151 @@
         if temproot is None:
             if config.temproot:
                 temproot = config.temproot
             else:
                 global _initialSystemTempRoot
                 temproot = _initialSystemTempRoot
         if isinstance(temproot, b"".__class__):
-            temproot = util.fsdecode(temproot)
+            temproot = os.fsdecode(temproot)
 
-        if (platform.system().startswith(u'Darwin') and defaults_to_tmp(temproot)):
+        if platform.system().startswith('Darwin') and defaults_to_tmp(temproot):
             # Use temp space from getconf, never /tmp
-            temproot = subprocess.check_output([u'getconf', u'DARWIN_USER_TEMP_DIR'])
-            temproot = util.fsdecode(temproot).rstrip()
+            temproot = subprocess.check_output(['getconf', 'DARWIN_USER_TEMP_DIR'])
+            temproot = os.fsdecode(temproot).rstrip()
 
-        self.__dir = tempfile.mkdtemp(u"-tempdir", u"duplicity-", temproot)
+        self.__dir = tempfile.mkdtemp("-tempdir", "duplicity-", temproot)
 
-        log.Info(_(u"Using temporary directory %s") % self.__dir)
+        log.Info(_("Using temporary directory %s") % self.__dir)
 
         # number of mktemp()/mkstemp() calls served so far
         self.__tempcount = 0
         # dict of paths pending deletion; use dict even though we are
         # not concearned with association, because it is unclear whether
         # sets are O(1), while dictionaries are.
         self.__pending = {}
 
         self.__lock = threading.Lock()  # protect private resources *AND* mktemp/mkstemp calls
 
     def dir(self):
-        u"""
+        """
         Returns the absolute pathname of the temp folder.
         """
         return self.__dir
 
     def __del__(self):
-        u"""
+        """
         Perform cleanup.
         """
         global _defaultInstance
         if _defaultInstance is not None:
             self.cleanup()
 
     def mktemp(self):
-        u"""
+        """
         Return a unique filename suitable for use for a temporary
         file. The file is not created.
 
         Subsequent calls to this method are guaranteed to never return
         the same filename again. As a result, it is safe to use under
         concurrent conditions.
 
         NOTE: mkstemp() is greatly preferred.
         """
         filename = None
 
         self.__lock.acquire()
         try:
             self.__tempcount = self.__tempcount + 1
-            suffix = u"-%d" % (self.__tempcount,)
-            filename = util.fsencode(tempfile.mktemp(suffix, u"mktemp-", self.__dir))
+            suffix = f"-{int(self.__tempcount)}"
+            filename = os.fsencode(tempfile.mktemp(suffix, "mktemp-", self.__dir))
 
-            log.Debug(_(u"Registering (mktemp) temporary file %s") % util.fsdecode(filename))
+            log.Debug(_("Registering (mktemp) temporary file %s") % os.fsdecode(filename))
             self.__pending[filename] = None
         finally:
             self.__lock.release()
 
         return filename
 
     def mkstemp(self):
-        u"""
+        """
         Returns a filedescriptor and a filename, as per os.mkstemp(),
         but located in the temporary directory and subject to tracking
         and automatic cleanup.
         """
         fd = None
         filename = None
 
         self.__lock.acquire()
         try:
             self.__tempcount = self.__tempcount + 1
-            suffix = u"-%d" % (self.__tempcount,)
-            fd, filename = tempfile.mkstemp(suffix, u"mkstemp-", self.__dir,)
+            suffix = f"-{int(self.__tempcount)}"
+            fd, filename = tempfile.mkstemp(suffix, "mkstemp-", self.__dir, )
 
-            log.Debug(_(u"Registering (mkstemp) temporary file %s") % filename)
+            log.Debug(_("Registering (mkstemp) temporary file %s") % filename)
             self.__pending[filename] = None
         finally:
             self.__lock.release()
 
         return fd, filename
 
     def mkstemp_file(self):
-        u"""
+        """
         Convenience wrapper around mkstemp(), with the file descriptor
         converted into a file object.
         """
         fd, filename = self.mkstemp()
 
-        return os.fdopen(fd, u"r+"), filename
+        return os.fdopen(fd, "r+"), filename
 
     def forget(self, fname):
-        u"""
+        """
         Forget about the given filename previously obtained through
         mktemp() or mkstemp(). This should be called *after* the file
         has been deleted, to stop a future cleanup() from trying to
         delete it.
 
         Forgetting is only needed for scaling purposes; that is, to
         avoid n timefile creations from implying that n filenames are
         kept in memory. Typically this whould never matter in
         duplicity, but for niceness sake callers are recommended to
         use this method whenever possible.
         """
         self.__lock.acquire()
         try:
             if fname in self.__pending:
-                log.Debug(_(u"Forgetting temporary file %s") % util.fsdecode(fname))
+                log.Debug(_("Forgetting temporary file %s") % os.fsdecode(fname))
                 del self.__pending[fname]
             else:
-                log.Warn(_(u"Attempt to forget unknown tempfile %s - this is probably a bug.") % util.fsdecode(fname))
+                log.Warn(_("Attempt to forget unknown tempfile %s - this is probably a bug.") % os.fsdecode(fname))
                 pass
         finally:
             self.__lock.release()
 
     def cleanup(self):
-        u"""
+        """
         Cleanup any files created in the temporary directory (that
         have not been forgotten), and clean up the temporary directory
         itself.
 
         On failure they are logged, but this method will not raise an
         exception.
         """
         self.__lock.acquire()
         try:
             if self.__dir is not None:
                 for file in list(self.__pending.keys()):
                     try:
-                        log.Debug(_(u"Removing still remembered temporary file %s") % util.fsdecode(file))
+                        log.Debug(_("Removing still remembered temporary file %s") % os.fsdecode(file))
                         util.ignore_missing(os.unlink, file)
                     except Exception:
-                        log.Info(_(u"Cleanup of temporary file %s failed") % util.fsdecode(file))
+                        log.Info(_("Cleanup of temporary file %s failed") % os.fsdecode(file))
                         pass
                 try:
                     os.rmdir(self.__dir)
                 except Exception:
-                    log.Warn(_(u"Cleanup of temporary directory %s failed - "
-                               u"this is probably a bug.") % util.fsdecode(self.__dir))
+                    log.Warn(_("Cleanup of temporary directory %s failed - "
+                               "this is probably a bug.") % os.fsdecode(self.__dir))
                     pass
                 self.__pending = None
                 self.__dir = None
         finally:
             self.__lock.release()
```

### Comparing `duplicity-1.2.3.dev43/duplicity/tarfile.py` & `duplicity-2.0.0rc0/duplicity/tarfile.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,17 +14,15 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Like system tarfile but with caching."""
-
-from __future__ import absolute_import
+"""Like system tarfile but with caching."""
 
 import tarfile
 from duplicity import cached_ops
 
 # Grab all symbols in tarfile, to try to reproduce its API exactly.
 # from <> import * wouldn't get everything we want, since tarfile defines
 # __all__.  So we do it ourselves.
```

### Comparing `duplicity-1.2.3.dev43/duplicity/progress.py` & `duplicity-2.0.0rc0/duplicity/progress.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,30 +17,29 @@
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 #
 # @author: Juan Antonio Moya Vicen <juan@nowcomputing.com>
 #
-u"""
+"""
 Functions to compute progress of compress & upload files
 The heuristics try to infer the ratio between the amount of data collected
 by the deltas and the total size of the changing files. It also infers the
 compression and encryption ration of the raw deltas before sending them to
 the backend.
 With the inferred ratios, the heuristics estimate the percentage of completion
 and the time left to transfer all the (yet unknown) amount of data to send.
 This is a forecast based on gathered evidence.
 """
 
-from __future__ import absolute_import
-from __future__ import division
-from builtins import object
-
-from datetime import datetime, timedelta
+from datetime import (
+    datetime,
+    timedelta,
+)
 import collections as sys_collections
 import math
 import pickle
 import threading
 import time
 
 from duplicity import config
@@ -48,48 +47,50 @@
 from duplicity import util
 
 tracker = None
 progress_thread = None
 
 
 class Snapshot(sys_collections.deque):
-    u"""
+    """
     A convenience class for storing snapshots in a space/timing efficient manner
     Stores up to 10 consecutive progress snapshots, one for each volume
     """
 
     @staticmethod
     def unmarshall():
-        u"""
+        """
         De-serializes cached data it if present
         """
         snapshot = Snapshot()
         # If restarting Full, discard marshalled data and start over
         if config.restart is not None and config.restart.start_vol >= 1:
             try:
-                progressfd = open(u'%s/progress' % config.archive_dir_path.name, u'r')
+                progressfd = open(f'{config.archive_dir_path.name}/progress', 'r')
                 snapshot = pickle.load(progressfd)
                 progressfd.close()
             except Exception as e:
-                log.Warn(u"Warning, cannot read stored progress info from previous backup: {}".format(util.uexc(e)),
+                log.Warn(f"Warning, cannot read stored progress info from previous backup: {util.uexc(e)}",
                          log.WarningCode.cannot_stat)
                 snapshot = Snapshot()
         # Reached here no cached data found or wrong marshalling
         return snapshot
 
     def marshall(self):
-        u"""
+        """
         Serializes object to cache
         """
-        progressfd = open(b'%s/progress' % config.archive_dir_path.name, u'wb+')
+        progressfd = open(b'%s/progress' % config.archive_dir_path.name, 'wb+')
         pickle.dump(self, progressfd)
         progressfd.close()
 
-    def __init__(self, iterable=[], maxlen=10):
-        super(Snapshot, self).__init__(iterable, maxlen)
+    def __init__(self, iterable=None, maxlen=10):
+        if iterable is None:
+            iterable = []
+        super().__init__(iterable, maxlen)
         self.last_vol = 0
 
     def get_snapshot(self, volume):
         nitems = len(self)
         if nitems <= 0:
             return 0.0
         return self[max(0, min(nitems + volume - self.last_vol - 1, nitems - 1))]
@@ -98,15 +99,15 @@
         self.append(snapshot_data)
         self.last_vol = volume
 
     def pop_snapshot(self):
         return self.popleft()
 
     def clear(self):
-        super(Snapshot, self).clear()
+        super().clear()
         self.last_vol = 0
 
 
 class ProgressTracker(object):
 
     def __init__(self):
         self.total_stats = None
@@ -126,32 +127,32 @@
         self.transfers = sys_collections.deque()
         self.is_full = False
         self.current_estimation = 0.0
         self.prev_estimation = 0.0
         self.prev_data = None
 
     def snapshot_progress(self, volume):
-        u"""
+        """
         Snapshots the current progress status for each volume into the disk cache
         If backup is interrupted, next restart will deserialize the data and try start
         progress from the snapshot
         """
         if self.prev_data is not None:
             self.prev_data.push_snapshot(volume, self.progress_estimation)
             self.prev_data.marshall()
 
     def has_collected_evidence(self):
-        u"""
+        """
         Returns true if the progress computation is on and duplicity has not
         yet started the first dry-run pass to collect some information
         """
-        return (self.total_stats is not None)
+        return self.total_stats is not None
 
     def log_upload_progress(self):
-        u"""
+        """
         Aproximative and evolving method of computing the progress of upload
         """
         if not config.progress or not self.has_collected_evidence():
             return
 
         current_time = datetime.now()
         if self.start_time is None:
@@ -172,15 +173,15 @@
                                  self.speed,
                                  True
                                  )
             return
 
         self.nsteps += 1
 
-        u"""
+        """
         Compute the ratio of information being written for deltas vs file sizes
         Using Knuth algorithm to estimate approximate upper bound in % of completion
         The progress is estimated on the current bytes written vs the total bytes to
         change as estimated by a first-dry-run. The weight is the ratio of changing
         data (Delta) against the total file sizes. (pessimistic estimation)
         The method computes the upper bound for the progress, when using a sufficient
         large volsize to accomodate and changes, as using a small volsize may inject
@@ -202,52 +203,52 @@
             # Compute mean ratio of data transfer, estimating unknown progress
             change_ratio = float(self.total_bytecount) / float(diffdir.stats.RawDeltaSize)
             change_delta = change_ratio - self.change_mean_ratio
             self.change_mean_ratio += change_delta / float(self.nsteps)  # mean cumulated ratio
             self.change_r_estimation += change_delta * (change_ratio - self.change_mean_ratio)
             change_sigma = math.sqrt(math.fabs(self.change_r_estimation / float(self.nsteps)))
 
-            u"""
+            """
             Combine variables for progress estimation
             Fit a smoothed curve that covers the most common data density distributions,
             aiming for a large number of incremental changes.
             The computation is:
                 Use 50% confidence interval lower bound during first half of the progression.
                 Conversely, use 50% C.I. upper bound during the second half. Scale it to the
                 changes/total ratio
             """
             self.current_estimation = float(changes) / float(total_changes) * (
                 (self.change_mean_ratio - 0.67 * change_sigma) * (1.0 - self.current_estimation) +
                 (self.change_mean_ratio + 0.67 * change_sigma) * self.current_estimation
             )
-            u"""
+            """
             In case that we overpassed the 100%, drop the confidence and trust more the mean as the
             sigma may be large.
             """
             if self.current_estimation > 1.0:
                 self.current_estimation = float(changes) / float(total_changes) * (
                     (self.change_mean_ratio - 0.33 * change_sigma) * (1.0 - self.current_estimation) +
                     (self.change_mean_ratio + 0.33 * change_sigma) * self.current_estimation
                 )
-            u"""
+            """
             Meh!, if again overpassed the 100%, drop the confidence to 0 and trust only the mean.
             """
             if self.current_estimation > 1.0:
                 self.current_estimation = self.change_mean_ratio * float(changes) / float(total_changes)
 
-        u"""
+        """
         Lastly, just cap it... nothing else we can do to approximate it better.
         Cap it to 99%, as the remaining 1% to 100% we reserve for the last step
         uploading of signature and manifests
         """
         self.progress_estimation = max(0.0, min(self.prev_estimation +
                                                 (1.0 - self.prev_estimation) *
                                                 self.current_estimation, 0.99))
 
-        u"""
+        """
         Estimate the time just as a projection of the remaining time, fit to a
         [(1 - x) / x] curve
         """
         # As sum of timedeltas, so as to avoid clock skew in long runs
         # (adding also microseconds)
         self.elapsed_sum += elapsed
         projection = 1.0
@@ -255,15 +256,15 @@
             projection = (1.0 - self.progress_estimation) / self.progress_estimation
         self.time_estimation = int(projection * float(self.elapsed_sum.total_seconds()))
 
         # Apply values only when monotonic, so the estimates look more consistent to the human eye
         if self.progress_estimation < last_progress_estimation:
             self.progress_estimation = last_progress_estimation
 
-        u"""
+        """
         Compute Exponential Moving Average of speed as bytes/sec of the last 30 probes
         """
         if elapsed.total_seconds() > 0:
             self.transfers.append(float(self.total_bytecount - self.last_total_bytecount) /
                                   float(elapsed.total_seconds()))
         self.last_total_bytecount = self.total_bytecount
         if len(self.transfers) > 30:
@@ -277,66 +278,67 @@
                              self.total_bytecount,
                              (current_time - self.start_time).seconds,
                              self.speed,
                              False
                              )
 
     def annotate_written_bytes(self, bytecount):
-        u"""
+        """
         Annotate the number of bytes that have been added/changed since last time
         this function was called.
         bytecount param will show the number of bytes since the start of the current
         volume and for the current volume
         """
         changing = max(bytecount - self.last_bytecount, 0)
         self.total_bytecount += int(changing)  # Annotate only changing bytes since last probe
         self.last_bytecount = bytecount
         if changing > 0:
             self.stall_last_time = datetime.now()
 
     def set_evidence(self, stats, is_full):
-        u"""
+        """
         Stores the collected statistics from a first-pass dry-run, to use this
         information later so as to estimate progress
         """
         self.total_stats = stats
         self.is_full = is_full
 
     def set_start_volume(self, volume):
         self.prev_data = Snapshot.unmarshall()
         self.prev_estimation = self.prev_data.get_snapshot(volume)
         self.progress_estimation = max(0.0, min(self.prev_estimation, 0.99))
 
     def total_elapsed_seconds(self):
-        u"""
+        """
         Elapsed seconds since the first call to log_upload_progress method
         """
         return (datetime.now() - self.start_time).seconds
 
 
 def report_transfer(bytecount, totalbytes):  # pylint: disable=unused-argument
-    u"""
+    """
     Method to call tracker.annotate_written_bytes from outside
     the class, and to offer the "function(long, long)" signature
     which is handy to pass as callback
     """
     global tracker
     global progress_thread
     if progress_thread is not None and tracker is not None:
         tracker.annotate_written_bytes(bytecount)
 
 
 class LogProgressThread(threading.Thread):
-    u"""
+    """
     Background thread that reports progress to the log,
     every --progress-rate seconds
     """
+
     def __init__(self):
-        super(LogProgressThread, self).__init__()
-        self.setDaemon(True)
+        super().__init__()
+        self.daemon = True
         self.finished = False
 
     def run(self):
         global tracker
         if not config.dry_run and config.progress and tracker.has_collected_evidence():
             while not self.finished:
                 tracker.log_upload_progress()
```

### Comparing `duplicity-1.2.3.dev43/duplicity/gpg.py` & `duplicity-2.0.0rc0/duplicity/gpg.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,67 +15,61 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 duplicity's gpg interface, builds upon Frank Tobin's GnuPGInterface
 which is now patched with some code for iterative threaded execution
 see duplicity's README for details
 """
 
-from builtins import next
-from builtins import str
-from builtins import object
-import os
-import sys
-import tempfile
-import re
 import gzip
 import locale
+import os
+import re
+import tempfile
 
 from duplicity import config
 from duplicity import gpginterface
+from duplicity import log
 from duplicity import tempdir
 from duplicity import util
 
-try:
-    from hashlib import sha1
-    from hashlib import md5
-except ImportError:
-    from sha import new as sha1
-    from md5 import new as md5
+from hashlib import sha1
+from hashlib import md5
 
 blocksize = 256 * 1024
 
 
 class GPGError(Exception):
-    u"""
+    """
     Indicate some GPG Error
     """
     pass
 
 
 class GPGProfile(object):
-    u"""
+    """
     Just hold some GPG settings, avoid passing tons of arguments
     """
+
     def __init__(self, passphrase=None, sign_key=None,
                  recipients=None, hidden_recipients=None):
-        u"""
+        """
         Set all data with initializer
 
         passphrase is the passphrase.  If it is None (not ""), assume
         it hasn't been set.  sign_key can be blank if no signing is
         indicated, and recipients should be a list of keys.  For all
         keys, the format should be an hex key like 'AA0E73D2'.
         """
-        assert passphrase is None or isinstance(passphrase, (str, u"".__class__))
+        assert passphrase is None or isinstance(passphrase, str)
 
         self.passphrase = passphrase
         self.signing_passphrase = passphrase
         self.sign_key = sign_key
         self.encrypt_secring = None
         if recipients is not None:
             assert isinstance(recipients, list)  # must be list, not tuple
@@ -101,28 +95,29 @@
 
         # user supplied options
         if config.gpg_options:
             for opt in config.gpg_options.split():
                 gnupg.options.extra_args.append(opt)
 
         # get gpg version
-        res = gnupg.run([u"--version"], create_fhs=[u"stdout"])
-        line = res.handles[u"stdout"].readline().rstrip()
+        res = gnupg.run(["--version"], create_fhs=["stdout"])
+        line = res.handles["stdout"].readline().rstrip()
         m = self._version_re.search(line)
         if m is not None:
-            return int(m.group(u"maj")), int(m.group(u"min")), int(m.group(u"bug"))
-        raise GPGError(u"failed to determine gnupg version of %s from %s" % (binary, line))
+            return int(m.group("maj")), int(m.group("min")), int(m.group("bug"))
+        raise GPGError(f"failed to determine gnupg version of {binary} from {line}")
 
 
 class GPGFile(object):
-    u"""
+    """
     File-like object that encrypts decrypts another file on the fly
     """
+
     def __init__(self, encrypt, encrypt_path, profile):
-        u"""
+        """
         GPGFile initializer
 
         If recipients is set, use public key encryption and encrypt to
         the given keys.  Otherwise, use symmetric encryption.
 
         encrypt_path is the Path of the gpg encrypted file.  Right now
         only symmetric encryption/decryption is supported.
@@ -139,101 +134,104 @@
 
         # Start GPG process - copied from GnuPGInterface docstring.
         gnupg = gpginterface.GnuPG()
         # overrides default gpg binary 'gpg'
         if config.gpg_binary is not None:
             gnupg.call = config.gpg_binary
         gnupg.options.meta_interactive = 0
-        gnupg.options.extra_args.append(u'--no-secmem-warning')
-        gnupg.options.extra_args.append(u'--ignore-mdc-error')
+        gnupg.options.extra_args.append('--no-secmem-warning')
+        gnupg.options.extra_args.append('--ignore-mdc-error')
 
         # Support three versions of gpg present 1.x, 2.0.x, 2.1.x
         if profile.gpg_version[:1] == (1,):
             if config.use_agent:
                 # gpg1 agent use is optional
-                gnupg.options.extra_args.append(u'--use-agent')
+                gnupg.options.extra_args.append('--use-agent')
 
         elif profile.gpg_version[:2] == (2, 0):
             pass
 
         elif profile.gpg_version[:2] >= (2, 1):
             if not config.use_agent:
                 # This forces gpg2 to ignore the agent.
                 # Necessary to enforce truly non-interactive operation.
-                gnupg.options.extra_args.append(u'--pinentry-mode=loopback')
+                gnupg.options.extra_args.append('--pinentry-mode=loopback')
 
         else:
-            raise GPGError(u"Unsupported GNUPG version, %s" % profile.gpg_version)
+            raise GPGError(f"Unsupported GNUPG version, {profile.gpg_version}")
 
         # user supplied options
         if config.gpg_options:
             for opt in config.gpg_options.split():
                 gnupg.options.extra_args.append(opt)
 
         cmdlist = []
         if profile.sign_key:
             gnupg.options.default_key = profile.sign_key
-            cmdlist.append(u"--sign")
+            cmdlist.append("--sign")
         # encrypt: sign key needs passphrase
         # decrypt: encrypt key needs passphrase
         # special case: allow different symmetric pass with empty sign pass
         if encrypt and profile.sign_key and profile.signing_passphrase:
             passphrase = profile.signing_passphrase
         else:
             passphrase = profile.passphrase
         # in case the passphrase is not set, pass an empty one to prevent
         # TypeError: expected a character buffer object on .write()
         if passphrase is None:
-            passphrase = u""
+            passphrase = ""
 
         if encrypt:
             if profile.recipients:
                 gnupg.options.recipients = profile.recipients
             if profile.hidden_recipients:
                 gnupg.options.hidden_recipients = profile.hidden_recipients
             if profile.recipients or profile.hidden_recipients:
-                cmdlist.append(u'--encrypt')
+                cmdlist.append('--encrypt')
             else:
-                cmdlist.append(u'--symmetric')
+                cmdlist.append('--symmetric')
             # use integrity protection
-            gnupg.options.extra_args.append(u'--force-mdc')
+            gnupg.options.extra_args.append('--force-mdc')
             # Skip the passphrase if using the agent
             if config.use_agent:
-                gnupg_fhs = [u'stdin', ]
+                gnupg_fhs = ['stdin', ]
             else:
-                gnupg_fhs = [u'stdin', u'passphrase']
+                gnupg_fhs = ['stdin', 'passphrase']
+            # Turn off compression if needed
+            if not config.compression:
+                cmdlist.append('--compress-algo=none')
             p1 = gnupg.run(cmdlist,
                            create_fhs=gnupg_fhs,
-                           attach_fhs={u'stdout': encrypt_path.open(u"wb"),
-                                       u'stderr': self.stderr_fp})
+                           attach_fhs={'stdout': encrypt_path.open("wb"),
+                                       'stderr': self.stderr_fp})
             if not config.use_agent:
-                p1.handles[u'passphrase'].write(passphrase)
-                p1.handles[u'passphrase'].close()
-            self.gpg_input = p1.handles[u'stdin']
+                p1.handles['passphrase'].write(passphrase)
+                p1.handles['passphrase'].close()
+            self.gpg_input = p1.handles['stdin']
         else:
             if (profile.recipients or profile.hidden_recipients) and profile.encrypt_secring:
-                cmdlist.append(u'--secret-keyring')
+                cmdlist.append('--secret-keyring')
                 cmdlist.append(profile.encrypt_secring)
-            gpg_attach = {u'stdin': encrypt_path.open(u"rb"),
-                          u'stderr': self.stderr_fp}
+            gpg_attach = {'stdin': encrypt_path.open("rb"),
+                          'stderr': self.stderr_fp}
             if profile.sign_key:
                 self.status_fp = tempfile.TemporaryFile(dir=tempdir.default().dir())
-                gpg_attach[u'status'] = self.status_fp
+                gpg_attach['status'] = self.status_fp
             # Skip the passphrase if using the agent
             if config.use_agent:
-                gnupg_fhs = [u'stdout', ]
+                gnupg_fhs = ['stdout', ]
             else:
-                gnupg_fhs = [u'stdout', u'passphrase']
-            p1 = gnupg.run([u'--decrypt'],
+                gnupg_fhs = ['stdout', 'passphrase']
+            p1 = gnupg.run(['--decrypt'],
                            create_fhs=gnupg_fhs,
                            attach_fhs=gpg_attach)
             if not config.use_agent:
-                p1.handles[u'passphrase'].write(passphrase)
-                p1.handles[u'passphrase'].close()
-            self.gpg_output = p1.handles[u'stdout']
+                p1.handles['passphrase'].write(passphrase)
+                p1.handles['passphrase'].close()
+            self.gpg_output = p1.handles['stdout']
         self.gpg_process = p1
         self.encrypt = encrypt
 
     def read(self, length=-1):
         try:
             res = self.gpg_output.read(length)
             if res is not None:
@@ -242,45 +240,42 @@
             self.gpg_failed()
         return res
 
     def write(self, buf):
         try:
             res = self.gpg_input.write(buf)
             if res is not None:
-                if sys.version_info.major >= 3:
-                    self.byte_count += res
-                else:
-                    self.byte_count += len(res)
+                self.byte_count += res
         except Exception:
             self.gpg_failed()
         return res
 
     def tell(self):
         return self.byte_count
 
     def seek(self, offset):
         assert not self.encrypt
-        assert offset >= self.byte_count, u"%d < %d" % (offset, self.byte_count)
+        assert offset >= self.byte_count, f"{int(offset)} < {int(self.byte_count)}"
         if offset > self.byte_count:
             self.read(offset - self.byte_count)
 
     def gpg_failed(self):
-        msg = u"GPG Failed, see log below:\n"
-        msg += u"===== Begin GnuPG log =====\n"
+        msg = "GPG Failed, see log below:\n"
+        msg += "===== Begin GnuPG log =====\n"
         self.stderr_fp.seek(0)
         for line in self.stderr_fp:
             try:
-                msg += str(line.strip(), locale.getpreferredencoding(), u'replace') + u"\n"
+                msg += f"{str(line.strip(), locale.getpreferredencoding(), u'replace')}\n"
             except Exception as e:
-                msg += line.strip() + u"\n"
-        msg += u"===== End GnuPG log =====\n"
-        if not (msg.find(u"invalid packet (ctb=14)") > -1):
+                msg += f"{line.strip()}\n"
+        msg += "===== End GnuPG log =====\n"
+        if not (msg.find("invalid packet (ctb=14)") > -1):
             raise GPGError(msg)
         else:
-            return u""
+            return ""
 
     def close(self):
         if self.encrypt:
             try:
                 self.gpg_input.close()
             except Exception:
                 self.gpg_failed()
@@ -308,42 +303,42 @@
                 self.gpg_process.wait()
             except Exception:
                 self.gpg_failed()
         self.stderr_fp.close()
         self.closed = 1
 
     def set_signature(self):
-        u"""
+        """
         Set self.signature to signature keyID
 
         This only applies to decrypted files.  If the file was not
         signed, set self.signature to None.
         """
         self.status_fp.seek(0)
         status_buf = self.status_fp.read()
-        match = re.search(b"^\\[GNUPG:\\] GOODSIG ([0-9A-F]*)",
+        match = re.search(b"GOODSIG ([0-9A-F]*)",
                           status_buf, re.M)
         if not match:
             self.signature = None
         else:
             assert len(match.group(1)) >= 8
             self.signature = match.group(1).decode()
 
     def get_signature(self):
-        u"""
+        """
         Return  keyID of signature, or None if none
         """
         assert self.closed
         return self.signature
 
 
 def GPGWriteFile(block_iter, filename, profile,
                  size=200 * 1024 * 1024,
                  max_footer_size=16 * 1024):
-    u"""
+    """
     Write GPG compressed file of given size
 
     This function writes a gpg compressed file by reading from the
     input iter and writing to filename.  When it has read an amount
     close to the size limit, it "tops off" the incoming data with
     incompressible data, to try to hit the limit exactly.
 
@@ -359,22 +354,22 @@
     Returns true if succeeded in writing until end of block_iter.
     """
 
     # workaround for circular module imports
     from duplicity import path
 
     def top_off(bytelen, file):
-        u"""
+        """
         Add bytelen of incompressible data to to_gpg_fp
 
         In this case we take the incompressible data from the
         beginning of filename (it should contain enough because size
         >> largest block size).
         """
-        incompressible_fp = open(filename, u"rb")
+        incompressible_fp = open(filename, "rb")
         assert util.copyfileobj(incompressible_fp, file.gpg_input, bytelen) == bytelen
         incompressible_fp.close()
 
     def get_current_size():
         return os.stat(filename).st_size
 
     target_size = size - 50 * 1024  # fudge factor, compensate for gpg buffering
@@ -387,14 +382,16 @@
             if bytes_to_go < block_iter.get_read_size():
                 break
             try:
                 data = block_iter.__next__().data
             except StopIteration:
                 at_end_of_blockiter = 1
                 break
+            except Exception as e:
+                log.FatalError(f"Read error on {filename}: {str(e)}")
             file.write(data)
 
         file.write(block_iter.get_footer())
         if not at_end_of_blockiter:
             # don't pad last volume
             cursize = get_current_size()
             if cursize < target_size:
@@ -404,46 +401,48 @@
     except Exception:
         # ensure that GPG processing terminates
         file.close()
         raise
 
 
 def GzipWriteFile(block_iter, filename, size=200 * 1024 * 1024, gzipped=True):
-    u"""
+    """
     Write gzipped compressed file of given size
 
     This is like the earlier GPGWriteFile except it writes a gzipped
     file instead of a gpg'd file.  This function is somewhat out of
     place, because it doesn't deal with GPG at all, but it is very
     similar to GPGWriteFile so they might as well be defined together.
 
     The input requirements on block_iter and the output is the same as
     GPGWriteFile (returns true if wrote until end of block_iter).
     """
+
     class FileCounted(object):
-        u"""
+        """
         Wrapper around file object that counts number of bytes written
         """
+
         def __init__(self, fileobj):
             self.fileobj = fileobj
             self.byte_count = 0
 
         def write(self, buf):
             result = self.fileobj.write(buf)
             self.byte_count += len(buf)
             return result
 
         def close(self):
             return self.fileobj.close()
 
-    file_counted = FileCounted(open(filename, u"wb"))
+    file_counted = FileCounted(open(filename, "wb"))
 
     # if gzipped wrap with GzipFile else plain file out
     if gzipped:
-        outfile = gzip.GzipFile(None, u"wb", 6, file_counted)
+        outfile = gzip.GzipFile(None, "wb", 6, file_counted)
     else:
         outfile = file_counted
     at_end_of_blockiter = 0
     while True:
         bytes_to_go = size - file_counted.byte_count
         if bytes_to_go < block_iter.get_read_size():
             break
@@ -455,45 +454,45 @@
         outfile.write(new_block.data)
 
     assert not outfile.close() and not file_counted.close()
     return at_end_of_blockiter
 
 
 def PlainWriteFile(block_iter, filename, size=200 * 1024 * 1024, gzipped=False):
-    u"""
+    """
     Write plain uncompressed file of given size
 
     This is like the earlier GPGWriteFile except it writes a gzipped
     file instead of a gpg'd file.  This function is somewhat out of
     place, because it doesn't deal with GPG at all, but it is very
     similar to GPGWriteFile so they might as well be defined together.
 
     The input requirements on block_iter and the output is the same as
     GPGWriteFile (returns true if wrote until end of block_iter).
     """
     return GzipWriteFile(block_iter, filename, size, gzipped)
 
 
 def get_hash(hash, path, hex=1):  # pylint: disable=redefined-builtin
-    u"""
+    """
     Return hash of path
 
     hash should be "MD5" or "SHA1".  The output will be in hexadecimal
     form if hex is true, and in text (base64) otherwise.
     """
     # assert path.isreg()
-    fp = path.open(u"rb")
-    if hash == u"SHA1":
+    fp = path.open("rb")
+    if hash == "SHA1":
         hash_obj = sha1()
-    elif hash == u"MD5":
+    elif hash == "MD5":
         hash_obj = md5()
     else:
-        assert 0, u"Unknown hash %s" % (hash,)
+        assert 0, f"Unknown hash {hash}"
 
-    while 1:
+    while True:
         buf = fp.read(blocksize)
         if not buf:
             break
         hash_obj.update(buf)
     assert not fp.close()
     if hex:
         return hash_obj.hexdigest()
```

### Comparing `duplicity-1.2.3.dev43/duplicity/filechunkio.py` & `duplicity-2.0.0rc0/duplicity/filechunkio.py`

 * *Files 7% similar despite different names*

```diff
@@ -4,77 +4,77 @@
 #
 # This module is included with granted permission from the original author.
 # The original source is available at http://bitbucket.org/fabian/filechunkio
 
 import io
 import os
 
-
-SEEK_SET = getattr(io, u'SEEK_SET', 0)
-SEEK_CUR = getattr(io, u'SEEK_CUR', 1)
-SEEK_END = getattr(io, u'SEEK_END', 2)
+SEEK_SET = getattr(io, 'SEEK_SET', 0)
+SEEK_CUR = getattr(io, 'SEEK_CUR', 1)
+SEEK_END = getattr(io, 'SEEK_END', 2)
 
 
 class FileChunkIO(io.FileIO):
-    u"""
+    """
     A class that allows you reading only a chunk of a file.
     """
-    def __init__(self, name, mode=u'r', closefd=True, offset=0, bytes=None,  # pylint: disable=redefined-builtin
+
+    def __init__(self, name, mode='r', closefd=True, offset=0, bytes=None,  # pylint: disable=redefined-builtin
                  *args, **kwargs):  # pylint: disable=redefined-builtin
-        u"""
+        """
         Open a file chunk. The mode can only be 'r' for reading. Offset
         is the amount of bytes that the chunks starts after the real file's
         first byte. Bytes defines the amount of bytes the chunk has, which you
         can set to None to include the last byte of the real file.
         """
-        if not mode.startswith(u'r'):
-            raise ValueError(u"Mode string must begin with 'r'")
+        if not mode.startswith('r'):
+            raise ValueError("Mode string must begin with 'r'")
         self.offset = offset
         self.bytes = bytes
         if bytes is None:
             self.bytes = os.stat(name).st_size - self.offset
-        super(FileChunkIO, self).__init__(os.fsdecode(name), mode, closefd, *args, **kwargs)
+        super().__init__(os.fsdecode(name), mode, closefd, *args, **kwargs)
         self.seek(0)
 
     def seek(self, offset, whence=SEEK_SET):
-        u"""
+        """
         Move to a new chunk position.
         """
         if whence == SEEK_SET:
-            super(FileChunkIO, self).seek(self.offset + offset)
+            super().seek(self.offset + offset)
         elif whence == SEEK_CUR:
             self.seek(self.tell() + offset)
         elif whence == SEEK_END:
             self.seek(self.bytes + offset)
 
     def tell(self):
-        u"""
+        """
         Current file position.
         """
-        return super(FileChunkIO, self).tell() - self.offset
+        return super().tell() - self.offset
 
     def read(self, n=-1):
-        u"""
+        """
         Read and return at most n bytes.
         """
         if n >= 0:
             max_n = self.bytes - self.tell()
             n = min([n, max_n])
-            return super(FileChunkIO, self).read(n)
+            return super().read(n)
         else:
             return self.readall()
 
     def readall(self):
-        u"""
+        """
         Read all data from the chunk.
         """
         return self.read(self.bytes - self.tell())
 
     def readinto(self, b):
-        u"""
+        """
         Same as RawIOBase.readinto().
         """
         data = self.read(len(b))
         n = len(data)
         try:
             b[:n] = data
         except TypeError as err:
```

### Comparing `duplicity-1.2.3.dev43/duplicity/patchdir.py` & `duplicity-2.0.0rc0/duplicity/patchdir.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,57 +15,45 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import map
-from builtins import next
-from builtins import object
-from builtins import range
 
-import re
-import sys
 import tempfile
 
-from duplicity import errors
 from duplicity import diffdir
-from duplicity import config
-from duplicity import librsync
-from duplicity import log
+from duplicity import errors
 from duplicity import selection
-from duplicity import tarfile
 from duplicity import tempdir
-from duplicity import util
-from duplicity.lazy import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 from duplicity.path import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 
-u"""Functions for patching of directories"""
+"""Functions for patching of directories"""
 
 
 class PatchDirException(Exception):
     pass
 
 
 def Patch(base_path, difftar_fileobj):
-    u"""Patch given base_path and file object containing delta"""
-    diff_tarfile = tarfile.TarFile(u"arbitrary", u"r", difftar_fileobj)
+    """Patch given base_path and file object containing delta"""
+    diff_tarfile = tarfile.TarFile("arbitrary", "r", difftar_fileobj)
     patch_diff_tarfile(base_path, diff_tarfile)
     assert not difftar_fileobj.close()
 
 
 def Patch_from_iter(base_path, fileobj_iter, restrict_index=()):
-    u"""Patch given base_path and iterator of delta file objects"""
+    """Patch given base_path and iterator of delta file objects"""
     diff_tarfile = TarFile_FromFileobjs(fileobj_iter)
     patch_diff_tarfile(base_path, diff_tarfile, restrict_index)
 
 
 def patch_diff_tarfile(base_path, diff_tarfile, restrict_index=()):
-    u"""Patch given Path object using delta tarfile (as in tarfile.TarFile)
+    """Patch given Path object using delta tarfile (as in tarfile.TarFile)
 
     If restrict_index is set, ignore any deltas in diff_tarfile that
     don't start with restrict_index.
 
     """
     if base_path.exists():
         path_iter = selection.Select(base_path).set_iter()
@@ -76,73 +64,73 @@
     if restrict_index:
         diff_path_iter = filter_path_iter(diff_path_iter, restrict_index)
     collated = diffdir.collate2iters(path_iter, diff_path_iter)
 
     ITR = IterTreeReducer(PathPatcher, [base_path])
     for basis_path, diff_ropath in collated:
         if basis_path:
-            log.Info(_(u"Patching %s") % (util.fsdecode(basis_path.get_relative_path())),
+            log.Info(_("Patching %s") % (os.fsdecode(basis_path.get_relative_path())),
                      log.InfoCode.patch_file_patching,
                      util.escape(basis_path.get_relative_path()))
             ITR(basis_path.index, basis_path, diff_ropath)
         else:
-            log.Info(_(u"Patching %s") % (util.fsdecode(diff_ropath.get_relative_path())),
+            log.Info(_("Patching %s") % (os.fsdecode(diff_ropath.get_relative_path())),
                      log.InfoCode.patch_file_patching,
                      util.escape(diff_ropath.get_relative_path()))
             ITR(diff_ropath.index, basis_path, diff_ropath)
     ITR.Finish()
     base_path.setdata()
 
 
 def empty_iter():
     if 0:
         yield 1  # this never happens, but fools into generator treatment
 
 
 def filter_path_iter(path_iter, index):
-    u"""Rewrite path elements of path_iter so they start with index
+    """Rewrite path elements of path_iter so they start with index
 
     Discard any that doesn't start with index, and remove the index
     prefix from the rest.
 
     """
     assert isinstance(index, tuple) and index, index
     l = len(index)
     for path in path_iter:
         if path.index[:l] == index:
             path.index = path.index[l:]
             yield path
 
 
 def difftar2path_iter(diff_tarfile):
-    u"""Turn file-like difftarobj into iterator of ROPaths"""
+    """Turn file-like difftarobj into iterator of ROPaths"""
     tar_iter = iter(diff_tarfile)
     multivol_fileobj = None
 
     # The next tar_info is stored in this one element list so
     # Multivol_Filelike below can update it.  Any StopIterations will
     # be passed upwards.
     try:
         tarinfo_list = [next(tar_iter)]
     except StopIteration:
         return
 
-    while 1:
+    while True:
         # This section relevant when a multivol diff is last in tar
         if not tarinfo_list[0]:
             return
         if multivol_fileobj and not multivol_fileobj.at_end:
             multivol_fileobj.close()  # aborting in middle of multivol
             continue
 
         index, difftype, multivol = get_index_from_tarinfo(tarinfo_list[0])
         ropath = ROPath(index)
         ropath.init_from_tarinfo(tarinfo_list[0])
         ropath.difftype = difftype
-        if difftype == u"deleted":
+        if difftype == "deleted":
             ropath.type = None
         elif ropath.isreg():
             if multivol:
                 multivol_fileobj = Multivol_Filelike(diff_tarfile, tar_iter,
                                                      tarinfo_list, index)
                 ropath.setfileobj(multivol_fileobj)
                 yield ropath
@@ -153,74 +141,67 @@
         try:
             tarinfo_list[0] = next(tar_iter)
         except StopIteration:
             return
 
 
 def get_index_from_tarinfo(tarinfo):
-    u"""Return (index, difftype, multivol) pair from tarinfo object"""
-    for prefix in [u"snapshot/", u"diff/", u"deleted/",
-                   u"multivol_diff/", u"multivol_snapshot/"]:
+    """Return (index, difftype, multivol) pair from tarinfo object"""
+    for prefix in ["snapshot/", "diff/", "deleted/",
+                   "multivol_diff/", "multivol_snapshot/"]:
         tiname = util.get_tarinfo_name(tarinfo)
-        if sys.version_info.major == 2 and isinstance(prefix, unicode):
-            prefix = prefix.encode()
         if tiname.startswith(prefix):
             name = tiname[len(prefix):]  # strip prefix
-            if prefix.startswith(u"multivol"):
-                if prefix == u"multivol_diff/":
-                    difftype = u"diff"
+            if prefix.startswith("multivol"):
+                if prefix == "multivol_diff/":
+                    difftype = "diff"
                 else:
-                    difftype = u"snapshot"
+                    difftype = "snapshot"
                 multivol = 1
                 name, num_subs = \
-                    re.subn(u"(?s)^multivol_(diff|snapshot)/?(.*)/[0-9]+$",
-                            u"\\2", tiname)
+                    re.subn("(?s)^multivol_(diff|snapshot)/?(.*)/[0-9]+$",
+                            "\\2", tiname)
                 if num_subs != 1:
-                    raise PatchDirException(u"Unrecognized diff entry %s" %
-                                            tiname)
+                    raise PatchDirException(f"Unrecognized diff entry {tiname}")
             else:
                 difftype = prefix[:-1]  # strip trailing /
                 name = tiname[len(prefix):]
                 if name.endswith(r"/"):
                     name = name[:-1]  # strip trailing /'s
                 multivol = 0
             break
     else:
-        raise PatchDirException(u"Unrecognized diff entry %s" %
-                                tiname)
+        raise PatchDirException(f"Unrecognized diff entry {tiname}")
     if name == r"." or name == r"":
         index = ()
     else:
-        if sys.version_info.major >= 3:
-            index = tuple(util.fsencode(name).split(b"/"))
-        else:
-            index = tuple(name.split(b"/"))
+        index = tuple(os.fsencode(name).split(b"/"))
         if b'..' in index:
-            raise PatchDirException(u"Tar entry %s contains '..'.  Security "
-                                    u"violation" % util.fsdecode(tiname))
+            raise PatchDirException(f"Tar entry {os.fsdecode(tiname)} contains '..'.  Security violation")
     return index, difftype, multivol
 
 
 class Multivol_Filelike(object):
-    u"""Emulate a file like object from multivols
+    """Emulate a file like object from multivols
 
     Maintains a buffer about the size of a volume.  When it is read()
     to the end, pull in more volumes as desired.
 
     """
+
     def __init__(self, tf, tar_iter, tarinfo_list, index):
-        u"""Initializer.  tf is TarFile obj, tarinfo is first tarinfo"""
+        """Initializer.  tf is TarFile obj, tarinfo is first tarinfo"""
         self.tf, self.tar_iter = tf, tar_iter
         self.tarinfo_list = tarinfo_list  # must store as list for write access
         self.index = index
         self.buffer = b""
         self.at_end = False
 
     def read(self, length=-1):
-        u"""Read length bytes from file"""
+        """Read length bytes from file"""
         if length < 0:
             while self.addtobuffer():
                 pass
             real_len = len(self.buffer)
         else:
             while len(self.buffer) < length:
                 if not self.addtobuffer():
@@ -228,15 +209,15 @@
             real_len = min(len(self.buffer), length)
 
         result = self.buffer[:real_len]
         self.buffer = self.buffer[real_len:]
         return result
 
     def addtobuffer(self):
-        u"""Add next chunk to buffer"""
+        """Add next chunk to buffer"""
         if self.at_end:
             return False
         index, difftype, multivol = get_index_from_tarinfo(self.tarinfo_list[0])
         if not multivol or index != self.index:
             # we've moved on
             # the following communicates next tarinfo to difftar2path_iter
             self.at_end = True
@@ -251,33 +232,34 @@
         except StopIteration:
             self.tarinfo_list[0] = None
             self.at_end = True
             return False
         return True
 
     def close(self):
-        u"""If not at end, read remaining data"""
+        """If not at end, read remaining data"""
         if not self.at_end:
             while True:
                 self.buffer = b""
                 if not self.addtobuffer():
                     break
         self.at_end = True
 
 
 class PathPatcher(ITRBranch):
-    u"""Used by DirPatch, process the given basis and diff"""
+    """Used by DirPatch, process the given basis and diff"""
+
     def __init__(self, base_path):
-        u"""Set base_path, Path of root of tree"""
+        """Set base_path, Path of root of tree"""
         self.dir_basis_path = None
         self.base_path = base_path
         self.dir_diff_ropath = None
 
     def start_process(self, index, basis_path, diff_ropath):
-        u"""Start processing when diff_ropath is a directory"""
+        """Start processing when diff_ropath is a directory"""
         if not (diff_ropath and diff_ropath.isdir()):
             assert index == (), util.uindex(index)  # should only happen for first elem
             self.fast_process(index, basis_path, diff_ropath)
             return
 
         if not basis_path:
             basis_path = self.base_path.new_index(index)
@@ -286,79 +268,80 @@
         elif not basis_path.isdir():
             basis_path.delete()
             basis_path.mkdir()
         self.dir_basis_path = basis_path
         self.dir_diff_ropath = diff_ropath
 
     def end_process(self):
-        u"""Copy directory permissions when leaving tree"""
+        """Copy directory permissions when leaving tree"""
         if self.dir_diff_ropath:
             self.dir_diff_ropath.copy_attribs(self.dir_basis_path)
 
     def can_fast_process(self, index, basis_path, diff_ropath):  # pylint: disable=unused-argument
-        u"""No need to recurse if diff_ropath isn't a directory"""
+        """No need to recurse if diff_ropath isn't a directory"""
         return not (diff_ropath and diff_ropath.isdir())
 
     def fast_process(self, index, basis_path, diff_ropath):
-        u"""For use when neither is a directory"""
+        """For use when neither is a directory"""
         if not diff_ropath:
             return  # no change
         elif not basis_path:
-            if diff_ropath.difftype == u"deleted":
+            if diff_ropath.difftype == "deleted":
                 pass  # already deleted
             else:
                 # just copy snapshot over
                 diff_ropath.copy(self.base_path.new_index(index))
-        elif diff_ropath.difftype == u"deleted":
+        elif diff_ropath.difftype == "deleted":
             if basis_path.isdir():
                 basis_path.deltree()
             else:
                 basis_path.delete()
-        elif not basis_path.isreg() or (basis_path.isreg() and diff_ropath.difftype == u"snapshot"):
+        elif not basis_path.isreg() or (basis_path.isreg() and diff_ropath.difftype == "snapshot"):
             if basis_path.isdir():
                 basis_path.deltree()
             else:
                 basis_path.delete()
             diff_ropath.copy(basis_path)
         else:
-            assert diff_ropath.difftype == u"diff", diff_ropath.difftype
+            assert diff_ropath.difftype == "diff", diff_ropath.difftype
             basis_path.patch_with_attribs(diff_ropath)
 
 
 class TarFile_FromFileobjs(object):
-    u"""Like a tarfile.TarFile iterator, but read from multiple fileobjs"""
+    """Like a tarfile.TarFile iterator, but read from multiple fileobjs"""
+
     def __init__(self, fileobj_iter):
-        u"""Make new tarinfo iterator
+        """Make new tarinfo iterator
 
         fileobj_iter should be an iterator of file objects opened for
         reading.  They will be closed at end of reading.
 
         """
         self.fileobj_iter = fileobj_iter
         self.tarfile, self.tar_iter = None, None
         self.current_fp = None
 
     def __iter__(self):  # pylint: disable=non-iterator-returned
         return self
 
     def set_tarfile(self):
-        u"""Set tarfile from next file object, or raise StopIteration"""
+        """Set tarfile from next file object, or raise StopIteration"""
         if self.current_fp:
             assert not self.current_fp.close()
 
         while True:
             x = next(self.fileobj_iter)
             if isinstance(x, errors.BadVolumeException):
                 # continue with the next volume
                 continue
             else:
                 self.current_fp = x
                 break
 
-        self.tarfile = util.make_tarfile(u"r", self.current_fp)
+        self.tarfile = util.make_tarfile("r", self.current_fp)
         self.tar_iter = iter(self.tarfile)
 
     def __next__(self):
         if not self.tarfile:
             try:
                 self.set_tarfile()
             except StopIteration:
@@ -367,20 +350,20 @@
             return next(self.tar_iter)
         except StopIteration:
             assert not self.tarfile.close()
             self.set_tarfile()
             return next(self.tar_iter)
 
     def extractfile(self, tarinfo):
-        u"""Return data associated with given tarinfo"""
+        """Return data associated with given tarinfo"""
         return self.tarfile.extractfile(tarinfo)
 
 
 def collate_iters(iter_list):
-    u"""Collate iterators by index
+    """Collate iterators by index
 
     Input is a list of n iterators each of which must iterate elements
     with an index attribute.  The elements must come out in increasing
     order, and the index should be a tuple itself.
 
     The output is an iterator which yields tuples where all elements
     in the tuple have the same index, and the tuple has n elements in
@@ -393,56 +376,58 @@
     iter_num = len(iter_list)
     if iter_num == 2:
         return diffdir.collate2iters(iter_list[0], iter_list[1])
     overflow = [None] * iter_num
     elems = overflow[:]
 
     def setrorps(overflow, elems):
-        u"""Set the overflow and rorps list"""
+        """Set the overflow and rorps list"""
         for i in range(iter_num):
             if not overflow[i] and elems[i] is None:
                 try:
                     elems[i] = next(iter_list[i])
                 except StopIteration:
                     overflow[i] = 1
                     elems[i] = None
 
     def getleastindex(elems):
-        u"""Return the first index in elems, assuming elems isn't empty"""
+        """Return the first index in elems, assuming elems isn't empty"""
         return min([elem.index for elem in [x for x in elems if x]])
 
     def yield_tuples(iter_num, overflow, elems):
-        while 1:
+        while True:
             setrorps(overflow, elems)
             if None not in overflow:
                 break
 
             index = getleastindex(elems)
             yieldval = []
             for i in range(iter_num):
                 if elems[i] and elems[i].index == index:
                     yieldval.append(elems[i])
                     elems[i] = None
                 else:
                     yieldval.append(None)
             yield tuple(yieldval)
+
     return yield_tuples(iter_num, overflow, elems)
 
 
 class IndexedTuple(object):
-    u"""Like a tuple, but has .index (used previously by collate_iters)"""
+    """Like a tuple, but has .index (used previously by collate_iters)"""
+
     def __init__(self, index, sequence):
         self.index = index
         self.data = tuple(sequence)
 
     def __len__(self):
         return len(self.data)
 
     def __getitem__(self, key):
-        u"""This only works for numerical keys (easier this way)"""
+        """This only works for numerical keys (easier this way)"""
         return self.data[key]
 
     def __lt__(self, other):
         return self.__cmp__(other) == -1
 
     def __le__(self, other):
         return self.__cmp__(other) != 1
@@ -470,79 +455,77 @@
             return self.index == other.index and self.data == other.data
         elif isinstance(other, tuple):
             return self.data == other
         else:
             return False
 
     def __str__(self):
-        return u"(%s).%s" % (u", ".join(map(str, self.data)), self.index)
+        return f"({', '.join(map(str, self.data))}).{self.index}"
 
 
 def normalize_ps(patch_sequence):
-    u"""Given an sequence of ROPath deltas, remove blank and unnecessary
+    """Given an sequence of ROPath deltas, remove blank and unnecessary
 
     The sequence is assumed to be in patch order (later patches apply
     to earlier ones).  A patch is unnecessary if a later one doesn't
     require it (for instance, any patches before a "delete" are
     unnecessary).
 
     """
     result_list = []
     i = len(patch_sequence) - 1
     while i >= 0:
         delta = patch_sequence[i]
         if delta is not None:
             # skip blank entries
             result_list.insert(0, delta)
-            if delta.difftype != u"diff":
+            if delta.difftype != "diff":
                 break
         i -= 1
     return result_list
 
 
 def patch_seq2ropath(patch_seq):
-    u"""Apply the patches in patch_seq, return single ropath"""
+    """Apply the patches in patch_seq, return single ropath"""
     first = patch_seq[0]
-    assert first.difftype != u"diff", u"First patch in sequence " \
-                                      u"%s was a diff" % patch_seq
+    assert first.difftype != "diff", f"First patch in sequence {patch_seq} was a diff"
     if not first.isreg():
         # No need to bother with data if not regular file
-        assert len(patch_seq) == 1, u"Patch sequence isn't regular, but " \
-                                    u"has %d entries" % len(patch_seq)
+        assert len(patch_seq) == 1, f"Patch sequence isn't regular, but has {len(patch_seq)} entries"
         return first.get_ropath()
 
-    current_file = first.open(u"rb")
+    current_file = first.open("rb")
 
     for delta_ropath in patch_seq[1:]:
-        assert delta_ropath.difftype == u"diff", delta_ropath.difftype
+        assert delta_ropath.difftype == "diff", delta_ropath.difftype
         try:
             cur_file.fileno()
-        except:
-            u"""
+        except Exception as e:
+            """
             librsync insists on a real file object, which we create manually
             by using the duplicity.tempdir to tell us where.
 
             See https://bugs.launchpad.net/duplicity/+bug/670891 for discussion
             of os.tmpfile() vs tempfile.TemporaryFile() w.r.t. Windows / Posix,
             which is worked around in librsync.PatchedFile() now.
             """
             tempfp = tempfile.TemporaryFile(dir=tempdir.default().dir())
             util.copyfileobj(current_file, tempfp)
             assert not current_file.close()
             tempfp.seek(0)
             current_file = tempfp
         current_file = librsync.PatchedFile(current_file,
-                                            delta_ropath.open(u"rb"))
+                                            delta_ropath.open("rb"))
     result = patch_seq[-1].get_ropath()
     result.setfileobj(current_file)
     return result
 
 
 def integrate_patch_iters(iter_list):
-    u"""Combine a list of iterators of ropath patches
+    """Combine a list of iterators of ropath patches
 
     The iter_list should be sorted in patch order, and the elements in
     each iter_list need to be orderd by index.  The output will be an
     iterator of the final ROPaths in index order.
 
     """
     collated = collate_iters(iter_list)
@@ -551,36 +534,36 @@
         try:
             final_ropath = patch_seq2ropath(normalized)
             if final_ropath.exists():
                 # otherwise final patch was delete
                 yield final_ropath
         except Exception as e:
             filename = normalized[-1].get_ropath().get_relative_path()
-            log.Warn(_(u"Error '%s' patching %s") %
-                     (util.uexc(e), util.fsdecode(filename)),
+            log.Warn(_("Error '%s' patching %s") %
+                     (util.uexc(e), os.fsdecode(filename)),
                      log.WarningCode.cannot_process,
                      util.escape(filename))
 
 
 def tarfiles2rop_iter(tarfile_list, restrict_index=()):
-    u"""Integrate tarfiles of diffs into single ROPath iter
+    """Integrate tarfiles of diffs into single ROPath iter
 
     Then filter out all the diffs in that index which don't start with
     the restrict_index.
 
     """
     diff_iters = [difftar2path_iter(x) for x in tarfile_list]
     if restrict_index:
         # Apply filter before integration
         diff_iters = [filter_path_iter(x, restrict_index) for x in diff_iters]
     return integrate_patch_iters(diff_iters)
 
 
 def Write_ROPaths(base_path, rop_iter):
-    u"""Write out ropaths in rop_iter starting at base_path
+    """Write out ropaths in rop_iter starting at base_path
 
     Returns 1 if something was actually written, 0 otherwise.
 
     """
     ITR = IterTreeReducer(ROPath_IterWriter, [base_path])
     return_val = 0
     for ropath in rop_iter:
@@ -588,28 +571,29 @@
         ITR(ropath.index, ropath)
     ITR.Finish()
     base_path.setdata()
     return return_val
 
 
 class ROPath_IterWriter(ITRBranch):
-    u"""Used in Write_ROPaths above
+    """Used in Write_ROPaths above
 
     We need to use an ITR because we have to update the
     permissions/times of directories after we write the files in them.
 
     """
+
     def __init__(self, base_path):
-        u"""Set base_path, Path of root of tree"""
+        """Set base_path, Path of root of tree"""
         self.base_path = base_path
         self.dir_diff_ropath = None
         self.dir_new_path = None
 
     def start_process(self, index, ropath):
-        u"""Write ropath.  Only handles the directory case"""
+        """Write ropath.  Only handles the directory case"""
         if not ropath.isdir():
             # Base may not be a directory, but rest should
             assert ropath.index == (), ropath.index
             new_path = self.base_path.new_index(index)
             if ropath.exists():
                 if new_path.exists():
                     new_path.deltree()
@@ -620,23 +604,23 @@
             # base may exist, but nothing else
             assert index == (), index
         else:
             self.dir_new_path.mkdir()
         self.dir_diff_ropath = ropath
 
     def end_process(self):
-        u"""Update information of a directory when leaving it"""
+        """Update information of a directory when leaving it"""
         if self.dir_diff_ropath:
             self.dir_diff_ropath.copy_attribs(self.dir_new_path)
 
     def can_fast_process(self, index, ropath):  # pylint: disable=unused-argument
-        u"""Can fast process (no recursion) if ropath isn't a directory"""
-        log.Info(_(u"Writing %s of type %s") %
-                 (util.fsdecode(ropath.get_relative_path()), ropath.type),
+        """Can fast process (no recursion) if ropath isn't a directory"""
+        log.Info(_("Writing %s of type %s") %
+                 (os.fsdecode(ropath.get_relative_path()), ropath.type),
                  log.InfoCode.patch_file_writing,
-                 u"%s %s" % (util.escape(ropath.get_relative_path()), ropath.type))
+                 f"{util.escape(ropath.get_relative_path())} {ropath.type}")
         return not ropath.isdir()
 
     def fast_process(self, index, ropath):
-        u"""Write non-directory ropath to destination"""
+        """Write non-directory ropath to destination"""
         if ropath.exists():
             ropath.copy(self.base_path.new_index(index))
```

### Comparing `duplicity-1.2.3.dev43/duplicity/manifest.py` & `duplicity-2.0.0rc0/duplicity/manifest.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,42 +15,38 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Create and edit manifest for session contents"""
-
-from builtins import map
-from builtins import range
-from builtins import object
+"""Create and edit manifest for session contents"""
 
+import os
 import re
-import sys
 
 from duplicity import config
 from duplicity import log
-from duplicity import config
 from duplicity import util
 
 
 class ManifestError(Exception):
-    u"""
+    """
     Exception raised when problem with manifest
     """
     pass
 
 
 class Manifest(object):
-    u"""
+    """
     List of volumes and information about each one
     """
+
     def __init__(self, fh=None):
-        u"""
+        """
         Create blank Manifest
 
         @param fh: fileobj for manifest
         @type fh: DupPath
 
         @rtype: Manifest
         @return: manifest
@@ -58,15 +54,15 @@
         self.hostname = None
         self.local_dirname = None
         self.volume_info_dict = {}  # dictionary vol numbers -> vol infos
         self.fh = fh
         self.files_changed = []
 
     def set_dirinfo(self):
-        u"""
+        """
         Set information about directory from config,
         and write to manifest file.
 
         @rtype: Manifest
         @return: manifest
         """
         self.hostname = config.hostname
@@ -75,15 +71,15 @@
             if self.hostname:
                 self.fh.write(b"Hostname %s\n" % self.hostname.encode())
             if self.local_dirname:
                 self.fh.write(b"Localdir %s\n" % Quote(self.local_dirname))
         return self
 
     def check_dirinfo(self):
-        u"""
+        """
         Return None if dirinfo is the same, otherwise error message
 
         Does not raise an error message if hostname or local_dirname
         are not available.
 
         @rtype: string
         @return: None or error message
@@ -92,77 +88,76 @@
             return
 
         # Check both hostname and fqdn (we used to write the fqdn into the
         # manifest, so we want to keep comparing against that)
         if (self.hostname and
                 self.hostname != config.hostname and
                 self.hostname != config.fqdn):
-            errmsg = _(u"Fatal Error: Backup source host has changed.\n"
-                       u"Current hostname: %s\n"
-                       u"Previous hostname: %s") % (config.hostname, self.hostname)
+            errmsg = _("Fatal Error: Backup source host has changed.\n"
+                       "Current hostname: %s\n"
+                       "Previous hostname: %s") % (config.hostname, self.hostname)
             code = log.ErrorCode.hostname_mismatch
-            code_extra = u"%s %s" % (util.escape(config.hostname), util.escape(self.hostname))
+            code_extra = f"{util.escape(config.hostname)} {util.escape(self.hostname)}"
 
-        elif (self.local_dirname and self.local_dirname != config.local_path.name):
-            errmsg = _(u"Fatal Error: Backup source directory has changed.\n"
-                       u"Current directory: %s\n"
-                       u"Previous directory: %s") % (config.local_path.name, self.local_dirname)
-            code = log.ErrorCode.source_dir_mismatch
-            code_extra = u"%s %s" % (util.escape(config.local_path.name),
-                                     util.escape(self.local_dirname))
+        elif self.local_dirname and self.local_dirname != config.local_path.name:
+            errmsg = _(f"Fatal Error: Backup source directory has changed.\n"
+                       f"Current directory: {config.local_path.uc_name}\n"
+                       f"Previous directory: {os.fsdecode(self.local_dirname)}")
+            code = log.ErrorCode.source_path_mismatch
+            code_extra = f"{util.escape(config.local_path.name)} {util.escape(self.local_dirname)}"
         else:
             return
 
-        log.FatalError(errmsg + u"\n\n" +
-                       _(u"Aborting because you may have accidentally tried to "
-                         u"backup two different data sets to the same remote "
-                         u"location, or using the same archive directory.  If "
-                         u"this is not a mistake, use the "
-                         u"--allow-source-mismatch switch to avoid seeing this "
-                         u"message"), code, code_extra)
+        log.FatalError(errmsg + "\n\n" +
+                       _("Aborting because you may have accidentally tried to "
+                         "backup two different data sets to the same remote "
+                         "location, or using the same archive directory.  If "
+                         "this is not a mistake, use the "
+                         "--allow-source-mismatch switch to avoid seeing this "
+                         "message"), code, code_extra)
 
     def set_files_changed_info(self, files_changed):
         if files_changed:
             self.files_changed = files_changed
 
         if self.fh:
             self.fh.write(b"Filelist %d\n" % len(self.files_changed))
             for fileinfo in self.files_changed:
                 self.fh.write(b"    %-7s  %s\n" % (fileinfo[1], Quote(fileinfo[0])))
 
     def add_volume_info(self, vi):
-        u"""
+        """
         Add volume info vi to manifest and write to manifest
 
         @param vi: volume info to add
         @type vi: VolumeInfo
 
         @return: void
         """
         vol_num = vi.volume_number
         self.volume_info_dict[vol_num] = vi
         if self.fh:
             self.fh.write(vi.to_string() + b"\n")
 
     def del_volume_info(self, vol_num):
-        u"""
+        """
         Remove volume vol_num from the manifest
 
         @param vol_num: volume number to delete
         @type vi: int
 
         @return: void
         """
         try:
             del self.volume_info_dict[vol_num]
         except Exception:
-            raise ManifestError(u"Volume %d not present in manifest" % (vol_num,))
+            raise ManifestError(f"Volume {int(vol_num)} not present in manifest")
 
     def to_string(self):
-        u"""
+        """
         Return string version of self (just concatenate vi strings)
 
         @rtype: string
         @return: self in string form
         """
         result = b""
         if self.hostname:
@@ -170,164 +165,164 @@
         if self.local_dirname:
             result += b"Localdir %s\n" % Quote(self.local_dirname)
 
         result += b"Filelist %d\n" % len(self.files_changed)
         for fileinfo in self.files_changed:
             result += b"    %-7s  %s\n" % (fileinfo[1], Quote(fileinfo[0]))
 
-        vol_num_list = list(self.volume_info_dict.keys())
-        vol_num_list.sort()
+        vol_num_list = sorted(self.volume_info_dict.keys())
 
         def vol_num_to_string(vol_num):
             return self.volume_info_dict[vol_num].to_string()
+
         result = b"%s%s\n" % (result,
                               b"\n".join(map(vol_num_to_string, vol_num_list)))
         return result
 
     __str__ = to_string
 
     def from_string(self, s):
-        u"""
+        """
         Initialize self from string s, return self
         """
 
         def get_field(fieldname):
-            u"""
+            """
             Return the value of a field by parsing s, or None if no field
             """
             if not isinstance(fieldname, bytes):
                 fieldname = fieldname.encode()
             m = re.search(b"(^|\\n)%s\\s(.*?)\n" % fieldname, s, re.I)
             if not m:
                 return None
             else:
                 return Unquote(m.group(2))
-        self.hostname = get_field(u"hostname")
+
+        self.hostname = get_field("hostname")
         if self.hostname is not None:
             self.hostname = self.hostname.decode()
-        self.local_dirname = get_field(u"localdir")
+        self.local_dirname = get_field("localdir")
 
         highest_vol = 0
         latest_vol = 0
         vi_regexp = re.compile(b"(?:^|\\n)(volume\\s.*(?:\\n.*)*?)(?=\\nvolume\\s|$)", re.I)
         vi_iterator = vi_regexp.finditer(s)
         for match in vi_iterator:
             vi = VolumeInfo().from_string(match.group(1))
             self.add_volume_info(vi)
             latest_vol = vi.volume_number
             highest_vol = max(highest_vol, latest_vol)
-            log.Debug(_(u"Found manifest volume %s") % latest_vol)
+            log.Debug(_("Found manifest volume %s") % latest_vol)
         # If we restarted after losing some remote volumes, the highest volume
         # seen may be higher than the last volume recorded.  That is, the
         # manifest could contain "vol1, vol2, vol3, vol2."  If so, we don't
         # want to keep vol3's info.
         for i in range(latest_vol + 1, highest_vol + 1):
             self.del_volume_info(i)
-        log.Info(_(u"Found %s volumes in manifest") % latest_vol)
+        log.Info(_("Found %s volumes in manifest") % latest_vol)
 
         # Get file changed list - not needed if --file-changed and
         # --show-changes-in-set are not present
         filecount = 0
         if config.file_changed is not None or config.show_changes_in_set is not None:
             filelist_regexp = re.compile(b"(^|\\n)filelist\\s([0-9]+)\\n(.*?)(\\nvolume\\s|$)", re.I | re.S)
             match = filelist_regexp.search(s)
             if match:
                 filecount = int(match.group(2))
             if filecount > 0:
                 def parse_fileinfo(line):
                     fileinfo = line.strip().split()
-                    return (fileinfo[0], b''.join(fileinfo[1:]))
+                    return fileinfo[0], b''.join(fileinfo[1:])
 
                 self.files_changed = list(map(parse_fileinfo, match.group(3).split(b'\n')))
 
             if filecount != len(self.files_changed):
-                log.Error(_(u"Manifest file '%s' is corrupt: File count says %d, File list contains %d" %
-                            (self.fh.base if self.fh else u"", filecount, len(self.files_changed))))
+                log.Error(_(f"Manifest file '{self.fh.base if self.fh else ''}' is corrupt: "
+                            f"File count says {int(filecount)}, File list contains {len(self.files_changed)}"))
                 self.corrupt_filelist = True
 
         return self
 
     def get_files_changed(self):
         return self.files_changed
 
     def __eq__(self, other):
-        u"""
+        """
         Two manifests are equal if they contain the same volume infos
         """
-        vi_list1 = list(self.volume_info_dict.keys())
-        vi_list1.sort()
-        vi_list2 = list(other.volume_info_dict.keys())
-        vi_list2.sort()
+        vi_list1 = sorted(self.volume_info_dict.keys())
+        vi_list2 = sorted(other.volume_info_dict.keys())
 
         if vi_list1 != vi_list2:
-            log.Notice(_(u"Manifests not equal because different volume numbers"))
+            log.Notice(_("Manifests not equal because different volume numbers"))
             return False
 
         for i in range(len(vi_list1)):
             if not vi_list1[i] == vi_list2[i]:
-                log.Notice(_(u"Manifests not equal because volume lists differ"))
+                log.Notice(_("Manifests not equal because volume lists differ"))
                 return False
 
         if (self.hostname != other.hostname or
                 self.local_dirname != other.local_dirname):
-            log.Notice(_(u"Manifests not equal because hosts or directories differ"))
+            log.Notice(_("Manifests not equal because hosts or directories differ"))
             return False
 
         return True
 
     def __ne__(self, other):
-        u"""
+        """
         Defines !=.  Not doing this always leads to annoying bugs...
         """
         return not self.__eq__(other)
 
     def write_to_path(self, path):
-        u"""
+        """
         Write string version of manifest to given path
         """
         assert not path.exists()
-        fout = path.open(u"wb")
+        fout = path.open("wb")
         fout.write(self.to_string())
         assert not fout.close()
         path.setdata()
 
     def get_containing_volumes(self, index_prefix):
-        u"""
+        """
         Return list of volume numbers that may contain index_prefix
         """
-        if len(index_prefix) == 1 and isinstance(index_prefix[0], u"".__class__):
+        if len(index_prefix) == 1 and isinstance(index_prefix[0], "".__class__):
             index_prefix = (index_prefix[0].encode(),)
         return [vol_num for vol_num in list(self.volume_info_dict.keys()) if
                 self.volume_info_dict[vol_num].contains(index_prefix)]
 
 
 class VolumeInfoError(Exception):
-    u"""
+    """
     Raised when there is a problem initializing a VolumeInfo from string
     """
     pass
 
 
 class VolumeInfo(object):
-    u"""
+    """
     Information about a single volume
     """
+
     def __init__(self):
-        u"""VolumeInfo initializer"""
+        """VolumeInfo initializer"""
         self.volume_number = None
         self.start_index = None
         self.start_block = None
         self.end_index = None
         self.end_block = None
         self.hashes = {}
 
     def set_info(self, vol_number,
                  start_index, start_block,
                  end_index, end_block):
-        u"""
+        """
         Set essential VolumeInfo information, return self
 
         Call with starting and ending paths stored in the volume.  If
         a multivol diff gets split between volumes, count it as being
         part of both volumes.
         """
         self.volume_number = vol_number
@@ -335,48 +330,49 @@
         self.start_block = start_block
         self.end_index = end_index
         self.end_block = end_block
 
         return self
 
     def set_hash(self, hash_name, data):
-        u"""
+        """
         Set the value of hash hash_name (e.g. "MD5") to data
         """
         if isinstance(hash_name, bytes):
             hash_name = hash_name.decode()
         if isinstance(data, bytes):
             data = data.decode()
         self.hashes[hash_name] = data
 
     def get_best_hash(self):
-        u"""
+        """
         Return pair (hash_type, hash_data)
 
         SHA1 is the best hash, and MD5 is the second best hash.  None
         is returned if no hash is available.
         """
         if not self.hashes:
             return None
         try:
-            return (u"SHA1", self.hashes[u'SHA1'])
+            return "SHA1", self.hashes['SHA1']
         except KeyError:
             pass
         try:
-            return (u"MD5", self.hashes[u'MD5'])
+            return "MD5", self.hashes['MD5']
         except KeyError:
             pass
         return list(self.hashes.items())[0]
 
     def to_string(self):
-        u"""
+        """
         Return nicely formatted string reporting all information
         """
+
         def index_to_string(index):
-            u"""Return printable version of index without any whitespace"""
+            """Return printable version of index without any whitespace"""
             if index:
                 s = b"/".join(index)
                 return Quote(s)
             else:
                 return b"."
 
         def bfmt(x):
@@ -394,43 +390,44 @@
             slist.append(b"%sHash %s %s" %
                          (whitespace, key.encode(), self.hashes[key].encode()))
         return b"\n".join(slist)
 
     __str__ = to_string
 
     def from_string(self, s):
-        u"""
+        """
         Initialize self from string s as created by to_string
         """
+
         def string_to_index(s):
-            u"""
+            """
             Return tuple index from string
             """
             s = Unquote(s)
             if s == b".":
                 return ()
             return tuple(s.split(b"/"))
 
         linelist = s.strip().split(b"\n")
 
         # Set volume number
         m = re.search(b"^Volume ([0-9]+):", linelist[0], re.I)
         if not m:
-            raise VolumeInfoError(u"Bad first line '%s'" % (linelist[0],))
+            raise VolumeInfoError(f"Bad first line '{linelist[0]}'")
         self.volume_number = int(m.group(1))
 
         # Set other fields
         for line in linelist[1:]:
             if not line:
                 continue
             line_split = line.strip().split()
             field_name = line_split[0].lower()
             other_fields = line_split[1:]
             if field_name == b"Volume":
-                log.Warn(_(u"Warning, found extra Volume identifier"))
+                log.Warn(_("Warning, found extra Volume identifier"))
                 break
             elif field_name == b"startingpath":
                 self.start_index = string_to_index(other_fields[0])
                 if len(other_fields) > 1:
                     self.start_block = int(other_fields[1])
                 else:
                     self.start_block = None
@@ -440,50 +437,48 @@
                     self.end_block = int(other_fields[1])
                 else:
                     self.end_block = None
             elif field_name == b"hash":
                 self.set_hash(other_fields[0], other_fields[1])
 
         if self.start_index is None or self.end_index is None:
-            raise VolumeInfoError(u"Start or end index not set")
+            raise VolumeInfoError("Start or end index not set")
         return self
 
     def __eq__(self, other):
-        u"""
+        """
         Used in test suite
         """
         if not isinstance(other, VolumeInfo):
-            log.Notice(_(u"Other is not VolumeInfo"))
+            log.Notice(_("Other is not VolumeInfo"))
             return None
         if self.volume_number != other.volume_number:
-            log.Notice(_(u"Volume numbers don't match"))
+            log.Notice(_("Volume numbers don't match"))
             return None
         if self.start_index != other.start_index:
-            log.Notice(_(u"start_indicies don't match"))
+            log.Notice(_("start_indicies don't match"))
             return None
         if self.end_index != other.end_index:
-            log.Notice(_(u"end_index don't match"))
+            log.Notice(_("end_index don't match"))
             return None
-        hash_list1 = list(self.hashes.items())
-        hash_list1.sort()
-        hash_list2 = list(other.hashes.items())
-        hash_list2.sort()
+        hash_list1 = sorted(self.hashes.items())
+        hash_list2 = sorted(other.hashes.items())
         if hash_list1 != hash_list2:
-            log.Notice(_(u"Hashes don't match"))
+            log.Notice(_("Hashes don't match"))
             return None
         return 1
 
     def __ne__(self, other):
-        u"""
+        """
         Defines !=
         """
         return not self.__eq__(other)
 
     def contains(self, index_prefix, recursive=1):
-        u"""
+        """
         Return true if volume might contain index
 
         If recursive is true, then return true if any index starting
         with index_prefix could be contained.  Otherwise, just check
         if index_prefix itself is between starting and ending
         indicies.
         """
@@ -494,15 +489,15 @@
             return self.start_index <= index_prefix <= self.end_index
 
 
 nonnormal_char_re = re.compile(b"(\\s|[\\\\\"'])")
 
 
 def Quote(s):
-    u"""
+    """
     Return quoted version of s safe to put in a manifest or volume info
     """
     if not nonnormal_char_re.search(s):
         return s  # no quoting necessary
     slist = []
     for i in range(0, len(s)):
         char = s[i:i + 1]
@@ -510,36 +505,30 @@
             slist.append(b"\\x%02x" % ord(char))
         else:
             slist.append(char)
     return b'"%s"' % b"".join(slist)
 
 
 def maybe_chr(ch):
-    if sys.version_info.major >= 3:
-        return chr(ch)
-    else:
-        return ch
+    return chr(ch)
 
 
 def Unquote(quoted_string):
-    u"""
+    """
     Return original string from quoted_string produced by above
     """
-    if not maybe_chr(quoted_string[0]) == u'"' or maybe_chr(quoted_string[0]) == u"'":
+    if not maybe_chr(quoted_string[0]) == '"' or maybe_chr(quoted_string[0]) == "'":
         return quoted_string
     assert quoted_string[0] == quoted_string[-1]
     return_list = []
     i = 1  # skip initial char
     while i < len(quoted_string) - 1:
         char = quoted_string[i:i + 1]
         if char == b"\\":
             # quoted section
-            assert maybe_chr(quoted_string[i + 1]) == u"x"
-            if sys.version_info.major >= 3:
-                return_list.append(int(quoted_string[i + 2:i + 4].decode(), 16).to_bytes(1, byteorder=u'big'))
-            else:
-                return_list.append(chr(int(quoted_string[i + 2:i + 4], 16)))
+            assert maybe_chr(quoted_string[i + 1]) == "x"
+            return_list.append(int(quoted_string[i + 2:i + 4].decode(), 16).to_bytes(1, byteorder='big'))
             i += 4
         else:
             return_list.append(char)
             i += 1
     return b"".join(return_list)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/file_naming.py` & `duplicity-2.0.0rc0/duplicity/file_naming.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
 # Copyright 2002 Ben Escoto <ben@emerose.org>
 # Copyright 2007 Kenneth Loafman <kenneth@loafman.com>
 #
 # This file is part of duplicity.
 #
 # Duplicity is free software; you can redistribute it and/or modify it
@@ -15,23 +14,20 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Produce and parse the names of duplicity's backup files"""
+"""Produce and parse the names of duplicity's backup files"""
 
-from builtins import str
-from builtins import range
-from builtins import object
 import re
-from duplicity import dup_time
+
 from duplicity import config
-import sys
+from duplicity import dup_time
 
 full_vol_re = None
 full_vol_re_short = None
 full_manifest_re = None
 full_manifest_re_short = None
 inc_vol_re = None
 inc_vol_re_short = None
@@ -141,162 +137,121 @@
                                   b"\\.(?P<end_time>[0-9a-z]+?)"
                                   b"\\.st"
                                   b"(?P<partial>(\\.p))?"
                                   b"(\\.|$)")
 
 
 def to_base36(n):
-    u"""
+    """
     Return string representation of n in base 36 (use 0-9 and a-z)
     """
     div, mod = divmod(n, 36)
     if mod <= 9:
         last_digit = str(mod)
     else:
-        last_digit = chr(ord(u'a') + mod - 10)
-    if sys.version_info.major >= 3:
-        last_digit = last_digit.encode()
+        last_digit = chr(ord('a') + mod - 10)
+    last_digit = last_digit.encode()
     if n == mod:
         return last_digit
     else:
         return to_base36(div) + last_digit
 
 
 def from_base36(s):
-    u"""
+    """
     Convert string s in base 36 to long int
     """
     total = 0
     for i in range(len(s)):
         total *= 36
-        if sys.version_info.major >= 3 and isinstance(s, bytes):
+        if isinstance(s, bytes):
             digit_ord = s[i]
         else:
             digit_ord = ord(s[i])
-        if ord(u'0') <= digit_ord <= ord(u'9'):
-            total += digit_ord - ord(u'0')
-        elif ord(u'a') <= digit_ord <= ord(u'z'):
-            total += digit_ord - ord(u'a') + 10
+        if ord('0') <= digit_ord <= ord('9'):
+            total += digit_ord - ord('0')
+        elif ord('a') <= digit_ord <= ord('z'):
+            total += digit_ord - ord('a') + 10
         else:
-            assert 0, u"Digit %s in %s not in proper range" % (s[i], s)
+            assert 0, f"Digit {s[i]} in {s} not in proper range"
     return total
 
 
 def get_suffix(encrypted, gzipped):
-    u"""
-    Return appropriate suffix depending on status of
-    encryption, compression, and short_filenames.
+    """
+    Return appropriate suffix depending on status of encryption or compression or neither.
     """
     if encrypted:
         gzipped = False
     if encrypted:
-        if config.short_filenames:
-            suffix = b'.g'
-        else:
-            suffix = b".gpg"
+        suffix = b".gpg"
     elif gzipped:
-        if config.short_filenames:
-            suffix = b".z"
-        else:
-            suffix = b'.gz'
+        suffix = b'.gz'
     else:
         suffix = b""
     return suffix
 
 
 def get(type, volume_number=None, manifest=False,  # pylint: disable=redefined-builtin
         encrypted=False, gzipped=False, partial=False):
-    u"""
+    """
     Return duplicity filename of specified type
 
     type can be "full", "inc", "full-sig", or "new-sig". volume_number
     can be given with the full and inc types.  If manifest is true the
     filename is of a full or inc manifest file.
     """
     assert dup_time.curtimestr
     if encrypted:
         gzipped = False
     suffix = get_suffix(encrypted, gzipped)
-    part_string = b""
-    if config.short_filenames:
-        if partial:
-            part_string = b".p"
-    else:
-        if partial:
-            part_string = b".part"
-
-    if type == u"full-sig" or type == u"new-sig":
+    part_string = b".part" if partial else b""
+    if type == "full-sig" or type == "new-sig":
         assert not volume_number and not manifest
         assert not (volume_number and part_string)
-        if type == u"full-sig":
-            if config.short_filenames:
-                return (config.file_prefix + config.file_prefix_signature +
-                        b"dfs.%s.st%s%s" %
-                        (to_base36(dup_time.curtime), part_string, suffix))
-            else:
-                return (config.file_prefix + config.file_prefix_signature +
-                        b"duplicity-full-signatures.%s.sigtar%s%s" %
-                        (dup_time.curtimestr.encode(), part_string, suffix))
-        elif type == u"new-sig":
-            if config.short_filenames:
-                return (config.file_prefix + config.file_prefix_signature +
-                        b"dns.%s.%s.st%s%s" %
-                        (to_base36(dup_time.prevtime),
-                         to_base36(dup_time.curtime),
-                         part_string, suffix))
-            else:
-                return (config.file_prefix + config.file_prefix_signature +
-                        b"duplicity-new-signatures.%s.to.%s.sigtar%s%s" %
-                        (dup_time.prevtimestr.encode(), dup_time.curtimestr.encode(),
-                         part_string, suffix))
+        if type == "full-sig":
+            return (config.file_prefix + config.file_prefix_signature +
+                    b"duplicity-full-signatures.%s.sigtar%s%s" %
+                    (dup_time.curtimestr.encode(), part_string, suffix))
+        elif type == "new-sig":
+            return (config.file_prefix + config.file_prefix_signature +
+                    b"duplicity-new-signatures.%s.to.%s.sigtar%s%s" %
+                    (dup_time.prevtimestr.encode(), dup_time.curtimestr.encode(),
+                     part_string, suffix))
     else:
         assert volume_number or manifest
         assert not (volume_number and manifest)
 
         prefix = config.file_prefix
 
         if volume_number:
-            if config.short_filenames:
-                vol_string = b"%s.dt" % to_base36(volume_number)
-            else:
-                vol_string = b"vol%d.difftar" % volume_number
+            vol_string = b"vol%d.difftar" % volume_number
             prefix += config.file_prefix_archive
         else:
-            if config.short_filenames:
-                vol_string = b"m"
-            else:
-                vol_string = b"manifest"
+            vol_string = b"manifest"
             prefix += config.file_prefix_manifest
 
-        if type == u"full":
-            if config.short_filenames:
-                return (b"%sdf.%s.%s%s%s" % (prefix, to_base36(dup_time.curtime),
-                                             vol_string, part_string, suffix))
-            else:
-                return (b"%sduplicity-full.%s.%s%s%s" % (prefix, dup_time.curtimestr.encode(),
-                                                         vol_string, part_string, suffix))
-        elif type == u"inc":
-            if config.short_filenames:
-                return (b"%sdi.%s.%s.%s%s%s" % (prefix, to_base36(dup_time.prevtime),
-                                                to_base36(dup_time.curtime),
-                                                vol_string, part_string, suffix))
-            else:
-                return (b"%sduplicity-inc.%s.to.%s.%s%s%s" % (prefix, dup_time.prevtimestr.encode(),
-                                                              dup_time.curtimestr.encode(),
-                                                              vol_string, part_string, suffix))
+        if type == "full":
+            return (b"%sduplicity-full.%s.%s%s%s" % (prefix, dup_time.curtimestr.encode(),
+                                                     vol_string, part_string, suffix))
+        elif type == "inc":
+            return (b"%sduplicity-inc.%s.to.%s.%s%s%s" % (prefix, dup_time.prevtimestr.encode(),
+                                                          dup_time.curtimestr.encode(),
+                                                          vol_string, part_string, suffix))
         else:
             assert 0
 
 
 def parse(filename):
-    u"""
+    """
     Parse duplicity filename, return None or ParseResults object
     """
+
     def str2time(timestr, short):
-        u"""
+        """
         Return time in seconds if string can be converted, None otherwise
         """
         if isinstance(timestr, bytes):
             timestr = timestr.decode()
 
         if short:
             t = from_base36(timestr)
@@ -304,141 +259,133 @@
             try:
                 t = dup_time.genstrtotime(timestr.upper())
             except dup_time.TimeException:
                 return None
         return t
 
     def get_vol_num(s, short):
-        u"""
+        """
         Return volume number from volume number string
         """
         if short:
             return from_base36(s)
         else:
             return int(s)
 
     def check_full():
-        u"""
+        """
         Return ParseResults if file is from full backup, None otherwise
         """
         prepare_regex()
         short = True
         m1 = full_vol_re_short.search(filename)
         m2 = full_manifest_re_short.search(filename)
-        if not m1 and not m2 and not config.short_filenames:
+        if not m1 and not m2:
             short = False
             m1 = full_vol_re.search(filename)
             m2 = full_manifest_re.search(filename)
         if m1 or m2:
-            t = str2time((m1 or m2).group(u"time"), short)
+            t = str2time((m1 or m2).group("time"), short)
             if t:
                 if m1:
-                    return ParseResults(u"full", time=t,
-                                        volume_number=get_vol_num(m1.group(u"num"), short))
+                    return ParseResults("full", time=t,
+                                        volume_number=get_vol_num(m1.group("num"), short))
                 else:
-                    return ParseResults(u"full", time=t, manifest=True,
-                                        partial=(m2.group(u"partial") is not None))
+                    return ParseResults("full", time=t, manifest=True,
+                                        partial=(m2.group("partial") is not None))
         return None
 
     def check_inc():
-        u"""
+        """
         Return ParseResults if file is from inc backup, None otherwise
         """
         prepare_regex()
         short = True
         m1 = inc_vol_re_short.search(filename)
         m2 = inc_manifest_re_short.search(filename)
-        if not m1 and not m2 and not config.short_filenames:
+        if not m1 and not m2:
             short = False
             m1 = inc_vol_re.search(filename)
             m2 = inc_manifest_re.search(filename)
         if m1 or m2:
-            t1 = str2time((m1 or m2).group(u"start_time"), short)
-            t2 = str2time((m1 or m2).group(u"end_time"), short)
+            t1 = str2time((m1 or m2).group("start_time"), short)
+            t2 = str2time((m1 or m2).group("end_time"), short)
             if t1 and t2:
                 if m1:
-                    return ParseResults(u"inc", start_time=t1,
-                                        end_time=t2, volume_number=get_vol_num(m1.group(u"num"), short))
+                    return ParseResults("inc", start_time=t1,
+                                        end_time=t2, volume_number=get_vol_num(m1.group("num"), short))
                 else:
-                    return ParseResults(u"inc", start_time=t1, end_time=t2, manifest=1,
-                                        partial=(m2.group(u"partial") is not None))
+                    return ParseResults("inc", start_time=t1, end_time=t2, manifest=1,
+                                        partial=(m2.group("partial") is not None))
         return None
 
     def check_sig():
-        u"""
+        """
         Return ParseResults if file is a signature, None otherwise
         """
         prepare_regex()
         short = True
         m = full_sig_re_short.search(filename)
-        if not m and not config.short_filenames:
+        if not m:
             short = False
             m = full_sig_re.search(filename)
         if m:
-            t = str2time(m.group(u"time"), short)
+            t = str2time(m.group("time"), short)
             if t:
-                return ParseResults(u"full-sig", time=t,
-                                    partial=(m.group(u"partial") is not None))
+                return ParseResults("full-sig", time=t,
+                                    partial=(m.group("partial") is not None))
             else:
                 return None
 
         short = True
         m = new_sig_re_short.search(filename)
-        if not m and not config.short_filenames:
+        if not m:
             short = False
             m = new_sig_re.search(filename)
         if m:
-            t1 = str2time(m.group(u"start_time"), short)
-            t2 = str2time(m.group(u"end_time"), short)
+            t1 = str2time(m.group("start_time"), short)
+            t2 = str2time(m.group("end_time"), short)
             if t1 and t2:
-                return ParseResults(u"new-sig", start_time=t1, end_time=t2,
-                                    partial=(m.group(u"partial") is not None))
+                return ParseResults("new-sig", start_time=t1, end_time=t2,
+                                    partial=(m.group("partial") is not None))
         return None
 
     def set_encryption_or_compression(pr):
-        u"""
+        """
         Set encryption and compression flags in ParseResults pr
         """
-        if (filename.endswith(b'.z') or
-                not config.short_filenames and filename.endswith(b'gz')):
-            pr.compressed = 1
-        else:
-            pr.compressed = None
-
-        if (filename.endswith(b'.g') or
-                not config.short_filenames and filename.endswith(b'.gpg')):
-            pr.encrypted = 1
-        else:
-            pr.encrypted = None
+        pr.compressed = filename.endswith(b'.z') or filename.endswith(b'.gz')
+        pr.encrypted = filename.endswith(b'.g') or filename.endswith(b'.gpg')
 
     pr = check_full()
     if not pr:
         pr = check_inc()
         if not pr:
             pr = check_sig()
             if not pr:
                 return None
     set_encryption_or_compression(pr)
     return pr
 
 
-class ParseResults(object):
-    u"""
+class ParseResults:
+    """
     Hold information taken from a duplicity filename
     """
+
     def __init__(self, type, manifest=None, volume_number=None,  # pylint: disable=redefined-builtin
                  time=None, start_time=None, end_time=None,
                  encrypted=None, compressed=None, partial=False):
 
-        assert type in [u"full-sig", u"new-sig", u"inc", u"full"]
+        assert type in ["full-sig", "new-sig", "inc", "full"]
 
         self.type = type
-        if type == u"inc" or type == u"full":
+        if type == "inc" or type == "full":
             assert manifest or volume_number
-        if type == u"inc" or type == u"new-sig":
+        if type == "inc" or type == "new-sig":
             assert start_time and end_time
         else:
             assert time
 
         self.manifest = manifest
         self.volume_number = volume_number
         self.time = time
```

### Comparing `duplicity-1.2.3.dev43/duplicity/_librsyncmodule.c` & `duplicity-2.0.0rc0/duplicity/_librsyncmodule.c`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/duplicity/dup_collections.py` & `duplicity-2.0.0rc0/duplicity/dup_collections.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,51 +15,39 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Classes and functions on collections of backup volumes"""
+"""Classes and functions on collections of backup volumes"""
 
-from builtins import str
-from builtins import zip
-from builtins import map
-from builtins import range
-from builtins import object
+import os
 
-import sys
-
-from duplicity import log
-from duplicity import file_naming
-from duplicity import path
-from duplicity import util
-from duplicity import dup_time
 from duplicity import config
+from duplicity import dup_time
+from duplicity import file_naming
+from duplicity import log
 from duplicity import manifest
+from duplicity import path
 from duplicity import util
 from duplicity.gpg import GPGError
 
-# For type testing against both int and long types that works in python 2/3
-if sys.version_info < (3,):
-    integer_types = (int, int)
-else:
-    integer_types = (int,)
-
 
 class CollectionsError(Exception):
     pass
 
 
 class BackupSet(object):
-    u"""
+    """
     Backup set - the backup information produced by one session
     """
+
     def __init__(self, backend, action):
-        u"""
+        """
         Initialize new backup set, only backend is required at first
         """
         self.backend = backend
         self.info_set = False  # true if fields are set
         self.volume_name_dict = {}  # dict from volume number to filename
         self.remote_manifest_name = None  # full name of remote manifest
         self.local_manifest_path = None  # full path to local manifest
@@ -68,36 +56,36 @@
         self.end_time = None  # will be set if inc
         self.partial = False  # true if a partial backup
         self.encrypted = False  # true if an encrypted backup
         self.files_changed = []
         self.action = action
 
     def is_complete(self):
-        u"""
+        """
         Assume complete if found manifest file
         """
         return self.remote_manifest_name
 
     def add_filename(self, filename, pr=None):
-        u"""
+        """
         Add a filename to given set.  Return true if it fits.
 
         The filename will match the given set if it has the right
         times and is of the right type.  The information will be set
         from the first filename given.
 
         @param filename: name of file to add
         @type filename: string
 
         @param pr: pre-computed result of file_naming.parse(filename)
         @type pr: Optional[ParseResults]
         """
         if not pr:
             pr = file_naming.parse(filename)
-        if not pr or not (pr.type == u"full" or pr.type == u"inc"):
+        if not pr or not (pr.type == "full" or pr.type == "inc"):
             return False
 
         if not self.info_set:
             self.set_info(pr)
         else:
             if pr.type != self.type:
                 return False
@@ -110,32 +98,29 @@
                 if self.partial and pr.encrypted:
                     self.encrypted = pr.encrypted
 
         if pr.manifest:
             self.set_manifest(filename)
         else:
             assert pr.volume_number is not None
-            assert pr.volume_number not in self.volume_name_dict, \
-                u"""Volume %d is already in the volume list as "%s".
-                "%s" has the same volume number.
-                Please check your command line and retry.""" % (
-                    pr.volume_number,
-                    util.fsdecode(self.volume_name_dict[pr.volume_number]),
-                    util.fsdecode(filename)
-                )
+            assert pr.volume_number not in self.volume_name_dict, (
+                f"Volume {int(pr.volume_number)} is already in the volume list as "
+                f"{os.fsdecode(self.volume_name_dict[pr.volume_number])}. "
+                f"{os.fsdecode(filename)} has the same volume number. "
+                f"Please check your command line and retry.")
             self.volume_name_dict[pr.volume_number] = filename
 
         return True
 
     def set_info(self, pr):
-        u"""
+        """
         Set BackupSet information from ParseResults object
 
         @param pr: parse results
-        @type pf: ParseResults
+        @type pr: ParseResults
         """
         assert not self.info_set
         self.type = pr.type
         self.time = pr.time
         self.start_time = pr.start_time
         self.end_time = pr.end_time
         self.time = pr.time
@@ -144,357 +129,349 @@
         self.info_set = True
 
     def set_files_changed(self):
         mf = self.get_manifest()
         self.files_changed = mf.get_files_changed()
 
     def set_manifest(self, remote_filename):
-        u"""
+        """
         Add local and remote manifest filenames to backup set
         """
         assert not self.remote_manifest_name, \
-            u"Cannot set filename of remote manifest to %s; already set to %s." % (
-                remote_filename,
-                self.remote_manifest_name,
-            )
+            f"Cannot set filename of remote manifest to {remote_filename}; already set to {self.remote_manifest_name}."
         self.remote_manifest_name = remote_filename
 
-        if self.action != u"replicate":
-            local_filename_list = config.archive_dir_path.listdir()
-        else:
-            local_filename_list = []
+        local_filename_list = config.archive_dir_path.listdir()
         for local_filename in local_filename_list:
             pr = file_naming.parse(local_filename)
             if (pr and pr.manifest and pr.type == self.type and
                     pr.time == self.time and
                     pr.start_time == self.start_time and
                     pr.end_time == self.end_time):
                 self.local_manifest_path = \
                     config.archive_dir_path.append(local_filename)
 
                 self.set_files_changed()
                 break
 
     def delete(self):
-        u"""
+        """
         Remove all files in set, both local and remote
         """
         rfn = self.get_filenames()
         rfn.reverse()
         try:
             self.backend.delete(rfn)
         except Exception:
-            log.Debug(_(u"BackupSet.delete: missing %s") % [util.fsdecode(f) for f in rfn])
+            log.Debug(_("BackupSet.delete: missing %s") % [os.fsdecode(f) for f in rfn])
             pass
-        if self.action != u"replicate":
-            local_filename_list = config.archive_dir_path.listdir()
-        else:
-            local_filename_list = []
+        local_filename_list = config.archive_dir_path.listdir()
         for lfn in local_filename_list:
             pr = file_naming.parse(lfn)
             if (pr and pr.time == self.time and
                     pr.start_time == self.start_time and
                     pr.end_time == self.end_time):
                 try:
                     config.archive_dir_path.append(lfn).delete()
                 except Exception:
-                    log.Debug(_(u"BackupSet.delete: missing %s") % [util.fsdecode(f) for f in lfn])
+                    log.Debug(_("BackupSet.delete: missing %s") % [os.fsdecode(f) for f in lfn])
                     pass
         util.release_lockfile()
 
     def __str__(self):
-        u"""
+        """
         For now just list files in set
         """
         filelist = []
         if self.remote_manifest_name:
             filelist.append(self.remote_manifest_name)
         filelist.extend(list(self.volume_name_dict.values()))
-        return u"[%s]" % u", ".join(map(util.fsdecode, filelist))
+        return f"[{', '.join(map(os.fsdecode, filelist))}]"
 
     def get_timestr(self):
-        u"""
+        """
         Return time string suitable for log statements
         """
         return dup_time.timetopretty(self.time or self.end_time)
 
     def check_manifests(self, check_remote=True):
-        u"""
+        """
         Make sure remote manifest is equal to local one
         """
         if not self.remote_manifest_name and not self.local_manifest_path:
-            log.FatalError(_(u"Fatal Error: No manifests found for most recent backup"),
+            log.FatalError(_("Fatal Error: No manifests found for most recent backup"),
                            log.ErrorCode.no_manifests)
-        assert self.remote_manifest_name, u"if only one, should be remote"
+        assert self.remote_manifest_name, "if only one, should be remote"
 
         remote_manifest = self.get_remote_manifest() if check_remote else None
         if self.local_manifest_path:
             local_manifest = self.get_local_manifest()
         if remote_manifest and self.local_manifest_path and local_manifest:
             if remote_manifest != local_manifest:
                 if config.check_remote:
-                    log.FatalError(_(u"Fatal Error: Remote manifest does not match "
-                                     u"local one.  Either the remote backup set or "
-                                     u"the local archive directory has been corrupted."),
+                    log.FatalError(_("Fatal Error: Remote manifest does not match "
+                                     "local one.  Either the remote backup set or "
+                                     "the local archive directory has been corrupted."),
                                    log.ErrorCode.mismatched_manifests)
                 else:
-                    log.Error(_(u"Error processing remote manifest (%s): %s") %
+                    log.Error(_("Error processing remote manifest (%s): %s") %
                               (util.fsdecode(self.remote_manifest_name), util.uexc(message)))
                     return None
         if not remote_manifest:
             if self.local_manifest_path:
                 remote_manifest = local_manifest
             else:
-                log.FatalError(_(u"Fatal Error: Neither remote nor local "
-                                 u"manifest is readable."),
+                log.FatalError(_("Fatal Error: Neither remote nor local "
+                                 "manifest is readable."),
                                log.ErrorCode.unreadable_manifests)
         remote_manifest.check_dirinfo()
 
     def get_local_manifest(self):
-        u"""
+        """
         Return manifest object by reading local manifest file
         """
         assert self.local_manifest_path
         manifest_buffer = self.local_manifest_path.get_data()
-        log.Info(_(u"Processing local manifest %s (%s)") % (
-            self.local_manifest_path.name, len(manifest_buffer)))
+        log.Info(_("Processing local manifest %s (%s)") % (
+            self.local_manifest_path.uc_name, len(manifest_buffer)))
         return manifest.Manifest().from_string(manifest_buffer)
 
     def get_remote_manifest(self):
-        u"""
+        """
         Return manifest by reading remote manifest on backend
         """
         assert self.remote_manifest_name
         try:
             manifest_buffer = self.backend.get_data(self.remote_manifest_name)
         except GPGError as message:
-            log.FatalError(_(u"Error processing remote manifest (%s): %s") %
-                           (util.fsdecode(self.remote_manifest_name), util.uexc(message)))
-        log.Info(_(u"Processing remote manifest %s (%s)") % (
-            util.fsdecode(self.remote_manifest_name), len(manifest_buffer)))
+            log.Error(_("Error processing remote manifest (%s): %s") %
+                      (os.fsdecode(self.remote_manifest_name), util.uexc(message)))
+            return None
+        log.Info(_("Processing remote manifest %s (%s)") % (
+            os.fsdecode(self.remote_manifest_name), len(manifest_buffer)))
         return manifest.Manifest().from_string(manifest_buffer)
 
     def get_manifest(self):
-        u"""
+        """
         Return manifest object, showing preference for local copy
         """
         if self.local_manifest_path:
             return self.get_local_manifest()
         else:
             return self.get_remote_manifest()
 
     def get_filenames(self):
-        u"""
+        """
         Return sorted list of (remote) filenames of files in set
         """
         assert self.info_set
-        volume_num_list = list(self.volume_name_dict.keys())
-        volume_num_list.sort()
+        volume_num_list = sorted(self.volume_name_dict.keys())
         volume_filenames = [self.volume_name_dict[x] for x in volume_num_list]
         if self.remote_manifest_name:
             # For convenience of implementation for restart support, we treat
             # local partial manifests as this set's remote manifest.  But
             # when specifically asked for a list of remote filenames, we
             # should not include it.
             pr = file_naming.parse(self.remote_manifest_name)
             if pr and not pr.partial:
                 volume_filenames.append(self.remote_manifest_name)
         return volume_filenames
 
     def get_time(self):
-        u"""
+        """
         Return time if full backup, or end_time if incremental
         """
         if self.time:
             return self.time
         if self.end_time:
             return self.end_time
-        assert 0, u"Neither self.time nor self.end_time set"
+        assert 0, "Neither self.time nor self.end_time set"
 
     def get_files_changed(self):
         return self.files_changed
 
     def __len__(self):
-        u"""
+        """
         Return the number of volumes in the set
         """
         return len(list(self.volume_name_dict.keys()))
 
     def __eq__(self, other):
-        u"""
+        """
         Return whether this backup set is equal to other
         """
         return self.type == other.type and \
             self.time == other.time and \
             self.start_time == other.start_time and \
             self.end_time == other.end_time and \
             len(self) == len(other)
 
 
 class BackupChain(object):
-    u"""
+    """
     BackupChain - a number of linked BackupSets
 
     A BackupChain always starts with a full backup set and continues
     with incremental ones.
     """
+
     def __init__(self, backend):
-        u"""
+        """
         Initialize new chain, only backend is required at first
         """
         self.backend = backend
         self.fullset = None
         self.incset_list = []  # sorted list of BackupSets
         self.start_time, self.end_time = None, None
 
     def set_full(self, fullset):
-        u"""
+        """
         Add full backup set
         """
         assert not self.fullset and isinstance(fullset, BackupSet)
         self.fullset = fullset
         assert fullset.time
         self.start_time, self.end_time = fullset.time, fullset.time
 
     def add_inc(self, incset):
-        u"""
+        """
         Add incset to self.  Return False if incset does not match
         """
         if self.end_time == incset.start_time:
             self.incset_list.append(incset)
         else:
             if (self.incset_list and
                     incset.start_time == self.incset_list[-1].start_time and
                     incset.end_time > self.incset_list[-1].end_time):
-                log.Info(_(u"Preferring Backupset over previous one!"))
+                log.Info(_("Preferring Backupset over previous one!"))
                 self.incset_list[-1] = incset
             else:
-                log.Info(_(u"Ignoring incremental Backupset (start_time: %s; needed: %s)") %
+                log.Info(_("Ignoring incremental Backupset (start_time: %s; needed: %s)") %
                          (dup_time.timetopretty(incset.start_time),
                           dup_time.timetopretty(self.end_time)))
                 return False
         self.end_time = incset.end_time
-        log.Info(_(u"Added incremental Backupset (start_time: %s / end_time: %s)") %
+        log.Info(_("Added incremental Backupset (start_time: %s / end_time: %s)") %
                  (dup_time.timetopretty(incset.start_time),
                   dup_time.timetopretty(incset.end_time)))
         assert self.end_time
         return True
 
     def delete(self, keep_full=False):
-        u"""
+        """
         Delete all sets in chain, in reverse order
         """
         for i in range(len(self.incset_list) - 1, -1, -1):
             self.incset_list[i].delete()
         if self.fullset and not keep_full:
             self.fullset.delete()
 
     def get_sets_at_time(self, time):
-        u"""
+        """
         Return a list of sets in chain earlier or equal to time
         """
         older_incsets = [s for s in self.incset_list if s.end_time <= time]
         return [self.fullset] + older_incsets
 
     def get_last(self):
-        u"""
+        """
         Return last BackupSet in chain
         """
         if self.incset_list:
             return self.incset_list[-1]
         else:
             return self.fullset
 
     def get_first(self):
-        u"""
+        """
         Return first BackupSet in chain (ie the full backup)
         """
         return self.fullset
 
     def short_desc(self):
-        u"""
+        """
         Return a short one-line description of the chain,
         suitable for log messages.
         """
-        return u"[%s]-[%s]" % (dup_time.timetopretty(self.start_time),
-                               dup_time.timetopretty(self.end_time))
+        return f"[{dup_time.timetopretty(self.start_time)}]-[{dup_time.timetopretty(self.end_time)}]"
 
-    def to_log_info(self, prefix=u''):
-        u"""
+    def to_log_info(self, prefix=''):
+        """
         Return summary, suitable for printing to log
         """
         l = []
         for s in self.get_all_sets():
             if s.time:
-                btype = u"full"
+                btype = "full"
                 time = s.time
             else:
-                btype = u"inc"
+                btype = "inc"
                 time = s.end_time
             if s.encrypted:
-                enc = u"enc"
+                enc = "enc"
             else:
-                enc = u"noenc"
-            l.append(u"%s%s %s %d %s" % (prefix, btype, dup_time.timetostring(time), (len(s)), enc))
+                enc = "noenc"
+            l.append(f"{prefix}{btype} {dup_time.timetostring(time)} {len(s)} {enc}")
         return l
 
     def __str__(self):
-        u"""
+        """
         Return string representation, for testing purposes
         """
-        set_schema = u"%20s   %30s   %15s"
-        l = [u"-------------------------",
-             _(u"Chain start time: ") + dup_time.timetopretty(self.start_time),
-             _(u"Chain end time: ") + dup_time.timetopretty(self.end_time),
-             _(u"Number of contained backup sets: %d") %
+        set_schema = "%20s   %30s   %15s"
+        l = ["-------------------------",
+             _("Chain start time: ") + dup_time.timetopretty(self.start_time),
+             _("Chain end time: ") + dup_time.timetopretty(self.end_time),
+             _("Number of contained backup sets: %d") %
              (len(self.incset_list) + 1,),
-             _(u"Total number of contained volumes: %d") %
+             _("Total number of contained volumes: %d") %
              (self.get_num_volumes(),),
-             set_schema % (_(u"Type of backup set:"), _(u"Time:"), _(u"Num volumes:"))]
+             set_schema % (_("Type of backup set:"), _("Time:"), _("Num volumes:"))]
 
         for s in self.get_all_sets():
             if s.time:
-                btype = _(u"Full")
+                btype = _("Full")
                 time = s.time
             else:
-                btype = _(u"Incremental")
+                btype = _("Incremental")
                 time = s.end_time
             l.append(set_schema % (btype, dup_time.timetopretty(time), len(s)))
 
-        l.append(u"-------------------------")
-        return u"\n".join(l)
+        l.append("-------------------------")
+        return "\n".join(l)
 
     def get_num_volumes(self):
-        u"""
+        """
         Return the total number of volumes in the chain
         """
         n = 0
         for s in self.get_all_sets():
             n += len(s)
         return n
 
     def get_all_sets(self):
-        u"""
+        """
         Return list of all backup sets in chain
         """
         if self.fullset:
             return [self.fullset] + self.incset_list
         else:
             return self.incset_list
 
 
 class SignatureChain(object):
-    u"""
+    """
     A number of linked SignatureSets
 
     Analog to BackupChain - start with a full-sig, and continue with
     new-sigs.
     """
+
     def __init__(self, local, location):
-        u"""
+        """
         Return new SignatureChain.
 
         local should be true iff the signature chain resides in
         config.archive_dir_path and false if the chain is in
         config.backend.
 
         @param local: True if sig chain in config.archive_dir_path
@@ -508,87 +485,87 @@
         else:
             self.archive_dir_path, self.backend = None, location
         self.fullsig = None  # filename of full signature
         self.inclist = []  # list of filenames of incremental signatures
         self.start_time, self.end_time = None, None
 
     def __str__(self):
-        u"""
+        """
         Local or Remote and List of files in the set
         """
         if self.archive_dir_path:
-            place = _(u"local")
+            place = _("local")
         else:
-            place = _(u"remote")
+            place = _("remote")
         filelist = []
         if self.fullsig:
             filelist.append(self.fullsig)
         filelist.extend(self.inclist)
-        return u"%s: [%s]" % (place, u", ".join(filelist))
+        return f"{place}: [{', '.join(filelist)}]"
 
     def check_times(self, time_list):
-        u"""
+        """
         Check to make sure times are in whole seconds
         """
         for time in time_list:
-            if type(time) not in integer_types:
-                assert 0, u"Time %s in %s wrong type" % (time, time_list)
+            if not isinstance(time, int):
+                assert 0, f"Time {time} in {time_list} wrong type"
 
     def islocal(self):
-        u"""
+        """
         Return true if represents a signature chain in archive_dir_path
         """
         if self.archive_dir_path:
             return True
         else:
             return False
 
     def add_filename(self, filename, pr=None):
-        u"""
+        """
         Add new sig filename to current chain.  Return true if fits
         """
         if not pr:
             pr = file_naming.parse(filename)
         if not pr:
             return None
 
         if self.fullsig:
-            if pr.type != u"new-sig":
+            if pr.type != "new-sig":
                 return None
             if pr.start_time != self.end_time:
                 return None
             self.inclist.append(filename)
             self.check_times([pr.end_time])
             self.end_time = pr.end_time
             return 1
         else:
-            if pr.type != u"full-sig":
+            if pr.type != "full-sig":
                 return None
             self.fullsig = filename
             self.check_times([pr.time, pr.time])
             self.start_time, self.end_time = pr.time, pr.time
             return 1
 
     def get_fileobjs(self, time=None):
-        u"""
+        """
         Return ordered list of signature fileobjs opened for reading,
         optionally at a certain time
         """
         assert self.fullsig
         if self.archive_dir_path:  # local
             def filename_to_fileobj(filename):
-                u"""Open filename in archive_dir_path, return filtered fileobj"""
+                """Open filename in archive_dir_path, return filtered fileobj"""
                 sig_dp = path.DupPath(self.archive_dir_path.name, (filename,))
-                return sig_dp.filtered_open(u"rb")
+                return sig_dp.filtered_open("rb")
         else:
             filename_to_fileobj = self.backend.get_fileobj_read
         return [filename_to_fileobj(f) for f in self.get_filenames(time)]
 
     def delete(self, keep_full=False):
-        u"""
+        """
         Remove all files in signature set
         """
         # Try to delete in opposite order, so something useful even if aborted
         if self.archive_dir_path:
             for i in range(len(self.inclist) - 1, -1, -1):
                 self.archive_dir_path.append(self.inclist[i]).delete()
             if not keep_full:
@@ -598,15 +575,15 @@
             inclist_copy = self.inclist[:]
             inclist_copy.reverse()
             if not keep_full:
                 inclist_copy.append(self.fullsig)
             self.backend.delete(inclist_copy)
 
     def get_filenames(self, time=None):
-        u"""
+        """
         Return ordered list of filenames in set, up to a provided time
         """
         if self.fullsig:
             l = [self.fullsig]
         else:
             l = []
 
@@ -615,19 +592,20 @@
             inclist = [n for n in inclist if file_naming.parse(n).end_time <= time]
 
         l.extend(inclist)
         return l
 
 
 class CollectionsStatus(object):
-    u"""
+    """
     Hold information about available chains and sets
     """
+
     def __init__(self, backend, archive_dir_path, action):
-        u"""
+        """
         Make new object.  Does not set values
         """
         self.backend = backend
         self.archive_dir_path = archive_dir_path
         self.action = action
 
         # Will hold (signature chain, backup chain) pair of active
@@ -645,94 +623,93 @@
         self.orphaned_backup_sets = None
         self.incomplete_backup_sets = None
 
         # True if set_values() below has run
         self.values_set = None
 
     def to_log_info(self):
-        u"""
+        """
         Return summary of the collection, suitable for printing to log
         """
-        l = [u"backend %s" % (self.backend.__class__.__name__,),
-             u"archive-dir %s" % (self.archive_dir_path,)]
+        l = [f"backend {self.backend.__class__.__name__}",
+             f"archive-dir {self.archive_dir_path}"]
 
         for i in range(len(self.other_backup_chains)):
             # A bit of a misnomer.  Chain might have a sig.
-            l.append(u"chain-no-sig %d" % (i,))
-            l += self.other_backup_chains[i].to_log_info(u' ')
+            l.append(f"chain-no-sig {int(i)}")
+            l += self.other_backup_chains[i].to_log_info(' ')
 
         if self.matched_chain_pair:
-            l.append(u"chain-complete")
-            l += self.matched_chain_pair[1].to_log_info(u' ')
+            l.append("chain-complete")
+            l += self.matched_chain_pair[1].to_log_info(' ')
 
-        l.append(u"orphaned-sets-num %d" % (len(self.orphaned_backup_sets),))
-        l.append(u"incomplete-sets-num %d" % (len(self.incomplete_backup_sets),))
+        l.append(f"orphaned-sets-num {len(self.orphaned_backup_sets)}")
+        l.append(f"incomplete-sets-num {len(self.incomplete_backup_sets)}")
 
         return l
 
     def __str__(self):
-        u"""
+        """
         Return string summary of the collection
         """
-        l = [_(u"Collection Status"),
-             u"-----------------",
-             _(u"Connecting with backend: %s") %
+        l = [_("Collection Status"),
+             "-----------------",
+             _("Connecting with backend: %s") %
              (self.backend.__class__.__name__,),
-             _(u"Archive dir: %s") % (self.archive_dir_path.uc_name if self.archive_dir_path else u'None',)]
+             _("Archive dir: %s") % (self.archive_dir_path.uc_name if self.archive_dir_path else 'None',)]
 
-        l.append(u"\n" + _(u"Found %d secondary backup chain(s).")
+        l.append("\n" + _("Found %d secondary backup chain(s).")
                  % len(self.other_backup_chains))
         for i in range(len(self.other_backup_chains)):
-            l.append(_(u"Secondary chain %d of %d:") %
+            l.append(_("Secondary chain %d of %d:") %
                      (i + 1, len(self.other_backup_chains)))
             l.append(str(self.other_backup_chains[i]))
-            l.append(u"")
+            l.append("")
 
         if self.matched_chain_pair:
-            l.append(u"\n" + _(u"Found primary backup chain with matching "
-                     u"signature chain:"))
+            l.append("\n" + _("Found primary backup chain with matching "
+                              "signature chain:"))
             l.append(str(self.matched_chain_pair[1]))
         else:
-            l.append(_(u"No backup chains with active signatures found"))
+            l.append(_("No backup chains with active signatures found"))
 
         if self.orphaned_backup_sets or self.incomplete_backup_sets:
-            l.append(_(u"Also found %d backup set(s) not part of any chain,")
+            l.append(_("Also found %d backup set(s) not part of any chain,")
                      % len(self.orphaned_backup_sets))
-            l.append(_(u"and %d incomplete backup set(s).")
+            l.append(_("and %d incomplete backup set(s).")
                      % len(self.incomplete_backup_sets))
             # TRANSL: "cleanup" is a hard-coded command, so do not translate it
-            l.append(_(u'These may be deleted by running duplicity with the '
-                       u'"cleanup" command.'))
+            l.append(_('These may be deleted by running duplicity with the '
+                       '"cleanup" command.'))
         else:
-            l.append(_(u"No orphaned or incomplete backup sets found."))
+            l.append(_("No orphaned or incomplete backup sets found."))
 
-        return u"\n".join(l)
+        return "\n".join(l)
 
     def set_values(self, sig_chain_warning=1):
-        u"""
+        """
         Set values from archive_dir_path and backend.
 
         Returns self for convenience.  If sig_chain_warning is set to None,
         do not warn about unnecessary sig chains.  This is because there may
         naturally be some unecessary ones after a full backup.
         """
         self.values_set = 1
 
         # get remote filename list
         backend_filename_list = self.backend.list()
-        log.Debug(_(u"%d file(s) exists on backend")
+        log.Debug(_("%d file(s) exists on backend")
                   % len(backend_filename_list))
 
         # get local filename list
-        if self.action != u"replicate":
-            local_filename_list = self.archive_dir_path.listdir()
-        else:
-            local_filename_list = []
-        log.Debug(_(u"%d file(s) exists in cache")
-                  % len(local_filename_list))
+        local_filename_list = self.archive_dir_path.listdir()
+        log.Debug(ngettext("%d file exists in cache",
+                           "%d files exist in cache",
+                           len(local_filename_list)) %
+                  len(local_filename_list))
 
         # check for partial backups
         partials = []
         for local_filename in local_filename_list:
             pr = file_naming.parse(local_filename)
             if pr and pr.partial:
                 partials.append(local_filename)
@@ -741,27 +718,27 @@
         (backup_chains, self.orphaned_backup_sets,
          self.incomplete_backup_sets) = \
             self.get_backup_chains(partials + backend_filename_list)
         backup_chains = self.get_sorted_chains(backup_chains)
         self.all_backup_chains = backup_chains
 
         assert len(backup_chains) == len(self.all_backup_chains), \
-            u"get_sorted_chains() did something more than re-ordering"
+            "get_sorted_chains() did something more than re-ordering"
 
         local_sig_chains, self.local_orphaned_sig_names = \
             self.get_signature_chains(True)
         remote_sig_chains, self.remote_orphaned_sig_names = \
             self.get_signature_chains(False, filelist=backend_filename_list)
         self.set_matched_chain_pair(local_sig_chains + remote_sig_chains,
                                     backup_chains)
         self.warn(sig_chain_warning)
         return self
 
     def set_matched_chain_pair(self, sig_chains, backup_chains):
-        u"""
+        """
         Set self.matched_chain_pair and self.other_sig/backup_chains
 
         The latest matched_chain_pair will be set.  If there are both
         remote and local signature chains capable of matching the
         latest backup chain, use the local sig chain (it does not need
         to be downloaded).
         """
@@ -774,16 +751,16 @@
             for i in range(len(sig_chains) - 1, -1, -1):
                 if sig_chains[i].end_time == latest_backup_chain.end_time:
                     pass
                 # See if the set before last matches:
                 elif (len(latest_backup_chain.get_all_sets()) >= 2 and
                       sig_chains[i].end_time == latest_backup_chain.get_all_sets()[-2].end_time):
                     # It matches, remove the last backup set:
-                    log.Warn(_(u"Warning, discarding last backup set, because "
-                               u"of missing signature file."))
+                    log.Warn(_("Warning, discarding last backup set, because "
+                               "of missing signature file."))
                     self.incomplete_backup_sets.append(latest_backup_chain.incset_list[-1])
                     latest_backup_chain.incset_list = latest_backup_chain.incset_list[:-1]
                 else:
                     continue
 
                 # Found a matching pair:
                 if self.matched_chain_pair is None:
@@ -791,183 +768,181 @@
 
                 break
 
         if self.matched_chain_pair:
             self.other_backup_chains.remove(self.matched_chain_pair[1])
 
     def warn(self, sig_chain_warning):
-        u"""
+        """
         Log various error messages if find incomplete/orphaned files
         """
         assert self.values_set
 
         if self.local_orphaned_sig_names:
-            log.Warn(_(u"Warning, found the following local orphaned signature file(s):") + u"\n" +
-                     u"\n".join(map(util.fsdecode, self.local_orphaned_sig_names)),
+            log.Warn(_("Warning, found the following local orphaned signature file(s):") + "\n" +
+                     "\n".join(map(os.fsdecode, self.local_orphaned_sig_names)),
                      log.WarningCode.orphaned_sig)
 
         if self.remote_orphaned_sig_names:
-            log.Warn(_(u"Warning, found the following remote orphaned signature file(s):") + u"\n" +
-                     u"\n".join(map(util.fsdecode, self.remote_orphaned_sig_names)),
+            log.Warn(_("Warning, found the following remote orphaned signature file(s):") + "\n" +
+                     "\n".join(map(os.fsdecode, self.remote_orphaned_sig_names)),
                      log.WarningCode.orphaned_sig)
 
         if self.all_sig_chains and sig_chain_warning and not self.matched_chain_pair:
-            log.Warn(_(u"Warning, found signatures but no corresponding "
-                       u"backup files"), log.WarningCode.unmatched_sig)
+            log.Warn(_("Warning, found signatures but no corresponding "
+                       "backup files"), log.WarningCode.unmatched_sig)
 
         if self.incomplete_backup_sets:
-            log.Warn(_(u"Warning, found incomplete backup sets, probably left "
-                       u"from aborted session"), log.WarningCode.incomplete_backup)
+            log.Warn(_("Warning, found incomplete backup sets, probably left "
+                       "from aborted session"), log.WarningCode.incomplete_backup)
 
         if self.orphaned_backup_sets:
-            log.Warn(_(u"Warning, found the following orphaned backup file(s):") + u"\n" +
-                     u"\n".join(map(str, self.orphaned_backup_sets)),
+            log.Warn(_("Warning, found the following orphaned backup file(s):") + "\n" +
+                     "\n".join(map(str, self.orphaned_backup_sets)),
                      log.WarningCode.orphaned_backup)
 
     def get_backup_chains(self, filename_list):
-        u"""
+        """
         Split given filename_list into chains
 
         Return value will be tuple (list of chains, list of sets, list
         of incomplete sets), where the list of sets will comprise sets
         not fitting into any chain, and the incomplete sets are sets
         missing files.
         """
-        log.Debug(_(u"Extracting backup chains from list of files: %s")
-                  % [util.fsdecode(f) for f in filename_list])
+        log.Debug(_("Extracting backup chains from list of files: %s")
+                  % [os.fsdecode(f) for f in filename_list])
         # First put filenames in set form
         sets = []
 
         def add_to_sets(filename):
-            u"""
+            """
             Try adding filename to existing sets, or make new one
             """
             pr = file_naming.parse(filename)
             for set in sets:  # pylint: disable=redefined-builtin
                 if set.add_filename(filename, pr):
-                    log.Debug(_(u"File %s is part of known set") % (util.fsdecode(filename),))
+                    log.Debug(_("File %s is part of known set") % (os.fsdecode(filename),))
                     break
             else:
-                log.Debug(_(u"File %s is not part of a known set; creating new set") % (util.fsdecode(filename),))
+                log.Debug(_("File %s is not part of a known set; creating new set") % (os.fsdecode(filename),))
                 new_set = BackupSet(self.backend, self.action)
                 if new_set.add_filename(filename, pr):
                     sets.append(new_set)
                 else:
-                    log.Debug(_(u"Ignoring file (rejected by backup set) '%s'") % util.fsdecode(filename))
+                    log.Debug(_("Ignoring file (rejected by backup set) '%s'") % os.fsdecode(filename))
 
         for f in filename_list:
             add_to_sets(f)
         sets, incomplete_sets = self.get_sorted_sets(sets)
 
         chains, orphaned_sets = [], []
 
         def add_to_chains(set):  # pylint: disable=redefined-builtin
-            u"""
+            """
             Try adding set to existing chains, or make new one
             """
-            if set.type == u"full":
+            if set.type == "full":
                 new_chain = BackupChain(self.backend)
                 new_chain.set_full(set)
                 chains.append(new_chain)
-                log.Debug(_(u"Found backup chain %s") % (new_chain.short_desc()))
+                log.Debug(_("Found backup chain %s") % (new_chain.short_desc()))
             else:
-                assert set.type == u"inc"
+                assert set.type == "inc"
                 for chain in chains:
                     if chain.add_inc(set):
-                        log.Debug(_(u"Added set %s to pre-existing chain %s") % (set.get_timestr(),
-                                                                                 chain.short_desc()))
+                        log.Debug(_("Added set %s to pre-existing chain %s") % (set.get_timestr(),
+                                                                                chain.short_desc()))
                         break
                 else:
-                    log.Debug(_(u"Found orphaned set %s") % (set.get_timestr(),))
+                    log.Debug(_("Found orphaned set %s") % (set.get_timestr(),))
                     orphaned_sets.append(set)
+
         for s in sets:
             add_to_chains(s)
         return chains, orphaned_sets, incomplete_sets
 
     def get_sorted_sets(self, set_list):
-        u"""
+        """
         Sort set list by end time, return (sorted list, incomplete)
         """
         time_set_pairs, incomplete_sets = [], []
         for set in set_list:  # pylint: disable=redefined-builtin
             if not set.is_complete():
                 incomplete_sets.append(set)
-            elif set.type == u"full":
+            elif set.type == "full":
                 time_set_pairs.append((set.time, set))
             else:
                 time_set_pairs.append((set.end_time, set))
         time_set_pairs.sort(key=lambda x: x[0])
         return [p[1] for p in time_set_pairs], incomplete_sets
 
     def get_signature_chains(self, local, filelist=None):
-        u"""
+        """
         Find chains in archive_dir_path (if local is true) or backend
 
         Use filelist if given, otherwise regenerate.  Return value is
         pair (list of chains, list of signature paths not in any
         chains).
         """
+
         def get_filelist():
             if filelist is not None:
                 return filelist
             elif local:
-                if self.action != u"replicate":
-                    return self.archive_dir_path.listdir()
-                else:
-                    return []
+                return self.archive_dir_path.listdir()
             else:
                 return self.backend.list()
 
         def get_new_sigchain():
-            u"""
+            """
             Return new empty signature chain
             """
             if local:
                 return SignatureChain(True, self.archive_dir_path)
             else:
                 return SignatureChain(False, self.backend)
 
         # Build initial chains from full sig filenames
         chains, new_sig_filenames = [], []
         for filename in get_filelist():
             pr = file_naming.parse(filename)
             if pr:
-                if pr.type == u"full-sig":
+                if pr.type == "full-sig":
                     new_chain = get_new_sigchain()
                     assert new_chain.add_filename(filename, pr)
                     chains.append(new_chain)
-                elif pr.type == u"new-sig":
+                elif pr.type == "new-sig":
                     new_sig_filenames.append(filename)
 
         # Try adding new signatures to existing chains
         orphaned_filenames = []
         new_sig_filenames.sort(key=lambda x: int(file_naming.parse(x).start_time))
         for sig_filename in new_sig_filenames:
             for chain in chains:
                 if chain.add_filename(sig_filename):
                     break
             else:
                 orphaned_filenames.append(sig_filename)
         return chains, orphaned_filenames
 
     def get_sorted_chains(self, chain_list):
-        u"""
+        """
         Return chains sorted by end_time.  If tie, local goes last
         """
         # Build dictionary from end_times to lists of corresponding chains
         endtime_chain_dict = {}
         for chain in chain_list:
             if chain.end_time in endtime_chain_dict:
                 endtime_chain_dict[chain.end_time].append(chain)
             else:
                 endtime_chain_dict[chain.end_time] = [chain]
 
         # Use dictionary to build final sorted list
-        sorted_end_times = list(endtime_chain_dict.keys())
-        sorted_end_times.sort()
+        sorted_end_times = sorted(endtime_chain_dict.keys())
         sorted_chain_list = []
         for end_time in sorted_end_times:
             chain_list = endtime_chain_dict[end_time]
             if len(chain_list) == 1:
                 sorted_chain_list.append(chain_list[0])
             else:
                 assert len(chain_list) == 2
@@ -977,69 +952,69 @@
                 else:  # is local, goes second
                     sorted_chain_list.append(chain_list[1])
                     sorted_chain_list.append(chain_list[0])
 
         return sorted_chain_list
 
     def get_backup_chain_at_time(self, time):
-        u"""
+        """
         Return backup chain covering specified time
 
         Tries to find the backup chain covering the given time.  If
         there is none, return the earliest chain before, and failing
         that, the earliest chain.
         """
         if not self.all_backup_chains:
-            raise CollectionsError(u"No backup chains found")
+            raise CollectionsError("No backup chains found")
 
         covering_chains = [c for c in self.all_backup_chains
                            if c.start_time <= time <= c.end_time]
         if len(covering_chains) > 1:
-            raise CollectionsError(u"Two chains cover the given time")
+            raise CollectionsError("Two chains cover the given time")
         elif len(covering_chains) == 1:
             return covering_chains[0]
 
         old_chains = [c for c in self.all_backup_chains if c.end_time < time]
         if old_chains:
             return old_chains[-1]
         else:
             return self.all_backup_chains[0]  # no chains are old enough
 
     def get_signature_chain_at_time(self, time):
-        u"""
+        """
         Return signature chain covering specified time
 
         Tries to find the signature chain covering the given time.  If
         there is none, return the earliest chain before, and failing
         that, the earliest chain.
         """
         if not self.all_sig_chains:
-            raise CollectionsError(u"No signature chains found")
+            raise CollectionsError("No signature chains found")
 
         covering_chains = [c for c in self.all_sig_chains
                            if c.start_time <= time <= c.end_time]
         if covering_chains:
             return covering_chains[-1]  # prefer local if multiple sig chains
 
         old_chains = [c for c in self.all_sig_chains if c.end_time < time]
         if old_chains:
             return old_chains[-1]
         else:
             # no chains are old enough, give oldest and warn user
             oldest = self.all_sig_chains[0]
             if time < oldest.start_time:
-                log.Warn(_(u"No signature chain for the requested time. "
-                           u"Using oldest available chain, starting at time %s.") %
+                log.Warn(_("No signature chain for the requested time. "
+                           "Using oldest available chain, starting at time %s.") %
                          dup_time.timetopretty(oldest.start_time),
                          log.WarningCode.no_sig_for_time,
                          dup_time.timetostring(oldest.start_time))
             return oldest
 
     def get_extraneous(self):
-        u"""
+        """
         Return list of the names of extraneous duplicity files
 
         A duplicity file is considered extraneous if it is
         recognizable as a duplicity file, but isn't part of some
         complete backup set, or current signature chain.
         """
         assert self.values_set
@@ -1052,86 +1027,85 @@
             else:
                 local_filenames.extend(set_or_chain.get_filenames())
         local_filenames += self.local_orphaned_sig_names
         remote_filenames += self.remote_orphaned_sig_names
         return local_filenames, remote_filenames
 
     def sort_sets(self, setlist):
-        u"""Return new list containing same elems of setlist, sorted by time"""
-        pairs = [(s.get_time(), s) for s in setlist]
-        pairs.sort()
+        """Return new list containing same elems of setlist, sorted by time"""
+        pairs = sorted([(s.get_time(), s) for s in setlist])
         return [p[1] for p in pairs]
 
     def get_chains_older_than(self, t):
-        u"""
+        """
         Returns a list of backup chains older than the given time t
 
         All of the times will be associated with an intact chain.
         Furthermore, none of the times will be of a chain which a newer
         set may depend on.  For instance, if set A is a full set older
         than t, and set B is an incremental based on A which is newer
         than t, then the time of set A will not be returned.
         """
         assert self.values_set
         old_chains = []
         for chain in self.all_backup_chains:
             if (chain.end_time < t and
-                (not self.matched_chain_pair or
-                 chain is not self.matched_chain_pair[1])):
+                    (not self.matched_chain_pair or
+                     chain is not self.matched_chain_pair[1])):
                 # don't delete the active (matched) chain
                 old_chains.append(chain)
         return old_chains
 
     def get_signature_chains_older_than(self, t):
-        u"""
+        """
         Returns a list of signature chains older than the given time t
 
         All of the times will be associated with an intact chain.
         Furthermore, none of the times will be of a chain which a newer
         set may depend on.  For instance, if set A is a full set older
         than t, and set B is an incremental based on A which is newer
         than t, then the time of set A will not be returned.
         """
         assert self.values_set
         old_chains = []
         for chain in self.all_sig_chains:
             if (chain.end_time < t and
-                (not self.matched_chain_pair or
-                 chain is not self.matched_chain_pair[0])):
+                    (not self.matched_chain_pair or
+                     chain is not self.matched_chain_pair[0])):
                 # don't delete the active (matched) chain
                 old_chains.append(chain)
         return old_chains
 
     def get_last_full_backup_time(self):
-        u"""
+        """
         Return the time of the last full backup,
         or 0 if there is none.
         """
         return self.get_nth_last_full_backup_time(1)
 
     def get_nth_last_full_backup_time(self, n):
-        u"""
+        """
         Return the time of the nth to last full backup,
         or 0 if there is none.
         """
         chain = self.get_nth_last_backup_chain(n)
         if chain is None:
             return 0
         else:
             return chain.get_first().time
 
     def get_last_backup_chain(self):
-        u"""
+        """
         Return the last full backup of the collection,
         or None if there is no full backup chain.
         """
         return self.get_nth_last_backup_chain(1)
 
     def get_nth_last_backup_chain(self, n):
-        u"""
+        """
         Return the nth-to-last full backup of the collection,
         or None if there is less than n backup chains.
 
         NOTE: n = 1 -> time of latest available chain (n = 0 is not
         a valid input). Thus the second-to-last is obtained with n=2
         rather than n=1.
         """
@@ -1144,30 +1118,30 @@
         sorted = self.all_backup_chains[:]  # pylint: disable=redefined-builtin
         sorted.sort(key=lambda x: x.get_first().time)
 
         sorted.reverse()
         return sorted[n - 1]
 
     def get_older_than(self, t):
-        u"""
+        """
         Returns a list of backup sets older than the given time t
 
         All of the times will be associated with an intact chain.
         Furthermore, none of the times will be of a set which a newer
         set may depend on.  For instance, if set A is a full set older
         than t, and set B is an incremental based on A which is newer
         than t, then the time of set A will not be returned.
         """
         old_sets = []
         for chain in self.get_chains_older_than(t):
             old_sets.extend(chain.get_all_sets())
         return self.sort_sets(old_sets)
 
     def get_older_than_required(self, t):
-        u"""
+        """
         Returns list of old backup sets required by new sets
 
         This function is similar to the previous one, but it only
         returns the times of sets which are old but part of the chains
         where the newer end of the chain is newer than t.
         """
         assert self.values_set
@@ -1175,84 +1149,84 @@
         result_sets = []
         for chain in new_chains:
             old_sets = [s for s in chain.get_all_sets() if s.get_time() < t]
             result_sets.extend(old_sets)
         return self.sort_sets(result_sets)
 
     def get_file_changed_record(self, filepath):
-        u"""
+        """
         Returns time line of specified file changed
         """
         # quick fix to spaces in filepath
         modified_filepath = filepath
-        if u" " in filepath:
-            modified_filepath = u'"' + filepath.replace(u" ", r"\x20") + u'"'
+        if " " in filepath:
+            modified_filepath = '"' + filepath.replace(" ", r"\x20") + '"'
 
         if not self.matched_chain_pair:
-            return u""
+            return ""
 
         all_backup_set = self.matched_chain_pair[1].get_all_sets()
         specified_file_backup_set = []
         specified_file_backup_type = []
 
-        modified_filepath = util.fsencode(modified_filepath)
+        modified_filepath = os.fsencode(modified_filepath)
         for bs in all_backup_set:
             filelist = [fileinfo[1] for fileinfo in bs.get_files_changed()]
             if modified_filepath in filelist:
                 specified_file_backup_set.append(bs)
                 index = filelist.index(modified_filepath)
                 specified_file_backup_type.append(bs.get_files_changed()[index][0])
 
         return FileChangedStatus(filepath, list(zip(specified_file_backup_type, specified_file_backup_set)))
 
     def get_all_file_changed_records(self, set_index):
-        u"""
+        """
         Returns file changes in the specific backup set
         """
         if not self.matched_chain_pair:
-            return u""
+            return ""
 
         all_backup_set = list(reversed(self.matched_chain_pair[1].get_all_sets()))
         return BackupSetChangesStatus(all_backup_set[set_index])
 
 
 class FileChangedStatus(object):
     def __init__(self, filepath, fileinfo_list):
         self.filepath = filepath
         self.fileinfo_list = fileinfo_list
 
     def __str__(self):
-        set_schema = u"%20s   %30s  %20s"
-        l = [u"-------------------------",
-             _(u"File: %s") % self.filepath,
-             _(u"Total number of backup: %d") % len(self.fileinfo_list),
-             set_schema % (_(u"Type of backup set:"), _(u"Time:"), _(u"Type of file change:"))]
+        set_schema = "%20s   %30s  %20s"
+        l = ["-------------------------",
+             _("File: %s") % self.filepath,
+             _("Total number of backup: %d") % len(self.fileinfo_list),
+             set_schema % (_("Type of backup set:"), _("Time:"), _("Type of file change:"))]
 
         for s in self.fileinfo_list:
             backup_type = s[0]
             backup_set = s[1]
             if backup_set.time:
-                type = _(u"Full")  # pylint: disable=redefined-builtin
+                type = _("Full")  # pylint: disable=redefined-builtin
             else:
-                type = _(u"Incremental")
+                type = _("Incremental")
             l.append(set_schema % (type, dup_time.timetopretty(backup_set.get_time()), backup_type.title()))
 
-        l.append(u"-------------------------")
-        return u"\n".join(l)
+        l.append("-------------------------")
+        return "\n".join(l)
 
 
 class BackupSetChangesStatus(object):
     def __init__(self, backup_set):
         self.backup_set = backup_set
 
     def __str__(self):
         changed_files = self.backup_set.get_files_changed()
         max_file_path_len = max([len(c[1]) for c in changed_files] + [5])
-        set_schema = u"%%-%ds  %%20s" % max_file_path_len
-        l = [u"-------------------------",
-             _(u" Backup set time: %s") % (self.backup_set.get_timestr()),
-             _(u"Total number of changes: %d") % len(changed_files),
-             set_schema % (_(u"File:"), _(u"Type of file change:"))] + \
-            [set_schema % (c[1].decode(u'utf-8'), c[0].decode(u'utf-8'))
+        set_schema = "%%-%ds  %%20s" % max_file_path_len
+        l = ["-------------------------",
+             _(" Backup set time: %s") % (self.backup_set.get_timestr()),
+             _("Total number of changes: %d") % len(changed_files),
+             set_schema % (_("File:"), _("Type of file change:"))] + \
+            [set_schema % (c[1].decode('utf-8'), c[0].decode('utf-8'))
              for c in changed_files] + \
-            [u"-------------------------"]
-        return u"\n".join(l)
+            ["-------------------------"]
+        return "\n".join(l)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/robust.py` & `duplicity-2.0.0rc0/duplicity/robust.py`

 * *Files 10% similar despite different names*

```diff
@@ -24,45 +24,45 @@
 from duplicity import librsync
 from duplicity import log
 
 tmp_file_index = 1
 
 
 def check_common_error(error_handler, function, args=()):
-    u"""Apply function to args, if error, run error_handler on exception
+    """Apply function to args, if error, run error_handler on exception
 
     This only catches certain exceptions which seem innocent
     enough.
 
     """
-    # todo: import here to avoid circular dependency issue
-    from duplicity import path
+    from duplicity import path  # TODO: avoid circ. dep. issue
 
     try:
         return function(*args)
     # except (EnvironmentError, SkipFileException, DSRPPermError,
     #        RPathException, Rdiff.RdiffException,
     #        librsync.librsyncError, C.UnknownFileTypeError), exc:
     #    TracebackArchive.add()
     except (IOError, EnvironmentError, librsync.librsyncError, path.PathException) as exc:
         if (not isinstance(exc, EnvironmentError) or
-            hasattr(exc, u"errno") and
-            errno.errorcode[exc.errno] in
-            [u'EPERM', u'ENOENT', u'EACCES', u'EBUSY', u'EEXIST',
-             u'ENOTDIR', u'ENAMETOOLONG', u'EINTR', u'ENOTEMPTY',
-             u'EIO', u'ETXTBSY', u'ESRCH', u'EINVAL', u'EOPNOTSUPP']):
+                hasattr(exc, "errno") and
+                errno.errorcode[exc.errno] in
+                ['EPERM', 'ENOENT', 'EACCES', 'EBUSY', 'EEXIST',
+                 'ENOTDIR', 'ENAMETOOLONG', 'EINTR', 'ENOTEMPTY',
+                 'EIO', 'ETXTBSY', 'ESRCH', 'EINVAL', 'EOPNOTSUPP']):
             # Log.exception()
             if error_handler:
                 return error_handler(exc, *args)
         else:
             # Log.exception(1, 2)
             raise
 
 
 def listpath(path):
-    u"""Like path.listdir() but return [] if error, and sort results"""
+    """Like path.listdir() but return [] if error, and sort results"""
+
     def error_handler(exc):  # pylint: disable=unused-argument
-        log.Warn(_(u"Error listing directory %s") % path.uc_name)
+        log.Warn(_("Error listing directory %s") % path.uc_name)
         return []
-    dir_listing = check_common_error(error_handler, path.listdir)
-    dir_listing.sort()
+
+    dir_listing = sorted(check_common_error(error_handler, path.listdir))
     return dir_listing
```

### Comparing `duplicity-1.2.3.dev43/duplicity/diffdir.py` & `duplicity-2.0.0rc0/duplicity/diffdir.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,78 +15,66 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Functions for producing signatures and deltas of directories
 
 Note that the main processes of this module have two parts.  In the
 first, the signature or delta is constructed of a ROPath iterator.  In
 the second, the ROPath iterator is put into tar block form.
 """
-from __future__ import division
-
-from future import standard_library
-standard_library.install_aliases()
-from builtins import map
-from builtins import next
-from builtins import str
-from builtins import range
-from builtins import object
 
 import io
-import sys
 
+from duplicity import progress
 from duplicity import statistics
 from duplicity import util
-from duplicity import config
 from duplicity.path import *  # pylint: disable=unused-wildcard-import,redefined-builtin
-from duplicity.lazy import *  # pylint: disable=unused-wildcard-import,redefined-builtin
-from duplicity import progress
 
 # A StatsObj will be written to this from DirDelta and DirDelta_WriteSig.
 stats = None
 tracker = None
 
 
 class DiffDirException(Exception):
     pass
 
 
 def DirSig(path_iter):
-    u"""
+    """
     Alias for SigTarBlockIter below
     """
     return SigTarBlockIter(path_iter)
 
 
 def DirFull(path_iter):
-    u"""
+    """
     Return a tarblock full backup of items in path_iter
 
     A full backup is just a diff starting from nothing (it may be less
     elegant than using a standard tar file, but we can be sure that it
     will be easy to split up the tar and make the volumes the same
     sizes).
     """
-    return DirDelta(path_iter, io.StringIO(u""))
+    return DirDelta(path_iter, io.StringIO(""))
 
 
 def DirFull_WriteSig(path_iter, sig_outfp):
-    u"""
+    """
     Return full backup like above, but also write signature to sig_outfp
     """
-    return DirDelta_WriteSig(path_iter, io.StringIO(u""), sig_outfp)
+    return DirDelta_WriteSig(path_iter, io.StringIO(""), sig_outfp)
 
 
 def DirDelta(path_iter, dirsig_fileobj_list):
-    u"""
+    """
     Produce tarblock diff given dirsig_fileobj_list and pathiter
 
     dirsig_fileobj_list should either be a tar fileobj or a list of
     those, sorted so the most recent is last.
     """
     global stats
     stats = statistics.StatsDeltaProcess()
@@ -99,136 +87,127 @@
     if config.dry_run or (config.progress and not progress.tracker.has_collected_evidence()):
         return DummyBlockIter(delta_iter)
     else:
         return DeltaTarBlockIter(delta_iter)
 
 
 def delta_iter_error_handler(exc, new_path, sig_path, sig_tar=None):  # pylint: disable=unused-argument
-    u"""
+    """
     Called by get_delta_iter, report error in getting delta
     """
     if new_path:
         index_string = new_path.get_relative_path()
     elif sig_path:
         index_string = sig_path.get_relative_path()
     else:
-        assert 0, u"Both new and sig are None for some reason"
-    log.Warn(_(u"Error %s getting delta for %s")
-             % (util.uexc(exc), util.fsdecode(index_string)))
+        assert 0, "Both new and sig are None for some reason"
+    log.Warn(_("Error %s getting delta for %s")
+             % (util.uexc(exc), os.fsdecode(index_string)))
     return None
 
 
 def get_delta_path(new_path, sig_path, sigTarFile=None):
-    u"""
+    """
     Return new delta_path which, when read, writes sig to sig_fileobj,
     if sigTarFile is not None
     """
     assert new_path
     if sigTarFile:
         ti = new_path.get_tarinfo()
         index = new_path.index
     delta_path = new_path.get_ropath()
-    log.Debug(_(u"Getting delta of %s and %s") % (new_path, sig_path))
+    log.Debug(_("Getting delta of %s and %s") % (new_path, sig_path))
 
     def callback(sig_string):
-        u"""
+        """
         Callback activated when FileWithSignature read to end
         """
         ti.size = len(sig_string)
-        if sys.version_info.major >= 3:
-            ti.name = u"signature/" + util.fsdecode(b"/".join(index))
-        else:
-            ti.name = b"signature/" + b"/".join(index)
+        ti.name = f"signature/{os.fsdecode(b'/'.join(index))}"
         sigTarFile.addfile(ti, io.BytesIO(sig_string))
 
-    if new_path.isreg() and sig_path and sig_path.isreg() and sig_path.difftype == u"signature":
-        delta_path.difftype = u"diff"
-        old_sigfp = sig_path.open(u"rb")
-        newfp = FileWithReadCounter(new_path.open(u"rb"))
+    if new_path.isreg() and sig_path and sig_path.isreg() and sig_path.difftype == "signature":
+        delta_path.difftype = "diff"
+        old_sigfp = sig_path.open("rb")
+        newfp = FileWithReadCounter(new_path.open("rb"))
         if sigTarFile:
             newfp = FileWithSignature(newfp, callback,
                                       new_path.getsize())
         delta_path.setfileobj(librsync.DeltaFile(old_sigfp, newfp))
     else:
-        delta_path.difftype = u"snapshot"
+        delta_path.difftype = "snapshot"
         if sigTarFile:
-            if sys.version_info.major >= 3:
-                ti.name = u"snapshot/" + util.fsdecode(b"/".join(index))
-            else:
-                ti.name = b"snapshot/" + b"/".join(index)
+            ti.name = f"snapshot/{os.fsdecode(b'/'.join(index))}"
         if not new_path.isreg():
             if sigTarFile:
                 sigTarFile.addfile(ti)
             if stats:
                 stats.SourceFileSize += delta_path.getsize()
         else:
-            newfp = FileWithReadCounter(new_path.open(u"rb"))
+            newfp = FileWithReadCounter(new_path.open("rb"))
             if sigTarFile:
                 newfp = FileWithSignature(newfp, callback,
                                           new_path.getsize())
             delta_path.setfileobj(newfp)
     new_path.copy_attribs(delta_path)
     delta_path.stat.st_size = new_path.stat.st_size
     return delta_path
 
 
 def log_delta_path(delta_path, new_path=None, stats=None):
-    u"""
+    """
     Look at delta path and log delta.  Add stats if new_path is set
     """
-    if delta_path.difftype == u"snapshot":
+    if delta_path.difftype == "snapshot":
         if new_path and stats:
             stats.add_new_file(new_path)
-        log.Info(_(u"A %s") %
-                 (util.fsdecode(delta_path.get_relative_path())),
+        log.Info(_("A %s") %
+                 (os.fsdecode(delta_path.get_relative_path())),
                  log.InfoCode.diff_file_new,
                  util.escape(delta_path.get_relative_path()))
     else:
         if new_path and stats:
             stats.add_changed_file(new_path)
-        log.Info(_(u"M %s") %
-                 (util.fsdecode(delta_path.get_relative_path())),
+        log.Info(_("M %s") %
+                 (os.fsdecode(delta_path.get_relative_path())),
                  log.InfoCode.diff_file_changed,
                  util.escape(delta_path.get_relative_path()))
 
 
 def get_delta_iter(new_iter, sig_iter, sig_fileobj=None):
-    u"""
+    """
     Generate delta iter from new Path iter and sig Path iter.
 
     For each delta path of regular file type, path.difftype with be
     set to "snapshot", "diff".  sig_iter will probably iterate ROPaths
     instead of Paths.
 
     If sig_fileobj is not None, will also write signatures to sig_fileobj.
     """
     collated = collate2iters(new_iter, sig_iter)
     if sig_fileobj:
-        sigTarFile = util.make_tarfile(u"w", sig_fileobj)
+        sigTarFile = util.make_tarfile("w", sig_fileobj)
     else:
         sigTarFile = None
     for new_path, sig_path in collated:
-        log.Debug(_(u"Comparing %s and %s") % (new_path and util.uindex(new_path.index),
-                                               sig_path and util.uindex(sig_path.index)))
+        log.Debug(_("Comparing %s and %s") % (new_path and util.uindex(new_path.index),
+                                              sig_path and util.uindex(sig_path.index)))
         if not new_path or not new_path.type:
             # File doesn't exist (but ignore attempts to delete base dir;
             # old versions of duplicity could have written out the sigtar in
             # such a way as to fool us; LP: #929067)
             if sig_path and sig_path.exists() and sig_path.index != ():
                 # but signature says it did
-                log.Info(_(u"D %s") %
-                         (util.fsdecode(sig_path.get_relative_path())),
+                log.Info(_("D %s") %
+                         (os.fsdecode(sig_path.get_relative_path())),
                          log.InfoCode.diff_file_deleted,
                          util.escape(sig_path.get_relative_path()))
                 if sigTarFile:
                     ti = ROPath(sig_path.index).get_tarinfo()
-                    if sys.version_info.major >= 3:
-                        ti.name = u"deleted/" + util.uindex(sig_path.index)
-                    else:
-                        ti.name = b"deleted/" + b"/".join(sig_path.index)
+                    ti.name = f"deleted/{util.uindex(sig_path.index)}"
                     sigTarFile.addfile(ti)
                 stats.add_deleted_file(sig_path)
                 yield ROPath(sig_path.index)
         elif not sig_path or new_path != sig_path:
             # Must calculate new signature and create delta
             delta_path = robust.check_common_error(delta_iter_error_handler,
                                                    get_delta_path,
@@ -244,117 +223,114 @@
             stats.add_unchanged_file(new_path)
     stats.close()
     if sigTarFile:
         sigTarFile.close()
 
 
 def sigtar2path_iter(sigtarobj):
-    u"""
+    """
     Convert signature tar file object open for reading into path iter
     """
-    tf = util.make_tarfile(u"r", sigtarobj)
+    tf = util.make_tarfile("r", sigtarobj)
     tf.debug = 1
     for tarinfo in tf:
         tiname = util.get_tarinfo_name(tarinfo)
         for prefix in [r"signature/", r"snapshot/", r"deleted/"]:
             if tiname.startswith(prefix):
                 # strip prefix and '/' from name and set it to difftype
                 name, difftype = tiname[len(prefix):], prefix[:-1]
                 break
         else:
-            raise DiffDirException(u"Bad tarinfo name %s" % (tiname,))
+            raise DiffDirException(f"Bad tarinfo name {tiname}")
 
-        if sys.version_info.major >= 3:
-            index = tuple(util.fsencode(name).split(b"/"))
-        else:
-            index = tuple(name.split(b"/"))
+        index = tuple(os.fsencode(name).split(b"/"))
         if not index[-1]:
             index = index[:-1]  # deal with trailing /, ""
 
         ropath = ROPath(index)
         ropath.difftype = difftype
-        if difftype == u"signature" or difftype == u"snapshot":
+        if difftype == "signature" or difftype == "snapshot":
             ropath.init_from_tarinfo(tarinfo)
             if ropath.isreg():
                 ropath.setfileobj(tf.extractfile(tarinfo))
         yield ropath
     sigtarobj.close()
 
 
 def collate2iters(riter1, riter2):
-    u"""
+    """
     Collate two iterators.
 
     The elements yielded by each iterator must be have an index
     variable, and this function returns pairs (elem1, elem2), (elem1,
     None), or (None, elem2) two elements in a pair will have the same
     index, and earlier indicies are yielded later than later indicies.
     """
     relem1, relem2 = None, None
-    while 1:
+    while True:
         if not relem1:
             try:
                 relem1 = next(riter1)
             except StopIteration:
                 if relem2:
-                    yield (None, relem2)
+                    yield None, relem2
                 for relem2 in riter2:
-                    yield (None, relem2)
+                    yield None, relem2
                 break
             index1 = relem1.index
         if not relem2:
             try:
                 relem2 = next(riter2)
             except StopIteration:
                 if relem1:
-                    yield (relem1, None)
+                    yield relem1, None
                 for relem1 in riter1:
-                    yield (relem1, None)
+                    yield relem1, None
                 break
             index2 = relem2.index
 
         if index1 < index2:
-            yield (relem1, None)
+            yield relem1, None
             relem1 = None
         elif index1 == index2:
-            yield (relem1, relem2)
+            yield relem1, relem2
             relem1, relem2 = None, None
         else:
             # index2 is less
-            yield (None, relem2)
+            yield None, relem2
             relem2 = None
 
 
 def combine_path_iters(path_iter_list):
-    u"""
+    """
     Produce new iterator by combining the iterators in path_iter_list
 
     This new iter will iterate every path that is in path_iter_list in
     order of increasing index.  If multiple iterators in
     path_iter_list yield paths with the same index, combine_path_iters
     will discard all paths but the one yielded by the last path_iter.
 
     This is used to combine signature iters, as the output will be a
     full up-to-date signature iter.
     """
     path_iter_list = path_iter_list[:]  # copy before destructive reverse
     path_iter_list.reverse()
 
     def get_triple(iter_index):
-        u"""
+        """
         Represent the next element as a triple, to help sorting
         """
         try:
             path = next(path_iter_list[iter_index])
         except StopIteration:
             return None
-        return (path.index, iter_index, path)
+        return path.index, iter_index, path
 
     def refresh_triple_list(triple_list):
-        u"""
+        """
         Update all elements with path_index same as first element
         """
         path_index = triple_list[0][0]
         iter_index = 0
         while iter_index < len(triple_list):
             old_triple = triple_list[iter_index]
             if old_triple[0] == path_index:
@@ -371,15 +347,15 @@
     while triple_list:
         triple_list.sort()
         yield triple_list[0][2]
         refresh_triple_list(triple_list)
 
 
 def DirDelta_WriteSig(path_iter, sig_infp_list, newsig_outfp):
-    u"""
+    """
     Like DirDelta but also write signature into sig_fileobj
 
     Like DirDelta, sig_infp_list can be a tar fileobj or a sorted list
     of those.  A signature will only be written to newsig_outfp if it
     is different from (the combined) sig_infp_list.
     """
     global stats
@@ -392,51 +368,52 @@
     if config.dry_run or (config.progress and not progress.tracker.has_collected_evidence()):
         return DummyBlockIter(delta_iter)
     else:
         return DeltaTarBlockIter(delta_iter)
 
 
 def get_combined_path_iter(sig_infp_list):
-    u"""
+    """
     Return path iter combining signatures in list of open sig files
     """
     return combine_path_iters([sigtar2path_iter(x) for x in sig_infp_list])
 
 
 class FileWithReadCounter(object):
-    u"""
+    """
     File-like object which also computes amount read as it is read
     """
+
     def __init__(self, infile):
-        u"""FileWithReadCounter initializer"""
+        """FileWithReadCounter initializer"""
         self.infile = infile
 
     def read(self, length=-1):
         try:
             buf = self.infile.read(length)
         except IOError as ex:
             buf = b""
-            log.Warn(_(u"Error %s getting delta for %s")
-                     % (util.uexc(ex), util.fsdecode(self.infile.name)))
+            log.Warn(_("Error %s getting delta for %s")
+                     % (util.uexc(ex), os.fsdecode(self.infile.name)))
         if stats:
             stats.SourceFileSize += len(buf)
         return buf
 
     def close(self):
         return self.infile.close()
 
 
 class FileWithSignature(object):
-    u"""
+    """
     File-like object which also computes signature as it is read
     """
     blocksize = 32 * 1024
 
     def __init__(self, infile, callback, filelen, *extra_args):
-        u"""
+        """
         FileTee initializer
 
         The object will act like infile, but whenever it is read it
         add infile's data to a SigGenerator object.  When the file has
         been read to the end the callback will be called with the
         calculated signature, and any extra_args if given.
 
@@ -459,80 +436,82 @@
                 pass
             self.activated_callback = 1
             self.callback(self.sig_gen.getsig(), *self.extra_args)
         return self.infile.close()
 
 
 class TarBlock(object):
-    u"""
+    """
     Contain information to add next file to tar
     """
+
     def __init__(self, index, data):
-        u"""
+        """
         TarBlock initializer - just store data
         """
         self.index = index
         self.data = data
 
 
 class TarBlockIter(object):
-    u"""
+    """
     A bit like an iterator, yield tar blocks given input iterator
 
     Unlike an iterator, however, control over the maximum size of a
     tarblock is available by passing an argument to next().  Also the
     get_footer() is available.
     """
+
     def __init__(self, input_iter):
-        u"""
+        """
         TarBlockIter initializer
         """
         self.input_iter = input_iter
         self.offset = 0  # total length of data read
         self.process_waiting = False  # process_continued has more blocks
         self.process_next_vol_number = None  # next volume number to write in multivol
         self.previous_index = None  # holds index of last block returned
         self.previous_block = None  # holds block of last block returned
         self.remember_next = False  # see remember_next_index()
         self.remember_value = None  # holds index of next block
         self.remember_block = None  # holds block of next block
         self.queued_data = None  # data to return in next next() call
 
     def tarinfo2tarblock(self, index, tarinfo, file_data=b""):
-        u"""
+        """
         Make tarblock out of tarinfo and file data
         """
         tarinfo.size = len(file_data)
-        headers = tarinfo.tobuf(errors=u'replace', encoding=config.fsencoding)
+        headers = tarinfo.tobuf(errors='replace', encoding=config.fsencoding)
         blocks, remainder = divmod(tarinfo.size, tarfile.BLOCKSIZE)
         if remainder > 0:
             filler_data = b"\0" * (tarfile.BLOCKSIZE - remainder)
         else:
             filler_data = b""
         return TarBlock(index, b"%s%s%s" % (headers, file_data, filler_data))
 
     def process(self, val):  # pylint: disable=unused-argument
-        u"""
+        """
         Turn next value of input_iter into a TarBlock
         """
         assert not self.process_waiting
-        XXX  # Override in subclass @UndefinedVariable
+        raise NotImplementedError("'process' not implemented.")
 
     def process_continued(self):
-        u"""
+        """
         Get more tarblocks
 
         If processing val above would produce more than one TarBlock,
         get the rest of them by calling process_continue.
         """
         assert self.process_waiting
-        XXX  # Override in subclass @UndefinedVariable
+        raise NotImplementedError("'process_continues' not implemented.")
 
     def __next__(self):
-        u"""
+        """
         Return next block and update offset
         """
         if self.queued_data is not None:
             result = self.queued_data
             self.queued_data = None
             # Keep rest of metadata as is (like previous_index)
             return result
@@ -556,57 +535,58 @@
         # read size must always be the same, because if we are restarting a
         # backup volume where the previous volume ended in a data block, we
         # have to be able to assume it's length in order to continue reading
         # the file from the right place.
         return 64 * 1024
 
     def get_previous_index(self):
-        u"""
+        """
         Return index of last tarblock, or None if no previous index
         """
         return self.previous_index, self.previous_block
 
     def queue_index_data(self, data):
-        u"""
+        """
         Next time next() is called, we will return data instead of processing
         """
         self.queued_data = data
 
     def remember_next_index(self):
-        u"""
+        """
         When called, remember the index of the next block iterated
         """
         self.remember_next = True
         self.remember_value = None
         self.remember_block = None
 
     def recall_index(self):
-        u"""
+        """
         Retrieve index remembered with remember_next_index
         """
         return self.remember_value, self.remember_block
 
     def get_footer(self):
-        u"""
+        """
         Return closing string for tarfile, reset offset
         """
         blocks, remainder = divmod(self.offset, tarfile.RECORDSIZE)
         self.offset = 0
         return b'\0' * (tarfile.RECORDSIZE - remainder)  # remainder can be 0
 
     def __iter__(self):  # pylint: disable=non-iterator-returned
         return self
 
 
 class DummyBlockIter(TarBlockIter):
-    u"""
+    """
     TarBlockIter that does no file reading
     """
+
     def process(self, delta_ropath):
-        u"""
+        """
         Get a fake tarblock from delta_ropath
         """
         ti = delta_ropath.get_tarinfo()
         index = delta_ropath.index
 
         # Return blocks of deleted files or fileless snapshots
         if not delta_ropath.type or not delta_ropath.fileobj:
@@ -618,114 +598,115 @@
             stats.SourceFiles += 1
             stats.SourceFileSize += delta_ropath.getsize()
             log.Progress(None, stats.SourceFileSize)
         return self.tarinfo2tarblock(index, ti)
 
 
 class SigTarBlockIter(TarBlockIter):
-    u"""
+    """
     TarBlockIter that yields blocks of a signature tar from path_iter
     """
+
     def process(self, path):
-        u"""
+        """
         Return associated signature TarBlock from path
         """
         ti = path.get_tarinfo()
         if path.isreg():
-            sfp = librsync.SigFile(path.open(u"rb"),
+            sfp = librsync.SigFile(path.open("rb"),
                                    get_block_size(path.getsize()))
             sigbuf = sfp.read()
             sfp.close()
             ti.name = b"signature/" + b"/".join(path.index)
-            if sys.version_info.major >= 3:
-                ti.name = util.fsdecode(ti.name)
+            ti.name = os.fsdecode(ti.name)
             return self.tarinfo2tarblock(path.index, ti, sigbuf)
         else:
             ti.name = b"snapshot/" + b"/".join(path.index)
-            if sys.version_info.major >= 3:
-                ti.name = util.fsdecode(ti.name)
+            ti.name = os.fsdecode(ti.name)
             return self.tarinfo2tarblock(path.index, ti)
 
 
 class DeltaTarBlockIter(TarBlockIter):
-    u"""
+    """
     TarBlockIter that yields parts of a deltatar file
 
     Unlike SigTarBlockIter, the argument to __init__ is a
     delta_path_iter, so the delta information has already been
     calculated.
     """
+
     def process(self, delta_ropath):
-        u"""
+        """
         Get a tarblock from delta_ropath
         """
+
         def add_prefix(tarinfo, prefix):
-            u"""Add prefix to the name of a tarinfo file"""
+            """Add prefix to the name of a tarinfo file"""
             if tarinfo.name == r".":
-                tarinfo.name = prefix + r"/"
+                tarinfo.name = f"{prefix}/"
             else:
                 tarinfo.name = r"%s/%s" % (prefix, tarinfo.name)
 
         ti = delta_ropath.get_tarinfo()
         index = delta_ropath.index
 
         # Return blocks of deleted files or fileless snapshots
         if not delta_ropath.type or not delta_ropath.fileobj:
             if not delta_ropath.type:
                 add_prefix(ti, r"deleted")
             else:
-                assert delta_ropath.difftype == u"snapshot"
+                assert delta_ropath.difftype == "snapshot"
                 add_prefix(ti, r"snapshot")
             return self.tarinfo2tarblock(index, ti)
 
         # Now handle single volume block case
-        fp = delta_ropath.open(u"rb")
+        fp = delta_ropath.open("rb")
         data, last_block = self.get_data_block(fp)
         if stats:
             stats.RawDeltaSize += len(data)
         if last_block:
-            if delta_ropath.difftype == u"snapshot":
+            if delta_ropath.difftype == "snapshot":
                 add_prefix(ti, r"snapshot")
-            elif delta_ropath.difftype == u"diff":
+            elif delta_ropath.difftype == "diff":
                 add_prefix(ti, r"diff")
             else:
-                assert 0, u"Unknown difftype"
+                assert 0, "Unknown difftype"
             return self.tarinfo2tarblock(index, ti, data)
 
         # Finally, do multivol snapshot or diff case
         full_name = r"multivol_%s/%s" % (delta_ropath.difftype, ti.name)
-        ti.name = full_name + r"/1"
+        ti.name = f"{full_name}/1"
         self.process_prefix = full_name
         self.process_fp = fp
         self.process_ropath = delta_ropath
         self.process_waiting = 1
         self.process_next_vol_number = 2
         return self.tarinfo2tarblock(index, ti, data)
 
     def get_data_block(self, fp):
-        u"""
+        """
         Return pair (next data block, boolean last data block)
         """
         read_size = self.get_read_size()
         buf = fp.read(read_size)
         if len(buf) < read_size:
             if fp.close():
-                raise DiffDirException(u"Error closing file")
-            return (buf, True)
+                raise DiffDirException("Error closing file")
+            return buf, True
         else:
-            return (buf, False)
+            return buf, False
 
     def process_continued(self):
-        u"""
+        """
         Return next volume in multivol diff or snapshot
         """
         assert self.process_waiting
         ropath = self.process_ropath
         ti, index = ropath.get_tarinfo(), ropath.index
-        ti.name = u"%s/%d" % (self.process_prefix, self.process_next_vol_number)
+        ti.name = f"{self.process_prefix}/{int(self.process_next_vol_number)}"
         data, last_block = self.get_data_block(self.process_fp)
         if stats:
             stats.RawDeltaSize += len(data)
         if last_block:
             self.process_prefix = None
             self.process_fp = None
             self.process_ropath = None
@@ -733,33 +714,33 @@
             self.process_next_vol_number = None
         else:
             self.process_next_vol_number += 1
         return self.tarinfo2tarblock(index, ti, data)
 
 
 def write_block_iter(block_iter, out_obj):
-    u"""
+    """
     Write block_iter to filename, path, or file object
     """
     if isinstance(out_obj, Path):
-        fp = open(out_obj.name, u"wb")
-    elif isinstance(out_obj, (str, u"".__class__)):
-        fp = open(out_obj, u"wb")
+        fp = open(out_obj.name, "wb")
+    elif isinstance(out_obj, str):
+        fp = open(out_obj, "wb")
     else:
         fp = out_obj
     for block in block_iter:
         fp.write(block.data)
     fp.write(block_iter.get_footer())
     assert not fp.close()
     if isinstance(out_obj, Path):
         out_obj.setdata()
 
 
 def get_block_size(file_len):
-    u"""
+    """
     Return a reasonable block size to use on files of length file_len
 
     If the block size is too big, deltas will be bigger than is
     necessary.  If the block size is too small, making deltas and
     patching can take a really long time.
     """
     if file_len < 1024000:
```

### Comparing `duplicity-1.2.3.dev43/duplicity/cached_ops.py` & `duplicity-2.0.0rc0/duplicity/cached_ops.py`

 * *Files 7% similar despite different names*

```diff
@@ -14,23 +14,22 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Cache-wrapped functions for grp and pwd lookups."""
+"""Cache-wrapped functions for grp and pwd lookups."""
 
-from builtins import object
 import grp
 import pwd
 
 
 class CachedCall(object):
-    u"""Decorator for caching the results of function calls."""
+    """Decorator for caching the results of function calls."""
 
     def __init__(self, f):
         self.cache = {}
         self.f = f
 
     def __call__(self, *args):
         try:
```

### Comparing `duplicity-1.2.3.dev43/duplicity/util.py` & `duplicity-2.0.0rc0/duplicity/util.py`

 * *Files 18% similar despite different names*

```diff
@@ -15,159 +15,98 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Miscellaneous utilities.
 """
 
-from __future__ import print_function
-
-from future import standard_library
-standard_library.install_aliases()
-from builtins import isinstance
-from builtins import map
-from builtins import object
-from builtins import str
-
+import atexit
 import csv
 import errno
 import json
 import os
-import string
 import sys
 import traceback
-import atexit
-
-if sys.version_info.major == 2:
-    from cStringIO import StringIO  # pylint: disable=import-error
-else:
-    from io import StringIO  # pylint: disable=import-error
+from io import StringIO
 
-from duplicity import tarfile
 import duplicity.config as config
 import duplicity.log as log
-
-try:
-    # For paths, just use path.name/uname rather than converting with these
-    from os import fsencode, fsdecode  # pylint: disable=unused-import
-except ImportError:
-    # Most likely Python version < 3.2, so define our own fsencode/fsdecode.
-    # These are functions that encode/decode unicode paths to filesystem encoding,
-    # but the cleverness is that they handle non-unicode characters on Linux
-    # There is a *partial* backport to python available here:
-    # https://github.com/pjdelport/backports.os/blob/master/src/backports/os.py
-    # but if it cannot be trusted for full-circle translation, then we may as well
-    # just read and store the bytes version of the path as path.name before
-    # creating the unicode version (for path matching etc) and ensure that in
-    # real-world usage (as opposed to testing) we create the path objects from a
-    # bytes string.
-    # ToDo: Revisit this once we drop Python 2 support/the backport is complete
-
-    def fsencode(unicode_filename):
-        u"""Convert a unicode filename to a filename encoded in the system encoding"""
-        # For paths, just use path.name rather than converting with this
-        # If we are not doing any cleverness with non-unicode filename bytes,
-        # encoding to system encoding is good enough
-        if sys.version_info[:2] >= (3, 2):
-            return os.fsencode(unicode_filename)
-        else:
-            return unicode_filename.encode(config.fsencoding, u"replace")
-
-    def fsdecode(bytes_filename):
-        u"""Convert a filename encoded in the system encoding to unicode"""
-        # For paths, just use path.uc_name rather than converting with this
-        # If we are not doing any cleverness with non-unicode filename bytes,
-        # decoding using system encoding is good enough. Use "ignore" as
-        # Linux paths can contain non-Unicode characters
-        if sys.version_info[:2] >= (3, 2):
-            return os.fsdecode(bytes_filename)
-        else:
-            return bytes_filename.decode(config.fsencoding, u"replace")
+from duplicity import tarfile
 
 
 def exception_traceback(limit=50):
-    u"""
+    """
     @return A string representation in typical Python format of the
             currently active/raised exception.
     """
     type, value, tb = sys.exc_info()  # pylint: disable=redefined-builtin
 
     lines = traceback.format_tb(tb, limit)
     lines.extend(traceback.format_exception_only(type, value))
 
-    msg = u"Traceback (innermost last):\n"
-    if sys.version_info.major >= 3:
-        msg = msg + u"%-20s %s" % (str.join(u"", lines[:-1]), lines[-1])
-    else:
-        msg = msg + u"%-20s %s" % (string.join(lines[:-1], u""), lines[-1])
+    msg = "Traceback (innermost last):\n"
+    msg = msg + "%-20s %s" % (str.join("", lines[:-1]), lines[-1])
 
-    if sys.version_info.major < 3:
-        return msg.decode(u'unicode-escape', u'replace')
     return msg
 
 
 def escape(string):
-    u"""Convert a (bytes) filename to a format suitable for logging (quoted utf8)"""
-    string = fsdecode(string).encode(u'unicode-escape', u'replace')
-    return u"'%s'" % string.decode(u'utf8', u'replace').replace(u"'", u'\\x27')
+    """Convert a (bytes) filename to a format suitable for logging (quoted utf8)"""
+    string = os.fsdecode(string).encode('unicode-escape', 'replace')
+    return "'%s'" % string.decode('utf8', 'replace').replace("'", '\\x27')
 
 
 def uindex(index):
-    u"""Convert an index (a tuple of path parts) to unicode for printing"""
+    """Convert an index (a tuple of path parts) to unicode for printing"""
     if index:
-        return os.path.join(*list(map(fsdecode, index)))
+        return os.path.join(*list(map(os.fsdecode, index)))
     else:
-        return u'.'
+        return '.'
 
 
 def uexc(e):
-    u"""Returns the exception message in Unicode"""
+    """Returns the exception message in Unicode"""
     # Exceptions in duplicity often have path names in them, which if they are
     # non-ascii will cause a UnicodeDecodeError when implicitly decoding to
     # unicode.  So we decode manually, using the filesystem encoding.
     # 99.99% of the time, this will be a fine encoding to use.
     if e and e.args:
         # Find arg that is a string
         for m in e.args:
             if isinstance(m, str):
                 # Already unicode
                 return m
             elif isinstance(m, bytes):
                 # Encoded, likely in filesystem encoding
-                return fsdecode(m)
+                return os.fsdecode(m)
         # If the function did not return yet, we did not
         # succeed in finding a string; return the whole message.
-        # This fails for Python 2, so only do this in Python 3.
-        if sys.version_info[0] > 2:
-            return str(e)
-        # For Python 2, fall back to returning an empty string.
-        else:
-            return u''
+        return str(e)
     else:
-        return u''
+        return ''
 
 
 def maybe_ignore_errors(fn):
-    u"""
+    """
     Execute fn. If the global configuration setting ignore_errors is
     set to True, catch errors and log them but do continue (and return
     None).
 
     @param fn: A callable.
     @return Whatever fn returns when called, or None if it failed and ignore_errors is true.
     """
     try:
         return fn()
     except Exception as e:
         if config.ignore_errors:
-            log.Warn(_(u"IGNORED_ERROR: Warning: ignoring error as requested: %s: %s")
+            log.Warn(_("IGNORED_ERROR: Warning: ignoring error as requested: %s: %s")
                      % (e.__class__.__name__, uexc(e)))
             return None
         else:
             raise
 
 
 class BlackHoleList(list):
@@ -187,36 +126,36 @@
 
 
 def make_tarfile(mode, fp):
     # We often use 'empty' tarfiles for signatures that haven't been filled out
     # yet.  So we want to ignore ReadError exceptions, which are used to signal
     # this.
     try:
-        tf = tarfile.TarFile(u"arbitrary", mode, fp)
+        tf = tarfile.TarFile("arbitrary", mode, fp)
         # Now we cause TarFile to not cache TarInfo objects.  It would end up
         # consuming a lot of memory over the lifetime of our long-lasting
         # signature files otherwise.
         tf.members = BlackHoleList()
         return tf
     except tarfile.ReadError:
         return FakeTarFile()
 
 
 def get_tarinfo_name(ti):
     # Python versions before 2.6 ensure that directories end with /, but 2.6
     # and later ensure they they *don't* have /.  ::shrug::  Internally, we
     # continue to use pre-2.6 method.
     if ti.isdir() and not ti.name.endswith(r"/"):
-        return ti.name + r"/"
+        return f"{ti.name}/"
     else:
         return ti.name
 
 
 def ignore_missing(fn, filename):
-    u"""
+    """
     Execute fn on filename.  Ignore ENOENT errors, otherwise raise exception.
 
     @param fn: callable
     @param filename: string
     """
     try:
         fn(filename)
@@ -225,37 +164,37 @@
             pass
         else:
             raise
 
 
 @atexit.register
 def release_lockfile():
-    if config.lockfile:
-        log.Debug(_(u"Releasing lockfile %s") % config.lockpath)
+    if config.lockfile and os.path.exists(config.lockpath):
+        log.Debug(_("Releasing lockfile %s") % os.fsdecode(config.lockpath))
         try:
             config.lockfile.release()
-            config.lockfile = None
             os.remove(config.lockpath)
-            config.lockpath = u""
+            config.lockfile = None
+            config.lockpath = ""
         except Exception as e:
-            log.Error(u"Could not release lockfile: %s" % str(e))
+            log.Error(f"Could not release lockfile: {str(e)}")
             pass
 
 
 def copyfileobj(infp, outfp, byte_count=-1):
-    u"""Copy byte_count bytes from infp to outfp, or all if byte_count < 0
+    """Copy byte_count bytes from infp to outfp, or all if byte_count < 0
 
     Returns the number of bytes actually written (may be less than
     byte_count if find eof.  Does not close either fileobj.
 
     """
     blocksize = 64 * 1024
     bytes_written = 0
     if byte_count < 0:
-        while 1:
+        while True:
             buf = infp.read(blocksize)
             if not buf:
                 break
             bytes_written += len(buf)
             outfp.write(buf)
     else:
         while bytes_written + blocksize <= byte_count:
@@ -267,55 +206,55 @@
         buf = infp.read(byte_count - bytes_written)
         bytes_written += len(buf)
         outfp.write(buf)
     return bytes_written
 
 
 def which(program):
-    u"""
+    """
     Return absolute path for program name.
     Returns None if program not found.
     """
 
     def is_exe(fpath):
         return os.path.isfile(fpath) and os.path.isabs(fpath) and os.access(fpath, os.X_OK)
 
     fpath, fname = os.path.split(program)
     if fpath:
         if is_exe(program):
             return program
     else:
-        for path in os.getenv(u"PATH").split(os.pathsep):
-            path = path.strip(u'"')
+        for path in os.getenv("PATH").split(os.pathsep):
+            path = path.strip('"')
             exe_file = os.path.abspath(os.path.join(path, program))
             if is_exe(exe_file):
                 return exe_file
 
     return None
 
 
 def start_debugger():
-    if u'--pydevd' in sys.argv or os.environ.get(u"PYDEVD", None):
+    if '--pydevd' in sys.argv or os.environ.get("PYDEVD", None):
         try:
             import pydevd_pycharm  # pylint: disable=import-error
         except ImportError:
-            log.FatalError(u"Module pydevd_pycharm must be available for debugging.\n"
-                           u"Remove '--pydevd' from command line and unset 'PYDEVD'\n"
-                           u"from the environment to avoid starting the debugger.")
+            log.FatalError("Module pydevd_pycharm must be available for debugging.\n"
+                           "Remove '--pydevd' from command line and unset 'PYDEVD'\n"
+                           "from the environment to avoid starting the debugger.")
 
         # NOTE: this needs to be customized for your system
-        debug_host = u'dione.local'
+        debug_host = 'dione.local'
         debug_port = 6700
 
         # get previous pid:port if any
         # return if pid the same as ours
         prev_port = None
-        debug_running = os.environ.get(u"DEBUG_RUNNING", False)
+        debug_running = os.environ.get("DEBUG_RUNNING", False)
         if debug_running:
-            prev_pid, prev_port = map(int, debug_running.split(u":"))
+            prev_pid, prev_port = list(map(int, debug_running.split(":")))
             if prev_pid == os.getpid():
                 return
 
         # new pid, next port, start a new debugger
         if prev_port:
             debug_port = int(prev_port) + 1
 
@@ -324,58 +263,56 @@
             pydevd_pycharm.settrace(debug_host,
                                     port=debug_port,
                                     suspend=False,
                                     stdoutToServer=True,
                                     stderrToServer=True,
                                     # patch_multiprocessing=True,
                                     )
-            log.Info(u"Connection {0}:{1} accepted for debug."
-                     .format(debug_host, debug_port))
+            log.Info(f"Connection {debug_host}:{debug_port} accepted for debug.")
         except ConnectionRefusedError as e:
-            log.Info(u"Connection {0}:{1} refused for debug: {2}"
-                     .format(debug_host, debug_port, str(e)))
+            log.Info(f"Connection {debug_host}:{debug_port} refused for debug: {str(e)}")
 
         # in a dev environment the path is screwed so fix it.
         base = sys.path.pop(0)
         base = base.split(os.path.sep)[:-1]
         base = os.path.sep.join(base)
         sys.path.insert(0, base)
 
         # save last debug pid:port used
-        os.environ[u'DEBUG_RUNNING'] = u"{0}:{1}".format(os.getpid(), debug_port)
+        os.environ['DEBUG_RUNNING'] = f"{os.getpid()}:{debug_port}"
 
 
 def merge_dicts(*dict_args):
-    u"""
+    """
     Given any number of dictionaries, shallow copy and merge into a new dict,
     precedence goes to key-value pairs in latter dictionaries.
     """
     result = {}
     for dictionary in dict_args:
         result.update(dictionary)
     return result
 
 
 def csv_args_to_dict(arg):
-    u"""
+    """
     Given the string arg in single line csv format, split into pairs (key, val)
     and produce a dictionary from those key:val pairs.
     """
     mydict = {}
     with StringIO(arg) as infile:
         rows = csv.reader(infile)
         for row in rows:
             for i in range(0, len(row), 2):
                 mydict[row[i]] = row[i + 1]
     return mydict
 
 
 # TODO: just use util.fsdecode().casefold() directly when python27 is gone
 def casefold_compat(s):
-    u"""
+    """
     Compatability function for casefolding which provides an acceptable for
     older pythons. Can likely be removed once python2 support is no longer o
     any interest.
     """
     if sys.version_info.major >= 3 and sys.version_info.minor >= 3:
         return s.casefold()
     else:
```

### Comparing `duplicity-1.2.3.dev43/duplicity/dup_temp.py` & `duplicity-2.0.0rc0/duplicity/dup_temp.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,264 +15,263 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Manage temporary files"""
-
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import object
+"""Manage temporary files"""
 
 import os
-import sys
 import shutil
+import sys
 
+from duplicity import config
+from duplicity import file_naming
+from duplicity import gpg
 from duplicity import log
 from duplicity import path
-from duplicity import file_naming
 from duplicity import tempdir
-from duplicity import config
-from duplicity import gpg
 
 
 def new_temppath():
-    u"""
+    """
     Return a new TempPath
     """
     filename = tempdir.default().mktemp()
     return TempPath(filename)
 
 
 class TempPath(path.Path):
-    u"""
+    """
     Path object used as a temporary file
     """
+
     def delete(self):
-        u"""
+        """
         Forget and delete
         """
         path.Path.delete(self)
         tempdir.default().forget(self.name)
 
     def open_with_delete(self, mode):
-        u"""
+        """
         Returns a fileobj.  When that is closed, delete file
         """
         fh = FileobjHooked(path.Path.open(self, mode))
         fh.addhook(self.delete)
         return fh
 
 
 def get_fileobj_duppath(dirpath, partname, permname, remname, overwrite=False):
-    u"""
+    """
     Return a file object open for writing, will write to filename
 
     Data will be processed and written to a temporary file.  When the
     return fileobject is closed, rename to final position.  filename
     must be a recognizable duplicity data file.
     """
     if not config.restart:
         td = tempdir.TemporaryDirectory(dirpath.name)
         tdpname = td.mktemp()
         tdp = TempDupPath(tdpname, parseresults=file_naming.parse(partname))
-        fh = FileobjHooked(tdp.filtered_open(u"wb"), tdp=tdp, dirpath=dirpath,
+        fh = FileobjHooked(tdp.filtered_open("wb"), tdp=tdp, dirpath=dirpath,
                            partname=partname, permname=permname, remname=remname)
     else:
         dp = path.DupPath(dirpath.name, index=(partname,))
-        mode = u"ab"
+        mode = "ab"
         if overwrite:
-            mode = u"wb"
+            mode = "wb"
         fh = FileobjHooked(dp.filtered_open(mode), tdp=None, dirpath=dirpath,
                            partname=partname, permname=permname, remname=remname)
 
     def rename_and_forget():
         tdp.rename(dirpath.append(partname))
         td.forget(tdpname)
 
     if not config.restart:
         fh.addhook(rename_and_forget)
 
     return fh
 
 
 def new_tempduppath(parseresults):
-    u"""
+    """
     Return a new TempDupPath, using settings from parseresults
     """
     filename = tempdir.default().mktemp()
     return TempDupPath(filename, parseresults=parseresults)
 
 
 class TempDupPath(path.DupPath):
-    u"""
+    """
     Like TempPath, but build around DupPath
     """
+
     def delete(self):
-        u"""
+        """
         Forget and delete
         """
         path.DupPath.delete(self)
         tempdir.default().forget(self.name)
 
     def filtered_open_with_delete(self, mode):
-        u"""
+        """
         Returns a filtered fileobj.  When that is closed, delete file
         """
         fh = FileobjHooked(path.DupPath.filtered_open(self, mode))
         fh.addhook(self.delete)
         return fh
 
-    def open_with_delete(self, mode=u"rb"):
-        u"""
+    def open_with_delete(self, mode="rb"):
+        """
         Returns a fileobj.  When that is closed, delete file
         """
-        assert mode == u"rb"  # Why write a file and then close it immediately?
+        assert mode == "rb"  # Why write a file and then close it immediately?
         fh = FileobjHooked(path.DupPath.open(self, mode))
         fh.addhook(self.delete)
         return fh
 
 
 class FileobjHooked(object):
-    u"""
+    """
     Simulate a file, but add hook on close
     """
+
     def __init__(self, fileobj, tdp=None, dirpath=None,
                  partname=None, permname=None, remname=None):
-        u"""
+        """
         Initializer.  fileobj is the file object to simulate
         """
         self.fileobj = fileobj  # the actual file object
         self.closed = False  # True if closed
         self.hooklist = []  # filled later with thunks to run on close
         self.tdp = tdp  # TempDupPath object
         self.dirpath = dirpath  # path to directory
         self.partname = partname  # partial filename
         self.permname = permname  # permanent filename
         self.remname = remname  # remote filename
 
     def write(self, buf):
-        u"""
+        """
         Write fileobj, return result of write()
         """
         return self.fileobj.write(buf)
 
     def flush(self):
-        u"""
+        """
         Flush fileobj and force sync.
         """
         self.fileobj.flush()
         os.fsync(self.fileobj.fileno())
 
     def to_partial(self):
-        u"""
+        """
         We have achieved the first checkpoint, make file visible and permanent.
         """
         assert not config.restart
         self.tdp.rename(self.dirpath.append(self.partname))
         self.fileobj.flush()
         del self.hooklist[0]
 
     def to_remote(self):
-        u"""
+        """
         We have written the last checkpoint, now encrypt or compress
         and send a copy of it to the remote for final storage.
         """
-        log.Debug(u"TO_REMOTE")
         pr = file_naming.parse(self.remname)
         src = self.dirpath.append(self.partname)
         tgt = self.dirpath.append(self.remname)
         src_iter = SrcIter(src)
         if pr.compressed:
             gpg.GzipWriteFile(src_iter, tgt.name, size=sys.maxsize)
         elif pr.encrypted:
             gpg.GPGWriteFile(src_iter, tgt.name, config.gpg_profile, size=sys.maxsize)
         else:
             shutil.copyfile(src.name, tgt.name)
         config.backend.move(tgt)
 
     def to_final(self):
-        u"""
+        """
         We are finished, rename to final, gzip if needed.
         """
         src = self.dirpath.append(self.partname)
         tgt = self.dirpath.append(self.permname)
         src_iter = SrcIter(src)
         pr = file_naming.parse(self.permname)
         if pr.compressed:
             gpg.GzipWriteFile(src_iter, tgt.name, size=sys.maxsize)
             os.unlink(src.name)
         else:
             os.rename(src.name, tgt.name)
 
     def read(self, length=-1):
-        u"""
+        """
         Read fileobj, return result of read()
         """
         return self.fileobj.read(length)
 
     def tell(self):
-        u"""
+        """
         Returns current location of fileobj
         """
         return self.fileobj.tell()
 
     def seek(self, offset):
-        u"""
+        """
         Seeks to a location of fileobj
         """
         return self.fileobj.seek(offset)
 
     def close(self):
-        u"""
+        """
         Close fileobj, running hooks right afterwards
         """
         assert not self.fileobj.close()
         for hook in self.hooklist:
             hook()
 
     def addhook(self, hook):
-        u"""
+        """
         Add hook (function taking no arguments) to run upon closing
         """
         self.hooklist.append(hook)
 
     def get_name(self):
-        u"""
+        """
         Return the name of the file
         """
         return self.fileobj.name
 
     name = property(get_name)
 
 
 class Block(object):
-    u"""
+    """
     Data block to return from SrcIter
     """
+
     def __init__(self, data):
         self.data = data
 
 
 class SrcIter(object):
-    u"""
+    """
     Iterate over source and return Block of data.
     """
+
     def __init__(self, src):
         self.src = src
-        self.fp = src.open(u"rb")
+        self.fp = src.open("rb")
 
     def __next__(self):
         try:
             res = Block(self.fp.read(self.get_read_size()))
         except Exception:
-            log.FatalError(_(u"Failed to read %s: %s") %
+            log.FatalError(_("Failed to read %s: %s") %
                            (self.src.uc_name, sys.exc_info()),
                            log.ErrorCode.generic)
         if not res.data:
             self.fp.close()
             raise StopIteration
         return res
```

### Comparing `duplicity-1.2.3.dev43/duplicity/asyncscheduler.py` & `duplicity-2.0.0rc0/duplicity/asyncscheduler.py`

 * *Files 8% similar despite different names*

```diff
@@ -16,35 +16,30 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""
+"""
 Asynchronous job scheduler, for concurrent execution with minimalistic
 dependency guarantees.
 """
 
-from future import standard_library
-standard_library.install_aliases()
-from builtins import object
-import duplicity
+import _thread
+import threading
+
 from duplicity import log
-from duplicity.dup_threading import require_threading
-from duplicity.dup_threading import interruptably_wait
 from duplicity.dup_threading import async_split
+from duplicity.dup_threading import interruptably_wait
 from duplicity.dup_threading import with_lock
 
-thread = duplicity.dup_threading.thread_module()
-threading = duplicity.dup_threading.threading_module()
-
 
 class AsyncScheduler(object):
-    u"""
+    """
     Easy-to-use scheduler of function calls to be executed
     concurrently. A very simple dependency mechanism exists in the
     form of barriers (see insert_barrier()).
 
     Each instance has a concurrency level associated with it. A
     concurrency of 0 implies that all tasks will be executed
     synchronously when scheduled. A concurrency of 1 indicates that a
@@ -58,58 +53,54 @@
 
     An AsynchScheduler should be created for any independent process;
     the scheduler will assume that if any background job fails (raises
     an exception), it makes further work moot.
     """
 
     def __init__(self, concurrency):
-        u"""
+        """
         Create an asynchronous scheduler that executes jobs with the
         given level of concurrency.
         """
-        log.Info(u"%s: %s" % (self.__class__.__name__,
-                              _(u"instantiating at concurrency %d") %
-                              (concurrency)))
-        assert concurrency >= 0, u"%s concurrency level must be >= 0" % (self.__class__.__name__,)
+        log.Info(f"{self.__class__.__name__}: {_('instantiating at concurrency %d') % concurrency}")
+        assert concurrency >= 0, f"{self.__class__.__name__} concurrency level must be >= 0"
 
         self.__failed = False  # has at least one task failed so far?
         self.__failed_waiter = None  # when __failed, the waiter of the first task that failed
         self.__concurrency = concurrency
         self.__worker_count = 0  # number of active workers
         self.__waiter_count = 0  # number of threads waiting to submit work
         self.__barrier = False  # barrier currently in effect?
-        self.__cv = threading.Condition()  # for simplicity, we use a single cv with its lock
-#                                                    # for everything, even if the resulting notifyAll():s
-#                                                    # are not technically efficient.
-
-        if concurrency > 0:
-            require_threading(u"concurrency > 0 (%d)" % (concurrency,))
+        # for simplicity, we use a single cv with its lock
+        # for everything, even if the resulting notify_all()'s
+        # are not technically efficient.
+        self.__cv = threading.Condition()
 
     def insert_barrier(self):
-        u"""
+        """
         Proclaim that any tasks scheduled prior to the call to this
         method MUST be executed prior to any tasks scheduled after the
         call to this method.
 
         The intended use case is that if task B depends on A, a
         barrier must be inserted in between to guarantee that A
         happens before B.
         """
-        log.Debug(u"%s: %s" % (self.__class__.__name__, _(u"inserting barrier")))
+        log.Debug(f"{self.__class__.__name__}: {_('inserting barrier')}")
         # With concurrency 0 it's a NOOP, and due to the special case in
         # task scheduling we do not want to append to the queue (will never
         # be popped).
         if self.__concurrency > 0:
             def _insert_barrier():
                 self.__barrier = True
 
             with_lock(self.__cv, _insert_barrier)
 
     def schedule_task(self, fn, params):
-        u"""
+        """
         Schedule the given task (callable, typically function) for
         execution. Pass the given parameters to the function when
         calling it. Returns a callable which can optionally be used
         to wait for the task to complete, either by returning its
         return value or by propagating any exception raised by said
         task.
 
@@ -138,120 +129,118 @@
         # terms of ensuring the scheduler is garbage collected/shut
         # down properly when no longer referenced/needed by calling
         # code.
 
         if self.__concurrency == 0:
             # special case this to not require any platform support for
             # threading at all
-            log.Info(u"%s: %s" % (self.__class__.__name__,
-                     _(u"running task synchronously (asynchronicity disabled)")),
+            log.Info(f"{self.__class__.__name__}: {_('running task synchronously (asynchronicity disabled)')}",
                      log.InfoCode.synchronous_upload_begin)
 
             return self.__run_synchronously(fn, params)
         else:
-            log.Info(u"%s: %s" % (self.__class__.__name__,
-                     _(u"scheduling task for asynchronous execution")),
+            log.Info(f"{self.__class__.__name__}: {_('scheduling task for asynchronous execution')}",
                      log.InfoCode.asynchronous_upload_begin)
 
             return self.__run_asynchronously(fn, params)
 
     def wait(self):
-        u"""
+        """
         Wait for the scheduler to become entirely empty (i.e., all
         tasks having run to completion).
 
         IMPORTANT: This is only useful with a single caller scheduling
         tasks, such that no call to schedule_task() is currently in
         progress or may happen subsequently to the call to wait().
         """
+
         def _wait():
             interruptably_wait(self.__cv, lambda: self.__worker_count == 0 and self.__waiter_count == 0)
 
         with_lock(self.__cv, _wait)
 
     def __run_synchronously(self, fn, params):
 
         # When running synchronously, we immediately leak any exception raised
         # for immediate failure reporting to calling code.
         ret = fn(*params)
 
         def _waiter():
             return ret
 
-        log.Info(u"%s: %s" % (self.__class__.__name__,
-                 _(u"task completed successfully")),
+        log.Info(f"{self.__class__.__name__}: {_('task completed successfully')}",
                  log.InfoCode.synchronous_upload_done)
 
         return _waiter
 
     def __run_asynchronously(self, fn, params):
         (waiter, caller) = async_split(lambda: fn(*params))
 
         def check_pending_failure():
             if self.__failed:
-                log.Info(u"%s: %s" % (self.__class__.__name__,
-                         _(u"a previously scheduled task has failed; "
-                           u"propagating the result immediately")),
+                log.Info(f"{self.__class__.__name__}: "
+                         f"_('a previously scheduled task has failed; propagating the result immediately')",
                          log.InfoCode.asynchronous_upload_done)
                 self.__failed_waiter()
-                raise AssertionError(u"%s: waiter should have raised an exception; "
-                                     u"this is a bug" % (self.__class__.__name__,))
+                raise AssertionError(f"{self.__class__.__name__}: "
+                                     f"waiter should have raised an exception; this is a bug")
 
         def wait_for_and_register_launch():
             check_pending_failure()  # raise on fail
             while self.__worker_count >= self.__concurrency or self.__barrier:
                 if self.__worker_count == 0:
-                    assert self.__barrier, u"barrier should be in effect"
+                    assert self.__barrier, "barrier should be in effect"
                     self.__barrier = False
-                    self.__cv.notifyAll()
+                    self.__cv.notify_all()
                 else:
                     self.__waiter_count += 1
                     self.__cv.wait()
                     self.__waiter_count -= 1
 
                 check_pending_failure()  # raise on fail
 
             self.__worker_count += 1
-            log.Debug(u"%s: %s" % (self.__class__.__name__,
-                                   _(u"active workers = %d") % (self.__worker_count,)))
+            log.Debug(f"{self.__class__.__name__}: {_('active workers = %d') % (self.__worker_count,)}")
 
         # simply wait for an OK condition to start, then launch our worker. the worker
         # never waits on us, we just wait for them.
         with_lock(self.__cv, wait_for_and_register_launch)
 
         self.__start_worker(caller)
 
         return waiter
 
     def __start_worker(self, caller):
-        u"""
+        """
         Start a new worker.
         """
+
         def trampoline():
             try:
                 self.__execute_caller(caller)
             finally:
                 def complete_worker():
                     self.__worker_count -= 1
-                    log.Debug(u"%s: %s" % (self.__class__.__name__,
-                                           _(u"active workers = %d") % (self.__worker_count,)))
-                    self.__cv.notifyAll()
+                    log.Debug(f"{self.__class__.__name__}: {_('active workers = %d') % (self.__worker_count,)}")
+                    self.__cv.notify_all()
+
                 with_lock(self.__cv, complete_worker)
 
-        thread.start_new_thread(trampoline, ())
+        _thread.start_new_thread(trampoline, ())
 
     def __execute_caller(self, caller):
         # The caller half that we get here will not propagate
         # errors back to us, but rather propagate it back to the
         # "other half" of the async split.
         succeeded, waiter = caller()
         if not succeeded:
             def _signal_failed():
                 if not self.__failed:
                     self.__failed = True
                     self.__failed_waiter = waiter
-                    self.__cv.notifyAll()
+                    self.__cv.notify_all()
+
             with_lock(self.__cv, _signal_failed)
 
-        log.Info(u"%s: %s" % (self.__class__.__name__,
-                 _(u"task execution done (success: %s)") % succeeded),
+        log.Info("%s: %s" % (self.__class__.__name__,
+                             _("task execution done (success: %s)") % succeeded),
                  log.InfoCode.asynchronous_upload_done)
```

### Comparing `duplicity-1.2.3.dev43/duplicity/statistics.py` & `duplicity-2.0.0rc0/duplicity/statistics.py`

 * *Files 21% similar despite different names*

```diff
@@ -15,117 +15,113 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Generate and process backup statistics"""
-from __future__ import division
-
-from builtins import zip
-from builtins import map
-from builtins import str
-from builtins import object
+"""Generate and process backup statistics"""
 
+import os
 import re
 import time
-import os
 
 from duplicity import config
 from duplicity import dup_time
 
 
 class StatsException(Exception):
     pass
 
 
 class StatsObj(object):
-    u"""Contains various statistics, provide string conversion functions"""
+    """Contains various statistics, provide string conversion functions"""
     # used when quoting files in get_stats_line
-    space_regex = re.compile(u" ")
+    space_regex = re.compile(" ")
 
-    stat_file_attrs = (u'SourceFiles',
-                       u'SourceFileSize',
-                       u'NewFiles',
-                       u'NewFileSize',
-                       u'DeletedFiles',
-                       u'ChangedFiles',
-                       u'ChangedFileSize',
-                       u'ChangedDeltaSize',
-                       u'DeltaEntries',
-                       u'RawDeltaSize')
-    stat_misc_attrs = (u'Errors',
-                       u'TotalDestinationSizeChange')
-    stat_time_attrs = (u'StartTime',
-                       u'EndTime',
-                       u'ElapsedTime')
-    stat_attrs = ((u'Filename',) + stat_time_attrs +
+    stat_file_attrs = ('SourceFiles',
+                       'SourceFileSize',
+                       'NewFiles',
+                       'NewFileSize',
+                       'DeletedFiles',
+                       'ChangedFiles',
+                       'ChangedFileSize',
+                       'ChangedDeltaSize',
+                       'DeltaEntries',
+                       'RawDeltaSize')
+    stat_misc_attrs = ('Errors',
+                       'TotalDestinationSizeChange')
+    stat_time_attrs = ('StartTime',
+                       'EndTime',
+                       'ElapsedTime')
+    stat_attrs = (('Filename',) + stat_time_attrs +
                   stat_misc_attrs + stat_file_attrs)
 
     # Below, the second value in each pair is true iff the value
     # indicates a number of bytes
-    stat_file_pairs = ((u'SourceFiles', False),
-                       (u'SourceFileSize', True),
-                       (u'NewFiles', False),
-                       (u'NewFileSize', True),
-                       (u'DeletedFiles', False),
-                       (u'ChangedFiles', False),
-                       (u'ChangedFileSize', True),
-                       (u'ChangedDeltaSize', True),
-                       (u'DeltaEntries', False),
-                       (u'RawDeltaSize', True))
+    stat_file_pairs = (('SourceFiles', False),
+                       ('SourceFileSize', True),
+                       ('NewFiles', False),
+                       ('NewFileSize', True),
+                       ('DeletedFiles', False),
+                       ('ChangedFiles', False),
+                       ('ChangedFileSize', True),
+                       ('ChangedDeltaSize', True),
+                       ('DeltaEntries', False),
+                       ('RawDeltaSize', True))
 
     # This is used in get_byte_summary_string below
-    byte_abbrev_list = ((1024 * 1024 * 1024 * 1024, u"TB"),
-                        (1024 * 1024 * 1024, u"GB"),
-                        (1024 * 1024, u"MB"),
-                        (1024, u"KB"))
+    byte_abbrev_list = ((1024 * 1024 * 1024 * 1024, "TB"),
+                        (1024 * 1024 * 1024, "GB"),
+                        (1024 * 1024, "MB"),
+                        (1024, "KB"))
 
     def __init__(self):
-        u"""Set attributes to None"""
+        """Set attributes to None"""
         for attr in self.stat_attrs:
             self.__dict__[attr] = None
 
     def get_stat(self, attribute):
-        u"""Get a statistic"""
+        """Get a statistic"""
         return self.__dict__[attribute]
 
     def set_stat(self, attr, value):
-        u"""Set attribute to given value"""
+        """Set attribute to given value"""
         self.__dict__[attr] = value
 
     def increment_stat(self, attr):
-        u"""Add 1 to value of attribute"""
+        """Add 1 to value of attribute"""
         self.__dict__[attr] += 1
 
     def get_stats_line(self, index, use_repr=1):
-        u"""Return one line abbreviated version of full stats string"""
+        """Return one line abbreviated version of full stats string"""
         file_attrs = [str(self.get_stat(a)) for a in self.stat_file_attrs]
         if not index:
-            filename = u"."
+            filename = "."
         else:
             filename = os.path.join(*index)
             if use_repr:
                 # use repr to quote newlines in relative filename, then
                 # take of leading and trailing quote and quote spaces.
-                filename = self.space_regex.sub(u"\\\\x20", repr(filename))
+                filename = self.space_regex.sub("\\\\x20", repr(filename))
                 n = 1
-                if filename[0] == u'u':
+                if filename[0] == 'u':
                     n = 2
                 filename = filename[n:-1]
-        return u" ".join([filename, ] + file_attrs)
+        return " ".join([filename, ] + file_attrs)
 
     def set_stats_from_line(self, line):
-        u"""Set statistics from given line"""
+        """Set statistics from given line"""
+
         def error():
-            raise StatsException(u"Bad line '%s'" % line)
-        if line[-1] == u"\n":
+            raise StatsException(f"Bad line '{line}'")
+
+        if line[-1] == "\n":
             line = line[:-1]
-        lineparts = line.split(u" ")
+        lineparts = line.split(" ")
         if len(lineparts) < len(self.stat_file_attrs):
             error()
         for attr, val_string in zip(self.stat_file_attrs,
                                     lineparts[-len(self.stat_file_attrs):]):
             try:
                 val = int(val_string)
             except ValueError:
@@ -133,101 +129,98 @@
                     val = float(val_string)
                 except ValueError:
                     error()
             self.set_stat(attr, val)
         return self
 
     def get_stats_string(self):
-        u"""Return extended string printing out statistics"""
-        return u"%s%s%s" % (self.get_timestats_string(),
-                            self.get_filestats_string(),
-                            self.get_miscstats_string())
+        """Return extended string printing out statistics"""
+        return f"{self.get_timestats_string()}{self.get_filestats_string()}{self.get_miscstats_string()}"
 
     def get_timestats_string(self):
-        u"""Return portion of statistics string dealing with time"""
+        """Return portion of statistics string dealing with time"""
         timelist = []
         if self.StartTime is not None:
-            timelist.append(u"StartTime %.2f (%s)\n" %  # pylint: disable=bad-string-format-type
+            timelist.append("StartTime %.2f (%s)\n" %  # pylint: disable=bad-string-format-type
                             (self.StartTime, dup_time.timetopretty(self.StartTime)))
         if self.EndTime is not None:
-            timelist.append(u"EndTime %.2f (%s)\n" %  # pylint: disable=bad-string-format-type
+            timelist.append("EndTime %.2f (%s)\n" %  # pylint: disable=bad-string-format-type
                             (self.EndTime, dup_time.timetopretty(self.EndTime)))
         if self.ElapsedTime or (self.StartTime is not None and  # pylint:disable=access-member-before-definition
                                 self.EndTime is not None):
             if self.ElapsedTime is None:  # pylint:disable=access-member-before-definition
                 self.ElapsedTime = self.EndTime - self.StartTime
-            timelist.append(u"ElapsedTime %.2f (%s)\n" %
-                            (self.ElapsedTime, dup_time.inttopretty(self.ElapsedTime)))
-        return u"".join(timelist)
+            timelist.append(f"ElapsedTime {self.ElapsedTime:.2f} ({dup_time.inttopretty(self.ElapsedTime)})\n")
+        return "".join(timelist)
 
     def get_filestats_string(self):
-        u"""Return portion of statistics string about files and bytes"""
+        """Return portion of statistics string about files and bytes"""
+
         def fileline(stat_file_pair):
-            u"""Return zero or one line of the string"""
+            """Return zero or one line of the string"""
             attr, in_bytes = stat_file_pair
             val = self.get_stat(attr)
             if val is None:
-                return u""
+                return ""
             if in_bytes:
-                return u"%s %s (%s)\n" % (attr, val,
-                                          self.get_byte_summary_string(val))
+                return f"{attr} {val} ({self.get_byte_summary_string(val)})\n"
             else:
-                return u"%s %s\n" % (attr, val)
+                return f"{attr} {val}\n"
 
-        return u"".join(map(fileline, self.stat_file_pairs))
+        return "".join(map(fileline, self.stat_file_pairs))
 
     def get_miscstats_string(self):
-        u"""Return portion of extended stat string about misc attributes"""
-        misc_string = u""
+        """Return portion of extended stat string about misc attributes"""
+        misc_string = ""
         tdsc = self.TotalDestinationSizeChange
         if tdsc is not None:
-            misc_string += (u"TotalDestinationSizeChange %s (%s)\n" %
-                            (tdsc, self.get_byte_summary_string(tdsc)))
+            misc_string += f"TotalDestinationSizeChange {tdsc} ({self.get_byte_summary_string(tdsc)})\n"
         if self.Errors is not None:
-            misc_string += u"Errors %d\n" % self.Errors
+            misc_string += f"Errors {int(self.Errors)}\n"
         return misc_string
 
     def get_byte_summary_string(self, byte_count):
-        u"""Turn byte count into human readable string like "7.23GB" """
+        """Turn byte count into human readable string like "7.23GB" """
         if byte_count < 0:
-            sign = u"-"
+            sign = "-"
             byte_count = -byte_count
         else:
-            sign = u""
+            sign = ""
 
         for abbrev_bytes, abbrev_string in self.byte_abbrev_list:
             if byte_count >= abbrev_bytes:
                 # Now get 3 significant figures
                 abbrev_count = float(byte_count) / abbrev_bytes
                 if abbrev_count >= 100:
                     precision = 0
                 elif abbrev_count >= 10:
                     precision = 1
                 else:
                     precision = 2
-                return u"%s%%.%df %s" % (sign, precision, abbrev_string) \
-                       % (abbrev_count,)
+                return f"{sign}%.{int(precision)}f {abbrev_string}" \
+                    % (abbrev_count,)
         byte_count = round(byte_count)
         if byte_count == 1:
-            return sign + u"1 byte"
+            return f"{sign}1 byte"
         else:
-            return u"%s%d bytes" % (sign, byte_count)
+            return f"{sign}{int(byte_count)} bytes"
 
     def get_stats_logstring(self, title):
-        u"""Like get_stats_string, but add header and footer"""
-        header = u"--------------[ %s ]--------------" % title
-        footer = u"-" * len(header)
-        return u"%s\n%s%s\n" % (header, self.get_stats_string(), footer)
+        """Like get_stats_string, but add header and footer"""
+        header = f"--------------[ {title} ]--------------"
+        footer = "-" * len(header)
+        return f"{header}\n{self.get_stats_string()}{footer}\n"
 
     def set_stats_from_string(self, s):
-        u"""Initialize attributes from string, return self for convenience"""
+        """Initialize attributes from string, return self for convenience"""
+
         def error(line):
-            raise StatsException(u"Bad line '%s'" % line)
+            raise StatsException(f"Bad line '{line}'")
 
-        for line in s.split(u"\n"):
+        for line in s.split("\n"):
             if not line:
                 continue
             line_parts = line.split()
             if len(line_parts) < 2:
                 error(line)
             attr, value_string = line_parts[:2]
             if attr not in self.stat_attrs:
@@ -243,36 +236,36 @@
                 else:
                     self.set_stat(attr, val2)  # use float
             except ValueError:
                 error(line)
         return self
 
     def write_stats_to_path(self, path):
-        u"""Write statistics string to given path"""
-        fin = path.open(u"w")
+        """Write statistics string to given path"""
+        fin = path.open("w")
         fin.write(self.get_stats_string())
         assert not fin.close()
 
     def read_stats_from_path(self, path):
-        u"""Set statistics from path, return self for convenience"""
-        fp = path.open(u"r")
+        """Set statistics from path, return self for convenience"""
+        fp = path.open("r")
         self.set_stats_from_string(fp.read())
         assert not fp.close()
         return self
 
     def stats_equal(self, s):
-        u"""Return true if s has same statistics as self"""
+        """Return true if s has same statistics as self"""
         assert isinstance(s, StatsObj)
         for attr in self.stat_file_attrs:
             if self.get_stat(attr) != s.get_stat(attr):
                 return None
         return 1
 
     def set_to_average(self, statobj_list):
-        u"""Set self's attributes to average of those in statobj_list"""
+        """Set self's attributes to average of those in statobj_list"""
         for attr in self.stat_attrs:
             self.set_stat(attr, 0)
         for statobj in statobj_list:
             for attr in self.stat_attrs:
                 if statobj.get_stat(attr) is None:
                     self.set_stat(attr, None)
                 elif self.get_stat(attr) is not None:
@@ -286,67 +279,68 @@
         for attr in self.stat_attrs:
             if self.get_stat(attr) is not None:
                 self.set_stat(attr,
                               self.get_stat(attr) / float(len(statobj_list)))
         return self
 
     def get_statsobj_copy(self):
-        u"""Return new StatsObj object with same stats as self"""
+        """Return new StatsObj object with same stats as self"""
         s = StatsObj()
         for attr in self.stat_attrs:
             s.set_stat(attr, self.get_stat(attr))
         return s
 
 
 class StatsDeltaProcess(StatsObj):
-    u"""Keep track of statistics during DirDelta process"""
+    """Keep track of statistics during DirDelta process"""
+
     def __init__(self):
-        u"""StatsDeltaProcess initializer - zero file attributes"""
+        """StatsDeltaProcess initializer - zero file attributes"""
         StatsObj.__init__(self)
         for attr in StatsObj.stat_file_attrs:
             self.__dict__[attr] = 0
         self.Errors = 0
         self.StartTime = time.time()
         self.files_changed = []
 
     def add_new_file(self, path):
-        u"""Add stats of new file path to statistics"""
+        """Add stats of new file path to statistics"""
         filesize = path.getsize()
         self.SourceFiles += 1
         # SourceFileSize is added-to incrementally as read
         self.NewFiles += 1
         self.NewFileSize += filesize
         self.DeltaEntries += 1
         self.add_delta_entries_file(path, b'new')
 
     def add_changed_file(self, path):
-        u"""Add stats of file that has changed since last backup"""
+        """Add stats of file that has changed since last backup"""
         filesize = path.getsize()
         self.SourceFiles += 1
         # SourceFileSize is added-to incrementally as read
         self.ChangedFiles += 1
         self.ChangedFileSize += filesize
         self.DeltaEntries += 1
         self.add_delta_entries_file(path, b'changed')
 
     def add_deleted_file(self, path):
-        u"""Add stats of file no longer in source directory"""
+        """Add stats of file no longer in source directory"""
         self.DeletedFiles += 1  # can't add size since not available
         self.DeltaEntries += 1
         self.add_delta_entries_file(path, b'deleted')
 
     def add_unchanged_file(self, path):
-        u"""Add stats of file that hasn't changed since last backup"""
+        """Add stats of file that hasn't changed since last backup"""
         filesize = path.getsize()
         self.SourceFiles += 1
         self.SourceFileSize += filesize
 
     def close(self):
-        u"""End collection of data, set EndTime"""
+        """End collection of data, set EndTime"""
         self.EndTime = time.time()
 
     def add_delta_entries_file(self, path, action_type):
-        if not config.no_files_changed and path.isreg():
+        if config.files_changed and path.isreg():
             self.files_changed.append((path.get_relative_path(), action_type))
 
     def get_delta_entries_file(self):
         return self.files_changed
```

### Comparing `duplicity-1.2.3.dev43/duplicity/lazy.py` & `duplicity-2.0.0rc0/duplicity/lazy.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,161 +15,155 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Define some lazy data structures and functions acting on them"""
-
-from __future__ import print_function
-
-from builtins import map
-from builtins import next
-from builtins import range
-from builtins import object
+"""Define some lazy data structures and functions acting on them"""
 
 import os
+import sys
 
 from duplicity import log
 from duplicity import robust
 from duplicity import util
 
 
 class Iter(object):
-    u"""Hold static methods for the manipulation of lazy iterators"""
+    """Hold static methods for the manipulation of lazy iterators"""
 
     @staticmethod
     def filter(predicate, iterator):
-        u"""Like filter in a lazy functional programming language"""
+        """Like filter in a lazy functional programming language"""
         for i in iterator:
             if predicate(i):
                 yield i
 
     @staticmethod
     def map(function, iterator):
-        u"""Like map in a lazy functional programming language"""
+        """Like map in a lazy functional programming language"""
         for i in iterator:
             yield function(i)
 
     @staticmethod
     def foreach(function, iterator):
-        u"""Run function on each element in iterator"""
+        """Run function on each element in iterator"""
         for i in iterator:
             function(i)
 
     @staticmethod
     def cat(*iters):
-        u"""Lazily concatenate iterators"""
+        """Lazily concatenate iterators"""
         for iter in iters:  # pylint: disable=redefined-builtin
             for i in iter:
                 yield i
 
     @staticmethod
     def cat2(iter_of_iters):
-        u"""Lazily concatenate iterators, iterated by big iterator"""
+        """Lazily concatenate iterators, iterated by big iterator"""
         for iter in iter_of_iters:  # pylint: disable=redefined-builtin
             for i in iter:
                 yield i
 
     @staticmethod
     def empty(iter):  # pylint: disable=redefined-builtin
-        u"""True if iterator has length 0"""
+        """True if iterator has length 0"""
         for i in iter:
             return None
         return 1
 
     @staticmethod
     def equal(iter1, iter2, verbose=None, operator=lambda x, y: x == y):
-        u"""True if iterator 1 has same elements as iterator 2
+        """True if iterator 1 has same elements as iterator 2
 
         Use equality operator, or == if it is unspecified.
 
         """
         for i1 in iter1:
             try:
                 i2 = next(iter2)
             except StopIteration:
                 if verbose:
-                    print(u"End when i1 = %s" % (i1,))
+                    print(f"End when i1 = {i1}", file=sys.stderr)
                 return None
             if not operator(i1, i2):
                 if verbose:
-                    print(u"%s not equal to %s" % (i1, i2))
+                    print(f"{i1} not equal to {i2}", file=sys.stderr)
                 return None
         try:
             i2 = next(iter2)
         except StopIteration:
             return 1
         if verbose:
-            print(u"End when i2 = %s" % (i2,))
+            print(f"End when i2 = {i2}", file=sys.stderr)
         return None
 
     @staticmethod
     def Or(iter):  # pylint: disable=redefined-builtin
-        u"""True if any element in iterator is true.  Short circuiting"""
+        """True if any element in iterator is true.  Short circuiting"""
         i = None
         for i in iter:
             if i:
                 return i
         return i
 
     @staticmethod
     def And(iter):  # pylint: disable=redefined-builtin
-        u"""True if all elements in iterator are true.  Short circuiting"""
+        """True if all elements in iterator are true.  Short circuiting"""
         i = 1
         for i in iter:
             if not i:
                 return i
         return i
 
     @staticmethod
     def len(iter):  # pylint: disable=redefined-builtin
-        u"""Return length of iterator"""
+        """Return length of iterator"""
         i = 0
-        while 1:
+        while True:
             try:
                 next(iter)
             except StopIteration:
                 return i
             i = i + 1
 
     @staticmethod
     def foldr(f, default, iter):  # pylint: disable=redefined-builtin
-        u"""foldr the "fundamental list recursion operator"?"""
+        """foldr the "fundamental list recursion operator"?"""
         try:
             next_item = next(iter)
         except StopIteration:
             return default
         return f(next_item, Iter.foldr(f, default, iter))
 
     @staticmethod
     def foldl(f, default, iter):  # pylint: disable=redefined-builtin
-        u"""the fundamental list iteration operator.."""
-        while 1:
+        """the fundamental list iteration operator.."""
+        while True:
             try:
                 next_item = next(iter)
             except StopIteration:
                 return default
             default = f(default, next_item)
 
     @staticmethod
     def multiplex(iter, num_of_forks, final_func=None, closing_func=None):  # pylint: disable=redefined-builtin
-        u"""Split a single iterater into a number of streams
+        """Split a single iterater into a number of streams
 
         The return val will be a list with length num_of_forks, each
         of which will be an iterator like iter.  final_func is the
         function that will be called on each element in iter just as
         it is being removed from the buffer.  closing_func is called
         when all the streams are finished.
 
         """
         if num_of_forks == 2 and not final_func and not closing_func:
             im2 = IterMultiplex2(iter)
-            return (im2.yielda(), im2.yieldb())
+            return im2.yielda(), im2.yieldb()
         if not final_func:
             final_func = lambda i: None
         if not closing_func:
             closing_func = lambda: None
 
         # buffer is a list of elements that some iterators need and others
         # don't
@@ -178,15 +172,15 @@
         # buffer[forkposition[i]] is the next element yieled by iterator
         # i.  If it is -1, yield from the original iter
         starting_forkposition = [-1] * num_of_forks
         forkposition = starting_forkposition[:]
         called_closing_func = [None]
 
         def get_next(fork_num):
-            u"""Return the next element requested by fork_num"""
+            """Return the next element requested by fork_num"""
             if forkposition[fork_num] == -1:
                 try:
                     buffer.insert(0, next(iter))
                 except StopIteration:
                     # call closing_func if necessary
                     if (forkposition == starting_forkposition and
                             not called_closing_func[0]):
@@ -211,32 +205,33 @@
             while True:
                 try:
                     ret = get_next(fork_num)
                 except StopIteration:
                     return
                 yield ret
 
-        return tuple(map(make_iterator, list(range(num_of_forks))))
+        return tuple(map(make_iterator, range(num_of_forks)))
 
 
 class IterMultiplex2(object):
-    u"""Multiplex an iterator into 2 parts
+    """Multiplex an iterator into 2 parts
 
     This is a special optimized case of the Iter.multiplex function,
     used when there is no closing_func or final_func, and we only want
     to split it into 2.  By profiling, this is a time sensitive class.
 
     """
+
     def __init__(self, iter):  # pylint: disable=redefined-builtin
         self.a_leading_by = 0  # How many places a is ahead of b
         self.buffer = []
         self.iter = iter
 
     def yielda(self):
-        u"""Return first iterator"""
+        """Return first iterator"""
         buf, iter = self.buffer, self.iter  # pylint: disable=redefined-builtin
         while True:
             if self.a_leading_by >= 0:
                 # a is in front, add new element
                 try:
                     elem = next(iter)
                 except StopIteration:
@@ -245,15 +240,15 @@
             else:
                 # b is in front, subtract an element
                 elem = buf.pop(0)
             self.a_leading_by += 1
             yield elem
 
     def yieldb(self):
-        u"""Return second iterator"""
+        """Return second iterator"""
         buf, iter = self.buffer, self.iter  # pylint: disable=redefined-builtin
         while True:
             if self.a_leading_by <= 0:
                 # b is in front, add new element
                 try:
                     elem = next(iter)
                 except StopIteration:
@@ -263,83 +258,84 @@
                 # a is in front, subtract an element
                 elem = buf.pop(0)
             self.a_leading_by -= 1
             yield elem
 
 
 class IterTreeReducer(object):
-    u"""Tree style reducer object for iterator - stolen from rdiff-backup
+    """Tree style reducer object for iterator - stolen from rdiff-backup
 
     The indicies of a RORPIter form a tree type structure.  This class
     can be used on each element of an iter in sequence and the result
     will be as if the corresponding tree was reduced.  This tries to
     bridge the gap between the tree nature of directories, and the
     iterator nature of the connection between hosts and the temporal
     order in which the files are processed.
 
     This will usually be used by subclassing ITRBranch below and then
     call the initializer below with the new class.
 
     """
+
     def __init__(self, branch_class, branch_args):
-        u"""ITR initializer"""
+        """ITR initializer"""
         self.branch_class = branch_class
         self.branch_args = branch_args
         self.index = None
         self.root_branch = branch_class(*branch_args)
         self.branches = [self.root_branch]
 
     def finish_branches(self, index):
-        u"""Run Finish() on all branches index has passed
+        """Run Finish() on all branches index has passed
 
         When we pass out of a branch, delete it and process it with
         the parent.  The innermost branches will be the last in the
         list.  Return None if we are out of the entire tree, and 1
         otherwise.
 
         """
         branches = self.branches
-        while 1:
+        while True:
             to_be_finished = branches[-1]
             base_index = to_be_finished.base_index
             if base_index != index[:len(base_index)]:
                 # out of the tree, finish with to_be_finished
                 to_be_finished.call_end_proc()
                 del branches[-1]
                 if not branches:
                     return None
                 branches[-1].branch_process(to_be_finished)
             else:
                 return 1
 
     def add_branch(self):
-        u"""Return branch of type self.branch_class, add to branch list"""
+        """Return branch of type self.branch_class, add to branch list"""
         branch = self.branch_class(*self.branch_args)
         self.branches.append(branch)
         return branch
 
     def process_w_branch(self, index, branch, args):
-        u"""Run start_process on latest branch"""
+        """Run start_process on latest branch"""
         robust.check_common_error(branch.on_error,
                                   branch.start_process, args)
         if not branch.caught_exception:
             branch.start_successful = 1
         branch.base_index = index
 
     def Finish(self):
-        u"""Call at end of sequence to tie everything up"""
-        while 1:
+        """Call at end of sequence to tie everything up"""
+        while True:
             to_be_finished = self.branches.pop()
             to_be_finished.call_end_proc()
             if not self.branches:
                 break
             self.branches[-1].branch_process(to_be_finished)
 
     def __call__(self, *args):
-        u"""Process args, where args[0] is current position in iterator
+        """Process args, where args[0] is current position in iterator
 
         Returns true if args successfully processed, false if index is
         not in the current tree and thus the final result is
         available.
 
         Also note below we set self.index after doing the necessary
         start processing, in case there is a crash in the middle.
@@ -348,15 +344,15 @@
         index = args[0]
         if self.index is None:
             self.process_w_branch(index, self.root_branch, args)
             self.index = index
             return 1
 
         if index <= self.index:
-            log.Warn(_(u"Warning: oldindex %s >= newindex %s") %
+            log.Warn(_("Warning: oldindex %s >= newindex %s") %
                      (util.uindex(self.index), util.uindex(index)))
             return 1
 
         if self.finish_branches(index) is None:
             return None  # We are no longer in the main tree
         last_branch = self.branches[-1]
         if last_branch.start_successful:
@@ -370,73 +366,73 @@
             last_branch.log_prev_error(index)
 
         self.index = index
         return 1
 
 
 class ITRBranch(object):
-    u"""Helper class for IterTreeReducer above
+    """Helper class for IterTreeReducer above
 
     There are five stub functions below: start_process, end_process,
     branch_process, fast_process, and can_fast_process.  A class that
     subclasses this one will probably fill in these functions to do
     more.
 
     """
     base_index = index = None
     finished = None
     caught_exception = start_successful = None
 
     def call_end_proc(self):
-        u"""Runs the end_process on self, checking for errors"""
+        """Runs the end_process on self, checking for errors"""
         if self.finished or not self.start_successful:
             self.caught_exception = 1
 
         # Since all end_process does is copy over attributes, might as
         # well run it even if we did get errors earlier.
         robust.check_common_error(self.on_error, self.end_process)
 
         self.finished = 1
 
     def start_process(self, *args):
-        u"""Do some initial processing (stub)"""
+        """Do some initial processing (stub)"""
         pass
 
     def end_process(self):
-        u"""Do any final processing before leaving branch (stub)"""
+        """Do any final processing before leaving branch (stub)"""
         pass
 
     def branch_process(self, branch):
-        u"""Process a branch right after it is finished (stub)"""
+        """Process a branch right after it is finished (stub)"""
         assert branch.finished
         pass
 
     def can_fast_process(self, *args):  # pylint: disable=unused-argument
-        u"""True if object can be processed without new branch (stub)"""
+        """True if object can be processed without new branch (stub)"""
         return None
 
     def fast_process(self, *args):
-        u"""Process args without new child branch (stub)"""
+        """Process args without new child branch (stub)"""
         pass
 
     def on_error(self, exc, *args):
-        u"""This is run on any exception in start/end-process"""
+        """This is run on any exception in start/end-process"""
         self.caught_exception = 1
         if args and args[0] and isinstance(args[0], tuple):
             filename = os.path.join(*args[0])
         elif self.index:
             filename = os.path.join(*self.index)  # pylint: disable=not-an-iterable
         else:
-            filename = u"."
-        log.Warn(_(u"Error '%s' processing %s") % (exc, util.fsdecode(filename)),
+            filename = "."
+        log.Warn(_("Error '%s' processing %s") % (exc, os.fsdecode(filename)),
                  log.WarningCode.cannot_process,
                  util.escape(filename))
 
     def log_prev_error(self, index):
-        u"""Call function if no pending exception"""
+        """Call function if no pending exception"""
         if not index:
-            index_str = u"."
+            index_str = "."
         else:
             index_str = os.path.join(*index)
-        log.Warn(_(u"Skipping %s because of previous error") % util.fsdecode(index_str),
+        log.Warn(_("Skipping %s because of previous error") % os.fsdecode(index_str),
                  log.WarningCode.process_skipped,
                  util.escape(index_str))
```

### Comparing `duplicity-1.2.3.dev43/duplicity/path.py` & `duplicity-2.0.0rc0/duplicity/path.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,217 +15,208 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Wrapper class around a file like "/usr/bin/env"
+"""Wrapper class around a file like "/usr/bin/env"
 
 This class makes certain file operations more convenient and
 associates stat information with filenames
 
 """
 
-from __future__ import print_function
-from future import standard_library
-standard_library.install_aliases()
-from builtins import str
-from builtins import object
-
 import errno
 import gzip
-import os
 import re
 import shutil
 import socket
 import stat
 import time
 
 from duplicity import cached_ops
 from duplicity import config
 from duplicity import dup_time
 from duplicity import file_naming
 from duplicity import gpg
 from duplicity import librsync
-from duplicity import log
 from duplicity import tarfile
-from duplicity import util
 from duplicity.lazy import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 
-_copy_blocksize = 64 * 1024
 _tmp_path_counter = 1
 
 
 class StatResult(object):
-    u"""Used to emulate the output of os.stat() and related"""
+    """Used to emulate the output of os.stat() and related"""
     # st_mode is required by the TarInfo class, but it's unclear how
     # to generate it from file permissions.
     st_mode = 0
 
 
 class PathException(Exception):
     pass
 
 
 class ROPath(object):
-    u"""Read only Path
+    """Read only Path
 
     Objects of this class doesn't represent real files, so they don't
     have a name.  They are required to be indexed though.
 
     """
+
     def __init__(self, index, stat=None):  # pylint: disable=unused-argument
-        u"""ROPath initializer"""
+        """ROPath initializer"""
         self.opened, self.fileobj = None, None
         self.index = index
         self.stat, self.type = None, None
         self.mode, self.devnums = None, None
 
     def set_from_stat(self):
-        u"""Set the value of self.type, self.mode from self.stat"""
+        """Set the value of self.type, self.mode from self.stat"""
         if not self.stat:
             self.type = None
 
         st_mode = self.stat.st_mode
         if stat.S_ISREG(st_mode):
-            self.type = u"reg"
+            self.type = "reg"
         elif stat.S_ISDIR(st_mode):
-            self.type = u"dir"
+            self.type = "dir"
         elif stat.S_ISLNK(st_mode):
-            self.type = u"sym"
+            self.type = "sym"
         elif stat.S_ISFIFO(st_mode):
-            self.type = u"fifo"
+            self.type = "fifo"
         elif stat.S_ISSOCK(st_mode):
-            raise PathException(util.fsdecode(self.get_relative_path()) +
-                                u"is a socket, unsupported by tar")
-            self.type = u"sock"  # pylint: disable=unreachable
+            raise PathException(os.fsdecode(self.get_relative_path()) +
+                                "is a socket, unsupported by tar")
+            self.type = "sock"  # pylint: disable=unreachable
         elif stat.S_ISCHR(st_mode):
-            self.type = u"chr"
+            self.type = "chr"
         elif stat.S_ISBLK(st_mode):
-            self.type = u"blk"
+            self.type = "blk"
         else:
-            raise PathException(u"Unknown type")
+            raise PathException("Unknown type")
 
         self.mode = stat.S_IMODE(st_mode)
-        if self.type in (u"chr", u"blk"):
+        if self.type in ("chr", "blk"):
             try:
                 self.devnums = (os.major(self.stat.st_rdev),
                                 os.minor(self.stat.st_rdev))
-            except:
-                log.Warn(_(u"Warning: %s invalid devnums (0x%X), treating as (0, 0).")
-                         % (util.fsdecode(self.get_relative_path()), self.stat.st_rdev))
+            except Exception as e:
+                log.Warn(_("Warning: %s invalid devnums (0x%X), treating as (0, 0).")
+                         % (os.fsdecode(self.get_relative_path()), self.stat.st_rdev))
                 self.devnums = (0, 0)
 
     def blank(self):
-        u"""Black out self - set type and stat to None"""
+        """Black out self - set type and stat to None"""
         self.type, self.stat = None, None
 
     def exists(self):
-        u"""True if corresponding file exists"""
+        """True if corresponding file exists"""
         return self.type
 
     def isreg(self):
-        u"""True if self corresponds to regular file"""
-        return self.type == u"reg"
+        """True if self corresponds to regular file"""
+        return self.type == "reg"
 
     def isdir(self):
-        u"""True if self is dir"""
-        return self.type == u"dir"
+        """True if self is dir"""
+        return self.type == "dir"
 
     def issym(self):
-        u"""True if self is sym"""
-        return self.type == u"sym"
+        """True if self is sym"""
+        return self.type == "sym"
 
     def isfifo(self):
-        u"""True if self is fifo"""
-        return self.type == u"fifo"
+        """True if self is fifo"""
+        return self.type == "fifo"
 
     def issock(self):
-        u"""True is self is socket"""
-        return self.type == u"sock"
+        """True is self is socket"""
+        return self.type == "sock"
 
     def isdev(self):
-        u"""True is self is a device file"""
-        return self.type == u"chr" or self.type == u"blk"
+        """True is self is a device file"""
+        return self.type == "chr" or self.type == "blk"
 
     def getdevloc(self):
-        u"""Return device number path resides on"""
+        """Return device number path resides on"""
         return self.stat.st_dev
 
     def getsize(self):
-        u"""Return length in bytes from stat object"""
+        """Return length in bytes from stat object"""
         return self.stat.st_size
 
     def getmtime(self):
-        u"""Return mod time of path in seconds"""
+        """Return mod time of path in seconds"""
         return int(self.stat.st_mtime)
 
     def get_relative_path(self):
-        u"""Return relative path, created from index"""
+        """Return relative path, created from index"""
         if self.index:
             return b"/".join(self.index)
         else:
             return b"."
 
     def getperms(self):
-        u"""Return permissions mode, owner and group"""
+        """Return permissions mode, owner and group"""
         s1 = self.stat
-        return u'%s:%s %o' % (s1.st_uid, s1.st_gid, self.mode)
+        return f'{s1.st_uid}:{s1.st_gid} {self.mode:o}'
 
     def open(self, mode):
-        u"""Return fileobj associated with self"""
-        assert mode == u"rb" and self.fileobj and not self.opened, \
-            u"%s %s %s" % (mode, self.fileobj, self.opened)
+        """Return fileobj associated with self"""
+        assert mode == "rb" and self.fileobj and not self.opened, \
+            f"{mode} {self.fileobj} {self.opened}"
         self.opened = 1
         return self.fileobj
 
     def get_data(self):
-        u"""Return contents of associated fileobj in string"""
-        fin = self.open(u"rb")
+        """Return contents of associated fileobj in string"""
+        fin = self.open("rb")
         buf = fin.read()
         assert not fin.close()
         return buf
 
     def setfileobj(self, fileobj):
-        u"""Set file object returned by open()"""
+        """Set file object returned by open()"""
         assert not self.fileobj
         self.fileobj = fileobj
         self.opened = None
 
     def init_from_tarinfo(self, tarinfo):
-        u"""Set data from tarinfo object (part of tarfile module)"""
+        """Set data from tarinfo object (part of tarfile module)"""
         # Set the typepp
         type = tarinfo.type  # pylint: disable=redefined-builtin
         if type == tarfile.REGTYPE or type == tarfile.AREGTYPE:
-            self.type = u"reg"
+            self.type = "reg"
         elif type == tarfile.LNKTYPE:
-            raise PathException(u"Hard links not supported yet")
+            raise PathException("Hard links not supported yet")
         elif type == tarfile.SYMTYPE:
-            self.type = u"sym"
+            self.type = "sym"
             self.symtext = tarinfo.linkname
-            if isinstance(self.symtext, u"".__class__):
-                self.symtext = util.fsencode(self.symtext)
+            if isinstance(self.symtext, "".__class__):
+                self.symtext = os.fsencode(self.symtext)
         elif type == tarfile.CHRTYPE:
-            self.type = u"chr"
+            self.type = "chr"
             self.devnums = (tarinfo.devmajor, tarinfo.devminor)
         elif type == tarfile.BLKTYPE:
-            self.type = u"blk"
+            self.type = "blk"
             self.devnums = (tarinfo.devmajor, tarinfo.devminor)
         elif type == tarfile.DIRTYPE:
-            self.type = u"dir"
+            self.type = "dir"
         elif type == tarfile.FIFOTYPE:
-            self.type = u"fifo"
+            self.type = "fifo"
         else:
-            raise PathException(u"Unknown tarinfo type %s" % (type,))
+            raise PathException(f"Unknown tarinfo type {type}")
 
         self.mode = tarinfo.mode
         self.stat = StatResult()
 
-        u""" If do_not_restore_owner is False,
+        """ If do_not_restore_owner is False,
         set user and group id
         use numeric id if name lookup fails
         OR
         --numeric-owner is set
         """
         try:
             if config.numeric_owner:
@@ -238,46 +229,46 @@
                 raise KeyError
             self.stat.st_gid = cached_ops.getgrnam(tarinfo.gname)[2]
         except KeyError:
             self.stat.st_gid = tarinfo.gid
 
         self.stat.st_mtime = int(tarinfo.mtime)
         if self.stat.st_mtime < 0:
-            log.Warn(_(u"Warning: %s has negative mtime, treating as 0.")
-                     % (tarinfo.uc_name))
+            log.Warn(_("Warning: %s has negative mtime, treating as 0.")
+                     % tarinfo.uc_name)
             self.stat.st_mtime = 0
         self.stat.st_size = tarinfo.size
 
     def get_ropath(self):
-        u"""Return ropath copy of self"""
+        """Return ropath copy of self"""
         new_ropath = ROPath(self.index, self.stat)
         new_ropath.type, new_ropath.mode = self.type, self.mode
         if self.issym():
             new_ropath.symtext = self.symtext
         elif self.isdev():
             new_ropath.devnums = self.devnums
         if self.exists():
             new_ropath.stat = self.stat
         return new_ropath
 
     def get_tarinfo(self):
-        u"""Generate a tarfile.TarInfo object based on self
+        """Generate a tarfile.TarInfo object based on self
 
         Doesn't set size based on stat, because we may want to replace
         data wiht other stream.  Size should be set separately by
         calling function.
 
         """
         ti = tarfile.TarInfo()
         if self.index:
-            ti.name = util.fsdecode(b"/".join(self.index))
+            ti.name = os.fsdecode(b"/".join(self.index))
         else:
-            ti.name = u"."
+            ti.name = "."
         if self.isdir():
-            ti.name += u"/"  # tar dir naming convention
+            ti.name += "/"  # tar dir naming convention
 
         ti.size = 0
         if self.type:
             # Lots of this is specific to tarfile.py, hope it doesn't
             # change much...
             if self.isreg():
                 ti.type = tarfile.REGTYPE
@@ -286,54 +277,54 @@
                 ti.type = tarfile.DIRTYPE
             elif self.isfifo():
                 ti.type = tarfile.FIFOTYPE
             elif self.issym():
                 ti.type = tarfile.SYMTYPE
                 ti.linkname = self.symtext
                 if isinstance(ti.linkname, bytes):
-                    ti.linkname = util.fsdecode(ti.linkname)
+                    ti.linkname = os.fsdecode(ti.linkname)
             elif self.isdev():
-                if self.type == u"chr":
+                if self.type == "chr":
                     ti.type = tarfile.CHRTYPE
                 else:
                     ti.type = tarfile.BLKTYPE
                 ti.devmajor, ti.devminor = self.devnums
             else:
-                raise PathException(u"Unrecognized type " + str(self.type))
+                raise PathException(f"Unrecognized type {str(self.type)}")
 
             ti.mode = self.mode
             ti.uid, ti.gid = self.stat.st_uid, self.stat.st_gid
             if self.stat.st_mtime < 0:
-                log.Warn(_(u"Warning: %s has negative mtime, treating as 0.")
-                         % (util.fsdecode(self.get_relative_path())))
+                log.Warn(_("Warning: %s has negative mtime, treating as 0.")
+                         % (os.fsdecode(self.get_relative_path())))
                 ti.mtime = 0
             else:
                 ti.mtime = int(self.stat.st_mtime)
 
             try:
                 ti.uname = cached_ops.getpwuid(ti.uid)[0]
             except KeyError:
-                ti.uname = u''
+                ti.uname = ''
             try:
                 ti.gname = cached_ops.getgrgid(ti.gid)[0]
             except KeyError:
-                ti.gname = u''
+                ti.gname = ''
 
             if ti.type in (tarfile.CHRTYPE, tarfile.BLKTYPE):
-                if hasattr(os, u"major") and hasattr(os, u"minor"):
+                if hasattr(os, "major") and hasattr(os, "minor"):
                     ti.devmajor, ti.devminor = self.devnums
         else:
             # Currently we depend on an uninitiliazed tarinfo file to
             # already have appropriate headers.  Still, might as well
             # make sure mode and size set.
             ti.mode, ti.size = 0, 0
         return ti
 
     def __eq__(self, other):
-        u"""Used to compare two ROPaths.  Doesn't look at fileobjs"""
+        """Used to compare two ROPaths.  Doesn't look at fileobjs"""
         if not self.type and not other.type:
             return 1  # neither exists
         if not self.stat and other.stat or not other.stat and self.stat:
             return 0
         if self.type != other.type:
             return 0
 
@@ -353,450 +344,450 @@
             return self.perms_equal(other) and self.devnums == other.devnums
         assert 0
 
     def __ne__(self, other):
         return not self.__eq__(other)
 
     def compare_verbose(self, other, include_data=0):
-        u"""Compare ROPaths like __eq__, but log reason if different
+        """Compare ROPaths like __eq__, but log reason if different
 
         This is placed in a separate function from __eq__ because
         __eq__ should be very time sensitive, and logging statements
         would slow it down.  Used when verifying.
 
         Only run if include_data is true.
 
         """
+
         def log_diff(log_string):
-            log_str = _(u"Difference found:") + u" " + log_string
-            log.Notice(log_str % (util.fsdecode(self.get_relative_path())))
+            log_str = f"{_('Difference found:')} {log_string}"
+            log.Notice(log_str % (os.fsdecode(self.get_relative_path())))
 
         if include_data is False:
             return True
 
         if not self.type and not other.type:
             return 1
         if not self.stat and other.stat:
-            log_diff(_(u"New file %s"))
+            log_diff(_("New file %s"))
             return 0
         if not other.stat and self.stat:
-            log_diff(_(u"File %s is missing"))
+            log_diff(_("File %s is missing"))
             return 0
         if self.type != other.type:
-            log_diff(_(u"File %%s has type %s, expected %s") %
+            log_diff(_("File %%s has type %s, expected %s") %
                      (other.type, self.type))
             return 0
 
         if self.isreg() or self.isdir() or self.isfifo():
             if not self.perms_equal(other):
-                log_diff(_(u"File %%s has permissions %s, expected %s") %
+                log_diff(_("File %%s has permissions %s, expected %s") %
                          (other.getperms(), self.getperms()))
                 return 0
             if ((int(self.stat.st_mtime) != int(other.stat.st_mtime)) and
                     (self.stat.st_mtime > 0 or other.stat.st_mtime > 0)):
-                log_diff(_(u"File %%s has mtime %s, expected %s") %
+                log_diff(_("File %%s has mtime %s, expected %s") %
                          (dup_time.timetopretty(int(other.stat.st_mtime)),
                           dup_time.timetopretty(int(self.stat.st_mtime))))
                 return 0
             if self.isreg():
                 if self.compare_data(other):
                     return 1
                 else:
-                    log_diff(_(u"Data for file %s is different"))
+                    log_diff(_("Data for file %s is different"))
                     return 0
             else:
                 return 1
         elif self.issym():
-            if self.symtext == other.symtext or self.symtext + util.fsencode(os.sep) == other.symtext:
+            if self.symtext == other.symtext or self.symtext + os.fsencode(os.sep) == other.symtext:
                 return 1
             else:
-                log_diff(_(u"Symlink %%s points to %s, expected %s") %
+                log_diff(_("Symlink %%s points to %s, expected %s") %
                          (other.symtext, self.symtext))
                 return 0
         elif self.isdev():
             if not self.perms_equal(other):
-                log_diff(_(u"File %%s has permissions %s, expected %s") %
+                log_diff(_("File %%s has permissions %s, expected %s") %
                          (other.getperms(), self.getperms()))
                 return 0
             if self.devnums != other.devnums:
-                log_diff(_(u"Device file %%s has numbers %s, expected %s")
+                log_diff(_("Device file %%s has numbers %s, expected %s")
                          % (other.devnums, self.devnums))
                 return 0
             return 1
         assert 0
 
     def compare_data(self, other):
-        u"""Compare data from two regular files, return true if same"""
-        f1 = self.open(u"rb")
-        f2 = other.open(u"rb")
+        """Compare data from two regular files, return true if same"""
+        f1 = self.open("rb")
+        f2 = other.open("rb")
 
         def close():
             assert not f1.close()
             assert not f2.close()
 
-        while 1:
-            buf1 = f1.read(_copy_blocksize)
-            buf2 = f2.read(_copy_blocksize)
+        while True:
+            buf1 = f1.read(config.copy_blocksize)
+            buf2 = f2.read(config.copy_blocksize)
             if buf1 != buf2:
                 close()
                 return 0
             if not buf1:
                 close()
                 return 1
 
     def perms_equal(self, other):
-        u"""True if self and other have same permissions and ownership"""
+        """True if self and other have same permissions and ownership"""
         s1, s2 = self.stat, other.stat
         return (self.mode == other.mode and
                 s1.st_gid == s2.st_gid and s1.st_uid == s2.st_uid)
 
     def copy(self, other):
-        u"""Copy self to other.  Also copies data.  Other must be Path"""
+        """Copy self to other.  Also copies data.  Other must be Path"""
         if self.isreg():
-            other.writefileobj(self.open(u"rb"))
+            other.writefileobj(self.open("rb"))
         elif self.isdir():
             os.mkdir(other.name)
         elif self.issym():
             os.symlink(self.symtext, other.name)
-            if not config.do_not_restore_ownership:
+            if config.restore_ownership:
                 os.lchown(other.name, self.stat.st_uid, self.stat.st_gid)
             other.setdata()
             return  # no need to copy symlink attributes
         elif self.isfifo():
             os.mkfifo(other.name)
         elif self.issock():
             socket.socket(socket.AF_UNIX).bind(other.name)
         elif self.isdev():
-            if self.type == u"chr":
-                devtype = u"c"
+            if self.type == "chr":
+                devtype = "c"
             else:
-                devtype = u"b"
+                devtype = "b"
             other.makedev(devtype, *self.devnums)
         self.copy_attribs(other)
 
     def copy_attribs(self, other):
-        u"""Only copy attributes from self to other"""
+        """Only copy attributes from self to other"""
         if isinstance(other, Path):
             if not self.issym():
-                if self.stat and not config.do_not_restore_ownership:
+                if self.stat and config.restore_ownership:
                     util.maybe_ignore_errors(lambda: os.chown(other.name, self.stat.st_uid, self.stat.st_gid))
                 util.maybe_ignore_errors(lambda: os.chmod(other.name, self.mode))
                 util.maybe_ignore_errors(lambda: os.utime(other.name, (time.time(), self.stat.st_mtime)))
             other.setdata()
         else:
             # write results to fake stat object
             assert isinstance(other, ROPath)
             stat = StatResult()
             stat.st_uid, stat.st_gid = self.stat.st_uid, self.stat.st_gid
             stat.st_mtime = int(self.stat.st_mtime)
             other.stat = stat
             other.mode = self.mode
 
     def __str__(self):
-        u"""Return string representation"""
-        return u"(%s %s)" % (util.uindex(self.index), self.type)
+        """Return string representation"""
+        return f"({util.uindex(self.index)} {self.type})"
 
 
 class Path(ROPath):
-    u"""
+    """
     Path class - wrapper around ordinary local files
 
     Besides caching stat() results, this class organizes various file
     code.
     """
-    regex_chars_to_quote = re.compile(u"[\\\\\\\"\\$`]")
+    regex_chars_to_quote = re.compile("[\\\\\\\"\\$`]")
 
     def rename_index(self, index):
         if not config.rename or not index:
             return index  # early exit
         path = os.path.normcase(os.path.join(*index))
         tail = []
         while path and path not in config.rename:
             path, extra = os.path.split(path)
             tail.insert(0, extra)
         if path:
-            return config.rename[path].split(util.fsencode(os.sep)) + tail
+            return config.rename[path].split(os.fsencode(os.sep)) + tail
         else:
             return index  # no rename found
 
     def __init__(self, base, index=()):
-        u"""Path initializer"""
+        """Path initializer"""
         # self.opened should be true if the file has been opened, and
         # self.fileobj can override returned fileobj
+        super().__init__(index)
         self.opened, self.fileobj = None, None
         if isinstance(base, str):
-            # For now (Python 2), it is helpful to know that all paths
-            # are starting with bytes -- see note above util.fsencode definition
-            base = util.fsencode(base)
+            base = os.fsencode(base)
         self.base = base
 
         # Create self.index, which is the path as a tuple
         self.index = self.rename_index(index)
 
         self.name = os.path.join(base, *self.index)
 
         # We converted any unicode base to filesystem encoding, so self.name should
         # be in filesystem encoding already and does not need to change
-        self.uc_name = util.fsdecode(self.name)
+        self.uc_name = os.fsdecode(self.name)
 
         self.setdata()
 
     def setdata(self):
-        u"""Refresh stat cache"""
+        """Refresh stat cache"""
         try:
             # We may be asked to look at the target of symlinks rather than
             # the link itself.
             if config.copy_links:
                 self.stat = os.stat(self.name)
             else:
                 self.stat = os.lstat(self.name)
         except OSError as e:
             err_string = errno.errorcode[e.errno]
-            if err_string in [u"ENOENT", u"ENOTDIR", u"ELOOP", u"ENOTCONN", u"ENODEV"]:
+            if err_string in ["ENOENT", "ENOTDIR", "ELOOP", "ENOTCONN", "ENODEV"]:
                 self.stat, self.type = None, None  # file doesn't exist
                 self.mode = None
             else:
                 raise
         else:
             self.set_from_stat()
             if self.issym():
                 self.symtext = os.readlink(self.name)
 
     def append(self, ext):
-        u"""Return new Path with ext added to index"""
-        if isinstance(ext, u"".__class__):
-            ext = util.fsencode(ext)
+        """Return new Path with ext added to index"""
+        if isinstance(ext, "".__class__):
+            ext = os.fsencode(ext)
         return self.__class__(self.base, self.index + (ext,))
 
     def new_index(self, index):
-        u"""Return new Path with index index"""
+        """Return new Path with index index"""
         return self.__class__(self.base, index)
 
     def listdir(self):
-        u"""Return list generated by os.listdir"""
+        """Return list generated by os.listdir"""
         return os.listdir(self.name)
 
     def isemptydir(self):
-        u"""Return true if path is a directory and is empty"""
+        """Return true if path is a directory and is empty"""
         return self.isdir() and not self.listdir()
 
     def contains(self, child):
-        u"""Return true if path is a directory and contains child"""
-        if isinstance(child, u"".__class__):
-            child = util.fsencode(child)
+        """Return true if path is a directory and contains child"""
+        if isinstance(child, "".__class__):
+            child = os.fsencode(child)
         # We don't use append(child).exists() here because that requires exec
         # permissions as well as read. listdir() just needs read permissions.
         return self.isdir() and child in self.listdir()
 
-    def open(self, mode=u"rb"):
-        u"""
+    def open(self, mode="rb"):
+        """
         Return fileobj associated with self
 
         Usually this is just the file data on disk, but can be
         replaced with arbitrary data using the setfileobj method.
         """
         assert not self.opened
         if self.fileobj:
             result = self.fileobj
         else:
             result = open(self.name, mode)
         return result
 
     def makedev(self, type, major, minor):  # pylint: disable=redefined-builtin
-        u"""Make a device file with specified type, major/minor nums"""
-        cmdlist = [u'mknod', self.name, type, str(major), str(minor)]
-        if os.spawnvp(os.P_WAIT, u'mknod', cmdlist) != 0:
-            raise PathException(u"Error running %s" % cmdlist)
+        """Make a device file with specified type, major/minor nums"""
+        cmdlist = ['mknod', self.name, type, str(major), str(minor)]
+        if os.spawnvp(os.P_WAIT, 'mknod', cmdlist) != 0:
+            raise PathException(f"Error running {cmdlist}")
         self.setdata()
 
     def mkdir(self):
-        u"""Make directory(s) at specified path"""
-        log.Info(_(u"Making directory %s") % self.uc_name)
+        """Make directory(s) at specified path"""
+        log.Info(_("Making directory %s") % self.uc_name)
         try:
             os.makedirs(self.name)
         except OSError:
-            if (not config.force):
-                raise PathException(u"Error creating directory %s" % self.uc_name, 7)
+            if not config.force:
+                raise PathException(f"Error creating directory {self.uc_name}", 7)
         self.setdata()
 
     def delete(self):
-        u"""Remove this file"""
-        log.Info(_(u"Deleting %s") % self.uc_name)
+        """Remove this file"""
+        log.Info(_("Deleting %s") % self.uc_name)
         if self.isdir():
             util.ignore_missing(os.rmdir, self.name)
         else:
             util.ignore_missing(os.unlink, self.name)
         self.setdata()
 
     def touch(self):
-        u"""Open the file, write 0 bytes, close"""
-        log.Info(_(u"Touching %s") % self.uc_name)
-        fp = self.open(u"wb")
+        """Open the file, write 0 bytes, close"""
+        log.Info(_("Touching %s") % self.uc_name)
+        fp = self.open("wb")
         fp.close()
 
     def deltree(self):
-        u"""Remove self by recursively deleting files under it"""
-        from duplicity import selection  # todo: avoid circ. dep. issue
-        log.Info(_(u"Deleting tree %s") % self.uc_name)
+        """Remove self by recursively deleting files under it"""
+        from duplicity import selection  # TODO: avoid circ. dep. issue
+        log.Info(_("Deleting tree %s") % self.uc_name)
         itr = IterTreeReducer(PathDeleter, [])
         for path in selection.Select(self).set_iter():
             itr(path.index, path)
         itr.Finish()
         self.setdata()
 
     def get_parent_dir(self):
-        u"""Return directory that self is in"""
+        """Return directory that self is in"""
         if self.index:
             return Path(self.base, self.index[:-1])
         else:
             components = self.base.split(b"/")
             if len(components) == 2 and not components[0]:
                 return Path(b"/")  # already in root directory
             else:
                 return Path(b"/".join(components[:-1]))
 
     def writefileobj(self, fin):
-        u"""Copy file object fin to self.  Close both when done."""
-        fout = self.open(u"wb")
-        while 1:
-            buf = fin.read(_copy_blocksize)
+        """Copy file object fin to self.  Close both when done."""
+        fout = self.open("wb")
+        while True:
+            buf = fin.read(config.copy_blocksize)
             if not buf:
                 break
             fout.write(buf)
         if fin.close() or fout.close():
-            raise PathException(u"Error closing file object")
+            raise PathException("Error closing file object")
         self.setdata()
 
     def rename(self, new_path):
-        u"""Rename file at current path to new_path."""
+        """Rename file at current path to new_path."""
         shutil.move(self.name, new_path.name)
         self.setdata()
         new_path.setdata()
 
     def move(self, new_path):
-        u"""Like rename but destination may be on different file system"""
+        """Like rename but destination may be on different file system"""
         self.copy(new_path)
         self.delete()
 
     def chmod(self, mode):
-        u"""Change permissions of the path"""
+        """Change permissions of the path"""
         os.chmod(self.name, mode)
         self.setdata()
 
     def patch_with_attribs(self, diff_ropath):
-        u"""Patch self with diff and then copy attributes over"""
+        """Patch self with diff and then copy attributes over"""
         assert self.isreg() and diff_ropath.isreg()
         temp_path = self.get_temp_in_same_dir()
-        fbase = self.open(u"rb")
-        fdiff = diff_ropath.open(u"rb")
+        fbase = self.open("rb")
+        fdiff = diff_ropath.open("rb")
         patch_fileobj = librsync.PatchedFile(fbase, fdiff)
         temp_path.writefileobj(patch_fileobj)
         assert not fbase.close()
         assert not fdiff.close()
         diff_ropath.copy_attribs(temp_path)
         temp_path.rename(self)
 
     def get_temp_in_same_dir(self):
-        u"""Return temp non existent path in same directory as self"""
+        """Return temp non existent path in same directory as self"""
         global _tmp_path_counter
         parent_dir = self.get_parent_dir()
-        while 1:
-            temp_path = parent_dir.append(u"duplicity_temp." +
-                                          str(_tmp_path_counter))
+        while True:
+            temp_path = parent_dir.append(f"duplicity_temp.{str(_tmp_path_counter)}")
             if not temp_path.type:
                 return temp_path
             _tmp_path_counter += 1
             assert _tmp_path_counter < 10000, \
-                u"Warning too many temp files created for " + self.uc_name
+                f"Warning too many temp files created for {self.uc_name}"
 
     def compare_recursive(self, other, verbose=None):
-        u"""Compare self to other Path, descending down directories"""
-        from duplicity import selection  # todo: avoid circ. dep. issue
+        """Compare self to other Path, descending down directories"""
+        from duplicity import selection  # TODO: avoid circ. dep. issue
         selfsel = selection.Select(self).set_iter()
         othersel = selection.Select(other).set_iter()
         return Iter.equal(selfsel, othersel, verbose)
 
     def __repr__(self):
-        u"""Return string representation"""
-        return u"(%s %s %s)" % (self.index, self.name, self.type)
+        """Return string representation"""
+        return f"({self.index} {self.uc_name} {self.type})"
 
     def quote(self, s=None):
-        u"""
+        """
         Return quoted version of s (defaults to self.name)
 
         The output is meant to be interpreted with shells, so can be
         used with os.system.
         """
         if not s:
             s = self.uc_name
-        return u'"%s"' % self.regex_chars_to_quote.sub(lambda m: u"\\" + m.group(0), s)
+        return '"%s"' % self.regex_chars_to_quote.sub(lambda m: f"\\{m.group(0)}", s)
 
     def unquote(self, s):
-        u"""Return unquoted version of string s, as quoted by above quote()"""
-        assert s[0] == s[-1] == u"\""  # string must be quoted by above
-        result = u""
+        """Return unquoted version of string s, as quoted by above quote()"""
+        assert s[0] == s[-1] == "\""  # string must be quoted by above
+        result = ""
         i = 1
         while i < len(s) - 1:
-            if s[i] == u"\\":
+            if s[i] == "\\":
                 result += s[i + 1]
                 i += 2
             else:
                 result += s[i]
                 i += 1
         return result
 
     def get_filename(self):
-        u"""Return filename of last component"""
+        """Return filename of last component"""
         components = self.name.split(b"/")
         assert components and components[-1]
         return components[-1]
 
     def get_canonical(self):
-        u"""
+        """
         Return string of canonical version of path
 
         Remove ".", and trailing slashes where possible.  Note that
         it's harder to remove "..", as "foo/bar/.." is not necessarily
         "foo", so we can't use path.normpath()
         """
         newpath = b"/".join([x for x in self.name.split(b"/") if x and x != b"."])
-        if self.uc_name[0] == u"/":
+        if self.uc_name[0] == "/":
             return b"/" + newpath
         elif newpath:
             return newpath
         else:
             return b"."
 
 
 class DupPath(Path):
-    u"""
+    """
     Represent duplicity data files
 
     Based on the file name, files that are compressed or encrypted
     will have different open() methods.
     """
+
     def __init__(self, base, index=(), parseresults=None):
-        u"""
+        """
         DupPath initializer
 
         The actual filename (no directory) must be the single element
         of the index, unless parseresults is given.
 
         """
         if parseresults:
             self.pr = parseresults
         else:
             assert len(index) == 1
             self.pr = file_naming.parse(index[0])
-            assert self.pr, u"must be a recognizable duplicity file"
+            assert self.pr, "must be a recognizable duplicity file"
 
         Path.__init__(self, base, index)
 
-    def filtered_open(self, mode=u"rb", gpg_profile=None):
-        u"""
+    def filtered_open(self, mode="rb", gpg_profile=None):
+        """
         Return fileobj with appropriate encryption/compression
 
         If encryption is specified but no gpg_profile, use
         config.default_profile.
         """
         assert not self.opened and not self.fileobj
         assert not (self.pr.encrypted and self.pr.compressed)
@@ -804,24 +795,25 @@
             assert self.pr.encrypted
 
         if self.pr.compressed:
             return gzip.GzipFile(self.name, mode)
         elif self.pr.encrypted:
             if not gpg_profile:
                 gpg_profile = config.gpg_profile
-            if mode == u"rb":
+            if mode == "rb":
                 return gpg.GPGFile(False, self, gpg_profile)
-            elif mode == u"wb":
+            elif mode == "wb":
                 return gpg.GPGFile(True, self, gpg_profile)
         else:
             return self.open(mode)
 
 
 class PathDeleter(ITRBranch):
-    u"""Delete a directory.  Called by Path.deltree"""
+    """Delete a directory.  Called by Path.deltree"""
+
     def start_process(self, index, path):  # pylint: disable=unused-argument
         self.path = path
 
     def end_process(self):
         self.path.delete()
 
     def can_fast_process(self, index, path):  # pylint: disable=unused-argument
```

### Comparing `duplicity-1.2.3.dev43/duplicity/selection.py` & `duplicity-2.0.0rc0/duplicity/selection.py`

 * *Files 17% similar despite different names*

```diff
@@ -16,40 +16,36 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from builtins import next
-from builtins import str
-from builtins import object
 
-import os
-import stat
 import sys
-import re
+from textwrap import dedent
 
-from duplicity import config
 from duplicity import diffdir
-from duplicity import log
-from duplicity import util
-from duplicity.globmatch import GlobbingError, FilePrefixError, select_fn_from_glob
+from duplicity.globmatch import (
+    GlobbingError,
+    FilePrefixError,
+    select_fn_from_glob,
+)
 from duplicity.path import *  # pylint: disable=unused-wildcard-import,redefined-builtin
 
-u"""Iterate exactly the requested files in a directory
+"""
+Iterate exactly the requested files in a directory
 
 Parses includes and excludes to yield correct files.  More
 documentation on what this code does can be found on the man page.
-
 """
 
 
 class Select(object):
-    u"""Iterate appropriate Paths in given directory
+    """Iterate appropriate Paths in given directory
 
     This class acts as an iterator on account of its next() method.
     Basically, it just goes through all the files in a directory in
     order (depth-first) and subjects each file to a bunch of tests
     (selection functions) in order.  The first test that includes or
     excludes the file means that the file gets included (iterated) or
     excluded.  The default is include, so with no tests we would just
@@ -72,118 +68,118 @@
     1 - the file is included
     2 - the test says the file (must be directory) should be scanned
 
     Also, a selection function f has a variable f.exclude which should
     be true if f could potentially exclude some file. This is used
     to signal an error if the last function only includes, which would
     be redundant and presumably isn't what the user intends.
-
     """
+
     def __init__(self, path):
-        u"""Initializer, called with Path of root directory"""
+        """Initializer, called with Path of root directory"""
         assert isinstance(path, Path), str(path)
         self.selection_functions = []
         self.rootpath = path
         self.prefix = self.rootpath.uc_name
         self.files_from = None
 
     def __iter__(self):  # pylint: disable=non-iterator-returned
         return self
 
     def __next__(self):
         return next(self.iter)
 
     def set_iter(self):
-        u"""Initialize generator, prepare to iterate."""
+        """Initialize generator, prepare to iterate."""
         # Externally-accessed method
         self.rootpath.setdata()  # this may have changed since Select init
         self.iter = self.Iterate(self.rootpath)
         return self
 
     def Iterate(self, path):
-        u"""Return iterator yielding paths in path
+        """Return iterator yielding paths in path
 
         This function looks a bit more complicated than it needs to be
         because it avoids extra recursion (and no extra function calls
         for non-directory files) while still doing the "directory
         scanning" bit.
 
         """
+
         # Only called by set_iter. Internal.
         def error_handler(exc, path, filename):  # pylint: disable=unused-argument
             fullpath = os.path.join(path.name, filename)
             try:
                 mode = os.stat(fullpath)[stat.ST_MODE]
                 if stat.S_ISSOCK(mode):
-                    log.Info(_(u"Skipping socket %s") % util.fsdecode(fullpath),
+                    log.Info(_("Skipping socket %s") % os.fsdecode(fullpath),
                              log.InfoCode.skipping_socket,
                              util.escape(fullpath))
                 else:
-                    log.Warn(_(u"Error initializing file %s") % util.fsdecode(fullpath),
+                    log.Warn(_("Error initializing file %s") % os.fsdecode(fullpath),
                              log.WarningCode.cannot_iterate,
                              util.escape(fullpath))
             except OSError:
-                log.Warn(_(u"Error accessing possibly locked file %s") % util.fsdecode(fullpath),
+                log.Warn(_("Error accessing possibly locked file %s") % os.fsdecode(fullpath),
                          log.WarningCode.cannot_stat, util.escape(fullpath))
             return None
 
         def dir_scanner(path):
-            u"""Generator of files to be included under from filesystems
+            """Generator of files to be included under from filesystems
 
             Yields (subpath, scan) where scan indicates that path is a
             directory and should be included *if* something inside is
             subsequently included (i.e. generated later)
 
             This generator applies the configured selection functions and
             so will not yield paths which are to be excluded.
 
             If --files-from has been specified, this will yield paths from
             that filelist only, subject to any selection functions.
 
             """
             # Only called by Iterate. Internal.
-            # todo: get around circular dependency issue by importing here
-            from duplicity import robust
+            from duplicity import robust  # TODO: avoid circ. dep. issue
 
             if self.files_from is None:
                 files = robust.listpath(path)
             elif path.uc_name in self.files_from:
                 files = self.files_from[path.uc_name]
             else:
                 return
 
             for filename in files:
                 new_path = robust.check_common_error(
                     error_handler, Path.append, (path, filename))
                 if new_path:
                     s = self.Select(new_path)
-                    if (new_path.type in [u"reg", u"dir"]
+                    if (new_path.type in ["reg", "dir"]
                         and not os.access(new_path.name, os.R_OK)) \
                             and (s == 1 or s == 2):
                         # Path is a file or folder that cannot be read, but
                         # should be included or scanned.
-                        log.Warn(_(u"Error accessing possibly locked file %s") %
+                        log.Warn(_("Error accessing possibly locked file %s") %
                                  new_path.uc_name,
                                  log.WarningCode.cannot_read,
                                  util.escape(new_path.name))
                         if diffdir.stats:
                             diffdir.stats.Errors += 1
                     elif s == 1:
                         # Should be included
-                        yield (new_path, False)
+                        yield new_path, False
                     elif s == 2 and new_path.isdir():
                         # Is a directory that should be scanned
-                        yield (new_path, True)
+                        yield new_path, True
 
         if not path.type:
             # base doesn't exist
-            log.Warn(_(u"Warning: base %s doesn't exist, continuing") %
+            log.Warn(_("Warning: base %s doesn't exist, continuing") %
                      path.uc_name)
             return
-        log.Debug(_(u"Selecting %s") % path.uc_name)
+        log.Debug(_("Selecting %s") % path.uc_name)
         yield path
         if not path.isdir():
             return
 
         dirs_to_scan = [dir_scanner(path)]
         dirs_deferred = []
         while dirs_to_scan:
@@ -196,34 +192,33 @@
                 continue
             if scan:
                 dirs_deferred.append(subpath)
                 dirs_to_scan.append(dir_scanner(subpath))
             else:
                 if dirs_deferred:
                     for delayed_path in dirs_deferred:
-                        log.Log(_(u"Selecting %s") % delayed_path.uc_name, 6)
+                        log.Log(_("Selecting %s") % delayed_path.uc_name, 6)
                         yield delayed_path
                     del dirs_deferred[:]
-                log.Debug(_(u"Selecting %s") % subpath.uc_name)
+                log.Debug(_("Selecting %s") % subpath.uc_name)
                 yield subpath
                 if subpath.isdir():
                     dirs_to_scan.append(dir_scanner(subpath))
 
     def Select(self, path):
-        u"""Run through the selection functions and return dominant val 0/1/2"""
+        """Run through the selection functions and return dominant val 0/1/2"""
         # Only used by diryield and tests. Internal.
-        log.Debug(u"Selection: examining path %s" % path.uc_name)
+        log.Debug(f"Selection: examining path {path.uc_name}")
         if not self.selection_functions:
-            log.Debug(u"Selection:     + no selection functions found. Including")
+            log.Debug("Selection:     + no selection functions found. Including")
             return 1
         scan_pending = False
         for sf in self.selection_functions:
             result = sf(path)
-            log.Debug(u"Selection:     result: %4s from function: %s" %
-                      (str(result), sf.name))
+            log.Debug(f"Selection:     result: {str(result):4} from function: {sf.name}")
             if result == 2:
                 # Selection function says that the path should be scanned for matching files, but keep going
                 # through the selection functions looking for a real match (0 or 1).
                 scan_pending = True
             elif result == 0 or result == 1:
                 # A real match found, no need to try other functions.
                 break
@@ -232,460 +227,454 @@
             # A selection function returned 2 and either no real match was
             # found or the highest-priority match was 0
             result = 2
         if result is None:
             result = 1
 
         if result == 0:
-            log.Debug(u"Selection:     - excluding file")
+            log.Debug("Selection:     - excluding file")
         elif result == 1:
-            log.Debug(u"Selection:     + including file")
+            log.Debug("Selection:     + including file")
         else:
             assert result == 2
-            log.Debug(u"Selection:     ? scanning directory for matches")
+            log.Debug("Selection:     ? scanning directory for matches")
 
         return result
 
     def ParseArgs(self, argtuples, filelists):
-        u"""Create selection functions based on list of tuples
+        """Create selection functions based on list of tuples
 
         The tuples are created when the initial commandline arguments
         are read.  They have the form (option string, additional
         argument) except for the filelist tuples, which should be
         (option-string, (additional argument, filelist_fp)).
 
         """
         # Sanity checks on --filter-* options for the benefit of users
-        if argtuples and argtuples[-1][0].startswith(u"--filter-"):
-            log.FatalError(_(u"""\
-The last file selection option is the filter option %s, which will have no
-effect as there are no subsequent file selection options. Exiting because
-this probably isn't what you meant.""") %
-                           (argtuples[-1][0],),
-                           log.ErrorCode.trailing_filter)
+        if argtuples and argtuples[-1][0].startswith("--filter-"):
+            log.FatalError(dedent(_(
+                """\
+                The last file selection option is the filter option %s, which will have no
+                effect as there are no subsequent file selection options. Exiting because
+                this probably isn't what you meant.""")) %
+                (argtuples[-1][0],),
+                log.ErrorCode.trailing_filter)
         f_opt = set(opt[0] for opt in argtuples if opt[0].startswith(u"--filter-"))
         f_def = (u"--filter-globbing", u"--filter-strictcase")
         if f_opt and all(opt in f_def for opt in f_opt):
-            log.FatalError(_(u"""\
-Only these filter mode options were specified:
-    %s
-Case sensitive globbing is the default behaviour and so this has no effect.
-Exiting because this probably isn't what you meant.""") %
-                           (u", ".join(f_opt),),
-                           log.ErrorCode.redundant_filter)
+            log.FatalError(dedent(_(
+                """\
+                Only these filter mode options were specified:
+                    %s
+                Case sensitive globbing is the default behaviour and so this has no effect.
+                Exiting because this probably isn't what you meant.""")) %
+                (u", ".join(f_opt),),
+                log.ErrorCode.redundant_filter)
 
-        # Called by commandline.py set_selection. External.
+        # Called by cli_main.py set_selection. External.
         filelists_index = 0
-        mode = u"globbing"
+        mode = "globbing"
         no_case = False
         try:
             for opt, arg in argtuples:
-                if opt == u"--exclude":
+                if opt == "--exclude":
                     self.add_selection_func(self.general_get_sf(arg, 0, mode, ignore_case=no_case))
-                elif opt == u"--exclude-if-present":
+                elif opt == "--exclude-if-present":
                     self.add_selection_func(self.present_get_sf(arg, 0), add_to_start=True)
-                elif opt == u"--exclude-device-files":
+                elif opt == "--exclude-device-files":
                     self.add_selection_func(self.devfiles_get_sf(), add_to_start=True)
-                elif opt == u"--exclude-filelist":
+                elif opt == "--exclude-filelist":
                     for sf in self.filelist_general_get_sfs(filelists[filelists_index], 0, arg, mode, no_case):
                         self.add_selection_func(sf)
                     filelists_index += 1
-                elif opt == u"--exclude-globbing-filelist":
-                    # --exclude-globbing-filelist is now deprecated, but if it
-                    # turns up then it needs to always work in globbing mode...
-                    for sf in self.filelist_general_get_sfs(filelists[filelists_index], 0, arg, u"globbing", no_case):
-                        self.add_selection_func(sf)
-                    filelists_index += 1
-                elif opt == u"--exclude-other-filesystems":
+                elif opt == "--exclude-other-filesystems":
                     self.add_selection_func(self.other_filesystems_get_sf(0))
-                elif opt == u"--exclude-regexp":
+                elif opt == "--exclude-regexp":
                     self.add_selection_func(self.regexp_get_sf(arg, 0, no_case))
-                elif opt == u"--exclude-older-than":
+                elif opt == "--exclude-older-than":
                     self.add_selection_func(self.exclude_older_get_sf(arg))
-                elif opt == u"--filter-strictcase":
+                elif opt == "--filter-strictcase":
                     no_case = False
-                elif opt == u"--filter-globbing":
-                    mode = u"globbing"
-                elif opt == u"--filter-ignorecase":
+                elif opt == "--filter-globbing":
+                    mode = "globbing"
+                elif opt == "--filter-ignorecase":
                     no_case = True
-                elif opt == u"--filter-literal":
-                    mode = u"literal"
-                elif opt == u"--filter-regexp":
-                    mode = u"regex"
-                elif opt == u"--files-from":
+                elif opt == "--filter-literal":
+                    mode = "literal"
+                elif opt == "--filter-regexp":
+                    mode = "regex"
+                elif opt == "--files-from":
                     self.parse_files_from(filelists[filelists_index], arg)
                     filelists_index += 1
-                elif opt == u"--include":
+                elif opt == "--include":
                     self.add_selection_func(self.general_get_sf(arg, 1, mode, no_case))
-                elif opt == u"--include-filelist":
+                elif opt == "--include-filelist":
                     for sf in self.filelist_general_get_sfs(filelists[filelists_index], 1, arg, mode, no_case):
                         self.add_selection_func(sf)
                     filelists_index += 1
-                elif opt == u"--include-globbing-filelist":
-                    # --include-globbing-filelist is now deprecated, but if it
-                    # turns up then it needs to always work in globbing mode...
-                    for sf in self.filelist_general_get_sfs(filelists[filelists_index], 1, arg, u"globbing", no_case):
-                        self.add_selection_func(sf)
-                    filelists_index += 1
-                elif opt == u"--include-regexp":
+                elif opt == "--include-regexp":
                     self.add_selection_func(self.regexp_get_sf(arg, 1, no_case))
                 else:
-                    assert 0, u"Bad selection option %s" % opt
+                    assert 0, f"Bad selection option {opt}"
         except GlobbingError as e:
             self.parse_catch_error(e)
         assert filelists_index == len(filelists)
         self.parse_last_excludes()
 
     def parse_catch_error(self, exc):
-        u"""Deal with selection error exc"""
+        """Deal with selection error exc"""
         # Internal, used by ParseArgs.
         if isinstance(exc, FilePrefixError):
-            log.FatalError(_(u"""\
-Fatal Error: The file specification
-    %s
-cannot match any files in the base directory
-    %s
-Useful file specifications begin with the base directory or some
-pattern (such as '**') which matches the base directory.""") %
-                           (exc, self.prefix), log.ErrorCode.file_prefix_error)
+            log.FatalError(dedent(_(
+                """\
+                Fatal Error: The file specification
+                    %s
+                cannot match any files in the base directory
+                    %s
+                Useful file specifications begin with the base directory or some
+                pattern (such as '**') which matches the base directory.""")) %
+                (exc, self.prefix), log.ErrorCode.file_prefix_error)
         elif isinstance(exc, GlobbingError):
-            log.FatalError(_(u"Fatal Error while processing expression\n"
-                             u"%s") % exc, log.ErrorCode.globbing_error)
+            log.FatalError(_("Fatal Error while processing expression\n"
+                             "%s") % exc, log.ErrorCode.globbing_error)
         else:
             raise  # pylint: disable=misplaced-bare-raise
 
     def parse_files_from(self, filelist_fp, list_name):
-        u"""Loads an explicit list of files to backup from a filelist, building
+        """Loads an explicit list of files to backup from a filelist, building
         a dictionary of directories and their contents which can be used later
         to emulate a filesystem walk over the listed files only.
 
         Each specified path is unwound to identify the parents folder(s) as these
         are implicitly to be included.
 
         Paths read are not to be stripped, checked for comments, etc. Every
         character on each line is significant and treated as part of the path.
         """
         # Internal. Used by ParseArgs.
-        log.Notice(_(u"Reading files to backup from list %s") % list_name)
-        separator = config.null_separator and u"\0" or u"\n"
+        log.Notice(_("Reading files to backup from list %s") % list_name)
+        separator = config.null_separator and "\0" or "\n"
         filelist = {}
         absolute_path = None
         for line in filelist_fp.read().split(separator):
-            if not line:                # skip blanks
+            if not line:  # skip blanks
                 continue
-            if line.startswith(u"/"):   # no absolute paths thanks
+            if line.startswith("/"):  # no absolute paths thanks
                 absolute_path = line
                 break
             while line:
                 dirname, basename = os.path.split(line)
                 path = os.path.join(self.rootpath.uc_name, dirname).rstrip(os.path.sep)
                 if path not in filelist:
                     filelist[path] = set()
                 if isinstance(basename, str):
-                    filelist[path].add(util.fsencode(basename))
+                    filelist[path].add(os.fsencode(basename))
                 else:
                     filelist[path].add(basename)
                 line = dirname
 
         if absolute_path:
-            log.FatalError(_(u"""\
-Files-from list contains the absolute path:
-    %s
-All paths specified in a files-from list must be given relative to the backup
-source path.""") %
-                           (absolute_path,),
-                           log.ErrorCode.absolute_files_from)
+            log.FatalError(dedent(_(
+                """\
+                Files-from list contains the absolute path:
+                    %s
+                All paths specified in a files-from list must be given relative to the backup
+                source path.""")) %
+                (absolute_path,),
+                log.ErrorCode.absolute_files_from)
 
         if not filelist:
-            log.FatalError(_(u"""\
-Files-from list specified which contains no files, the backup will be empty as
-a result. Exiting as this probably isn't what you meant,"""), log.ErrorCode.empty_files_from)
+            log.FatalError(dedent(_(
+                """\
+                Files-from list specified which contains no files, the backup will be empty as
+                a result. Exiting as this probably isn't what you meant,""")),
+                log.ErrorCode.empty_files_from)
 
         self.files_from = {d: sorted(f) for d, f in filelist.items()}
 
     def parse_last_excludes(self):
-        u"""Exit with error if last selection function isn't an exclude"""
+        """Exit with error if last selection function isn't an exclude"""
         # Internal. Used by ParseArgs.
         if self.selection_functions and not self.selection_functions[-1].exclude:
-            log.FatalError(_(u"""\
-Last selection expression:
-    %s
-only specifies that files be included.  Because the default is to
-include all files, the expression is redundant.  Exiting because this
-probably isn't what you meant.""") %
-                           (self.selection_functions[-1].name,),
-                           log.ErrorCode.redundant_inclusion)
+            log.FatalError(dedent(_(
+                """\
+                Last selection expression:
+                    %s
+                only specifies that files be included.  Because the default is to
+                include all files, the expression is redundant.  Exiting because this
+                probably isn't what you meant.""")) %
+                (self.selection_functions[-1].name,),
+                log.ErrorCode.redundant_inclusion)
 
     def add_selection_func(self, sel_func, add_to_start=None):
-        u"""Add another selection function at the end or beginning"""
+        """Add another selection function at the end or beginning"""
         # Internal. Used by ParseArgs.
         if add_to_start:
             self.selection_functions.insert(0, sel_func)
         else:
             self.selection_functions.append(sel_func)
 
     def filelist_sanitise_line(self, line, include_default):
-        u"""
+        """
         Sanitises lines of both normal and globbing filelists, returning
         (line, include) and line=None if blank/comment
 
         The aim is to parse filelists in a consistent way, prior to the
         interpretation of globbing statements. The function removes
         whitespace, comment lines and processes modifiers (leading +/-)
         and quotes.
         """
         # Internal. Used by filelist_general_get_sfs
 
         line = line.strip()
         if not line:  # skip blanks
             return None, include_default
-        if line.startswith(u"#"):  # skip full-line comments
+        if line.startswith("#"):  # skip full-line comments
             return None, include_default
 
         include = include_default
-        if line.startswith(u"+ "):
+        if line.startswith("+ "):
             # Check for "+ " or "- " syntax
             include = 1
             line = line[2:]
-        elif line.startswith(u"- "):
+        elif line.startswith("- "):
             include = 0
             line = line[2:]
 
-        if (line.startswith(u"'") and line.endswith(u"'")) or (line.startswith(u'"') and line.endswith(u'"')):
+        if (line.startswith("'") and line.endswith("'")) or (line.startswith('"') and line.endswith('"')):
             line = line[1:-1]
 
         return line, include
 
-    def filelist_general_get_sfs(self, filelist_fp, inc_default, list_name, mode=u"globbing", ignore_case=False):
-        u"""Return list of selection functions by reading fileobj
+    def filelist_general_get_sfs(self, filelist_fp, inc_default, list_name, mode="globbing", ignore_case=False):
+        """Return list of selection functions by reading fileobj
 
         filelist_fp should be an open file object
         inc_default is true if this is an include list
         list_name is just the name of the list, used for logging
         mode indicates whether to glob, regex, or not
 
         """
         # Internal. Used by ParseArgs.
-        log.Notice(_(u"Reading %s filelist %s") % (mode, list_name))
-        separator = config.null_separator and u"\0" or u"\n"
+        log.Notice(_("Reading %s filelist %s") % (mode, list_name))
+        separator = config.null_separator and "\0" or "\n"
         try:
             filelist_fp.seek(0)
-        except:
+        except Exception as e:
             pass
         for line in filelist_fp.read().split(separator):
             line, include = self.filelist_sanitise_line(line, inc_default)
             if not line:
                 # Skip blanks and comment lines
                 continue
             yield self.general_get_sf(line, include, mode, ignore_case)
 
     def other_filesystems_get_sf(self, include):
-        u"""Return selection function matching files on other filesystems"""
+        """Return selection function matching files on other filesystems"""
         # Internal. Used by ParseArgs and unit tests.
         assert include == 0 or include == 1
         root_devloc = self.rootpath.getdevloc()
 
         def sel_func(path):
             if path.exists() and path.getdevloc() != root_devloc:
                 return include
             else:
                 return None
 
         sel_func.exclude = not include
-        sel_func.name = u"Match other filesystems"
+        sel_func.name = "Match other filesystems"
         return sel_func
 
     def regexp_get_sf(self, regexp_string, include, ignore_case=False):
-        u"""Return selection function given by regexp_string"""
+        """Return selection function given by regexp_string"""
         # Internal. Used by ParseArgs and unit tests.
         assert include == 0 or include == 1
 
         flags = 0
         if ignore_case:
             flags = re.IGNORECASE
 
         try:
             regexp = re.compile(regexp_string, flags)
         except Exception:
-            log.Warn(_(u"Error compiling regular expression %s") % regexp_string)
+            log.Warn(_("Error compiling regular expression %s") % regexp_string)
             raise
 
         def sel_func(path):
             if regexp.search(path.uc_name):
                 return include
             else:
                 return None
 
         sel_func.exclude = not include
-        sel_func.name = u"regular expression %s %scase: %s" % \
-            (include and u"include" or u"exclude", ignore_case and u"no-" or u"", regexp_string)
+        sel_func.name = f"regular expression {include and 'include' or 'exclude'} " \
+                        f"{ignore_case and 'no-' or ''}case: {regexp_string}"
         return sel_func
 
     def devfiles_get_sf(self):
-        u"""Return a selection function to exclude all dev files"""
+        """Return a selection function to exclude all dev files"""
         # Internal. Used by ParseArgs.
         def sel_func(path):
             if path.isdev():
                 return 0
             else:
                 return None
 
         sel_func.exclude = 1
-        sel_func.name = u"Exclude device files"
+        sel_func.name = "Exclude device files"
         return sel_func
 
-    def general_get_sf(self, pattern_str, include, mode=u"globbing", ignore_case=False):
-        u"""Return selection function given by a pattern string
+    def general_get_sf(self, pattern_str, include, mode="globbing", ignore_case=False):
+        """Return selection function given by a pattern string
 
         The selection patterns are interpretted in accordance with the mode
         argument, "globbing", "literal", or "regex".
 
         The 'ignorecase:' prefix is a legacy feature which historically lived on
         the globbing code path and was only ever documented as working for globs.
         """
 
         # Internal. Used by ParseArgs, filelist_general_get_sfs and unit tests.
         assert include == 0 or include == 1
         assert isinstance(pattern_str, str)
 
         # legacy prefix applies *only* in globbing mode
-        if mode == u"globbing" and pattern_str.lower().startswith(u"ignorecase:"):
-            pattern_str = pattern_str[len(u"ignorecase:"):]
-            pattern_str = util.casefold_compat(util.fsdecode(pattern_str))
+        if mode == "globbing" and pattern_str.lower().startswith("ignorecase:"):
+            pattern_str = pattern_str[len("ignorecase:"):]
+            pattern_str = os.fsdecode(pattern_str).casefold()
             ignore_case = True
 
-        if mode == u"globbing":
+        if mode == "globbing":
             return self.glob_get_sf(pattern_str, include, ignore_case)
-        elif mode == u"literal":
+        elif mode == "literal":
             return self.literal_get_sf(pattern_str, include, ignore_case)
-        elif mode == u"regex":
+        elif mode == "regex":
             return self.regexp_get_sf(pattern_str, include, ignore_case)
         else:
-            assert 0, u"Bad selection mode %s" % mode
+            assert 0, f"Bad selection mode {mode}"
 
     def present_get_sf(self, filename, include):
-        u"""Return selection function given by existence of a file in a directory"""
+        """Return selection function given by existence of a file in a directory"""
         # Internal. Used by ParseArgs.
         assert include == 0 or include == 1
 
-        # todo: get around circular dependency issue by importing here
-        from duplicity.robust import check_common_error
+        from duplicity.robust import check_common_error  # TODO: avoid circ. dep. issue
 
         def exclude_sel_func(path):
             # do not follow symbolic links when checking for file existence!
             if path.isdir():
                 def error_handler(_exc, _filename):
                     # Path is not read accessible
-                    # ToDo: Ideally this error would only show if the folder
+                    # TODO: Ideally this error would only show if the folder
                     # was ultimately included by the full set of selection
                     # functions. Currently this will give an error for any
                     # locked directory within the folder being backed up.
                     log.Warn(_(
-                        u"Error accessing possibly locked file %s") % path.uc_name,
+                        "Error accessing possibly locked file %s") % path.uc_name,
                         log.WarningCode.cannot_read, util.escape(path.uc_name))
                     if diffdir.stats:
                         diffdir.stats.Errors += 1
                     return False
+
                 if check_common_error(error_handler, path.contains, [filename]):
                     return 0
                 else:
                     return None
 
         if include == 0:
             sel_func = exclude_sel_func
         else:
-            log.FatalError(u"--include-if-present not implemented (would it make sense?).",
+            log.FatalError("--include-if-present not implemented (would it make sense?).",
                            log.ErrorCode.not_implemented)
 
         sel_func.exclude = not include
-        sel_func.name = u"Command-line %s filename: %s" % \
-                        (include and u"include-if-present" or u"exclude-if-present", filename)
+        sel_func.name = f"Command-line {include and 'include-if-present' or 'exclude-if-present'} filename: {filename}"
         return sel_func
 
     def glob_get_sf(self, glob_str, include, ignore_case=False):
-        u"""Return selection function based on glob_str"""
+        """Return selection function based on glob_str"""
         assert isinstance(glob_str, str), \
-            u"The glob string " + glob_str.decode(sys.getfilesystemencoding(), u"ignore") + u" is not unicode"
+            f"The glob string {glob_str.decode(sys.getfilesystemencoding(), 'ignore')} is not unicode"
 
         # Check to make sure prefix is ok, i.e. the glob string is within
         # the root folder being backed up
         if not select_fn_from_glob(glob_str, 1, ignore_case)(self.rootpath):
             # file_prefix_selection == 1 (include) or 2 (scan)
             raise FilePrefixError(glob_str)
 
-        if glob_str == u"**":
+        if glob_str == "**":
             sel_func = lambda path: include
         else:
             sel_func = select_fn_from_glob(glob_str, include, ignore_case)
 
         sel_func.exclude = not include
-        sel_func.name = u"shell glob %s %scase: %s" % \
-                        (include and u"include" or u"exclude", ignore_case and u"no-" or u"", glob_str)
+        sel_func.name = f"shell glob {include and 'include' or 'exclude'} {ignore_case and 'no-' or ''}case: {glob_str}"
 
         return sel_func
 
     def literal_get_sf(self, lit_str, include, ignore_case=False):
-        u"""Return a selection function that matches a literal string while
+        """Return a selection function that matches a literal string while
         still including the contents of any folders which are matched
         """
 
         # Check to make sure prefix is ok, see also glob_get_sf()
         if not self.select_fn_from_literal(lit_str, 1, ignore_case)(self.rootpath):
             raise FilePrefixError(lit_str)
 
         sel_func = self.select_fn_from_literal(lit_str, include, ignore_case)
         sel_func.exclude = not include
-        sel_func.name = u"literal string %s %scase: %s" % \
-                        (include and u"include" or u"exclude", ignore_case and u"no-" or u"", lit_str)
+        sel_func.name = f"literal string {include and 'include' or 'exclude'} " \
+                        f"{ignore_case and 'no-' or ''}case: {lit_str}"
         return sel_func
 
     def exclude_older_get_sf(self, date):
-        u"""Return selection function based on files older than modification date """
+        """Return selection function based on files older than modification date """
+
         # Internal. Used by ParseArgs.
 
         def sel_func(path):
             if not path.isreg():
                 return None
             try:
                 if os.path.getmtime(path.name) < date:
                     return 0
             except OSError as e:
                 pass  # this is probably only on a race condition of file being deleted
             return None
 
         sel_func.exclude = True
-        sel_func.name = u"Select older than %s" % (date,)
+        sel_func.name = f"Select older than {date}"
         return sel_func
 
     def select_fn_from_literal(self, lit_str, include, ignore_case=False):
-        u"""Return a function test_fn(path) which test where a path matches a
+        """Return a function test_fn(path) which test where a path matches a
         literal string. See also select_fn_from_blog() in globmatch.py
 
         This function is separated from literal_get_sf() so that it can be used
         to test the prefix without creating a loop.
 
-        TODO: this doesn't need to be part of the Select class type, but not
-        sure where else to put it?
         """
-        if lit_str != u"/" and lit_str[-1] == u"/":
+        # TODO: this doesn't need to be part of the Select class type, but not
+        #       sure where else to put it?
+        if lit_str != "/" and lit_str[-1] == "/":
             lit_str = lit_str[:-1]
 
         if ignore_case:
-            lit_str = util.casefold_compat(util.fsdecode(lit_str))
+            lit_str = os.fsdecode(lit_str).casefold()
 
         def test_fn(path):
-            # FIXME: caller to do this once, rather than for every path?
+            # TODO: caller to do this once, rather than for every path?
             if ignore_case:
-                uc_name = util.casefold_compat(util.fsdecode(path.uc_name))
+                uc_name = os.fsdecode(path.uc_name).casefold()
             else:
                 uc_name = path.uc_name
 
             if uc_name == lit_str:
                 return include
-            elif uc_name.startswith(lit_str) and uc_name[len(lit_str)] == u"/":
+            elif uc_name.startswith(lit_str) and uc_name[len(lit_str)] == "/":
                 return include
-            elif lit_str.startswith(uc_name) and lit_str[len(uc_name)] == u"/" and include == 1:
+            elif lit_str.startswith(uc_name) and lit_str[len(uc_name)] == "/" and include == 1:
                 return 2
             else:
                 return None
 
         return test_fn
```

### Comparing `duplicity-1.2.3.dev43/duplicity/log.py` & `duplicity-2.0.0rc0/duplicity/log.py`

 * *Files 12% similar despite different names*

```diff
@@ -17,19 +17,16 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-u"""Log various messages depending on verbosity level"""
-from __future__ import division
+"""Log various messages depending on verbosity level"""
 
-from builtins import str
-from builtins import object
 import datetime
 import logging
 import os
 import sys
 
 MIN = 0
 ERROR = 0
@@ -40,75 +37,75 @@
 MAX = 9
 
 _logger = None
 _log_timestamp = False
 
 
 def DupToLoggerLevel(verb):
-    u"""Convert duplicity level to the logging module's system, where higher is
+    """Convert duplicity level to the logging module's system, where higher is
         more severe"""
     return MAX - verb + 1
 
 
 def LoggerToDupLevel(verb):
-    u"""Convert logging module level to duplicity's system, where lower is
+    """Convert logging module level to duplicity's system, where lower is
         more severe"""
     return DupToLoggerLevel(verb)
 
 
 def LevelName(level):
     if level >= 9:
-        return u"DEBUG"
+        return "DEBUG"
     elif level >= 5:
-        return u"INFO"
+        return "INFO"
     elif level >= 3:
-        return u"NOTICE"
+        return "NOTICE"
     elif level >= 1:
-        return u"WARNING"
+        return "WARNING"
     else:
-        return u"ERROR"
+        return "ERROR"
 
 
 def Log(s, verb_level, code=1, extra=None, force_print=False, transfer_progress=False):
-    u"""Write s to stderr if verbosity level low enough"""
+    """Write s to stderr if verbosity level low enough"""
     global _logger
     if extra:
-        controlLine = u'%d %s' % (code, extra)
+        controlLine = f'{int(code)} {extra}'
     else:
-        controlLine = u'%d' % (code)
+        controlLine = f'{int(code)}'
     if not s:
-        s = u''  # If None is passed, standard logging would render it as 'None'
+        s = ''  # If None is passed, standard logging would render it as 'None'
 
     if force_print:
         initial_level = _logger.getEffectiveLevel()
         _logger.setLevel(DupToLoggerLevel(MAX))
 
     # If all the backends kindly gave us unicode, we could enable this next
     # assert line.  As it is, we'll attempt to convert s to unicode if we
     # are handed bytes.  One day we should update the backends.
     # assert isinstance(s, unicode)
     if not isinstance(s, str):
-        s = s.decode(u"utf8", u"replace")
+        s = s.decode("utf8", "replace")
 
     _logger.log(DupToLoggerLevel(verb_level), s,
-                extra={u'levelName': LevelName(verb_level),
-                       u'controlLine': controlLine,
-                       u'transferProgress': transfer_progress})
+                extra={'levelName': LevelName(verb_level),
+                       'controlLine': controlLine,
+                       'transferProgress': transfer_progress})
 
     if force_print:
         _logger.setLevel(initial_level)
 
 
 def Debug(s):
-    u"""Shortcut used for debug message (verbosity 9)."""
+    """Shortcut used for debug message (verbosity 9)."""
     Log(s, DEBUG)
 
 
 class InfoCode(object):
-    u"""Enumeration class to hold info code values.
+    """Enumeration class to hold info code values.
         These values should never change, as frontends rely upon them.
         Don't use 0 or negative numbers."""
     generic = 1
     progress = 2
     collection_status = 3
     diff_file_new = 4
     diff_file_changed = 5
@@ -122,130 +119,125 @@
     synchronous_upload_done = 13
     asynchronous_upload_done = 14
     skipping_socket = 15
     upload_progress = 16
 
 
 def Info(s, code=InfoCode.generic, extra=None):
-    u"""Shortcut used for info messages (verbosity 5)."""
+    """Shortcut used for info messages (verbosity 5)."""
     Log(s, INFO, code, extra)
 
 
 def Progress(s, current, total=None):
-    u"""Shortcut used for progress messages (verbosity 5)."""
+    """Shortcut used for progress messages (verbosity 5)."""
     if total:
-        controlLine = u'%d %d' % (current, total)
+        controlLine = f'{int(current)} {int(total)}'
     else:
-        controlLine = u'%d' % current
+        controlLine = f'{int(current)}'
     Log(s, INFO, InfoCode.progress, controlLine)
 
 
 def _ElapsedSecs2Str(secs):
     tdelta = datetime.timedelta(seconds=secs)
     hours, rem = divmod(tdelta.seconds, 3600)
     minutes, seconds = divmod(rem, 60)
-    fmt = u""
+    fmt = ""
     if tdelta.days > 0:
-        fmt = u"%dd," % (tdelta.days)
-    fmt = u"%s%02d:%02d:%02d" % (fmt, hours, minutes, seconds)
+        fmt = f"{int(tdelta.days)}d,"
+    fmt = f"{fmt}{int(hours):02}:{int(minutes):02}:{int(seconds):02}"
     return fmt
 
 
 def _RemainingSecs2Str(secs):
     tdelta = datetime.timedelta(seconds=secs)
     hours, rem = divmod(tdelta.seconds, 3600)
     minutes, seconds = divmod(rem, 60)
-    fmt = u""
+    fmt = ""
     if tdelta.days > 0:
-        fmt = u"%dd" % (tdelta.days)
+        fmt = f"{int(tdelta.days)}d"
         if hours > 0:
-            fmt = u"%s %dh" % (fmt, hours)
+            fmt = f"{fmt} {int(hours)}h"
         if minutes > 0:
-            fmt = u"%s %dmin" % (fmt, minutes)
+            fmt = f"{fmt} {int(minutes)}min"
     elif hours > 0:
-        fmt = u"%dh" % hours
+        fmt = f"{int(hours)}h"
         if minutes > 0:
-            fmt = u"%s %dmin" % (fmt, minutes)
+            fmt = f"{fmt} {int(minutes)}min"
     elif minutes > 5:
-        fmt = u"%dmin" % minutes
+        fmt = f"{int(minutes)}min"
     elif minutes > 0:
-        fmt = u"%dmin" % minutes
+        fmt = f"{int(minutes)}min"
         if seconds >= 30:
-            fmt = u"%s 30sec" % fmt
+            fmt = f"{fmt} 30sec"
     elif seconds > 45:
-        fmt = u"< 1min"
+        fmt = "< 1min"
     elif seconds > 30:
-        fmt = u"< 45sec"
+        fmt = "< 45sec"
     elif seconds > 15:
-        fmt = u"< 30sec"
+        fmt = "< 30sec"
     else:
-        fmt = u"%dsec" % seconds
+        fmt = f"{int(seconds)}sec"
     return fmt
 
 
 def TransferProgress(progress, eta, changed_bytes, elapsed, speed, stalled):
-    u"""Shortcut used for upload progress messages (verbosity 5)."""
+    """Shortcut used for upload progress messages (verbosity 5)."""
     dots = int(0.4 * progress)  # int(40.0 * progress / 100.0) -- for 40 chars
     data_amount = float(changed_bytes) / 1024.0
-    data_scale = u"KB"
+    data_scale = "KB"
     if data_amount > 1000.0:
         data_amount /= 1024.0
-        data_scale = u"MB"
+        data_scale = "MB"
     if data_amount > 1000.0:
         data_amount /= 1024.0
-        data_scale = u"GB"
+        data_scale = "GB"
     if stalled:
-        eta_str = u"Stalled!"
+        eta_str = "Stalled!"
         speed_amount = 0
-        speed_scale = u"B"
+        speed_scale = "B"
     else:
         eta_str = _RemainingSecs2Str(eta)
         speed_amount = float(speed) / 1024.0
-        speed_scale = u"KB"
+        speed_scale = "KB"
         if speed_amount > 1000.0:
             speed_amount /= 1024.0
-            speed_scale = u"MB"
+            speed_scale = "MB"
         if speed_amount > 1000.0:
             speed_amount /= 1024.0
-            speed_scale = u"GB"
-    s = u"%.1f%s %s [%.1f%s/s] [%s>%s] %d%% ETA %s" % (data_amount, data_scale,
-                                                       _ElapsedSecs2Str(elapsed),
-                                                       speed_amount, speed_scale,
-                                                       u'=' * dots, u' ' * (40 - dots),
-                                                       progress,
-                                                       eta_str
-                                                       )
+            speed_scale = "GB"
+    s = f"{data_amount:.1f}{data_scale} {_ElapsedSecs2Str(elapsed)} [{speed_amount:.1f}{speed_scale}/s] " \
+        f"[{'=' * dots}>{' ' * (40 - dots)}] {int(progress)}% ETA {eta_str}"
 
-    controlLine = u"%d %d %d %d %d %d" % (changed_bytes, elapsed, progress, eta, speed, stalled)
+    controlLine = f"{int(changed_bytes)} {int(elapsed)} {int(progress)} {int(eta)} {int(speed)} {int(stalled)}"
     Log(s, NOTICE, InfoCode.upload_progress, controlLine, transfer_progress=True)
 
 
 def PrintCollectionStatus(col_stats, force_print=False):
-    u"""Prints a collection status to the log"""
+    """Prints a collection status to the log"""
     Log(str(col_stats), 8, InfoCode.collection_status,
-        u'\n' + u'\n'.join(col_stats.to_log_info()), force_print)
+        '\n' + '\n'.join(col_stats.to_log_info()), force_print)
 
 
 def PrintCollectionFileChangedStatus(col_stats, filepath, force_print=False):
-    u"""Prints a collection status to the log"""
+    """Prints a collection status to the log"""
     Log(str(col_stats.get_file_changed_record(filepath)), 8, InfoCode.collection_status, None, force_print)
 
 
 def PrintCollectionChangesInSet(col_stats, set_index, force_print=False):
-    u"""Prints changes in the specified set to the log"""
+    """Prints changes in the specified set to the log"""
     Log(str(col_stats.get_all_file_changed_records(set_index)), 8, InfoCode.collection_status, None, force_print)
 
 
 def Notice(s):
-    u"""Shortcut used for notice messages (verbosity 3, the default)."""
+    """Shortcut used for notice messages (verbosity 3, the default)."""
     Log(s, NOTICE)
 
 
 class WarningCode(object):
-    u"""Enumeration class to hold warning code values.
+    """Enumeration class to hold warning code values.
         These values should never change, as frontends rely upon them.
         Don't use 0 or negative numbers."""
     generic = 1
     orphaned_sig = 2
     unnecessary_sig = 3
     unmatched_sig = 4
     incomplete_backup = 5
@@ -256,64 +248,64 @@
     cannot_read = 10
     no_sig_for_time = 11
     cannot_process = 12
     process_skipped = 13
 
 
 def Warn(s, code=WarningCode.generic, extra=None):
-    u"""Shortcut used for warning messages (verbosity 2)"""
+    """Shortcut used for warning messages (verbosity 2)"""
     Log(s, WARNING, code, extra)
 
 
 class ErrorCode(object):
-    u"""Enumeration class to hold error code values.
+    """Enumeration class to hold error code values.
         These values should never change, as frontends rely upon them.
         Don't use 0 or negative numbers.  This code is returned by duplicity
         to indicate which error occurred via both exit code and log."""
     generic = 1  # Don't use if possible, please create a new code and use it
     command_line = 2
     hostname_mismatch = 3
     no_manifests = 4
     mismatched_manifests = 5
     unreadable_manifests = 6
     cant_open_filelist = 7
     bad_url = 8
     bad_archive_dir = 9
-    bad_sign_key = 10
-    restore_dir_exists = 11
+    deprecated_option = 10
+    restore_path_exists = 11
     verify_dir_doesnt_exist = 12
     backup_dir_doesnt_exist = 13
     file_prefix_error = 14
     globbing_error = 15
     redundant_inclusion = 16
     inc_without_sigs = 17
     no_sigs = 18
-    restore_dir_not_found = 19
+    restore_path_not_found = 19
     no_restore_files = 20
     mismatched_hash = 21
     unsigned_volume = 22
     user_error = 23
-    boto_old_style = 24
-    boto_lib_too_old = 25
-    boto_calling_format = 26
+    # boto_old_style = 24 # deprecated
+    # boto_lib_too_old = 25 # deprecated
+    # boto_calling_format = 26 # deprecated
     ftp_ncftp_missing = 27
     ftp_ncftp_too_old = 28
     # ftp_ncftp_v320 = 29 # moved to warning
     exception = 30
     gpg_failed = 31
-    s3_bucket_not_style = 32
+    # s3_bucket_not_style = 32 # deprecated
     not_implemented = 33
     get_freespace_failed = 34
     not_enough_freespace = 35
     get_ulimit_failed = 36
     maxopen_too_low = 37
     connection_failed = 38
     restart_file_not_found = 39
     gio_not_available = 40
-    source_dir_mismatch = 42  # 41 is reserved for par2
+    source_path_mismatch = 42  # 41 is reserved for par2
     ftps_lftp_missing = 43
     volume_wrong_size = 44
     enryption_mismatch = 45
     pythonoptimize_set = 46
 
     dpbx_nologin = 47
 
@@ -330,57 +322,64 @@
 
     # file selection filter mode errors
     redundant_filter = 70
     trailing_filter = 71
     absolute_files_from = 72
     empty_files_from = 73
 
+    # gpg key errors
+    bad_sign_key = 80
+    bad_encrypt_key = 81
+    bad_hidden_encrypt_key = 82
+
     # Reserve 126 because it is used as an error code for pkexec
     # Reserve 127 because it is used as an error code for pkexec
     # Reserve 255 because it is used as an error code for gksu
 
 
 def Error(s, code=ErrorCode.generic, extra=None):
-    u"""Write error message"""
+    """Write error message"""
     Log(s, ERROR, code, extra)
 
 
 def FatalError(s, code=ErrorCode.generic, extra=None):
-    u"""Write fatal error message and exit"""
+    """Write fatal error message and exit"""
     Log(s, ERROR, code, extra)
     shutdown()
     sys.exit(code)
 
 
 class OutFilter(logging.Filter):
-    u"""Filter that only allows warning or less important messages"""
+    """Filter that only allows warning or less important messages"""
+
     def filter(self, record):
         return record.msg and record.levelno <= DupToLoggerLevel(WARNING)
 
 
 class ErrFilter(logging.Filter):
-    u"""Filter that only allows messages more important than warnings"""
+    """Filter that only allows messages more important than warnings"""
+
     def filter(self, record):
         return record.msg and record.levelno > DupToLoggerLevel(WARNING)
 
 
 def setup():
-    u"""Initialize logging"""
+    """Initialize logging"""
     global _logger
     global _log_timestamp
     if _logger:
         return
 
     # have to get log options from commandline before initializing logger
     # hackish? yes, but I see no other way other than external config
-    if u'--log-timestamp' in sys.argv[1:]:
+    if '--log-timestamp' in sys.argv[1:]:
         _log_timestamp = True
 
     # OK, now we can start setup
-    _logger = logging.getLogger(u"duplicity")
+    _logger = logging.getLogger("duplicity")
 
     # Default verbosity allows notices and above
     setverbosity(NOTICE)
 
     # stdout and stderr are for different logging levels
     outHandler = logging.StreamHandler(sys.stdout)
     if _log_timestamp:
@@ -396,109 +395,112 @@
     else:
         errHandler.setFormatter(PrettyProgressFormatter())
     errHandler.addFilter(ErrFilter())
     _logger.addHandler(errHandler)
 
 
 class PrettyProgressFormatter(logging.Formatter):
-    u"""Formatter that overwrites previous progress lines on ANSI terminals"""
+    """Formatter that overwrites previous progress lines on ANSI terminals"""
     last_record_was_progress = False
 
     def __init__(self):
         # 'message' will be appended by format()
         # Note that we use our own, custom-created 'levelName' instead of the
         # standard 'levelname'.  This is because the standard 'levelname' can
         # be adjusted by any library anywhere in our stack without us knowing.
         # But we control 'levelName'.
-        logging.Formatter.__init__(self, u"%(message)s")
+        logging.Formatter.__init__(self, "%(message)s")
 
     def format(self, record):
         s = logging.Formatter.format(self, record)
 
         # So we don't overwrite actual log lines
         if self.last_record_was_progress and record.transferProgress:
             # Go up one line, then erase it
-            s = u"\033[F\033[2K" + s
+            s = "\033[F\033[2K" + s
 
         self.last_record_was_progress = record.transferProgress
 
         return s
 
 
 class DetailFormatter(logging.Formatter):
-    u"""Formatter that creates messages in a syntax somewhat like syslog."""
+    """Formatter that creates messages in a syntax somewhat like syslog."""
+
     def __init__(self):
         # 'message' will be appended by format()
         # Note that we use our own, custom-created 'levelName' instead of the
         # standard 'levelname'.  This is because the standard 'levelname' can
         # be adjusted by any library anywhere in our stack without us knowing.
         # But we control 'levelName'.
-        logging.Formatter.__init__(self, u"%(asctime)s %(levelName)s %(message)s")
+        logging.Formatter.__init__(self, "%(asctime)s %(levelName)s %(message)s")
 
     def format(self, record):
         s = logging.Formatter.format(self, record)
         return s
 
 
 class MachineFormatter(logging.Formatter):
-    u"""Formatter that creates messages in a syntax easily consumable by other processes."""
+    """Formatter that creates messages in a syntax easily consumable by other processes."""
+
     def __init__(self):
         # 'message' will be appended by format()
         # Note that we use our own, custom-created 'levelName' instead of the
         # standard 'levelname'.  This is because the standard 'levelname' can
         # be adjusted by any library anywhere in our stack without us knowing.
         # But we control 'levelName'.
-        logging.Formatter.__init__(self, u"%(levelName)s %(controlLine)s")
+        logging.Formatter.__init__(self, "%(levelName)s %(controlLine)s")
 
     def format(self, record):
         s = logging.Formatter.format(self, record)
 
         # Add user-text hint of 'message' back in, with each line prefixed by a
         # dot, so consumers know it's not part of 'controlLine'
         if record.message:
-            s += (u'\n' + record.message).replace(u'\n', u'\n. ')
+            s += ('\n' + record.message).replace('\n', '\n. ')
 
         # Add a newline so consumers know the message is over.
-        return s + u'\n'
+        return s + '\n'
 
 
 class MachineFilter(logging.Filter):
-    u"""Filter that only allows levels that are consumable by other processes."""
+    """Filter that only allows levels that are consumable by other processes."""
+
     def filter(self, record):
         # We only want to allow records that have our custom level names
-        return hasattr(record, u'levelName')
+        return hasattr(record, 'levelName')
 
 
 def add_fd(fd):
-    u"""Add stream to which to write machine-readable logging"""
+    """Add stream to which to write machine-readable logging"""
     global _logger
-    handler = logging.StreamHandler(os.fdopen(fd, u'w'))
+    handler = logging.StreamHandler(os.fdopen(fd, 'w'))
     handler.setFormatter(MachineFormatter())
     handler.addFilter(MachineFilter())
     _logger.addHandler(handler)
 
 
 def add_file(filename):
-    u"""Add file to which to write machine-readable logging"""
+    """Add file to which to write machine-readable logging"""
     global _logger
-    handler = logging.FileHandler(filename, encoding=u'utf8')
+    handler = logging.FileHandler(filename, encoding='utf8')
     handler.setFormatter(MachineFormatter())
     handler.addFilter(MachineFilter())
     _logger.addHandler(handler)
 
 
 def setverbosity(verb):
-    u"""Set the verbosity level"""
+    """Set the verbosity level"""
     global _logger
     _logger.setLevel(DupToLoggerLevel(verb))
 
 
 def getverbosity():
-    u"""Get the verbosity level"""
+    """Get the verbosity level"""
     global _logger
     return LoggerToDupLevel(_logger.getEffectiveLevel())
 
 
 def shutdown():
-    u"""Cleanup and flush loggers"""
+    """Cleanup and flush loggers"""
     global _logger
     logging.shutdown()
```

### Comparing `duplicity-1.2.3.dev43/duplicity/gpginterface.py` & `duplicity-2.0.0rc0/duplicity/gpginterface.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # -*- Mode:Python; indent-tabs-mode:nil; tab-width:4; encoding:utf-8 -*-
 #
-u"""Interface to GNU Privacy Guard (GnuPG)
+"""Interface to GNU Privacy Guard (GnuPG)
 
 !!! This was renamed to gpginterface.py.
     Please refer to duplicity's README for the reason. !!!
 
 gpginterface is a Python module to interface with GnuPG which based on
 GnuPGInterface by Frank J. Tobin.
 It concentrates on interacting with GnuPG via filehandles,
@@ -221,58 +221,49 @@
 
 You should have received a copy of the GNU Lesser General Public
 License along with this library; if not, write to the Free Software
 Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 or see http://www.gnu.org/copyleft/lesser.html
 """
 
-from builtins import object
+import fcntl
 import os
 import sys
-import fcntl
 
 from duplicity import log
 
-# TODO: remove dummy_threading import after Python 3.7 EOL
-try:
-    import threading
-except ImportError:
-    try:
-        import dummy_threading as threading
-        log.Warn(_(u"Threading not available -- zombie processes may appear"))
-    except ImportError:
-        log.FatalError(u"Neither threading nor dummy_threading available.")
-
-__author__ = u"Frank J. Tobin, ftobin@neverending.org"
-__version__ = u"0.3.2"
-__revision__ = u"$Id: GnuPGInterface.py,v 1.6 2009/06/06 17:35:19 loafman Exp $"
+import threading
+
+__author__ = "Frank J. Tobin, ftobin@neverending.org"
+__version__ = "0.3.2"
+__revision__ = "$Id: GnuPGInterface.py,v 1.6 2009/06/06 17:35:19 loafman Exp $"
 
 # "standard" filehandles attached to processes
-_stds = [u'stdin', u'stdout', u'stderr']
+_stds = ['stdin', 'stdout', 'stderr']
 
 # the permissions each type of fh needs to be opened with
-_fd_modes = {u'stdin': u'wb',
-             u'stdout': u'rb',
-             u'stderr': u'r',
-             u'passphrase': u'w',
-             u'command': u'w',
-             u'logger': u'r',
-             u'status': u'r'
+_fd_modes = {'stdin': 'wb',
+             'stdout': 'rb',
+             'stderr': 'r',
+             'passphrase': 'w',
+             'command': 'w',
+             'logger': 'r',
+             'status': 'r'
              }
 
 # correlation between handle names and the arguments we'll pass
-_fd_options = {u'passphrase': u'--passphrase-fd',
-               u'logger': u'--logger-fd',
-               u'status': u'--status-fd',
-               u'command': u'--command-fd'
+_fd_options = {'passphrase': '--passphrase-fd',
+               'logger': '--logger-fd',
+               'status': '--status-fd',
+               'command': '--command-fd'
                }
 
 
 class GnuPG(object):
-    u"""Class instances represent GnuPG.
+    """Class instances represent GnuPG.
 
     Instance attributes of a GnuPG object are:
 
     * call -- string to call GnuPG with.  Defaults to "gpg"
 
     * passphrase -- Since it is a common operation
       to pass in a passphrase to GnuPG,
@@ -285,20 +276,20 @@
 
     * options -- Object of type gpginterface.Options.
       Attribute-setting in options determines
       the command-line options used when calling GnuPG.
     """
 
     def __init__(self):
-        self.call = u'gpg'
+        self.call = 'gpg'
         self.passphrase = None
         self.options = Options()
 
     def run(self, gnupg_commands, args=None, create_fhs=None, attach_fhs=None):
-        u"""Calls GnuPG with the list of string commands gnupg_commands,
+        """Calls GnuPG with the list of string commands gnupg_commands,
         complete with prefixing dashes.
         For example, gnupg_commands could be
         '["--sign", "--encrypt"]'
         Returns a gpginterface.Process object.
 
         args is an optional list of GnuPG command arguments (not options),
         such as keyID's to export, filenames to process, etc.
@@ -361,130 +352,129 @@
         if create_fhs is None:
             create_fhs = []
         if attach_fhs is None:
             attach_fhs = {}
 
         for std in _stds:
             if std not in attach_fhs \
-               and std not in create_fhs:
+                    and std not in create_fhs:
                 attach_fhs.setdefault(std, getattr(sys, std))
 
         handle_passphrase = 0
 
         if self.passphrase is not None \
-           and u'passphrase' not in attach_fhs \
-           and u'passphrase' not in create_fhs:
+                and 'passphrase' not in attach_fhs \
+                and 'passphrase' not in create_fhs:
             handle_passphrase = 1
-            create_fhs.append(u'passphrase')
+            create_fhs.append('passphrase')
 
         process = self._attach_fork_exec(gnupg_commands, args,
                                          create_fhs, attach_fhs)
 
         if handle_passphrase:
-            passphrase_fh = process.handles[u'passphrase']
+            passphrase_fh = process.handles['passphrase']
             passphrase_fh.write(self.passphrase)
             passphrase_fh.close()
-            del process.handles[u'passphrase']
+            del process.handles['passphrase']
 
         return process
 
     def _attach_fork_exec(self, gnupg_commands, args, create_fhs, attach_fhs):
-        u"""This is like run(), but without the passphrase-helping
+        """This is like run(), but without the passphrase-helping
         (note that run() calls this)."""
 
         process = Process()
 
         for fh_name in create_fhs + list(attach_fhs.keys()):
             if fh_name not in _fd_modes:
-                raise KeyError(u"unrecognized filehandle name '%s'; must be one of %s"
-                               % (fh_name, list(_fd_modes.keys())))
+                raise KeyError(f"unrecognized filehandle name '{fh_name}'; "
+                               f"must be one of {list(_fd_modes.keys())}")
 
         for fh_name in create_fhs:
             # make sure the user doesn't specify a filehandle
             # to be created *and* attached
             if fh_name in attach_fhs:
-                raise ValueError(u"cannot have filehandle '%s' in both create_fhs and attach_fhs"
-                                 % fh_name)
+                raise ValueError(f"cannot have filehandle '{fh_name}' in both create_fhs and attach_fhs")
 
             pipe = os.pipe()
             # fix by drt@un.bewaff.net noting
             # that since pipes are unidirectional on some systems,
             # so we have to 'turn the pipe around'
             # if we are writing
-            if _fd_modes[fh_name] == u'w' or _fd_modes[fh_name] == u'wb':
+            if _fd_modes[fh_name] == 'w' or _fd_modes[fh_name] == 'wb':
                 pipe = (pipe[1], pipe[0])
-            if sys.version_info.major >= 3:
-                os.set_inheritable(pipe[0], True)
-                os.set_inheritable(pipe[1], True)
+            os.set_inheritable(pipe[0], True)
+            os.set_inheritable(pipe[1], True)
             process._pipes[fh_name] = Pipe(pipe[0], pipe[1], 0)
 
         for fh_name, fh in list(attach_fhs.items()):
             process._pipes[fh_name] = Pipe(fh.fileno(), fh.fileno(), 1)
 
         process.pid = os.fork()
         if process.pid != 0:
             # start a threaded_waitpid on the child
             process.thread = threading.Thread(target=threaded_waitpid,
-                                              name=u"wait%d" % process.pid,
+                                              name=f"wait{process.pid:d}",
                                               args=(process,))
             process.thread.start()
 
         if process.pid == 0:
             self._as_child(process, gnupg_commands, args)
         return self._as_parent(process)
 
     def _as_parent(self, process):
-        u"""Stuff run after forking in parent"""
+        """Stuff run after forking in parent"""
         for k, p in list(process._pipes.items()):
             if not p.direct:
                 os.close(p.child)
                 process.handles[k] = os.fdopen(p.parent, _fd_modes[k])
 
         # user doesn't need these
         del process._pipes
 
         return process
 
     def _as_child(self, process, gnupg_commands, args):
-        u"""Stuff run after forking in child"""
+        """Stuff run after forking in child"""
         # child
         for std in _stds:
             p = process._pipes[std]
-            os.dup2(p.child, getattr(sys, u"__%s__" % std).fileno())
+            os.dup2(p.child, getattr(sys, f"__{std}__").fileno())
 
         for k, p in list(process._pipes.items()):
             if p.direct and k not in _stds:
                 # we want the fh to stay open after execing
                 fcntl.fcntl(p.child, fcntl.F_SETFD, 0)
 
         fd_args = []
 
         for k, p in list(process._pipes.items()):
             # set command-line options for non-standard fds
             if k not in _stds:
-                fd_args.extend([_fd_options[k], u"%d" % p.child])
+                fd_args.extend([_fd_options[k], f"{p.child:d}"])
 
             if not p.direct:
                 os.close(p.parent)
 
         command = [self.call] + fd_args + self.options.get_args() + gnupg_commands + args
 
         os.execvp(command[0], command)
 
 
 class Pipe(object):
-    u"""simple struct holding stuff about pipes we use"""
+    """simple struct holding stuff about pipes we use"""
+
     def __init__(self, parent, child, direct):
         self.parent = parent
         self.child = child
         self.direct = direct
 
 
 class Options(object):
-    u"""Objects of this class encompass options passed to GnuPG.
+    """Objects of this class encompass options passed to GnuPG.
     This class is responsible for determining command-line arguments
     which are based on options.  It can be said that a GnuPG
     object has-a Options object in its options attribute.
 
     Attributes which correlate directly to GnuPG options:
 
     Each option here defaults to false or None, and is described in
@@ -583,83 +573,83 @@
         self.recipients = []
         self.hidden_recipients = []
 
         # miscellaneous arguments
         self.extra_args = []
 
     def get_args(self):
-        u"""Generate a list of GnuPG arguments based upon attributes."""
+        """Generate a list of GnuPG arguments based upon attributes."""
 
         return self.get_meta_args() + self.get_standard_args() + self.extra_args
 
     def get_standard_args(self):
-        u"""Generate a list of standard, non-meta or extra arguments"""
+        """Generate a list of standard, non-meta or extra arguments"""
         args = []
         if self.homedir is not None:
-            args.extend([u'--homedir', self.homedir])
+            args.extend(['--homedir', self.homedir])
         if self.options is not None:
-            args.extend([u'--options', self.options])
+            args.extend(['--options', self.options])
         if self.comment is not None:
-            args.extend([u'--comment', self.comment])
+            args.extend(['--comment', self.comment])
         if self.compress_algo is not None:
-            args.extend([u'--compress-algo', self.compress_algo])
+            args.extend(['--compress-algo', self.compress_algo])
         if self.default_key is not None:
-            args.extend([u'--default-key', self.default_key])
+            args.extend(['--default-key', self.default_key])
 
         if self.no_options:
-            args.append(u'--no-options')
+            args.append('--no-options')
         if self.armor:
-            args.append(u'--armor')
+            args.append('--armor')
         if self.textmode:
-            args.append(u'--textmode')
+            args.append('--textmode')
         if self.no_greeting:
-            args.append(u'--no-greeting')
+            args.append('--no-greeting')
         if self.verbose:
-            args.append(u'--verbose')
+            args.append('--verbose')
         if self.no_verbose:
-            args.append(u'--no-verbose')
+            args.append('--no-verbose')
         if self.quiet:
-            args.append(u'--quiet')
+            args.append('--quiet')
         if self.batch:
-            args.append(u'--batch')
+            args.append('--batch')
         if self.always_trust:
-            args.append(u'--always-trust')
+            args.append('--always-trust')
         if self.force_v3_sigs:
-            args.append(u'--force-v3-sigs')
+            args.append('--force-v3-sigs')
         if self.rfc1991:
-            args.append(u'--rfc1991')
+            args.append('--rfc1991')
         if self.openpgp:
-            args.append(u'--openpgp')
+            args.append('--openpgp')
 
         for r in self.recipients:
-            args.extend([u'--recipient', r])
+            args.extend(['--recipient', r])
         for r in self.hidden_recipients:
-            args.extend([u'--hidden-recipient', r])
+            args.extend(['--hidden-recipient', r])
         for r in self.encrypt_to:
-            args.extend([u'--encrypt-to', r])
+            args.extend(['--encrypt-to', r])
 
         return args
 
     def get_meta_args(self):
-        u"""Get a list of generated meta-arguments"""
+        """Get a list of generated meta-arguments"""
         args = []
 
         if self.meta_pgp_5_compatible:
-            args.extend([u'--compress-algo', u'1',
-                         u'--force-v3-sigs'])
+            args.extend(['--compress-algo', '1',
+                         '--force-v3-sigs'])
         if self.meta_pgp_2_compatible:
-            args.append(u'--rfc1991')
+            args.append('--rfc1991')
         if not self.meta_interactive:
-            args.extend([u'--batch', u'--no-tty'])
+            args.extend(['--batch', '--no-tty'])
 
         return args
 
 
 class Process(object):
-    u"""Objects of this class encompass properties of a GnuPG
+    """Objects of this class encompass properties of a GnuPG
     process spawned by GnuPG.run().
 
     # gnupg is a GnuPG object
     process = gnupg.run( [ '--decrypt' ], stdout = 1 )
     out = process.handles['stdout'].read()
     ...
     os.waitpid( process.pid, 0 )
@@ -673,45 +663,46 @@
 
     pid -- The PID of the spawned GnuPG process.
     Useful to know, since once should call
     os.waitpid() to clean up the process, especially
     if multiple calls are made to run().
     """
 
-    def __init__(self):
+    def __init__(self) -> object:
         self._pipes = {}
         self.handles = {}
         self.pid = None
         self._waited = None
         self.thread = None
         self.returned = None
 
     def wait(self):
-        u"""
+        """
         Wait on threaded_waitpid to exit and examine results.
         Will raise an IOError if the process exits non-zero.
         """
         if self.returned is None:
             self.thread.join()
         if self.returned != 0:
-            raise IOError(u"GnuPG exited non-zero, with code %d" % (self.returned >> 8))
+            raise IOError(f"GnuPG exited non-zero, with code {self.returned >> 8:d}")
 
 
 def threaded_waitpid(process):
-    u"""
+    """
     When started as a thread with the Process object, thread
     will execute an immediate waitpid() against the process
     pid and will collect the process termination info.  This
     will allow us to reap child processes as soon as possible,
     thus freeing resources quickly.
     """
     try:
         process.returned = os.waitpid(process.pid, 0)[1]
-    except:
-        log.Debug(_(u"GPG process %d terminated before wait()") % process.pid)
+    except Exception as e:
+        log.Debug(_(f"GPG process {process.pid} terminated before wait()"))
         process.returned = 0
 
 
-if __name__ == u'__main__':
+if __name__ == '__main__':
     import doctest
-    from . import gpginterface  # pylint: disable=import-error
+    from . import gpginterface
+
     doctest.testmod(gpginterface)
```

### Comparing `duplicity-1.2.3.dev43/README-LOG.md` & `duplicity-2.0.0rc0/README-LOG.md`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/PKG-INFO` & `duplicity-2.0.0rc0/PKG-INFO`

 * *Files 10% similar despite different names*

```diff
@@ -1,83 +1,67 @@
 Metadata-Version: 2.1
 Name: duplicity
-Version: 1.2.3.dev43
+Version: 2.0.0rc0
 Summary: Encrypted backup using rsync algorithm
 Home-page: http://duplicity.us
 Author: Ben Escoto <ben@emrose.org>
 Author-email: ben@emrose.org
 Maintainer: Kenneth Loafman <kenneth@loafman.com>
 Maintainer-email: kenneth@loafman.com
 Platform: any
 Classifier: Development Status :: 6 - Mature
 Classifier: Environment :: Console
 Classifier: License :: OSI Approved :: GNU General Public License v2 (GPLv2)
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: POSIX
 Classifier: Programming Language :: C
-Classifier: Programming Language :: Python :: 2
-Classifier: Programming Language :: Python :: 2.7
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.5
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Topic :: System :: Archiving :: Backup
-Requires-Python: >2.6, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, <4
+Requires-Python: >=3.8, <4
 Description-Content-Type: text/plain
 License-File: COPYING
 
 # INSTALLATION
 
 Thank you for trying duplicity.  To install, run:
-
 ```
-python setup.py install
+python3 setup.py install
 ```
 
 The build process can be also be run separately:
-
 ```
-python setup.py build
+python3 setup.py build
 ```
 
-If you want to use python 3 replace `python` with `python3`
-
 The default prefix is /usr, so files are put in /usr/bin,
 /usr/share/man/, etc.  An alternate prefix can be specified
 using the --prefix=<prefix> option.  For example:
-
 ```
-python setup.py install --prefix=/usr/local
+python3 setup.py install --prefix=/usr/local
 export PYTHONPATH='/usr/local/lib/python.x/site-packages/'
 /usr/local/bin/duplicity -V`
 ```
 
 # REQUIREMENTS
 
- * Python 2.7, or 3.5 to 3.10
+ * Python 3.8 to 3.10
  * librsync v0.9.6 or later
  * GnuPG for encryption
  * see `requirements.txt` for complete list
 
 If you install from the source package, you will also need:
 
  * Python development files, normally found in module 'python-dev'.
  * librsync development files, normally found in module 'librsync-dev'.
  
 Install python modules by performing the following command in duplicity's root directory:
-
-```
-pip install -r requirements.txt
-```
-or:
-
 ```
 pip3 install -r requirements.txt
 ```
 if you're using python3
 
 # DEVELOPMENT
```

### Comparing `duplicity-1.2.3.dev43/COPYING` & `duplicity-2.0.0rc0/COPYING`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/README-SNAP.md` & `duplicity-2.0.0rc0/README-SNAP.md`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/po/fi_FI.po` & `duplicity-2.0.0rc0/po/fi_FI.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Finnish\n"
 "Language: fi_FI\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/ru_MD.po` & `duplicity-2.0.0rc0/po/ru_RU.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-06-28 17:13\n"
 "Last-Translator: \n"
-"Language-Team: Russian, Moldova\n"
-"Language: ru_MD\n"
+"Language-Team: Russian\n"
+"Language: ru_RU\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 && n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 && n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: ru-MD\n"
+"X-Crowdin-Language: ru\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 #: ../bin/duplicity:106
 msgid "INT intercepted...exiting."
 msgstr "Перехват INT...выполняется выход."
 
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index не соответствует"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Хэши не совпадают"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Внимание: пропуск ошибки, как было обозначено в запросе: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Не удалось подключиться, проверьте пароль: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "путь"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
-msgstr ""
+msgstr "паттерн"
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "имя файла"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "время"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "параметры"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Выполнение в режиме 'пропуска ошибок' в связи с %s; пожалуйста, пересмотрите решение, если это не было намерением"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "количество"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "название резервной копии"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "команда"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "секунды"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "символ"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Использование каталога архива: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Использование наименования резервной копии: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Ошибка в командной строке: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Введите  'duplicity --help' для экрана справки."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "полный_путь"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "псевдоним"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "количество"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "каталог"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "модуль"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "пароль"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "порт"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "префикс"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "относительный_путь"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "некоторый_каталог"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "пользователь"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "удалённая"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Заглушки и формат их URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Команды:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Заданная папка архива '%s' не существует или не является папкой"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Каталог в который предназначено восстановление %s уже существует.\n"
 "Замена не будет произведена."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Убедитесь, что папка %s не существует"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Папка источника резервной копии %s не существует."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Предупреждение командной строки: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Параметры выбора --exclude/--include\n"
 "в настоящее время работают только для резервного копирования, не для восстановления."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Недопустимая адресная ссылка URL '%s'.\n"
 "Например: \"scp://user@host.net:1234/path\" и\n"
 "\"file:///usr/local\".  Для получения дополнительных сведений обратитесь в руководству (man)."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Главное действие: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1281,243 +1293,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Критическая ошибка: отсутствуют манифесты для недавней резервной копии"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Критическая ошибка: Удалённый манифест не соответствует локальному. Неисправен удалённый набор резервного копирования или папка локального архива."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Критическая ошибка: Нет доступа к чтению удалённого и локального манифеста."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Предпочтение набора резервного копирования вместо предыдущего!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Пропуск инкрементального  набора резервного копирования (время_запуска: %s; необходимо: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Добавлена пошаговая резервная копия (время_начала: %s / время_конца: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Цепочка начата: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Цепочка завершена: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Количество содержащихся наборов резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Общее число содержащихся томов: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Тип резервной копии:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Время:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Число томов:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Полная"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Пошаговая"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "Локальная"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Состояние сбора"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Соединение с внутренним интерфейсом: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Папка архива: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Вторичная цепочка %d из %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Найдена первичная цепочка резервного копирования с соответствующей цепочкой подписи:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Отсутствуют цепочки резервного копирования с найденными, задействованными подписями"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Это может быть удалено с помощью запуска duplicity с командой \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Отсутствуют изолированные или неполные наборы резервного копирования."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Внимание, отозван последний набор резервного копирования, в связи с отсутствием файла подписи."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Внимание, найдены подписи, которые не соответствуют с файлами резервной копии"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Внимание, обнаружены незавершённые наборы резервных копий, возможно они остались от прерванного сеанса"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Извлечение цепочек резервного копирования из списка файлов: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Файл %s является частью известного набора"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Файл %s не является частью известного набора; создаётся новый набор"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Пропуск файла (отклонено набором резервного копирования) '%s'"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Найдена резервная копия %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Добавление набора %s для ранее существующей цепочки %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Обнаружен изолированный набор %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Файл: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Общее количество резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Тип изменения файла:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Внесение изменений в %s"
```

### Comparing `duplicity-1.2.3.dev43/po/es_ES.po` & `duplicity-2.0.0rc0/po/es_ES.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Spanish\n"
 "Language: es_ES\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index no coinciden"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Hashes no coinciden"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Aviso: ignorando error tal como se pidió: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Publicando fichero de candado %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MultiBackend: falló al eliminar %s. Se probaron todos los almacenes de copias y ninguno funcionó"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Falló la conexión, compruebe su contraseña: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Faltan los módulos de Python «socket» o «ssl»."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "ruta"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nombre de archivo"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "expresión regular"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "hora"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opciones"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Ejecutando en modo «ignore errors» debido a %s; reconsidere esta opción si no es su intención"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "número"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nombre de respaldo"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "orden"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,242 +623,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "segundos"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "carácter"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Usando directorio de archivador: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Usando nombre de copia de seguridad: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Error de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Introduzca «duplicity --help» para tener ayuda en pantalla."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "ruta_absoluta"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nombre_cubo"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nombre_contenedor"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "recuento"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "directorio"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "módulo"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "otro.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "contraseña"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "puerto"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefijo"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "ruta_relativa"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "algun_dir"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "dir_origen"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_origen"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "dir_objetivo"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_objetivo"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "usuario"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "id_cuenta"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "clave_aplicación"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "remoto"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Motores y sus formatos de URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Órdenes:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "El directorio del archivador «%s» no existe, o no es un directorio"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "La clave de firma debería ser una cadena de 8, 16 o 40 caracteres hexadecimales , como «AA0E732D2».\n"
 "Se ha recibido «%s» en su lugar."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Restaurar directorio de destino %s ya existe.\n"
 "No sobrescribir."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "El directorio verificado %s no existe"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "El directorio de origen de respaldo %s no existe."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Aviso de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Las opciones de selección --exclude/--include\n"
 "actualmente funcionan solo cuando se respalda no al restaurar."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "El binario de GPG es %s, versión %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "URL erróneo «%s».\n"
 "Ejemplos de cadenas de URL son «scp://user@host.net:1234/path» \n"
 "y «file:///usr/local». Ver el manual para más información."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Acción principal: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "basis_file debe ser un archivo (verdadero) o un objeto cuyos atributos de archivo son el objeto del archivo verdadero subyacente"
 
@@ -1287,243 +1299,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: falta %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Error fatal: no se encontraron manifiestos para el respaldo más reciente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Error fatal: el manifiesto remoto no coincide con el local. Ni la configuración de copia de seguridad remota o el directorio del archivo local está dañado."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Error al procesar el manifiesto remoto (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Error fatal: ni el manifiesto remoto ni el local son legibles"
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Procesando manifiesto local %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Error al procesar el manifiesto remoto (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Procesando manifiesto remoto %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Preferir la configuración de copia de seguridad previa"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignorar la configuración de copia de seguridad incremental (start_time: %s; necesaria: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Añadida configuración de copia de seguridad incremental (start_time: %s / end_time: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Hora de inicio de la cadena: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Hora de terminación de la cadena: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Número de conjuntos de respaldo contenidos: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Número total de volúmenes contenidos: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Tipo de conjunto de respaldo"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Hora:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Número de volúmenes:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Completo"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Estado de la colección"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Conectar con el motor: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Directorio de archivador: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Cadena secundaria %d de %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Se encontró cadena de copia de seguridad primaria con cadena de firma coincidente:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "No encontró cadenas con firmas activas"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Esto se puede eliminar ejecutando duplicity con la orden «cleanup»"
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "No se han encontrado respaldos huérfanos o incompletos."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Aviso, descartando el último conjunto de respaldo, debido a la falta archivo de firma."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Aviso, se encontraron firmas pero no coinciden con los archivos de copia de seguridad"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Aviso, encontró conjuntos de copia de seguridad incompletos, probablemente de la sesión abortada"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Extrayendo cadenas de respaldo de la lista de archivos: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "El archivo %s es parte del conjunto conocido"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "El archivo %s no es parte de un conjunto conocido; creando un conjunto nuevo"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignorando archivo (rechazado por el conjunto) «%s»"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Se encontró una cadena de respaldo %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "conjunto %s añadido a la cadena %s preexistente"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Se encontró un conjunto huérfano %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "No hay cadena de firmas disponibles para la hora solicitada. Se está usando la cadena más antigua disponible, que comienza en %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Archivo: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Número total de copias de seguridad: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Tipo de cambio de archivo:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Parcheando %s"
```

### Comparing `duplicity-1.2.3.dev43/po/pt_BR.po` & `duplicity-2.0.0rc0/po/pt_BR.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Portuguese, Brazilian\n"
 "Language: pt_BR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "índice_final não correspondem"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Os hashes não correspondem"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "ERRO_IGNORADO: Aviso: ignorando erro, conforme solicitado: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Falha na conexão, verifique a sua senha: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "caminho"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "gpg-chave-id"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nome de arquivo"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "regular_expressão"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "tempo"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opções"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Executando no modo 'ignorar erros' devido a %s;  por favor, reconsidere se isso não foi planejado"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "número"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nome da cópia de segurança"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "comando"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "segundos"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "caractere"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Utilizando o arquivo dir: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Utilizando o nome da cópia de segurança: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Erro na linha de comando: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Insira 'duplicity --help' para ajuda na tela."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "caminho_absoluto"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "apelido"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nome_depósito"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nome_contêiner"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "contador"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "diretório"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "módulo"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "outro.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "senha"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "porta"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefixo"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "caminho_relativo"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "algum_dir"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "fonte_dir"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "fonte_url"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "alvo_dir"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "alvo_url"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "usuário"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "remoto"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Infraestruturas e seus formatos de URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Comandos:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "O diretório de arquivos especificado '%s' não existe, ou não é um diretório"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Restaurar destino diretório %s já existe.\n"
 "Não substituirá."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Verifique se diretório %s não existe"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "O diretório %s de origem da cópia de segurança não existe."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Aviso de linha de comando: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "As opções de seleção --exclude/--include\n"
 "atualmente só funcionam quando efetuando a cópia de segurança, e não quando restaurando."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "URL '%s' errada.\n"
 "Examplos de strings URL são \"scp://user@host.net:1234/path\" e\n"
 "\"file:///usr/local\".  Veja a man page para mais informações."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Ação principal: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1282,243 +1294,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Erro fatal: Nenhum manifesto encontrado para a cópia de segurança mais recente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Erro Fatal: o manifesto remoto não corresponde ao manifesto local. Ou então o conjunto de cópia de segurança remoto ou o diretório do arquivo local foi corrompido."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Erro Fatal: nem o manifesto local nem o remoto podem ser lidos."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Dando preferência ao conjunto de cópia de segurança sobre o conjunto anterior!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignorando conjunto de cópia de segurança incremental (hora_inicial: %s; necessário: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Conjunto de cópia de segurança incremental adicionado (hora_inicial: %s / hora_final: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Horário do início da cadeia: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Horário do fim da cadeia: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Número de conjuntos de cópia de segurança contidos: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Número total de volumes contidos: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Tipo de conjunto de cópia de segurança:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Hora:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Número de volumes:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Completo"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Status da coleção"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Conectando com intraestrutura %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Arquivo dir: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Cadeia secundária %d de %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Encontrada cadeia de cópia de segurança primária com cadeia assinatura correspondente:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Não foram encontradas cadeias de cópia de segurança com assinaturas ativas"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Estes podem ser excluídos, executando o duplicity com o comando \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Não foram encontrados conjuntos de cópias de segurança órfãos ou incompletos."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Aviso, descartando o último conjunto de cópia de segurança devido à falta de arquivo de assinatura."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Aviso, encontradas assinaturas, mas não os arquivos de cópia de segurança correspondentes"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Aviso, encontrados conjuntos de arquivos de cópia de segurança incompletos, provavelmente deixados por uma sessão abortada"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Extraindo cadeias de cópia de segurança da lista de arquivos: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "O arquivo %s é parte de um conjunto conhecido"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "O arquivo %s não é parte de um conjunto conhecido; criando um novo conjunto"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignorando arquivo (rejeitado pelo conjunto de cópia de segurança) '%s'"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Encontrada cadeia de cópia de segurança %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "O conjunto %s foi adicionado à cadeia pré-existente %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Encontrado conjunto órfão %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Correções %s"
```

### Comparing `duplicity-1.2.3.dev43/po/uk_UA/duplicity.mo` & `duplicity-2.0.0rc0/po/uk_UA/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Ukrainian\n"
 "Language: uk_UA\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 "
```

### Comparing `duplicity-1.2.3.dev43/po/en_GB.po` & `duplicity-2.0.0rc0/po/en_GB.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: English, United Kingdom\n"
 "Language: en_GB\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Missing socket or SSL Python modules."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1269,243 +1281,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Fatal Error: No manifest found for most recent backup"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Number of volumes:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Archive directory: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/zh_CN.po` & `duplicity-2.0.0rc0/po/zh_CN.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Chinese Simplified\n"
 "Language: zh_CN\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "结束索引不匹配"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "哈希值不匹配"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "忽略的错误：警告：根据设置忽略错误：%s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "释放锁文件 %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "多后台：删除 %s 失败。已尝试所有后台存储均失败"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "归集失败，请检查您的密码：%s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "路径"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "gpg证书编号"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "文件名"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "正则表达式"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "时间"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "选项"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "由于 %s，目前程序运行在“忽略错误”的模式下，请谨慎考虑"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "数字"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "备份名"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "命令"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,242 +623,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "秒"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "字符"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "使用存档目录：%s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "使用备份名：%s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "命令行错误：%s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "输入 duplicity --help 查看帮助"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "绝对路径"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "别名"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "S3的bucket名"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "容器名"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "数量"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "目录"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "模块"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "密码"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "端口"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "前缀"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "相对路径"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "路径"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "源路径"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "源url"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "目标路径"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "目标url"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "用户名"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "账户ID"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "Backblaze_B2的application_key"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "远程"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "后台及其 URL 格式："
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "命令："
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "指定的存档目录“%s”不存在，或者不是一个文件夹。"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "签名密钥应当为形如\"AA0E73D2\"的 8, 16 或 40 位的 16 进制字符串。\n"
 "然而接收的字符串为“%s”。"
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "回复目标文件夹 %s 已存在。\n"
 "不进行覆盖。"
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "校验目录 %s 不存在。"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "备份源目录 %s 不存在。"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "命令行警告：%s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "选择参数 --exclude/--include\n"
 "仅适用于备份操作，不适用于还原操作。"
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "无效 URL ”%s“。\n"
 "有效 URL 形如 “scp://user@host.net:1234/path” 和\n"
 "“file:///usr/local”，更多详情请查阅 man 手册。"
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "主要操作： "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1285,243 +1297,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: %s 丢失"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "致命错误：没有最近备份的清单"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "致命错误：远程和本地清单不匹配，本地存档目录或远程备份集崩溃。"
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "致命错误：本地和远程清单不可读"
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "使用前一个备份集！"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "忽略增量备份集 (开始时间：%s；结束时间：%s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "新增增量备份集 (开始时间：%s / 结束时间：%s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "备份链开始时间： "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "备份链结束时间： "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "包含的备份集数量：%d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "包含的卷数量：%d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "备份集类型："
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "时间："
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "卷数量："
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "完全"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "增量"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "本地"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "归集状态"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "正在连接后台设备：%s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "存档路径：%s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "第 %d 次级链 (总共 %d )："
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "找到主备份链及对应的签名链："
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "没有找到活动签名的备份链"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "可以通过“cleanup”命令删除。"
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "没有找到孤立或不完整的备份集。"
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "警告，由于缺少签名文件，将废弃最后一个备份集。"
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "警告，找到无对应备份文件的签名"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "警告，找到不完整的备份集，可能来自于中断的会话"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "从文件列表中提取备份链：%s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "文件 %s 属于已知集合"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "文件 %s 不属于任何已知集合，建立新集合"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "忽略 (被备份集拒绝) 文件 %s"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "找到备份链 %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "将集合 %s 加入已存在的备份链 %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "找到孤立的集合 %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "文件：%s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "备份总数：%d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "文件修改的类型："
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "写回 %s"
```

### Comparing `duplicity-1.2.3.dev43/po/no_NO.po` & `duplicity-2.0.0rc0/po/no_NO.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Norwegian\n"
 "Language: no_NO\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/nl_NL/duplicity.mo` & `duplicity-2.0.0rc0/po/zh_TW/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 12% similar despite different names*

```diff
@@ -1,32 +1,33 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 c601 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 d001 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2044 7574 6368 0a4c 616e  -Team: Dutch.Lan
-000000e0: 6775 6167 653a 206e 6c5f 4e4c 0a4d 494d  guage: nl_NL.MIM
-000000f0: 452d 5665 7273 696f 6e3a 2031 2e30 0a43  E-Version: 1.0.C
-00000100: 6f6e 7465 6e74 2d54 7970 653a 2074 6578  ontent-Type: tex
-00000110: 742f 706c 6169 6e3b 2063 6861 7273 6574  t/plain; charset
-00000120: 3d55 5446 2d38 0a43 6f6e 7465 6e74 2d54  =UTF-8.Content-T
-00000130: 7261 6e73 6665 722d 456e 636f 6469 6e67  ransfer-Encoding
-00000140: 3a20 3862 6974 0a50 6c75 7261 6c2d 466f  : 8bit.Plural-Fo
-00000150: 726d 733a 206e 706c 7572 616c 733d 323b  rms: nplurals=2;
-00000160: 2070 6c75 7261 6c3d 286e 2021 3d20 3129   plural=(n != 1)
-00000170: 3b0a 582d 4372 6f77 6469 6e2d 5072 6f6a  ;.X-Crowdin-Proj
-00000180: 6563 743a 2064 7570 6c69 6369 7479 0a58  ect: duplicity.X
-00000190: 2d43 726f 7764 696e 2d50 726f 6a65 6374  -Crowdin-Project
-000001a0: 2d49 443a 2035 3339 3530 380a 582d 4372  -ID: 539508.X-Cr
-000001b0: 6f77 6469 6e2d 4c61 6e67 7561 6765 3a20  owdin-Language: 
-000001c0: 6e6c 0a58 2d43 726f 7764 696e 2d46 696c  nl.X-Crowdin-Fil
-000001d0: 653a 202f 6d61 696e 2f70 6f2f 6475 706c  e: /main/po/dupl
-000001e0: 6963 6974 792e 706f 740a 582d 4372 6f77  icity.pot.X-Crow
-000001f0: 6469 6e2d 4669 6c65 2d49 443a 2036 0a00  din-File-ID: 6..
+000000d0: 2d54 6561 6d3a 2043 6869 6e65 7365 2054  -Team: Chinese T
+000000e0: 7261 6469 7469 6f6e 616c 0a4c 616e 6775  raditional.Langu
+000000f0: 6167 653a 207a 685f 5457 0a4d 494d 452d  age: zh_TW.MIME-
+00000100: 5665 7273 696f 6e3a 2031 2e30 0a43 6f6e  Version: 1.0.Con
+00000110: 7465 6e74 2d54 7970 653a 2074 6578 742f  tent-Type: text/
+00000120: 706c 6169 6e3b 2063 6861 7273 6574 3d55  plain; charset=U
+00000130: 5446 2d38 0a43 6f6e 7465 6e74 2d54 7261  TF-8.Content-Tra
+00000140: 6e73 6665 722d 456e 636f 6469 6e67 3a20  nsfer-Encoding: 
+00000150: 3862 6974 0a50 6c75 7261 6c2d 466f 726d  8bit.Plural-Form
+00000160: 733a 206e 706c 7572 616c 733d 313b 2070  s: nplurals=1; p
+00000170: 6c75 7261 6c3d 303b 0a58 2d43 726f 7764  lural=0;.X-Crowd
+00000180: 696e 2d50 726f 6a65 6374 3a20 6475 706c  in-Project: dupl
+00000190: 6963 6974 790a 582d 4372 6f77 6469 6e2d  icity.X-Crowdin-
+000001a0: 5072 6f6a 6563 742d 4944 3a20 3533 3935  Project-ID: 5395
+000001b0: 3038 0a58 2d43 726f 7764 696e 2d4c 616e  08.X-Crowdin-Lan
+000001c0: 6775 6167 653a 207a 682d 5457 0a58 2d43  guage: zh-TW.X-C
+000001d0: 726f 7764 696e 2d46 696c 653a 202f 6d61  rowdin-File: /ma
+000001e0: 696e 2f70 6f2f 6475 706c 6963 6974 792e  in/po/duplicity.
+000001f0: 706f 740a 582d 4372 6f77 6469 6e2d 4669  pot.X-Crowdin-Fi
+00000200: 6c65 2d49 443a 2036 0a00                 le-ID: 6..
```

### Comparing `duplicity-1.2.3.dev43/po/it_IT.po` & `duplicity-2.0.0rc0/po/it_IT.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Italian\n"
 "Language: it_IT\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "indici_termine non corrispondenti"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Gli hash non corrispondono"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "ERRORE_IGNORATO: attenzione, errore ignorato come richiesto: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Connessione non riuscita, controllare la password: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "percorso"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "id_chiave_gpg"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nome_file"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "espressione_regolare"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "data"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opzioni"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Esecuzione in modalità \"ignora errori\" fino a %s; riconsiderare se questo non era previsto"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "numero"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nome backup"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "comando"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "secondi"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "carattere"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Directory di archiviazione utilizzata: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Nome di backup utilizzato: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Errore riga di comando: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Usare \"duplicity --help\" per visualizzare l'aiuto."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "percorso_assoluto"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nome_bucket"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nome_container"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "conteggio"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "modulo"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "altro.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "porta"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefisso"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "percorso_relativo"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "una_direcory"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "directory_sorgente"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_sorgente"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "directory_destinazione"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_destinazione"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "utente"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "remoto"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Backend e relativi formati URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Comandi:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "La directory \"%s\", specificata per l'archiviazione, non esiste o non è una directory"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "La directory di destinazione da ripristinare %s esiste già.\n"
 "Non verrà sovrascritta."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "La directory di verifica %s non esiste"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "La directory sorgente di backup %s non esiste."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Avviso riga di comando: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Le opzioni di selezione --exclude e --include\n"
 "attualmente funzionano solo per il backup, non per il ripristino."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "URL \"%s\" errato.\n"
 "Esempi di stringhe URL sono \"scp://utente@host.net:1234/percorso\" e\n"
 "\"file:///usr/local\". Consultare il manuale per ulteriori informazioni."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Azione principale: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1282,243 +1294,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: manca %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Errore fatale: nessun file manifest trovato per il backup più recente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Errore fatale: il file manifest remoto non corrisponde a quello locale. Oppure il set di backup remoto o la directory di archiviazione locale sono danneggiati."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Errore fatale: né il file manifest remoto né quello locale sono leggibili."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Preferenza del backup set rispetto a quello precedente."
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignorato set di backup incrementale (start_time: %s; necessaria: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Aggiunto set di backup incrementale (start_time: %s / end_time: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Data di inizio della catena: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Data di fine della catena: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Numero dei set di backup contenuti: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Numero totale dei volumi contenuti: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Tipo del set di backup:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Data:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Numero di volumi:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Completo"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Incrementale"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "locale"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Stato collezione"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Connessione con il backend: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Directory di archiviazione: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Catena secondaria %d di %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Trovata catena di backup primaria con catena di firma corrispondente:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Non è stata trovata alcuna catena di backup con firme attive"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Questi possono essere eliminati eseguendo duplicity con il comando \"cleanup\""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Non sono stati trovati set di backup orfani o incompleti."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Attenzione, scartato l'ultimo set di backup in quanto privo del file di firma."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Attenzione, trovate le firme ma nessuna corrispondenza con i file di backup"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Attenzione, trovati set di backup incompleti, probabilmente lasciati dalla sessione interrotta"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Estrazione delle catene di backup dall'elenco di file: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Il file %s fa parte di un set conosciuto"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Il file %s non fa parte di un set conosciuto; creazione di un nuovo set"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "File ignorato (rifiutato dal set di backup) \"%s\""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Trovata catena di backup %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Aggiunto il set %s alla catena %s  preesistente"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Trovato set orfano %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Numero totale di backup: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Applicazione patch a %s"
```

### Comparing `duplicity-1.2.3.dev43/po/cs_CZ.po` & `duplicity-2.0.0rc0/po/cs_CZ.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Czech\n"
 "Language: cs_CZ\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=(n==1) ? 0 : (n>=2 && n<=4) ? 1 : 3;\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index se neshoduje"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Otisky (hash) se neshodují"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Varování: ignoruje se chyba, jak požadováno: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Uvolňování souboru zámku %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MultiBackend: nepodařilo se smazat %s. Vyzkoušena všechna úložiště a na žádném se neuspělo"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Připojení se nezdařilo, prosím zkontrolujte své heslo: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Chybějící python moduly pro socket nebo ssl."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -496,67 +501,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "popis umístění"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "identifikator_gpg_klice"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "soubor"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "r_egulární výraz"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "čas"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "volby"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Spuštěno v režimu „ignorovat chyby“ kvůli %s – znovu zvažte zda toto bylo zamýšleno"
@@ -576,15 +581,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "číslo"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "název zálohy"
@@ -595,15 +600,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "příkaz"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -622,242 +627,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "sekund"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "znak"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "S použitím archivní složky: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "S použitím názvu zálohy: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Chyba na příkazovém řádku: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Pro nápovědu zadejte „duplicty --help“."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "absolutni_popis_umisteni"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "alternativni_nazev"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nazev_kontejneru"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "název_kontejneru"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "počet"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "složka"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "modul"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "druhy.stroj"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "heslo"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "předpona"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "relativni_popis_umisteni"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "nejaka_slozka"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "zdrojová_složka"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "zdrojova_url"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "cílová_složka"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "cilova_url"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "uživatel"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "identifikator_uctu"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "aplikacni_klic"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "vzdálená"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Podpůrné vrstvy (backend) a formáty jejich URL adres:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Příkazy:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Zadaná složka archivu „%s“ neexistuje, nebo se nejedná o složku"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "Podpisový klíč by měl být 8, 16 a případně 40 znaků dlouhý hex řetězec jako např. „AA0E73D2“.\n"
 "Namísto toho obdrženo „%s“."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Složka %s do které se má obnovit už existuje.\n"
 "Nebude přepsána."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Ověřovací složka %s neexistuje"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Zdrojová složka zálohy %s neexistuje."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Varování příkazového řádku: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Volby výběru --exclude/--include\n"
 "v tuto chvíli fungují pouze pro zálohování, ne při obnovování."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "Spustitelný soubor GPG je %s, verze %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Chybná URL „%s“.\n"
 "Příklady URL řetězců jsou „scp://uzivatel@stroj.net:1234/popis_umisteni“ a\n"
 "\"file:///usr/local“. Další informace viz manuálová stránka."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Hlavní akce: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "je třeba, aby basis_file byl (skutečný) soubor nebo objekt, jehož souborový atribut je je skutečným souborovým objektem"
 
@@ -1282,243 +1294,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: chybějící %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Fatální chyba: nebyly nalezeny žádné manifesty pro nejnovější zálohu"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Fatální chyba: Vzdálený manifest se neshoduje s tím místním. Buď byla poškozena vzdálená sada záloh, nebo místní archivní složka."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Chyba při zpracovávání místního manifestu (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Fatální chyba: Ani vzdálený, ani místní manifest nejsou čitelné."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Zpracovávání místního manifestu %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Chyba při zpracovávání místního manifestu (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Zpracovávání vzdáleného manifestu %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Upřednostňování sady záloh před předchozím!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignoruje se přírůstková sada záloh (start_time: %s, potřebný: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Přidána přírůstková sada záloh (start_time: %s / end_time: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Čas začátku řetězu: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Čas konce řetězu: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Počet obsažených sad záloh: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Celkový počet obsažených svazků: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Typ sad záloh:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Čas:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Poč. svazků:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Plná"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Přírůstková"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "místní"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Stav sběru"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Spojování se s podpůrnou vrstvou: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Archivní složka: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Sekundární řetěz %d z %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Nalezen hlavní řetěz zálohy s odpovídajícím podpisovým řetězem:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Nebyly nalezený žádné řetězce záloh s aktivními podpisy"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Ty mohou být smazány spuštěním duplicity s příkazem „cleanup“ (vyčištění)."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Nebyly nalezeny žádné k ničemu nepatřící nebo neúplné sady záloh."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Varování, zahazuje se nejnovější sada záloh, protože chybí soubor s podpisem."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Varování, nalezeny podpisy ale žádné odpovídající soubory záloh"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Varování, nalezeny neúplné sady záloh, pravděpodobně zůstaly pro přerušeném sezení"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Vyzískávají se řetězce zálohy ze seznamu souborů: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Soubor %s je součástí známé sady"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Soubor %s není součástí známé sady, bude proto vytvořena nová"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignoruje se soubor (odmítnutý sadou záloh) „%s“"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Nalezen řetězec záloh %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Přidána sada %s k už existujícímu řetězci %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Nalezena sada %s, která k ničemu nepatří"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "Pro požadovaný čas neexistuje žádný řetězec podpisu. Náhradně se použije starší dostupný řetězec, začínající v čase %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Soubor: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Celkový počet záloh: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Typ změny souboru:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Opravuje se %s"
```

### Comparing `duplicity-1.2.3.dev43/po/hu_HU/duplicity.mo` & `duplicity-2.0.0rc0/po/hu_HU/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Hungarian\n"
 "Language: hu_HU\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/de_DE.po` & `duplicity-2.0.0rc0/po/de_DE.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: German\n"
 "Language: de_DE\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "Endindex stimmt nicht überein"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Prüfsummen stimmen nicht überein"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "VERNACHLÄSSIGTER FEHLER: Achtung: Fehler wird wie verlangt vernachlässigt: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Sperrdatei »%s« wird freigegeben"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MehrfachHintergrundprogramm: %s konnte nicht gelöscht werden. Es wurden alle Hintergrundspeicher versucht, aber ohne Erfolg"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Verbindung fehlgeschlagen, bitte Passwort prüfen: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Es fehlt ein Socket oder ein SSL Python Modul."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -496,67 +501,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "Pfad"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "GPG-Schlüsselkennung"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "Dateiname"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "regulärer Ausdruck"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "Zeit"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "Optionen"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "»Fehler vernachlässigen«-Modus läuft gerade, aufgrund von %s; bitte überprüfen wenn das nicht beabsichtigt war"
@@ -576,15 +581,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "Zahl"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "Sicherungsname"
@@ -595,15 +600,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr "Hot|Cool|Archiv"
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "Befehl"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -622,242 +627,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "Sekunden"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "Zeichen"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Folgendes Archivverzeichnis wird benutzt: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Folgender Sicherungsname wird benutzt: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Befehlszeilenfehler: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Bitte »--help« aufrufen, um eine Hilfeseite zu erhalten."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "absoluter_Pfad"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "Alias"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "Bucket_Name"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "Containername"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "Anzahl"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "Verzeichnis"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "Modul"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "anderer.Rechner"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "Passwort"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "Port"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "Präfix"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "relativer_Pfad"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "irgendein_Verzeichnis"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "Quellverzeichnis"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "Quelladresse"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "Zielverzeichnis"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "Zieladresse"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "Benutzer"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "Kontokennung"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "Anwendungsschlüssel"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "Entfernt"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Hintergrundprogramme und deren Adressformate:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Befehle:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Das angegebene Archivverzeichnis »%s« besteht nicht oder ist kein Verzeichnis"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "Der Signaturschlüssel sollte eine hexadezimale Zahl mit 8, 16 oder 40 Stellen, wie »AA0E73D2« sein.\n"
 "Stattdessen wurde »%s« empfangen."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Wiederherstellungszielverzeichnis %s besteht bereits.\n"
 "Wird nicht überschrieben."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Prüfverzeichnis %s besteht nicht"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Sicherungsquellverzeichnis %s existiert nicht."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Befehlszeilenwarnung: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Die Optionen --exclude/--include funktionieren\n"
 "im Moment nur bei der Sicherung, nicht bei der Wiederherstellung."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "Die GPG Programmdatei ist %s, Version %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Ungültige Adresse »%s«.\n"
 "Beispiele einer Adresszeichenkette sind »scp://benutzer@rechner:1234/pfad« und\n"
 "»file:///usr/local«. Für mehr Informationen bitte die man-Seite aufrufen."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Hauptaufgabe: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "basis_file muss eine (echte) Datei oder ein Objekt sein, dessen Datei-Attribut das zugrundeliegende Dateiobjekt ist"
 
@@ -1292,243 +1304,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "Sicherungssatz löschen: %s fehlt"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Kritischer Fehler: Kein Manifest zur letzten Sicherung gefunden"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Kritischer Fehler: Manifest im Hintergrundprogramm stimmt nicht mit der lokalen Version überein. Entweder der entfernte Sicherungssatz oder das lokale Archivverzeichnis ist fehlerhaft."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Fehler beim Verarbeiten des entfernten Manifest (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Kritischer Fehler: Weder das entfernte noch das lokale Manifest ist lesbar."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Verarbeitung des lokalen Manifest %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Fehler beim Verarbeiten des entfernten Manifest (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Verarbeitung des entfernten Manifest %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Sicherungssatz wird dem Vorherigen vorgezogen!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Schrittweiser Sicherungssatz wird vernachlässigt (Startzeit: %s; benötigt: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Schrittweiser Sicherungssatz wurde hinzugefügt (Startzeit: %s; Endzeit: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Erste Sicherung in dieser Kette: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Letzte Sicherung in dieser Kette: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Anzahl der enthaltenen Sicherungssätze: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Gesamtanzahl der enthaltenen Datenträger: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Typ des Sicherungssatzes:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Zeit:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Datenträgeranz.:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Vollständig"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Schrittweise"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "Lokal"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Sammlungszustand"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Mit Hintergrundprogramm wird verbunden: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Archivverzeichnis: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Zusätzliche Kette %d von %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Primäre Sicherungskette mit passender Signaturkette gefunden:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Keine Sicherungsketten mit aktiven Signaturen gefunden"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Sie können diese entfernen, indem Sie duplicity mit dem »cleanup«-Befehl starten."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Keine verwaisten oder unvollständigen Sicherungssätze gefunden."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Achtung, der letzte Sicherungssatz wird verworfen, weil die Signaturdatei fehlt."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Achtung, es wurden Signaturen ohne dazugehörige Sicherungsdaten gefunden"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Achtung, es wurden unvollständige Sicherungssätze gefunden, wahrscheinlich von einer abgebrochenen Sitzung zurückgelassen"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Sicherungsketten aus der Liste der Dateien werden entnommen: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Datei %s ist Teil eines bekannten Satzes"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Datei %s ist nicht Teil eines bekannten Sicherungssatzes; neuer Satz wird erstellt"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Datei »%s« wird vernachlässigt (vom Sicherungssatz abgelehnt)"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Sicherungskette %s gefunden"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Satz %s zur bestehenden Sicherungskette %s hinzugefügt"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Verwaister Satz %s gefunden"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "Keine Signaturkette für die angeforderte Zeit. Nutze die älteste verfügbare Kette, starte bei der Zeit %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Datei: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Gesamtzahl an Sicherungen: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Art der Dateiänderung:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "%s wird repariert"
```

### Comparing `duplicity-1.2.3.dev43/po/es_ES/duplicity.mo` & `duplicity-2.0.0rc0/po/es_ES/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Spanish\n"
 "Language: es_ES\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/zh_HK/duplicity.mo` & `duplicity-2.0.0rc0/po/zh_HK/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 5% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a35 300a 4c61 7374 2d54 7261 6e73  14:50.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2043 6869 6e65 7365 2054  -Team: Chinese T
 000000e0: 7261 6469 7469 6f6e 616c 2c20 486f 6e67  raditional, Hong
 000000f0: 204b 6f6e 670a 4c61 6e67 7561 6765 3a20   Kong.Language: 
 00000100: 7a68 5f48 4b0a 4d49 4d45 2d56 6572 7369  zh_HK.MIME-Versi
 00000110: 6f6e 3a20 312e 300a 436f 6e74 656e 742d  on: 1.0.Content-
 00000120: 5479 7065 3a20 7465 7874 2f70 6c61 696e  Type: text/plain
```

### Comparing `duplicity-1.2.3.dev43/po/da_DK.po` & `duplicity-2.0.0rc0/po/da_DK.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Danish\n"
 "Language: da_DK\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/pl_PL.po` & `duplicity-2.0.0rc0/po/pl_PL.po`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Polish\n"
 "Language: pl_PL\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=(n==1 ? 0 : (n%10>=2 && n%10<=4) && (n%100<12 || n%100>14) ? 1 : n!=1 && (n%10>=0 && n%10<=1) || (n%10>=5 && n%10<=9) || (n%100>=12 && n%100<=14) ? 2 : 3);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "Wartości end_index są różne"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Skróty są różne"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Ostrzeżenie: ignorowanie błędu zgodnie z intencją %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Odblokowywanie pliku zamka %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Połączenie nie powiodło się; sprawdź podane hasło: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "ścieżka"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "id_klucza_gpg"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nazwa_pliku"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "wyrażenie_regularne"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "data"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opcje"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Działanie w trybie 'ignorowania błędów' z powodu %s. Upewnij się, że tego właśnie chciałeś."
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "liczba"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nazwa kopii zapasowej"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "polecenie"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "sekund(-y)"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "znak"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Używanie katalogu archiwum: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Używanie nazwy kopii zapasowej: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Błąd linii poleceń: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Wykonaj 'duplicity --help', by uzyskać pomoc."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "ścieżka_absolutna"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nazwa_bucketa"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nazwa_kontenera"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "liczba"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "katalog"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "moduł"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "zdalny_adres"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "hasło"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefiks"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "ścieżka_względna"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "katalog"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "katalog_źródłowy"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_źródłowy"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "katalog_docelowy"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_docelowy"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "użytkownik"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "zdalna"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Backendy oraz ich formaty URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Polecenia:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Podana nazwa katalogu '%s' nie istnieje lub nie jest katalogiem"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Docelowy katalog %s już istnieje\n"
 "i nie zostanie nadpisany."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Katalog weryfikacji %s nie istnieje"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Katalog źródłowy kopii zapasowej %s nie istnieje."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Ostrzeżenie dotyczące linii poleceń: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Opcje --exclude oraz --include dotyczą\n"
 "tylko tworzenia kopii zapasowej, a nie odzyskiwania."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Błędny URL '%s'.\n"
 "Przykładowe adresy URL to np. \"scp://użytkownik@adres.net:1234/ścieżka\" oraz\n"
 "\"file:///usr/local\". Zobacz podręcznik systemowy, aby uzyskać więcej informacji."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Główna akcja: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1285,243 +1297,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: brakujący plik %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Krytyczny błąd: brak plików manifestu najnowszej kopii zapasowej"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Krytyczny błąd: Zdalny manifest jest różny od lokalnego. Zdalna kopia zapasowa lub lokalne archiwum musiały ulec oszkodzeniu."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Krytyczny błąd: zarówno zdalny jak i lokalny manifest jest nieczytelny."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Wybór tej kopii zapasowej zamiast poprzedniej"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Pominięcie przyrostowej kopii zapasowej (data rozpoczęcia: %s; oczekiwano: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Dodano przyrostową kopię zapasową (data rozpoczęcia: %s / data ukończenia: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Data utworzenia łańcucha: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Data ukończenia łańcucha: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Liczba zawartych kopii zapasowych: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Całkowita liczba zawartych woluminów: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Typ kopii zapasowej:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Data:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Liczba woluminów:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Pełny"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Przyrostowy"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "lokalna"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Status kolekcji"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Łączenie z backendem: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Katalog archiwum: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Drugorzędny łańcuch %d spośród %d"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Znaleziono podstawowy łańuch kopii zapasowej z pasującym podpisem:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Nie znaleziono łańcuchów kopii zapasowej z aktywnymi podpisami"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Te kopie można usunąć uruchamiając duplicity z komendą \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Nie znaleziono osieroconych ani niepełnych kopii zapasowych."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Uwaga, usuwanie ostatniej kopii zapasowej z powodu braku pliku podpisu."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Uwaga, znaleziono pliki podpisów, ale bez plików kopii zapasowej"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Uwaga, znaleziono nieukończone kopie zapasowe, prawdopodobnie pozostałości po przerwanej sesji"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Uzyskiwanie łańcuchów kopii zapasowych z listy plików: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Plik %s jest częścią znanej kopii zapasowej"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Plik %s nie jest częścią znanej kopii zapasowej; tworzenie nowej kopii"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Pominięcie pliku '%s' (wyrzucony z kopii zapasowej)"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Znaleziono łańcuch kopii zapasowych %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Dodano kopię zapasową %s  do istniejącego łańucha %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Znaleziono osierocony łańcuch %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Plik: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Łączna ilość kopii zapasowych: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Aktualizowanie pliku %s"
```

### Comparing `duplicity-1.2.3.dev43/po/nl_SR.po` & `duplicity-2.0.0rc0/po/nl_SR.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Dutch, Suriname\n"
 "Language: nl_SR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/ca_ES.po` & `duplicity-2.0.0rc0/po/ca_ES.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Catalan\n"
 "Language: ca_ES\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
@@ -1688,8 +1700,7 @@
 msgid "Touching %s"
 msgstr ""
 
 #: ../duplicity/path.py:639
 #, python-format
 msgid "Deleting tree %s"
 msgstr ""
-
```

### Comparing `duplicity-1.2.3.dev43/po/nl_BE/duplicity.mo` & `duplicity-2.0.0rc0/po/nl_BE/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 6% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a35 300a 4c61 7374 2d54 7261 6e73  14:50.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2044 7574 6368 2c20 4265  -Team: Dutch, Be
 000000e0: 6c67 6975 6d0a 4c61 6e67 7561 6765 3a20  lgium.Language: 
 000000f0: 6e6c 5f42 450a 4d49 4d45 2d56 6572 7369  nl_BE.MIME-Versi
 00000100: 6f6e 3a20 312e 300a 436f 6e74 656e 742d  on: 1.0.Content-
 00000110: 5479 7065 3a20 7465 7874 2f70 6c61 696e  Type: text/plain
 00000120: 3b20 6368 6172 7365 743d 5554 462d 380a  ; charset=UTF-8.
```

### Comparing `duplicity-1.2.3.dev43/po/el_GR.po` & `duplicity-2.0.0rc0/po/el_GR.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Greek\n"
 "Language: el_GR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "Διαδρομή"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "όνομα αρχείου"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "επιλογές"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "αριθμός"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "εντολή"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "δευτερόλεπτα"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "χαρακτήρας"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "υπολογισμός"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "κατάλογος"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "ενότητα"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "κωδικός πρόσβασης"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "θύρα"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "πρόθεμα"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "χρήστης"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Εντολές:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Ώρα:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Πλήρες"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Βηματικό"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "τοπικό"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/it_IT/duplicity.mo` & `duplicity-2.0.0rc0/po/it_IT/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Italian\n"
 "Language: it_IT\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/zh_HK.po` & `duplicity-2.0.0rc0/po/zh_HK.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Chinese Traditional, Hong Kong\n"
 "Language: zh_HK\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/ru_UA/duplicity.mo` & `duplicity-2.0.0rc0/po/ru_MD/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,24 +1,24 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
-"Language-Team: Russian, Ukraine\n"
-"Language: ru_UA\n"
+"Language-Team: Russian, Moldova\n"
+"Language: ru_MD\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 "
 "&& n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 "
 "&& n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: ru-UA\n"
+"X-Crowdin-Language: ru-MD\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 msgid "%s not found in archive - no files restored."
 msgstr "%s не найден в архиве, нет восстановленных файлов."
 
 msgid "A %s"
```

### Comparing `duplicity-1.2.3.dev43/po/es_EM/duplicity.mo` & `duplicity-2.0.0rc0/po/es_EM/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Spanish (Modern)\n"
 "Language: es_EM\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/ja_JP.po` & `duplicity-2.0.0rc0/po/ja_JP.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Japanese\n"
 "Language: ja_JP\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/pt_PT/duplicity.mo` & `duplicity-2.0.0rc0/po/pt_PT/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 4% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2050 6f72 7475 6775 6573  -Team: Portugues
 000000e0: 650a 4c61 6e67 7561 6765 3a20 7074 5f50  e.Language: pt_P
 000000f0: 540a 4d49 4d45 2d56 6572 7369 6f6e 3a20  T.MIME-Version: 
 00000100: 312e 300a 436f 6e74 656e 742d 5479 7065  1.0.Content-Type
 00000110: 3a20 7465 7874 2f70 6c61 696e 3b20 6368  : text/plain; ch
 00000120: 6172 7365 743d 5554 462d 380a 436f 6e74  arset=UTF-8.Cont
```

### Comparing `duplicity-1.2.3.dev43/po/zh_TW/duplicity.mo` & `duplicity-2.0.0rc0/po/af_ZA/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 12% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 d001 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 ca01 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2043 6869 6e65 7365 2054  -Team: Chinese T
-000000e0: 7261 6469 7469 6f6e 616c 0a4c 616e 6775  raditional.Langu
-000000f0: 6167 653a 207a 685f 5457 0a4d 494d 452d  age: zh_TW.MIME-
-00000100: 5665 7273 696f 6e3a 2031 2e30 0a43 6f6e  Version: 1.0.Con
-00000110: 7465 6e74 2d54 7970 653a 2074 6578 742f  tent-Type: text/
-00000120: 706c 6169 6e3b 2063 6861 7273 6574 3d55  plain; charset=U
-00000130: 5446 2d38 0a43 6f6e 7465 6e74 2d54 7261  TF-8.Content-Tra
-00000140: 6e73 6665 722d 456e 636f 6469 6e67 3a20  nsfer-Encoding: 
-00000150: 3862 6974 0a50 6c75 7261 6c2d 466f 726d  8bit.Plural-Form
-00000160: 733a 206e 706c 7572 616c 733d 313b 2070  s: nplurals=1; p
-00000170: 6c75 7261 6c3d 303b 0a58 2d43 726f 7764  lural=0;.X-Crowd
-00000180: 696e 2d50 726f 6a65 6374 3a20 6475 706c  in-Project: dupl
-00000190: 6963 6974 790a 582d 4372 6f77 6469 6e2d  icity.X-Crowdin-
-000001a0: 5072 6f6a 6563 742d 4944 3a20 3533 3935  Project-ID: 5395
-000001b0: 3038 0a58 2d43 726f 7764 696e 2d4c 616e  08.X-Crowdin-Lan
-000001c0: 6775 6167 653a 207a 682d 5457 0a58 2d43  guage: zh-TW.X-C
-000001d0: 726f 7764 696e 2d46 696c 653a 202f 6d61  rowdin-File: /ma
-000001e0: 696e 2f70 6f2f 6475 706c 6963 6974 792e  in/po/duplicity.
-000001f0: 706f 740a 582d 4372 6f77 6469 6e2d 4669  pot.X-Crowdin-Fi
-00000200: 6c65 2d49 443a 2036 0a00                 le-ID: 6..
+000000d0: 2d54 6561 6d3a 2041 6672 696b 6161 6e73  -Team: Afrikaans
+000000e0: 0a4c 616e 6775 6167 653a 2061 665f 5a41  .Language: af_ZA
+000000f0: 0a4d 494d 452d 5665 7273 696f 6e3a 2031  .MIME-Version: 1
+00000100: 2e30 0a43 6f6e 7465 6e74 2d54 7970 653a  .0.Content-Type:
+00000110: 2074 6578 742f 706c 6169 6e3b 2063 6861   text/plain; cha
+00000120: 7273 6574 3d55 5446 2d38 0a43 6f6e 7465  rset=UTF-8.Conte
+00000130: 6e74 2d54 7261 6e73 6665 722d 456e 636f  nt-Transfer-Enco
+00000140: 6469 6e67 3a20 3862 6974 0a50 6c75 7261  ding: 8bit.Plura
+00000150: 6c2d 466f 726d 733a 206e 706c 7572 616c  l-Forms: nplural
+00000160: 733d 323b 2070 6c75 7261 6c3d 286e 2021  s=2; plural=(n !
+00000170: 3d20 3129 3b0a 582d 4372 6f77 6469 6e2d  = 1);.X-Crowdin-
+00000180: 5072 6f6a 6563 743a 2064 7570 6c69 6369  Project: duplici
+00000190: 7479 0a58 2d43 726f 7764 696e 2d50 726f  ty.X-Crowdin-Pro
+000001a0: 6a65 6374 2d49 443a 2035 3339 3530 380a  ject-ID: 539508.
+000001b0: 582d 4372 6f77 6469 6e2d 4c61 6e67 7561  X-Crowdin-Langua
+000001c0: 6765 3a20 6166 0a58 2d43 726f 7764 696e  ge: af.X-Crowdin
+000001d0: 2d46 696c 653a 202f 6d61 696e 2f70 6f2f  -File: /main/po/
+000001e0: 6475 706c 6963 6974 792e 706f 740a 582d  duplicity.pot.X-
+000001f0: 4372 6f77 6469 6e2d 4669 6c65 2d49 443a  Crowdin-File-ID:
+00000200: 2036 0a00                                 6..
```

### Comparing `duplicity-1.2.3.dev43/po/de_AT.po` & `duplicity-2.0.0rc0/po/de_AT.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: German, Austria\n"
 "Language: de_AT\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "Endindex stimmt nicht überein"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Prüfsummen stimmen nicht überein"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "VERNACHLÄSSIGTER FEHLER: Achtung: Fehler wird wie verlangt vernachlässigt: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Sperrdatei »%s« wird freigegeben"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MehrfachHintergrundprogramm: %s konnte nicht gelöscht werden. Es wurden alle Hintergrundspeicher versucht, aber ohne Erfolg"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Verbindung fehlgeschlagen, bitte Passwort prüfen: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Es fehlt ein Socket oder ein SSL Python Modul."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -496,67 +501,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "Pfad"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "GPG-Schlüsselkennung"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "Dateiname"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "regulärer Ausdruck"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "Zeit"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "Optionen"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "»Fehler vernachlässigen«-Modus läuft gerade, aufgrund von %s; bitte überprüfen wenn das nicht beabsichtigt war"
@@ -576,15 +581,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "Zahl"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "Sicherungsname"
@@ -595,15 +600,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr "Hot|Cool|Archiv"
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "Befehl"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -622,242 +627,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "Sekunden"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "Zeichen"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Folgendes Archivverzeichnis wird benutzt: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Folgender Sicherungsname wird benutzt: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Befehlszeilenfehler: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Bitte »--help« aufrufen, um eine Hilfeseite zu erhalten."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "absoluter_Pfad"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "Alias"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "Bucket_Name"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "Containername"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "Anzahl"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "Verzeichnis"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "Modul"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "anderer.Rechner"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "Passwort"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "Port"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "Präfix"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "relativer_Pfad"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "irgendein_Verzeichnis"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "Quellverzeichnis"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "Quelladresse"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "Zielverzeichnis"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "Zieladresse"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "Benutzer"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "Kontokennung"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "Anwendungsschlüssel"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "Entfernt"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Hintergrundprogramme und deren Adressformate:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Befehle:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Das angegebene Archivverzeichnis »%s« besteht nicht oder ist kein Verzeichnis"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "Der Signaturschlüssel sollte eine hexadezimale Zahl mit 8, 16 oder 40 Stellen, wie »AA0E73D2« sein.\n"
 "Stattdessen wurde »%s« empfangen."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Wiederherstellungszielverzeichnis %s besteht bereits.\n"
 "Wird nicht überschrieben."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Prüfverzeichnis %s besteht nicht"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Sicherungsquellverzeichnis %s existiert nicht."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Befehlszeilenwarnung: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Die Optionen --exclude/--include funktionieren\n"
 "im Moment nur bei der Sicherung, nicht bei der Wiederherstellung."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "Die GPG Programmdatei ist %s, Version %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Ungültige Adresse »%s«.\n"
 "Beispiele einer Adresszeichenkette sind »scp://benutzer@rechner:1234/pfad« und\n"
 "»file:///usr/local«. Für mehr Informationen bitte die man-Seite aufrufen."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Hauptaufgabe: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "basis_file muss eine (echte) Datei oder ein Objekt sein, dessen Datei-Attribut das zugrundeliegende Dateiobjekt ist"
 
@@ -1292,243 +1304,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "Sicherungssatz löschen: %s fehlt"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Kritischer Fehler: Kein Manifest zur letzten Sicherung gefunden"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Kritischer Fehler: Manifest im Hintergrundprogramm stimmt nicht mit der lokalen Version überein. Entweder der entfernte Sicherungssatz oder das lokale Archivverzeichnis ist fehlerhaft."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Fehler beim Verarbeiten des entfernten Manifest (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Kritischer Fehler: Weder das entfernte noch das lokale Manifest ist lesbar."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Verarbeitung des lokalen Manifest %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Fehler beim Verarbeiten des entfernten Manifest (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Verarbeitung des entfernten Manifest %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Sicherungssatz wird dem Vorherigen vorgezogen!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Schrittweiser Sicherungssatz wird vernachlässigt (Startzeit: %s; benötigt: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Schrittweiser Sicherungssatz wurde hinzugefügt (Startzeit: %s; Endzeit: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Erste Sicherung in dieser Kette: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Letzte Sicherung in dieser Kette: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Anzahl der enthaltenen Sicherungssätze: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Gesamtanzahl der enthaltenen Datenträger: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Typ des Sicherungssatzes:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Zeit:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Datenträgeranz.:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Vollständig"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Schrittweise"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "Lokal"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Sammlungszustand"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Mit Hintergrundprogramm wird verbunden: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Archivverzeichnis: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Zusätzliche Kette %d von %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Primäre Sicherungskette mit passender Signaturkette gefunden:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Keine Sicherungsketten mit aktiven Signaturen gefunden"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Sie können diese entfernen, indem Sie duplicity mit dem »cleanup«-Befehl starten."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Keine verwaisten oder unvollständigen Sicherungssätze gefunden."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Achtung, der letzte Sicherungssatz wird verworfen, weil die Signaturdatei fehlt."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Achtung, es wurden Signaturen ohne dazugehörige Sicherungsdaten gefunden"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Achtung, es wurden unvollständige Sicherungssätze gefunden, wahrscheinlich von einer abgebrochenen Sitzung zurückgelassen"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Sicherungsketten aus der Liste der Dateien werden entnommen: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Datei %s ist Teil eines bekannten Satzes"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Datei %s ist nicht Teil eines bekannten Sicherungssatzes; neuer Satz wird erstellt"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Datei »%s« wird vernachlässigt (vom Sicherungssatz abgelehnt)"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Sicherungskette %s gefunden"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Satz %s zur bestehenden Sicherungskette %s hinzugefügt"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Verwaister Satz %s gefunden"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "Keine Signaturkette für die angeforderte Zeit. Nutze die älteste verfügbare Kette, starte bei der Zeit %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Datei: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Gesamtzahl an Sicherungen: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Art der Dateiänderung:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "%s wird repariert"
```

### Comparing `duplicity-1.2.3.dev43/po/en_GB/duplicity.mo` & `duplicity-2.0.0rc0/po/en_GB/duplicity.mo`

 * *Files 10% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: English, United Kingdom\n"
 "Language: en_GB\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/cs_CZ/duplicity.mo` & `duplicity-2.0.0rc0/po/cs_CZ/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Czech\n"
 "Language: cs_CZ\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=(n==1) ? 0 : (n>=2 && n<=4) ? 1 : 3;\n"
```

### Comparing `duplicity-1.2.3.dev43/po/pl_PL/duplicity.mo` & `duplicity-2.0.0rc0/po/pl_PL/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Polish\n"
 "Language: pl_PL\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=(n==1 ? 0 : (n%10>=2 && n%10<=4) && "
```

### Comparing `duplicity-1.2.3.dev43/po/en_US.po` & `duplicity-2.0.0rc0/po/en_US.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-03-20 15:04\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: English, United States\n"
 "Language: en_US\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/es_US/duplicity.mo` & `duplicity-2.0.0rc0/po/es_US/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Spanish, United States\n"
 "Language: es_US\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/he_IL/duplicity.mo` & `duplicity-2.0.0rc0/po/he_IL/duplicity.mo`

 * *Files 4% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Hebrew\n"
 "Language: he_IL\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=n%100==1 ? 0 : n%100==2 ? 1 : n%100==3 || "
```

### Comparing `duplicity-1.2.3.dev43/po/nl_NL.po` & `duplicity-2.0.0rc0/po/sr_SP.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
-"Language-Team: Dutch\n"
-"Language: nl_NL\n"
+"Language-Team: Serbian (Cyrillic)\n"
+"Language: sr_SP\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
-"Plural-Forms: nplurals=2; plural=(n != 1);\n"
+"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2);\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: nl\n"
+"X-Crowdin-Language: sr\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 #: ../bin/duplicity:106
 msgid "INT intercepted...exiting."
 msgstr ""
 
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/ru_BY/duplicity.mo` & `duplicity-2.0.0rc0/po/ru_BY/duplicity.mo`

 * *Files 1% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Russian, Belarus\n"
 "Language: ru_BY\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 "
```

### Comparing `duplicity-1.2.3.dev43/po/en_US/duplicity.mo` & `duplicity-2.0.0rc0/po/en_US/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 2% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3033 2d32 3020  ate: 2023-03-20 
-000000b0: 3135 3a30 340a 4c61 7374 2d54 7261 6e73  15:04.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2045 6e67 6c69 7368 2c20  -Team: English, 
 000000e0: 556e 6974 6564 2053 7461 7465 730a 4c61  United States.La
 000000f0: 6e67 7561 6765 3a20 656e 5f55 530a 4d49  nguage: en_US.MI
 00000100: 4d45 2d56 6572 7369 6f6e 3a20 312e 300a  ME-Version: 1.0.
 00000110: 436f 6e74 656e 742d 5479 7065 3a20 7465  Content-Type: te
 00000120: 7874 2f70 6c61 696e 3b20 6368 6172 7365  xt/plain; charse
```

### Comparing `duplicity-1.2.3.dev43/po/ar_SA/duplicity.mo` & `duplicity-2.0.0rc0/po/ar_SA/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 25% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 370a 4c61 7374 2d54 7261 6e73  19:47.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2041 7261 6269 630a 4c61  -Team: Arabic.La
 000000e0: 6e67 7561 6765 3a20 6172 5f53 410a 4d49  nguage: ar_SA.MI
 000000f0: 4d45 2d56 6572 7369 6f6e 3a20 312e 300a  ME-Version: 1.0.
 00000100: 436f 6e74 656e 742d 5479 7065 3a20 7465  Content-Type: te
 00000110: 7874 2f70 6c61 696e 3b20 6368 6172 7365  xt/plain; charse
 00000120: 743d 5554 462d 380a 436f 6e74 656e 742d  t=UTF-8.Content-
```

### Comparing `duplicity-1.2.3.dev43/po/pt_BR/duplicity.mo` & `duplicity-2.0.0rc0/po/pt_BR/duplicity.mo`

 * *Files 1% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Portuguese, Brazilian\n"
 "Language: pt_BR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/tr_TR/duplicity.mo` & `duplicity-2.0.0rc0/po/tr_TR/duplicity.mo`

 * *Files 2% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Turkish\n"
 "Language: tr_TR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/af_ZA/duplicity.mo` & `duplicity-2.0.0rc0/po/no_NO/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 8% similar despite different names*

```diff
@@ -4,30 +4,30 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 370a 4c61 7374 2d54 7261 6e73  19:47.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2041 6672 696b 6161 6e73  -Team: Afrikaans
-000000e0: 0a4c 616e 6775 6167 653a 2061 665f 5a41  .Language: af_ZA
+000000d0: 2d54 6561 6d3a 204e 6f72 7765 6769 616e  -Team: Norwegian
+000000e0: 0a4c 616e 6775 6167 653a 206e 6f5f 4e4f  .Language: no_NO
 000000f0: 0a4d 494d 452d 5665 7273 696f 6e3a 2031  .MIME-Version: 1
 00000100: 2e30 0a43 6f6e 7465 6e74 2d54 7970 653a  .0.Content-Type:
 00000110: 2074 6578 742f 706c 6169 6e3b 2063 6861   text/plain; cha
 00000120: 7273 6574 3d55 5446 2d38 0a43 6f6e 7465  rset=UTF-8.Conte
 00000130: 6e74 2d54 7261 6e73 6665 722d 456e 636f  nt-Transfer-Enco
 00000140: 6469 6e67 3a20 3862 6974 0a50 6c75 7261  ding: 8bit.Plura
 00000150: 6c2d 466f 726d 733a 206e 706c 7572 616c  l-Forms: nplural
 00000160: 733d 323b 2070 6c75 7261 6c3d 286e 2021  s=2; plural=(n !
 00000170: 3d20 3129 3b0a 582d 4372 6f77 6469 6e2d  = 1);.X-Crowdin-
 00000180: 5072 6f6a 6563 743a 2064 7570 6c69 6369  Project: duplici
 00000190: 7479 0a58 2d43 726f 7764 696e 2d50 726f  ty.X-Crowdin-Pro
 000001a0: 6a65 6374 2d49 443a 2035 3339 3530 380a  ject-ID: 539508.
 000001b0: 582d 4372 6f77 6469 6e2d 4c61 6e67 7561  X-Crowdin-Langua
-000001c0: 6765 3a20 6166 0a58 2d43 726f 7764 696e  ge: af.X-Crowdin
+000001c0: 6765 3a20 6e6f 0a58 2d43 726f 7764 696e  ge: no.X-Crowdin
 000001d0: 2d46 696c 653a 202f 6d61 696e 2f70 6f2f  -File: /main/po/
 000001e0: 6475 706c 6963 6974 792e 706f 740a 582d  duplicity.pot.X-
 000001f0: 4372 6f77 6469 6e2d 4669 6c65 2d49 443a  Crowdin-File-ID:
 00000200: 2036 0a00                                 6..
```

### Comparing `duplicity-1.2.3.dev43/po/POTFILES.skip` & `duplicity-2.0.0rc0/po/POTFILES.skip`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/po/nl_SR/duplicity.mo` & `duplicity-2.0.0rc0/po/sr_SP/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 26% similar despite different names*

```diff
@@ -1,33 +1,38 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 d301 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 1d02 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2044 7574 6368 2c20 5375  -Team: Dutch, Su
-000000e0: 7269 6e61 6d65 0a4c 616e 6775 6167 653a  riname.Language:
-000000f0: 206e 6c5f 5352 0a4d 494d 452d 5665 7273   nl_SR.MIME-Vers
-00000100: 696f 6e3a 2031 2e30 0a43 6f6e 7465 6e74  ion: 1.0.Content
-00000110: 2d54 7970 653a 2074 6578 742f 706c 6169  -Type: text/plai
-00000120: 6e3b 2063 6861 7273 6574 3d55 5446 2d38  n; charset=UTF-8
-00000130: 0a43 6f6e 7465 6e74 2d54 7261 6e73 6665  .Content-Transfe
-00000140: 722d 456e 636f 6469 6e67 3a20 3862 6974  r-Encoding: 8bit
-00000150: 0a50 6c75 7261 6c2d 466f 726d 733a 206e  .Plural-Forms: n
-00000160: 706c 7572 616c 733d 323b 2070 6c75 7261  plurals=2; plura
-00000170: 6c3d 286e 2021 3d20 3129 3b0a 582d 4372  l=(n != 1);.X-Cr
-00000180: 6f77 6469 6e2d 5072 6f6a 6563 743a 2064  owdin-Project: d
-00000190: 7570 6c69 6369 7479 0a58 2d43 726f 7764  uplicity.X-Crowd
-000001a0: 696e 2d50 726f 6a65 6374 2d49 443a 2035  in-Project-ID: 5
-000001b0: 3339 3530 380a 582d 4372 6f77 6469 6e2d  39508.X-Crowdin-
-000001c0: 4c61 6e67 7561 6765 3a20 6e6c 2d53 520a  Language: nl-SR.
-000001d0: 582d 4372 6f77 6469 6e2d 4669 6c65 3a20  X-Crowdin-File: 
-000001e0: 2f6d 6169 6e2f 706f 2f64 7570 6c69 6369  /main/po/duplici
-000001f0: 7479 2e70 6f74 0a58 2d43 726f 7764 696e  ty.pot.X-Crowdin
-00000200: 2d46 696c 652d 4944 3a20 360a 00         -File-ID: 6..
+000000d0: 2d54 6561 6d3a 2053 6572 6269 616e 2028  -Team: Serbian (
+000000e0: 4379 7269 6c6c 6963 290a 4c61 6e67 7561  Cyrillic).Langua
+000000f0: 6765 3a20 7372 5f53 500a 4d49 4d45 2d56  ge: sr_SP.MIME-V
+00000100: 6572 7369 6f6e 3a20 312e 300a 436f 6e74  ersion: 1.0.Cont
+00000110: 656e 742d 5479 7065 3a20 7465 7874 2f70  ent-Type: text/p
+00000120: 6c61 696e 3b20 6368 6172 7365 743d 5554  lain; charset=UT
+00000130: 462d 380a 436f 6e74 656e 742d 5472 616e  F-8.Content-Tran
+00000140: 7366 6572 2d45 6e63 6f64 696e 673a 2038  sfer-Encoding: 8
+00000150: 6269 740a 506c 7572 616c 2d46 6f72 6d73  bit.Plural-Forms
+00000160: 3a20 6e70 6c75 7261 6c73 3d33 3b20 706c  : nplurals=3; pl
+00000170: 7572 616c 3d28 6e25 3130 3d3d 3120 2626  ural=(n%10==1 &&
+00000180: 206e 2531 3030 213d 3131 203f 2030 203a   n%100!=11 ? 0 :
+00000190: 206e 2531 303e 3d32 2026 2620 6e25 3130   n%10>=2 && n%10
+000001a0: 3c3d 3420 2626 2028 6e25 3130 303c 3130  <=4 && (n%100<10
+000001b0: 207c 7c20 6e25 3130 303e 3d32 3029 203f   || n%100>=20) ?
+000001c0: 2031 203a 2032 293b 0a58 2d43 726f 7764   1 : 2);.X-Crowd
+000001d0: 696e 2d50 726f 6a65 6374 3a20 6475 706c  in-Project: dupl
+000001e0: 6963 6974 790a 582d 4372 6f77 6469 6e2d  icity.X-Crowdin-
+000001f0: 5072 6f6a 6563 742d 4944 3a20 3533 3935  Project-ID: 5395
+00000200: 3038 0a58 2d43 726f 7764 696e 2d4c 616e  08.X-Crowdin-Lan
+00000210: 6775 6167 653a 2073 720a 582d 4372 6f77  guage: sr.X-Crow
+00000220: 6469 6e2d 4669 6c65 3a20 2f6d 6169 6e2f  din-File: /main/
+00000230: 706f 2f64 7570 6c69 6369 7479 2e70 6f74  po/duplicity.pot
+00000240: 0a58 2d43 726f 7764 696e 2d46 696c 652d  .X-Crowdin-File-
+00000250: 4944 3a20 360a 00                        ID: 6..
```

### Comparing `duplicity-1.2.3.dev43/po/ru_RU/duplicity.mo` & `duplicity-2.0.0rc0/po/ru_UA/duplicity.mo`

 * *Files 2% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,24 +1,24 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
-"Language-Team: Russian\n"
-"Language: ru_RU\n"
+"Language-Team: Rսssian, Սkraine\n"
+"Language: ru_UA\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 "
 "&& n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 "
 "&& n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: ru\n"
+"X-Crowdin-Language: ru-UA\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 msgid "%s not found in archive - no files restored."
 msgstr "%s не найден в архиве, нет восстановленных файлов."
 
 msgid "A %s"
```

### Comparing `duplicity-1.2.3.dev43/po/ru_BY.po` & `duplicity-2.0.0rc0/po/ru_BY.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Russian, Belarus\n"
 "Language: ru_BY\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 && n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 && n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index не соответствует"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Хэши не совпадают"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Внимание: пропуск ошибки, как было обозначено в запросе: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Не удалось подключиться, проверьте пароль: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "путь"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "имя файла"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "время"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "параметры"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Выполнение в режиме 'пропуска ошибок' в связи с %s; пожалуйста, пересмотрите решение, если это не было намерением"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "количество"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "название резервной копии"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "команда"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "секунды"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "символ"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Использование каталога архива: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Использование наименования резервной копии: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Ошибка в командной строке: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Введите  'duplicity --help' для экрана справки."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "полный_путь"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "псевдоним"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "количество"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "каталог"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "модуль"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "пароль"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "порт"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "префикс"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "относительный_путь"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "некоторый_каталог"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "пользователь"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "удалённая"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Заглушки и формат их URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Команды:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Заданная папка архива '%s' не существует или не является папкой"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Каталог в который предназначено восстановление %s уже существует.\n"
 "Замена не будет произведена."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Убедитесь, что папка %s не существует"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Папка источника резервной копии %s не существует."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Предупреждение командной строки: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Параметры выбора --exclude/--include\n"
 "в настоящее время работают только для резервного копирования, не для восстановления."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Недопустимая адресная ссылка URL '%s'.\n"
 "Например: \"scp://user@host.net:1234/path\" и\n"
 "\"file:///usr/local\".  Для получения дополнительных сведений обратитесь в руководству (man)."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Главное действие: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1281,243 +1293,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Критическая ошибка: отсутствуют манифесты для недавней резервной копии"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Критическая ошибка: Удалённый манифест не соответствует локальному. Неисправен удалённый набор резервного копирования или папка локального архива."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Критическая ошибка: Нет доступа к чтению удалённого и локального манифеста."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Предпочтение набора резервного копирования вместо предыдущего!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Пропуск инкрементального  набора резервного копирования (время_запуска: %s; необходимо: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Добавлена пошаговая резервная копия (время_начала: %s / время_конца: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Цепочка начата: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Цепочка завершена: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Количество содержащихся наборов резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Общее число содержащихся томов: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Тип резервной копии:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Время:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Число томов:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Полная"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Пошаговая"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "Локальная"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Состояние сбора"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Соединение с внутренним интерфейсом: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Папка архива: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Вторичная цепочка %d из %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Найдена первичная цепочка резервного копирования с соответствующей цепочкой подписи:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Отсутствуют цепочки резервного копирования с найденными, задействованными подписями"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Это может быть удалено с помощью запуска duplicity с командой \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Отсутствуют изолированные или неполные наборы резервного копирования."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Внимание, отозван последний набор резервного копирования, в связи с отсутствием файла подписи."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Внимание, найдены подписи, которые не соответствуют с файлами резервной копии"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Внимание, обнаружены незавершённые наборы резервных копий, возможно они остались от прерванного сеанса"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Извлечение цепочек резервного копирования из списка файлов: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Файл %s является частью известного набора"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Файл %s не является частью известного набора; создаётся новый набор"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Пропуск файла (отклонено набором резервного копирования) '%s'"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Найдена резервная копия %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Добавление набора %s для ранее существующей цепочки %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Обнаружен изолированный набор %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Файл: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Общее количество резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Тип изменения файла:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Внесение изменений в %s"
```

### Comparing `duplicity-1.2.3.dev43/po/ca_ES/duplicity.mo` & `duplicity-2.0.0rc0/po/da_DK/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 8% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 c801 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 c701 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 370a 4c61 7374 2d54 7261 6e73  19:47.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2043 6174 616c 616e 0a4c  -Team: Catalan.L
-000000e0: 616e 6775 6167 653a 2063 615f 4553 0a4d  anguage: ca_ES.M
-000000f0: 494d 452d 5665 7273 696f 6e3a 2031 2e30  IME-Version: 1.0
-00000100: 0a43 6f6e 7465 6e74 2d54 7970 653a 2074  .Content-Type: t
-00000110: 6578 742f 706c 6169 6e3b 2063 6861 7273  ext/plain; chars
-00000120: 6574 3d55 5446 2d38 0a43 6f6e 7465 6e74  et=UTF-8.Content
-00000130: 2d54 7261 6e73 6665 722d 456e 636f 6469  -Transfer-Encodi
-00000140: 6e67 3a20 3862 6974 0a50 6c75 7261 6c2d  ng: 8bit.Plural-
-00000150: 466f 726d 733a 206e 706c 7572 616c 733d  Forms: nplurals=
-00000160: 323b 2070 6c75 7261 6c3d 286e 2021 3d20  2; plural=(n != 
-00000170: 3129 3b0a 582d 4372 6f77 6469 6e2d 5072  1);.X-Crowdin-Pr
-00000180: 6f6a 6563 743a 2064 7570 6c69 6369 7479  oject: duplicity
-00000190: 0a58 2d43 726f 7764 696e 2d50 726f 6a65  .X-Crowdin-Proje
-000001a0: 6374 2d49 443a 2035 3339 3530 380a 582d  ct-ID: 539508.X-
-000001b0: 4372 6f77 6469 6e2d 4c61 6e67 7561 6765  Crowdin-Language
-000001c0: 3a20 6361 0a58 2d43 726f 7764 696e 2d46  : ca.X-Crowdin-F
-000001d0: 696c 653a 202f 6d61 696e 2f70 6f2f 6475  ile: /main/po/du
-000001e0: 706c 6963 6974 792e 706f 740a 582d 4372  plicity.pot.X-Cr
-000001f0: 6f77 6469 6e2d 4669 6c65 2d49 443a 2036  owdin-File-ID: 6
-00000200: 0a00                                     ..
+000000d0: 2d54 6561 6d3a 2044 616e 6973 680a 4c61  -Team: Danish.La
+000000e0: 6e67 7561 6765 3a20 6461 5f44 4b0a 4d49  nguage: da_DK.MI
+000000f0: 4d45 2d56 6572 7369 6f6e 3a20 312e 300a  ME-Version: 1.0.
+00000100: 436f 6e74 656e 742d 5479 7065 3a20 7465  Content-Type: te
+00000110: 7874 2f70 6c61 696e 3b20 6368 6172 7365  xt/plain; charse
+00000120: 743d 5554 462d 380a 436f 6e74 656e 742d  t=UTF-8.Content-
+00000130: 5472 616e 7366 6572 2d45 6e63 6f64 696e  Transfer-Encodin
+00000140: 673a 2038 6269 740a 506c 7572 616c 2d46  g: 8bit.Plural-F
+00000150: 6f72 6d73 3a20 6e70 6c75 7261 6c73 3d32  orms: nplurals=2
+00000160: 3b20 706c 7572 616c 3d28 6e20 213d 2031  ; plural=(n != 1
+00000170: 293b 0a58 2d43 726f 7764 696e 2d50 726f  );.X-Crowdin-Pro
+00000180: 6a65 6374 3a20 6475 706c 6963 6974 790a  ject: duplicity.
+00000190: 582d 4372 6f77 6469 6e2d 5072 6f6a 6563  X-Crowdin-Projec
+000001a0: 742d 4944 3a20 3533 3935 3038 0a58 2d43  t-ID: 539508.X-C
+000001b0: 726f 7764 696e 2d4c 616e 6775 6167 653a  rowdin-Language:
+000001c0: 2064 610a 582d 4372 6f77 6469 6e2d 4669   da.X-Crowdin-Fi
+000001d0: 6c65 3a20 2f6d 6169 6e2f 706f 2f64 7570  le: /main/po/dup
+000001e0: 6c69 6369 7479 2e70 6f74 0a58 2d43 726f  licity.pot.X-Cro
+000001f0: 7764 696e 2d46 696c 652d 4944 3a20 360a  wdin-File-ID: 6.
+00000200: 00                                       .
```

### Comparing `duplicity-1.2.3.dev43/po/sr_SP.po` & `duplicity-2.0.0rc0/po/ro_RO.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
-"Language-Team: Serbian (Cyrillic)\n"
-"Language: sr_SP\n"
+"Language-Team: Romanian\n"
+"Language: ro_RO\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
-"Plural-Forms: nplurals=3; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && n%10<=4 && (n%100<10 || n%100>=20) ? 1 : 2);\n"
+"Plural-Forms: nplurals=3; plural=(n==1 ? 0 : (n==0 || (n%100>0 && n%100<20)) ? 1 : 2);\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: sr\n"
+"X-Crowdin-Language: ro\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 #: ../bin/duplicity:106
 msgid "INT intercepted...exiting."
 msgstr ""
 
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/zh_TW.po` & `duplicity-2.0.0rc0/po/zh_TW.po`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Chinese Traditional\n"
 "Language: zh_TW\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/ru_UA.po` & `duplicity-2.0.0rc0/po/ru_UA.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
-"Language-Team: Russian, Ukraine\n"
+"Language-Team: Rսssian, Սkraine\n"
 "Language: ru_UA\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 && n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 && n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index не соответствует"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Хэши не совпадают"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Внимание: пропуск ошибки, как было обозначено в запросе: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Не удалось подключиться, проверьте пароль: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "путь"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "имя файла"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "время"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "параметры"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Выполнение в режиме 'пропуска ошибок' в связи с %s; пожалуйста, пересмотрите решение, если это не было намерением"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "количество"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "название резервной копии"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "команда"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "секунды"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "символ"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Использование каталога архива: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Использование наименования резервной копии: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Ошибка в командной строке: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Введите  'duplicity --help' для экрана справки."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "полный_путь"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "псевдоним"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "количество"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "каталог"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "модуль"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "пароль"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "порт"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "префикс"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "относительный_путь"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "некоторый_каталог"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "пользователь"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "удалённая"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Заглушки и формат их URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Команды:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Заданная папка архива '%s' не существует или не является папкой"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Каталог в который предназначено восстановление %s уже существует.\n"
 "Замена не будет произведена."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Убедитесь, что папка %s не существует"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Папка источника резервной копии %s не существует."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Предупреждение командной строки: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Параметры выбора --exclude/--include\n"
 "в настоящее время работают только для резервного копирования, не для восстановления."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Недопустимая адресная ссылка URL '%s'.\n"
 "Например: \"scp://user@host.net:1234/path\" и\n"
 "\"file:///usr/local\".  Для получения дополнительных сведений обратитесь в руководству (man)."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Главное действие: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1281,243 +1293,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Критическая ошибка: отсутствуют манифесты для недавней резервной копии"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Критическая ошибка: Удалённый манифест не соответствует локальному. Неисправен удалённый набор резервного копирования или папка локального архива."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Критическая ошибка: Нет доступа к чтению удалённого и локального манифеста."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Предпочтение набора резервного копирования вместо предыдущего!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Пропуск инкрементального  набора резервного копирования (время_запуска: %s; необходимо: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Добавлена пошаговая резервная копия (время_начала: %s / время_конца: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Цепочка начата: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Цепочка завершена: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Количество содержащихся наборов резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Общее число содержащихся томов: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Тип резервной копии:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Время:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Число томов:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Полная"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Пошаговая"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "Локальная"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Состояние сбора"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Соединение с внутренним интерфейсом: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Папка архива: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Вторичная цепочка %d из %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Найдена первичная цепочка резервного копирования с соответствующей цепочкой подписи:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Отсутствуют цепочки резервного копирования с найденными, задействованными подписями"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Это может быть удалено с помощью запуска duplicity с командой \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Отсутствуют изолированные или неполные наборы резервного копирования."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Внимание, отозван последний набор резервного копирования, в связи с отсутствием файла подписи."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Внимание, найдены подписи, которые не соответствуют с файлами резервной копии"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Внимание, обнаружены незавершённые наборы резервных копий, возможно они остались от прерванного сеанса"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Извлечение цепочек резервного копирования из списка файлов: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Файл %s является частью известного набора"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Файл %s не является частью известного набора; создаётся новый набор"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Пропуск файла (отклонено набором резервного копирования) '%s'"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Найдена резервная копия %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Добавление набора %s для ранее существующей цепочки %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Обнаружен изолированный набор %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Файл: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Общее количество резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Тип изменения файла:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Внесение изменений в %s"
```

### Comparing `duplicity-1.2.3.dev43/po/ko_KR/duplicity.mo` & `duplicity-2.0.0rc0/po/ko_KR/duplicity.mo`

 * *Files 2% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Korean\n"
 "Language: ko_KR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
```

### Comparing `duplicity-1.2.3.dev43/po/en_AU.po` & `duplicity-2.0.0rc0/po/en_AU.po`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: English, Australia\n"
 "Language: en_AU\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1262,243 +1274,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/fi_FI/duplicity.mo` & `duplicity-2.0.0rc0/po/fi_FI/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 4% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2046 696e 6e69 7368 0a4c  -Team: Finnish.L
 000000e0: 616e 6775 6167 653a 2066 695f 4649 0a4d  anguage: fi_FI.M
 000000f0: 494d 452d 5665 7273 696f 6e3a 2031 2e30  IME-Version: 1.0
 00000100: 0a43 6f6e 7465 6e74 2d54 7970 653a 2074  .Content-Type: t
 00000110: 6578 742f 706c 6169 6e3b 2063 6861 7273  ext/plain; chars
 00000120: 6574 3d55 5446 2d38 0a43 6f6e 7465 6e74  et=UTF-8.Content
```

### Comparing `duplicity-1.2.3.dev43/po/uk_UA.po` & `duplicity-2.0.0rc0/po/uk_UA.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Ukrainian\n"
 "Language: uk_UA\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 && n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 && n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index не відповідає"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Хеші не збігаються"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "GNORED_ERROR: Увага: пропуск помилки, як було позначено у запиті: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Не вдалося під’єднатися, перевірте пароль: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "шлях"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "ім'я файлу"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "час"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "параметри"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Виконання у режимі 'ігнорування помилок' у зв’язку з %s; будь-ласка, перегляньте рішення, якщо це не було наміром"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "кількість"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "назва резервної копії"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "команда"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "секунди"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "символ"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Використання каталогу архіву: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Використання назви резервної копії: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Помилка у командному рядку: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Уведіть 'duplicity --help' для екрану довідки."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "повний_шлях"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "псевдонім"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "кількість"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "каталог"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "модуль"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "Пароль"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "порт"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "префікс"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "відносний_шлях"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "деякі_бібліотеки"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "джерельні_бібліотеки"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "джерельна_url"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "каталог_призначення"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_призначення"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "користувач"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "віддалено"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Заглушки та формат їх URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Команди:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Вказана тека архіву '%s' не існує або не є текою"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Каталог у який призначене відновлення %s вже існує.\n"
 "Заміну не буде проведено."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Переконайтеся, що теки %s не існує"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Теки джерела резервної копії %s не існує."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Попередження командного рядка: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Параметри вибору --exclude/--include\n"
 "на даний час працюють лише для резервного копіювання, не для відновлення."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Неприпустиме адресне посилання URL '%s'.\n"
 "Наприклад: \"scp://user@host.net:1234/path\" й\n"
 "\"file:///usr/local\". Для отримання додаткової інформації зверніться до керівництва (man)."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Основна дія: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1281,243 +1293,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: відсутній %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Фатальна помилка: відсутні маніфести для недавньої резервної копії"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Фатальна помилка: Вилучений маніфест не відповідає локальному. Несправний віддалений набір резервного копіювання або тека локального архіву."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Фатальна помилка: Немає доступу до читання віддаленого та локального маніфесту."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Перевага набору резервного копіювання замість попереднього!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ігнорування інкрементального набору резервного копіювання (час_запуску: %s; необхідно: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Додано покрокову резервну копію (час_початку: %s / час_кінця: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Ланцюжок почато: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Ланцюжок закінчено: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Кількість  наборів резервного копіювання що містяться: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Загальне число томів що містяться: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Тип резервної копії:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Час:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Число томів:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Повна"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Покрокова"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "місцева"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Стан збору"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "З’єднання з внутрішнім інтерфейсом: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Тека архіву: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Вторинний ланцюжок %d з %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Знайдено первинний ланцюжок резервного копіювання з відповідним ланцюжком підпису:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Відсутні ланцюжки резервного копіювання зі знайденими, залученими підписами"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Це може бути вилучено за допомогою запуску duplicity з командою \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Відсутні ізольовані або неповні набори резервного копіювання."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Увага, відкликано останній набір резервного копіювання, у зв’язку з відсутністю файлу підпису."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Увага, знайдено підписи, які не відповідають файлам резервної копії"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Увага, знайдено незакінчені набори резервних копій, можливо вони залишилися від перерваного сеансу"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Витягнення ланцюжків резервного копіювання зі списку файлів: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Файл %s є частиною відомого набору"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Файл %s не є частиною відомого набору; створюється новий набір"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ігнорування файлу (відхилено набором резервного копіювання) '%s'"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Знайдено резервну копію %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Додавання набору %s для раніше існуючого ланцюжка %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Знайдено ізольований набір %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Файл: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Тип змінення файлу:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Внесення змін у %s"
```

### Comparing `duplicity-1.2.3.dev43/po/POTFILES.in` & `duplicity-2.0.0rc0/po/POTFILES.in`

 * *Files 1% similar despite different names*

```diff
@@ -42,14 +42,15 @@
 duplicity/backends/onedrivebackend.py
 duplicity/backends/hubicbackend.py
 duplicity/backends/dpbxbackend.py
 duplicity/backends/s3_boto3_backend.py
 duplicity/backends/idrivedbackend.py
 duplicity/backends/b2backend.py
 duplicity/backends/azurebackend.py
+duplicity/backends/xorrisobackend.py
 duplicity/backends/rsyncbackend.py
 duplicity/backends/pyrax_identity/__init__.py
 duplicity/backends/pyrax_identity/hubic.py
 duplicity/backends/lftpbackend.py
 duplicity/backends/webdavbackend.py
 duplicity/globmatch.py
 duplicity/__init__.py
```

### Comparing `duplicity-1.2.3.dev43/po/sr_SP/duplicity.mo` & `duplicity-2.0.0rc0/po/ro_RO/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 18% similar despite different names*

```diff
@@ -1,38 +1,35 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 1d02 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 f501 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2053 6572 6269 616e 2028  -Team: Serbian (
-000000e0: 4379 7269 6c6c 6963 290a 4c61 6e67 7561  Cyrillic).Langua
-000000f0: 6765 3a20 7372 5f53 500a 4d49 4d45 2d56  ge: sr_SP.MIME-V
-00000100: 6572 7369 6f6e 3a20 312e 300a 436f 6e74  ersion: 1.0.Cont
-00000110: 656e 742d 5479 7065 3a20 7465 7874 2f70  ent-Type: text/p
-00000120: 6c61 696e 3b20 6368 6172 7365 743d 5554  lain; charset=UT
-00000130: 462d 380a 436f 6e74 656e 742d 5472 616e  F-8.Content-Tran
-00000140: 7366 6572 2d45 6e63 6f64 696e 673a 2038  sfer-Encoding: 8
-00000150: 6269 740a 506c 7572 616c 2d46 6f72 6d73  bit.Plural-Forms
-00000160: 3a20 6e70 6c75 7261 6c73 3d33 3b20 706c  : nplurals=3; pl
-00000170: 7572 616c 3d28 6e25 3130 3d3d 3120 2626  ural=(n%10==1 &&
-00000180: 206e 2531 3030 213d 3131 203f 2030 203a   n%100!=11 ? 0 :
-00000190: 206e 2531 303e 3d32 2026 2620 6e25 3130   n%10>=2 && n%10
-000001a0: 3c3d 3420 2626 2028 6e25 3130 303c 3130  <=4 && (n%100<10
-000001b0: 207c 7c20 6e25 3130 303e 3d32 3029 203f   || n%100>=20) ?
-000001c0: 2031 203a 2032 293b 0a58 2d43 726f 7764   1 : 2);.X-Crowd
-000001d0: 696e 2d50 726f 6a65 6374 3a20 6475 706c  in-Project: dupl
-000001e0: 6963 6974 790a 582d 4372 6f77 6469 6e2d  icity.X-Crowdin-
-000001f0: 5072 6f6a 6563 742d 4944 3a20 3533 3935  Project-ID: 5395
-00000200: 3038 0a58 2d43 726f 7764 696e 2d4c 616e  08.X-Crowdin-Lan
-00000210: 6775 6167 653a 2073 720a 582d 4372 6f77  guage: sr.X-Crow
-00000220: 6469 6e2d 4669 6c65 3a20 2f6d 6169 6e2f  din-File: /main/
-00000230: 706f 2f64 7570 6c69 6369 7479 2e70 6f74  po/duplicity.pot
-00000240: 0a58 2d43 726f 7764 696e 2d46 696c 652d  .X-Crowdin-File-
-00000250: 4944 3a20 360a 00                        ID: 6..
+000000d0: 2d54 6561 6d3a 2052 6f6d 616e 6961 6e0a  -Team: Romanian.
+000000e0: 4c61 6e67 7561 6765 3a20 726f 5f52 4f0a  Language: ro_RO.
+000000f0: 4d49 4d45 2d56 6572 7369 6f6e 3a20 312e  MIME-Version: 1.
+00000100: 300a 436f 6e74 656e 742d 5479 7065 3a20  0.Content-Type: 
+00000110: 7465 7874 2f70 6c61 696e 3b20 6368 6172  text/plain; char
+00000120: 7365 743d 5554 462d 380a 436f 6e74 656e  set=UTF-8.Conten
+00000130: 742d 5472 616e 7366 6572 2d45 6e63 6f64  t-Transfer-Encod
+00000140: 696e 673a 2038 6269 740a 506c 7572 616c  ing: 8bit.Plural
+00000150: 2d46 6f72 6d73 3a20 6e70 6c75 7261 6c73  -Forms: nplurals
+00000160: 3d33 3b20 706c 7572 616c 3d28 6e3d 3d31  =3; plural=(n==1
+00000170: 203f 2030 203a 2028 6e3d 3d30 207c 7c20   ? 0 : (n==0 || 
+00000180: 286e 2531 3030 3e30 2026 2620 6e25 3130  (n%100>0 && n%10
+00000190: 303c 3230 2929 203f 2031 203a 2032 293b  0<20)) ? 1 : 2);
+000001a0: 0a58 2d43 726f 7764 696e 2d50 726f 6a65  .X-Crowdin-Proje
+000001b0: 6374 3a20 6475 706c 6963 6974 790a 582d  ct: duplicity.X-
+000001c0: 4372 6f77 6469 6e2d 5072 6f6a 6563 742d  Crowdin-Project-
+000001d0: 4944 3a20 3533 3935 3038 0a58 2d43 726f  ID: 539508.X-Cro
+000001e0: 7764 696e 2d4c 616e 6775 6167 653a 2072  wdin-Language: r
+000001f0: 6f0a 582d 4372 6f77 6469 6e2d 4669 6c65  o.X-Crowdin-File
+00000200: 3a20 2f6d 6169 6e2f 706f 2f64 7570 6c69  : /main/po/dupli
+00000210: 6369 7479 2e70 6f74 0a58 2d43 726f 7764  city.pot.X-Crowd
+00000220: 696e 2d46 696c 652d 4944 3a20 360a 00    in-File-ID: 6..
```

### Comparing `duplicity-1.2.3.dev43/po/de_DE/duplicity.mo` & `duplicity-2.0.0rc0/po/de_DE/duplicity.mo`

 * *Files 1% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: German\n"
 "Language: de_DE\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/de_AT/duplicity.mo` & `duplicity-2.0.0rc0/po/de_AT/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: German, Austria\n"
 "Language: de_AT\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/ru_RU.po` & `duplicity-2.0.0rc0/po/ru_MD.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
-"Language-Team: Russian\n"
-"Language: ru_RU\n"
+"Language-Team: Russian, Moldova\n"
+"Language: ru_MD\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 && n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 && n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: ru\n"
+"X-Crowdin-Language: ru-MD\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 #: ../bin/duplicity:106
 msgid "INT intercepted...exiting."
 msgstr "Перехват INT...выполняется выход."
 
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index не соответствует"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Хэши не совпадают"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Внимание: пропуск ошибки, как было обозначено в запросе: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Не удалось подключиться, проверьте пароль: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "путь"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "имя файла"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "время"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "параметры"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Выполнение в режиме 'пропуска ошибок' в связи с %s; пожалуйста, пересмотрите решение, если это не было намерением"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "количество"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "название резервной копии"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "команда"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "секунды"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "символ"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Использование каталога архива: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Использование наименования резервной копии: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Ошибка в командной строке: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Введите  'duplicity --help' для экрана справки."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "полный_путь"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "псевдоним"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "количество"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "каталог"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "модуль"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "пароль"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "порт"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "префикс"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "относительный_путь"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "некоторый_каталог"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "пользователь"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "удалённая"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Заглушки и формат их URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Команды:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Заданная папка архива '%s' не существует или не является папкой"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Каталог в который предназначено восстановление %s уже существует.\n"
 "Замена не будет произведена."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Убедитесь, что папка %s не существует"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Папка источника резервной копии %s не существует."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Предупреждение командной строки: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Параметры выбора --exclude/--include\n"
 "в настоящее время работают только для резервного копирования, не для восстановления."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Недопустимая адресная ссылка URL '%s'.\n"
 "Например: \"scp://user@host.net:1234/path\" и\n"
 "\"file:///usr/local\".  Для получения дополнительных сведений обратитесь в руководству (man)."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Главное действие: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1281,243 +1293,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Критическая ошибка: отсутствуют манифесты для недавней резервной копии"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Критическая ошибка: Удалённый манифест не соответствует локальному. Неисправен удалённый набор резервного копирования или папка локального архива."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Критическая ошибка: Нет доступа к чтению удалённого и локального манифеста."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Предпочтение набора резервного копирования вместо предыдущего!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Пропуск инкрементального  набора резервного копирования (время_запуска: %s; необходимо: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Добавлена пошаговая резервная копия (время_начала: %s / время_конца: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Цепочка начата: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Цепочка завершена: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Количество содержащихся наборов резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Общее число содержащихся томов: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Тип резервной копии:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Время:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Число томов:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Полная"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Пошаговая"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "Локальная"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Состояние сбора"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Соединение с внутренним интерфейсом: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Папка архива: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Вторичная цепочка %d из %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Найдена первичная цепочка резервного копирования с соответствующей цепочкой подписи:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Отсутствуют цепочки резервного копирования с найденными, задействованными подписями"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Это может быть удалено с помощью запуска duplicity с командой \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Отсутствуют изолированные или неполные наборы резервного копирования."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Внимание, отозван последний набор резервного копирования, в связи с отсутствием файла подписи."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Внимание, найдены подписи, которые не соответствуют с файлами резервной копии"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Внимание, обнаружены незавершённые наборы резервных копий, возможно они остались от прерванного сеанса"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Извлечение цепочек резервного копирования из списка файлов: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Файл %s является частью известного набора"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Файл %s не является частью известного набора; создаётся новый набор"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Пропуск файла (отклонено набором резервного копирования) '%s'"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Найдена резервная копия %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Добавление набора %s для ранее существующей цепочки %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Обнаружен изолированный набор %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Файл: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Общее количество резервного копирования: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Тип изменения файла:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Внесение изменений в %s"
```

### Comparing `duplicity-1.2.3.dev43/po/sv_SE/duplicity.mo` & `duplicity-2.0.0rc0/po/sv_SE/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Swedish\n"
 "Language: sv_SE\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/fr_FR.po` & `duplicity-2.0.0rc0/po/fr_FR.po`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: French\n"
 "Language: fr_FR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n > 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "les indices_de_fin ne correspondent pas"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Les empreintes ne correspondent pas"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "ERREUR_IGNORÉE : attention : ignore l'erreur comme demandé : %s : %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Libération du fichier de verrouillage %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MultiBackend : la supression de %s a échoué. Essais faits dans tous les magasins de sauvegarde, aucun n'a réussi"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Connexion échouée, veuillez vérifier votre mot de passe : %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "chemin"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "identifiant_clé_gpg"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nom_de_fichier"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "expression_régulière"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "temps"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Exécution en mode « ignorer les erreurs » à cause de %s ; veuillez reconsidérer si ceci n’était pas souhaité"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "nombre"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nom_sauvegarde"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "commande"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,242 +623,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "secondes"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "caract."
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Utilisation du répertoire d’archive : %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Utilisation du nom de sauvegarde : %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Erreur de ligne de commande : %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Entrez « duplicity --help » pour afficher l’écran d’aide."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "chemin_absolu"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nom_de_bucket"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nom_de_conteneur"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "compte"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "dossier"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "autre.hote"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "mot_de_passe"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "préfixe"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "chemin_relatif"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "dossier_quelconque"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "dossier_source"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_source"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "dossier_cible"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_cible"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "utilisateur"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "identifiant_de_compte"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "clef_d_application"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "distant"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Moteurs et leurs formats URL :"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Commandes :"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Le dossier d'archivage spécifié « %s » n'existe pas ou n'est pas un dossier"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "La clef de signature devrait être une chaîne hexadécimale de 8, 16 ou 40 caractères, comme « AA0E73D2 ».\n"
 "Au lieu de cela, la chaîne reçue était « %s »."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Le dossier de restauration cible %s existe déjà.\n"
 "Il ne sera pas écrasé."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Vérifier que le dossier %s n'existe pas"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Le dossier source de sauvegarde %s n'existe pas."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Avertissement de la ligne de commande : %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "L'option de sélection --exlude/--include\n"
 "ne fonctionne actuellement que lors d'une sauvegarde et non pas lors d'une restauration."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "Le binaire GPG est %s, version %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Mauvaise URL « %s ».\n"
 "Un exemple d'URL est : « scp://utilisateur@hote.net:1234/chemin » et\n"
 "« file:///usr/local ». Veuillez voir la page de manuel pour plus d'informations."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Action principale : "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1286,243 +1298,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete : %s manquant"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Erreur fatale : aucun fichier manifest présent pour la sauvegarde la plus récente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Erreur fatale : le fichier manifest distant ne correspond pas à celui en local. Soit le jeu de sauvegarde distant, soit le dossier local d’archive a été corrompu."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Erreur fatale : ni le fichier manifest local, ni le distant ne sont lisibles."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Traitement du manifeste local %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Traitement du manifeste distant %s(%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Jeu de sauvegarde préféré au précédent !"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignore le jeu de sauvegarde incrémentale (date_début : %s ; nécessaire : %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Jeu de sauvegarde incrémentale ajouté (date_début : %s ; date_fin : %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Date de début de chaîne : "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Date de fin de chaîne : "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Nombre de jeux de sauvegarde contenus : %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Nombre total de volumes contenus : %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Type de jeu de sauvegarde :"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Date :"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Nombre de volumes :"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Complète"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Incrémentale"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "État de la collection"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Connexion au serveur central : %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Dossier d’archive : %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Chaîne secondaire %d sur %d :"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Chaîne primaire de sauvegarde trouvée avec la signature de chaîne correspondante :"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Aucune chaîne de sauvegarde avec les signatures actives n’a été trouvée"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Ceux-ci peuvent être supprimés en exécutant duplicity avec la commande « cleanup »."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Aucun jeu orphelin ou incomplet de sauvegarde n’a été trouvé."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Avertissement, rejet du dernier jeu de sauvegarde à cause de l’absence du fichier de signatures."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Avertissement, signatures trouvées mais aucun fichier de sauvegarde correspondant"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Avertissement, jeux de sauvegarde incomplets trouvés, probablement laissés par des sessions interrompues"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Extraction des chaînes de sauvegarde depuis la liste des fichiers : %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Le fichier %s fait partie d’un jeu connu"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Le fichier %s ne fait pas partie d’un jeu connu ; création d’un nouveau jeu"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Fichier ignoré (rejeté par le jeu de sauvegarde) « %s »"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Chaîne de sauvegarde %s trouvée"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Jeu %s ajouté à la chaîne préexistante %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Jeu orphelin %s trouvé"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Fichier : %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Nombre total de sauvegardes : %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Type de changement de fichier :"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "En train de réparer %s"
```

### Comparing `duplicity-1.2.3.dev43/po/pt_PT.po` & `duplicity-2.0.0rc0/po/pt_PT.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Portuguese\n"
 "Language: pt_PT\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/ro_RO/duplicity.mo` & `duplicity-2.0.0rc0/po/en_PR/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 24% similar despite different names*

```diff
@@ -1,35 +1,34 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 f501 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 d801 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 370a 4c61 7374 2d54 7261 6e73  19:47.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a35 300a 4c61 7374 2d54 7261 6e73  14:50.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2052 6f6d 616e 6961 6e0a  -Team: Romanian.
-000000e0: 4c61 6e67 7561 6765 3a20 726f 5f52 4f0a  Language: ro_RO.
-000000f0: 4d49 4d45 2d56 6572 7369 6f6e 3a20 312e  MIME-Version: 1.
-00000100: 300a 436f 6e74 656e 742d 5479 7065 3a20  0.Content-Type: 
-00000110: 7465 7874 2f70 6c61 696e 3b20 6368 6172  text/plain; char
-00000120: 7365 743d 5554 462d 380a 436f 6e74 656e  set=UTF-8.Conten
-00000130: 742d 5472 616e 7366 6572 2d45 6e63 6f64  t-Transfer-Encod
-00000140: 696e 673a 2038 6269 740a 506c 7572 616c  ing: 8bit.Plural
-00000150: 2d46 6f72 6d73 3a20 6e70 6c75 7261 6c73  -Forms: nplurals
-00000160: 3d33 3b20 706c 7572 616c 3d28 6e3d 3d31  =3; plural=(n==1
-00000170: 203f 2030 203a 2028 6e3d 3d30 207c 7c20   ? 0 : (n==0 || 
-00000180: 286e 2531 3030 3e30 2026 2620 6e25 3130  (n%100>0 && n%10
-00000190: 303c 3230 2929 203f 2031 203a 2032 293b  0<20)) ? 1 : 2);
-000001a0: 0a58 2d43 726f 7764 696e 2d50 726f 6a65  .X-Crowdin-Proje
-000001b0: 6374 3a20 6475 706c 6963 6974 790a 582d  ct: duplicity.X-
-000001c0: 4372 6f77 6469 6e2d 5072 6f6a 6563 742d  Crowdin-Project-
-000001d0: 4944 3a20 3533 3935 3038 0a58 2d43 726f  ID: 539508.X-Cro
-000001e0: 7764 696e 2d4c 616e 6775 6167 653a 2072  wdin-Language: r
-000001f0: 6f0a 582d 4372 6f77 6469 6e2d 4669 6c65  o.X-Crowdin-File
-00000200: 3a20 2f6d 6169 6e2f 706f 2f64 7570 6c69  : /main/po/dupli
-00000210: 6369 7479 2e70 6f74 0a58 2d43 726f 7764  city.pot.X-Crowd
-00000220: 696e 2d46 696c 652d 4944 3a20 360a 00    in-File-ID: 6..
+000000d0: 2d54 6561 6d3a 2045 6e67 6c69 7368 2c20  -Team: English, 
+000000e0: 5075 6572 746f 2052 6963 6f0a 4c61 6e67  Puerto Rico.Lang
+000000f0: 7561 6765 3a20 656e 5f50 520a 4d49 4d45  uage: en_PR.MIME
+00000100: 2d56 6572 7369 6f6e 3a20 312e 300a 436f  -Version: 1.0.Co
+00000110: 6e74 656e 742d 5479 7065 3a20 7465 7874  ntent-Type: text
+00000120: 2f70 6c61 696e 3b20 6368 6172 7365 743d  /plain; charset=
+00000130: 5554 462d 380a 436f 6e74 656e 742d 5472  UTF-8.Content-Tr
+00000140: 616e 7366 6572 2d45 6e63 6f64 696e 673a  ansfer-Encoding:
+00000150: 2038 6269 740a 506c 7572 616c 2d46 6f72   8bit.Plural-For
+00000160: 6d73 3a20 6e70 6c75 7261 6c73 3d32 3b20  ms: nplurals=2; 
+00000170: 706c 7572 616c 3d28 6e20 213d 2031 293b  plural=(n != 1);
+00000180: 0a58 2d43 726f 7764 696e 2d50 726f 6a65  .X-Crowdin-Proje
+00000190: 6374 3a20 6475 706c 6963 6974 790a 582d  ct: duplicity.X-
+000001a0: 4372 6f77 6469 6e2d 5072 6f6a 6563 742d  Crowdin-Project-
+000001b0: 4944 3a20 3533 3935 3038 0a58 2d43 726f  ID: 539508.X-Cro
+000001c0: 7764 696e 2d4c 616e 6775 6167 653a 2065  wdin-Language: e
+000001d0: 6e2d 5052 0a58 2d43 726f 7764 696e 2d46  n-PR.X-Crowdin-F
+000001e0: 696c 653a 202f 6d61 696e 2f70 6f2f 6475  ile: /main/po/du
+000001f0: 706c 6963 6974 792e 706f 740a 582d 4372  plicity.pot.X-Cr
+00000200: 6f77 6469 6e2d 4669 6c65 2d49 443a 2036  owdin-File-ID: 6
+00000210: 0a00                                     ..
```

### Comparing `duplicity-1.2.3.dev43/po/ar_SA.po` & `duplicity-2.0.0rc0/po/ar_SA.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Arabic\n"
 "Language: ar_SA\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=6; plural=(n==0 ? 0 : n==1 ? 1 : n==2 ? 2 : n%100>=3 && n%100<=10 ? 3 : n%100>=11 && n%100<=99 ? 4 : 5);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/el_GR/duplicity.mo` & `duplicity-2.0.0rc0/po/el_GR/duplicity.mo`

 * *Files 1% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Greek\n"
 "Language: el_GR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/he_IL.po` & `duplicity-2.0.0rc0/po/he_IL.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Hebrew\n"
 "Language: he_IL\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=n%100==1 ? 0 : n%100==2 ? 1 : n%100==3 || n%100==4 ? 2 : 3;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/hu_HU.po` & `duplicity-2.0.0rc0/po/hu_HU.po`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Hungarian\n"
 "Language: hu_HU\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "A vég_mutatószám nem egyezik"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "A hash-ek nem egyeznek"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Figyelem: a hibát figyelmen kívül hagyom, ahogy kérted: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Kapcsolódás sikertelen, kérlek ellenőrizd a jelszót: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "útvonal"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr "gpg-kulcs-azon"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "állománynév"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "reguláris_kifejezés"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "időpont"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opciók"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "'Hibák figyelmen kívül hagyása' módban vagyunk, emiatt: %s; kérlek gondold át, ez volt-e a szándékod"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "szám"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "biztonsági mentés neve"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "parancs"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "másodpercek"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "kar"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Archívum-könyvtár: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Biztonsági mentés neve: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Parancssori hiba: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "A súgó megjeleníthető a következő parancssal: 'duplicity --help'."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "teljes_útvonal"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "száma"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "könyvtár"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "modul"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "egyéb.kiszolgáló"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "jelszó"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "relatív_útvonal"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "valami_könyvtár"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "forrás_könyvtár"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "forrás_url"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "cél_könyvtár"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "cél_url"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "felhasználó"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "távoli"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Tárhelyek és azok URL formátumai:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Parancsok:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "A megadott '%s' archív könyvtár nem létezik, vagy nem könyvtár"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "A visszaállításhoz kért %s könyvár már létezik.\n"
 "Nem írom felül."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Az ellenőrzéshez kért %s könyvtár nem létezik"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Biztonsági mentés %s forráskönyvtár nem létezik."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Parancssori figyelmetetés: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Az --exclude/--include állományválasztó opciók jelenleg csak \n"
 "biztonsági mentéshez használhatók, visszaállításhoz nem."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Rossz URL '%s'.\n"
 "Néhány példa-URL: \"scp://user@host.net:1234/path\" vagy\n"
 "\"file:///usr/local\". Olvass utána a \"man\" oldalon."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Fő művelet: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1281,243 +1293,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Súlyos hiba: A legutóbbi biztonsági mentéshez nem találtam bizonylatot"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Súlyos hiba:"
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Súlyos hiba: Sem a helyi, sem a távoli kimutatás nem olvasható."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Mentés-készlet előnyben részesítve az előzővel szemben!"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Növekményes készlet figyelmen kívül hagyása (kezdésidő: %s; ez kellene: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Növekményes biztonsági mentés hozzáadva (kezdésidő: %s; vége: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Lánc kezdődiő: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Lánc vége: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Tartalmazott biztonsági mentés készletek száma: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Összes tartalmazott köteg száma: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Biztonsági mentés készlet típusa:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Idő:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Kötegek száma:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Teljes"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Növekményes"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "helyi"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Gyűjtemény állapota"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Kapcsolódás a tárhelyhez: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Archívum könyvtár: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Mentés-lánc %d, összesen %d"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Találtam elsődleges mentés-láncot amire illik az aláíráslánc:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Nem találtam mentés-láncot aminek aktív aláírása lenne"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Ezeket le lehet törölni a duplicity \"cleanup\" parancsával."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Nem találtam elárvult vagy félkész biztonsági mentés készletet."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Figyelem, törlöm az utolsó mentés készletet, mert hiányzik az aláírás-állomány."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Figyelem, találtam aláírásokat, de nincs hozzátartozó mentés állomány"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Figyelem, találtam félkész mentés készleteket, valószínűleg egy előző mentés félbeszakadt"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Biztonsági mentés láncok kiemelése állománylistából: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "A %s állomány nem része bármely ismert készletnek"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "A %s állomány nem része bármely ismert készletnek; új készlet létrehozása"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Állomány kihagyása (mentés készlet utasította el) '%s'"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Megvan a biztonsági mentés lánc: %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "%s készletet hozzáadtam a már létező %s lánchoz"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Elárvult %s készletet találtam"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "%s foltozása (patch)"
```

### Comparing `duplicity-1.2.3.dev43/po/nl_BE.po` & `duplicity-2.0.0rc0/po/nl_BE.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Dutch, Belgium\n"
 "Language: nl_BE\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/en_AU/duplicity.mo` & `duplicity-2.0.0rc0/po/en_AU/duplicity.mo`

 * *Files 9% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: English, Australia\n"
 "Language: en_AU\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/zh_MO.po` & `duplicity-2.0.0rc0/po/zh_MO.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Chinese Traditional, Macau\n"
 "Language: zh_MO\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/tr_TR.po` & `duplicity-2.0.0rc0/po/tr_TR.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Turkish\n"
 "Language: tr_TR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "yol"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "dosyaadı"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "saat"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "seçenekler"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "yedek adı"
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "komut"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "saniyeler"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "karakter"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Kullanılan yedek adı: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Komut satırı hatası: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "dizin"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "modül"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "parola"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "bağlantı noktası"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "önek"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "kaynak_url"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "hedef_dir"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "hedef_url"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "kullanıcı"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "uzak"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Komutlar:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "%s doğrulama dizini yok"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Komut satırı uyarısı: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Tüm"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "yerel"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/da_DK/duplicity.mo` & `duplicity-2.0.0rc0/po/ca_ES/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 27% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 c701 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 c801 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 370a 4c61 7374 2d54 7261 6e73  19:47.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a34 390a 4c61 7374 2d54 7261 6e73  14:49.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2044 616e 6973 680a 4c61  -Team: Danish.La
-000000e0: 6e67 7561 6765 3a20 6461 5f44 4b0a 4d49  nguage: da_DK.MI
-000000f0: 4d45 2d56 6572 7369 6f6e 3a20 312e 300a  ME-Version: 1.0.
-00000100: 436f 6e74 656e 742d 5479 7065 3a20 7465  Content-Type: te
-00000110: 7874 2f70 6c61 696e 3b20 6368 6172 7365  xt/plain; charse
-00000120: 743d 5554 462d 380a 436f 6e74 656e 742d  t=UTF-8.Content-
-00000130: 5472 616e 7366 6572 2d45 6e63 6f64 696e  Transfer-Encodin
-00000140: 673a 2038 6269 740a 506c 7572 616c 2d46  g: 8bit.Plural-F
-00000150: 6f72 6d73 3a20 6e70 6c75 7261 6c73 3d32  orms: nplurals=2
-00000160: 3b20 706c 7572 616c 3d28 6e20 213d 2031  ; plural=(n != 1
-00000170: 293b 0a58 2d43 726f 7764 696e 2d50 726f  );.X-Crowdin-Pro
-00000180: 6a65 6374 3a20 6475 706c 6963 6974 790a  ject: duplicity.
-00000190: 582d 4372 6f77 6469 6e2d 5072 6f6a 6563  X-Crowdin-Projec
-000001a0: 742d 4944 3a20 3533 3935 3038 0a58 2d43  t-ID: 539508.X-C
-000001b0: 726f 7764 696e 2d4c 616e 6775 6167 653a  rowdin-Language:
-000001c0: 2064 610a 582d 4372 6f77 6469 6e2d 4669   da.X-Crowdin-Fi
-000001d0: 6c65 3a20 2f6d 6169 6e2f 706f 2f64 7570  le: /main/po/dup
-000001e0: 6c69 6369 7479 2e70 6f74 0a58 2d43 726f  licity.pot.X-Cro
-000001f0: 7764 696e 2d46 696c 652d 4944 3a20 360a  wdin-File-ID: 6.
-00000200: 00                                       .
+000000d0: 2d54 6561 6d3a 2043 6174 616c 616e 0a4c  -Team: Catalan.L
+000000e0: 616e 6775 6167 653a 2063 615f 4553 0a4d  anguage: ca_ES.M
+000000f0: 494d 452d 5665 7273 696f 6e3a 2031 2e30  IME-Version: 1.0
+00000100: 0a43 6f6e 7465 6e74 2d54 7970 653a 2074  .Content-Type: t
+00000110: 6578 742f 706c 6169 6e3b 2063 6861 7273  ext/plain; chars
+00000120: 6574 3d55 5446 2d38 0a43 6f6e 7465 6e74  et=UTF-8.Content
+00000130: 2d54 7261 6e73 6665 722d 456e 636f 6469  -Transfer-Encodi
+00000140: 6e67 3a20 3862 6974 0a50 6c75 7261 6c2d  ng: 8bit.Plural-
+00000150: 466f 726d 733a 206e 706c 7572 616c 733d  Forms: nplurals=
+00000160: 323b 2070 6c75 7261 6c3d 286e 2021 3d20  2; plural=(n != 
+00000170: 3129 3b0a 582d 4372 6f77 6469 6e2d 5072  1);.X-Crowdin-Pr
+00000180: 6f6a 6563 743a 2064 7570 6c69 6369 7479  oject: duplicity
+00000190: 0a58 2d43 726f 7764 696e 2d50 726f 6a65  .X-Crowdin-Proje
+000001a0: 6374 2d49 443a 2035 3339 3530 380a 582d  ct-ID: 539508.X-
+000001b0: 4372 6f77 6469 6e2d 4c61 6e67 7561 6765  Crowdin-Language
+000001c0: 3a20 6361 0a58 2d43 726f 7764 696e 2d46  : ca.X-Crowdin-F
+000001d0: 696c 653a 202f 6d61 696e 2f70 6f2f 6475  ile: /main/po/du
+000001e0: 706c 6963 6974 792e 706f 740a 582d 4372  plicity.pot.X-Cr
+000001f0: 6f77 6469 6e2d 4669 6c65 2d49 443a 2036  owdin-File-ID: 6
+00000200: 0a00                                     ..
```

### Comparing `duplicity-1.2.3.dev43/po/zh_MO/duplicity.mo` & `duplicity-2.0.0rc0/po/zh_MO/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 4% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a35 300a 4c61 7374 2d54 7261 6e73  14:50.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2043 6869 6e65 7365 2054  -Team: Chinese T
 000000e0: 7261 6469 7469 6f6e 616c 2c20 4d61 6361  raditional, Maca
 000000f0: 750a 4c61 6e67 7561 6765 3a20 7a68 5f4d  u.Language: zh_M
 00000100: 4f0a 4d49 4d45 2d56 6572 7369 6f6e 3a20  O.MIME-Version: 
 00000110: 312e 300a 436f 6e74 656e 742d 5479 7065  1.0.Content-Type
 00000120: 3a20 7465 7874 2f70 6c61 696e 3b20 6368  : text/plain; ch
```

### Comparing `duplicity-1.2.3.dev43/po/es_PR/duplicity.mo` & `duplicity-2.0.0rc0/po/es_PR/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Spanish, Puerto Rico\n"
 "Language: es_PR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/zh_SG/duplicity.mo` & `duplicity-2.0.0rc0/po/zh_SG/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 25% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a35 300a 4c61 7374 2d54 7261 6e73  14:50.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
 000000d0: 2d54 6561 6d3a 2043 6869 6e65 7365 2054  -Team: Chinese T
 000000e0: 7261 6469 7469 6f6e 616c 2c20 5369 6e67  raditional, Sing
 000000f0: 6170 6f72 650a 4c61 6e67 7561 6765 3a20  apore.Language: 
 00000100: 7a68 5f53 470a 4d49 4d45 2d56 6572 7369  zh_SG.MIME-Versi
 00000110: 6f6e 3a20 312e 300a 436f 6e74 656e 742d  on: 1.0.Content-
 00000120: 5479 7065 3a20 7465 7874 2f70 6c61 696e  Type: text/plain
```

### Comparing `duplicity-1.2.3.dev43/po/es_US.po` & `duplicity-2.0.0rc0/po/es_US.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Spanish, United States\n"
 "Language: es_US\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index no coinciden"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Hashes no coinciden"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Aviso: ignorando error tal como se pidió: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Publicando fichero de candado %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MultiBackend: falló al eliminar %s. Se probaron todos los almacenes de copias y ninguno funcionó"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Falló la conexión, compruebe su contraseña: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Faltan los módulos de Python «socket» o «ssl»."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "ruta"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nombre de archivo"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "expresión regular"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "hora"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opciones"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Ejecutando en modo «ignore errors» debido a %s; reconsidere esta opción si no es su intención"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "número"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nombre de respaldo"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "orden"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,242 +623,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "segundos"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "carácter"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Usando directorio de archivador: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Usando nombre de copia de seguridad: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Error de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Introduzca «duplicity --help» para tener ayuda en pantalla."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "ruta_absoluta"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nombre_cubo"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nombre_contenedor"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "recuento"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "directorio"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "módulo"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "otro.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "contraseña"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "puerto"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefijo"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "ruta_relativa"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "algun_dir"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "dir_origen"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_origen"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "dir_objetivo"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_objetivo"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "usuario"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "id_cuenta"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "clave_aplicación"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "remoto"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Motores y sus formatos de URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Órdenes:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "El directorio del archivador «%s» no existe, o no es un directorio"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "La clave de firma debería ser una cadena de 8, 16 o 40 caracteres hexadecimales , como «AA0E732D2».\n"
 "Se ha recibido «%s» en su lugar."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Restaurar directorio de destino %s ya existe.\n"
 "No sobrescribir."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "El directorio verificado %s no existe"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "El directorio de origen de respaldo %s no existe."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Aviso de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Las opciones de selección --exclude/--include\n"
 "actualmente funcionan solo cuando se respalda no al restaurar."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "El binario de GPG es %s, versión %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "URL erróneo «%s».\n"
 "Ejemplos de cadenas de URL son «scp://user@host.net:1234/path» \n"
 "y «file:///usr/local». Ver el manual para más información."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Acción principal: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "basis_file debe ser un archivo (verdadero) o un objeto cuyos atributos de archivo son el objeto del archivo verdadero subyacente"
 
@@ -1287,243 +1299,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: falta %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Error fatal: no se encontraron manifiestos para el respaldo más reciente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Error fatal: el manifiesto remoto no coincide con el local. Ni la configuración de copia de seguridad remota o el directorio del archivo local está dañado."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Error al procesar el manifiesto remoto (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Error fatal: ni el manifiesto remoto ni el local son legibles"
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Procesando manifiesto local %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Error al procesar el manifiesto remoto (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Procesando manifiesto remoto %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Preferir la configuración de copia de seguridad previa"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignorar la configuración de copia de seguridad incremental (start_time: %s; necesaria: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Añadida configuración de copia de seguridad incremental (start_time: %s / end_time: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Hora de inicio de la cadena: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Hora de terminación de la cadena: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Número de conjuntos de respaldo contenidos: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Número total de volúmenes contenidos: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Tipo de conjunto de respaldo"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Hora:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Número de volúmenes:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Completo"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Estado de la colección"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Conectar con el motor: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Directorio de archivador: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Cadena secundaria %d de %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Se encontró cadena de copia de seguridad primaria con cadena de firma coincidente:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "No encontró cadenas con firmas activas"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Esto se puede eliminar ejecutando duplicity con la orden «cleanup»"
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "No se han encontrado respaldos huérfanos o incompletos."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Aviso, descartando el último conjunto de respaldo, debido a la falta archivo de firma."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Aviso, se encontraron firmas pero no coinciden con los archivos de copia de seguridad"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Aviso, encontró conjuntos de copia de seguridad incompletos, probablemente de la sesión abortada"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Extrayendo cadenas de respaldo de la lista de archivos: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "El archivo %s es parte del conjunto conocido"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "El archivo %s no es parte de un conjunto conocido; creando un conjunto nuevo"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignorando archivo (rechazado por el conjunto) «%s»"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Se encontró una cadena de respaldo %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "conjunto %s añadido a la cadena %s preexistente"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Se encontró un conjunto huérfano %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "No hay cadena de firmas disponibles para la hora solicitada. Se está usando la cadena más antigua disponible, que comienza en %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Archivo: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Número total de copias de seguridad: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Tipo de cambio de archivo:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Parcheando %s"
```

### Comparing `duplicity-1.2.3.dev43/po/es_MX/duplicity.mo` & `duplicity-2.0.0rc0/po/es_MX/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Spanish, Mexico\n"
 "Language: es_MX\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/po/ru_MD/duplicity.mo` & `duplicity-2.0.0rc0/po/ru_RU/duplicity.mo`

 * *Files 2% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,24 +1,24 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-06-28 17:13\n"
 "Last-Translator: \n"
-"Language-Team: Russian, Moldova\n"
-"Language: ru_MD\n"
+"Language-Team: Russian\n"
+"Language: ru_RU\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=4; plural=((n%10==1 && n%100!=11) ? 0 : ((n%10 >= 2 "
 "&& n%10 <=4 && (n%100 < 12 || n%100 > 14)) ? 1 : ((n%10 == 0 || (n%10 >= 5 "
 "&& n%10 <=9)) || (n%100 >= 11 && n%100 <= 14)) ? 2 : 3));\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: ru-MD\n"
+"X-Crowdin-Language: ru\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 msgid "%s not found in archive - no files restored."
 msgstr "%s не найден в архиве, нет восстановленных файлов."
 
 msgid "A %s"
@@ -770,14 +770,17 @@
 
 msgid "password"
 msgstr "пароль"
 
 msgid "path"
 msgstr "путь"
 
+msgid "pattern"
+msgstr "паттерн"
+
 msgid "port"
 msgstr "порт"
 
 msgid "prefix"
 msgstr "префикс"
 
 msgid "relative_path"
```

### Comparing `duplicity-1.2.3.dev43/po/zh_SG.po` & `duplicity-2.0.0rc0/po/zh_SG.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Chinese Traditional, Singapore\n"
 "Language: zh_SG\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/es_MX.po` & `duplicity-2.0.0rc0/po/es_MX.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Spanish, Mexico\n"
 "Language: es_MX\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index no coinciden"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Hashes no coinciden"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Aviso: ignorando error tal como se pidió: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Publicando fichero de candado %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MultiBackend: falló al eliminar %s. Se probaron todos los almacenes de copias y ninguno funcionó"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Falló la conexión, compruebe su contraseña: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Faltan los módulos de Python «socket» o «ssl»."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "ruta"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nombre de archivo"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "expresión regular"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "hora"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opciones"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Ejecutando en modo «ignore errors» debido a %s; reconsidere esta opción si no es su intención"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "número"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nombre de respaldo"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "orden"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,242 +623,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "segundos"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "carácter"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Usando directorio de archivador: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Usando nombre de copia de seguridad: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Error de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Introduzca «duplicity --help» para tener ayuda en pantalla."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "ruta_absoluta"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nombre_cubo"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nombre_contenedor"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "recuento"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "directorio"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "módulo"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "otro.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "contraseña"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "puerto"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefijo"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "ruta_relativa"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "algun_dir"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "dir_origen"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_origen"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "dir_objetivo"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_objetivo"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "usuario"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "id_cuenta"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "clave_aplicación"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "remoto"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Motores y sus formatos de URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Órdenes:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "El directorio del archivador «%s» no existe, o no es un directorio"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "La clave de firma debería ser una cadena de 8, 16 o 40 caracteres hexadecimales , como «AA0E732D2».\n"
 "Se ha recibido «%s» en su lugar."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Restaurar directorio de destino %s ya existe.\n"
 "No sobrescribir."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "El directorio verificado %s no existe"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "El directorio de origen de respaldo %s no existe."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Aviso de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Las opciones de selección --exclude/--include\n"
 "actualmente funcionan solo cuando se respalda no al restaurar."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "El binario de GPG es %s, versión %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "URL erróneo «%s».\n"
 "Ejemplos de cadenas de URL son «scp://user@host.net:1234/path» \n"
 "y «file:///usr/local». Ver el manual para más información."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Acción principal: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "basis_file debe ser un archivo (verdadero) o un objeto cuyos atributos de archivo son el objeto del archivo verdadero subyacente"
 
@@ -1287,243 +1299,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: falta %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Error fatal: no se encontraron manifiestos para el respaldo más reciente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Error fatal: el manifiesto remoto no coincide con el local. Ni la configuración de copia de seguridad remota o el directorio del archivo local está dañado."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Error al procesar el manifiesto remoto (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Error fatal: ni el manifiesto remoto ni el local son legibles"
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Procesando manifiesto local %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Error al procesar el manifiesto remoto (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Procesando manifiesto remoto %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Preferir la configuración de copia de seguridad previa"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignorar la configuración de copia de seguridad incremental (start_time: %s; necesaria: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Añadida configuración de copia de seguridad incremental (start_time: %s / end_time: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Hora de inicio de la cadena: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Hora de terminación de la cadena: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Número de conjuntos de respaldo contenidos: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Número total de volúmenes contenidos: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Tipo de conjunto de respaldo"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Hora:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Número de volúmenes:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Completo"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Estado de la colección"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Conectar con el motor: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Directorio de archivador: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Cadena secundaria %d de %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Se encontró cadena de copia de seguridad primaria con cadena de firma coincidente:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "No encontró cadenas con firmas activas"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Esto se puede eliminar ejecutando duplicity con la orden «cleanup»"
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "No se han encontrado respaldos huérfanos o incompletos."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Aviso, descartando el último conjunto de respaldo, debido a la falta archivo de firma."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Aviso, se encontraron firmas pero no coinciden con los archivos de copia de seguridad"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Aviso, encontró conjuntos de copia de seguridad incompletos, probablemente de la sesión abortada"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Extrayendo cadenas de respaldo de la lista de archivos: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "El archivo %s es parte del conjunto conocido"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "El archivo %s no es parte de un conjunto conocido; creando un conjunto nuevo"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignorando archivo (rechazado por el conjunto) «%s»"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Se encontró una cadena de respaldo %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "conjunto %s añadido a la cadena %s preexistente"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Se encontró un conjunto huérfano %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "No hay cadena de firmas disponibles para la hora solicitada. Se está usando la cadena más antigua disponible, que comienza en %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Archivo: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Número total de copias de seguridad: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Tipo de cambio de archivo:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Parcheando %s"
```

### Comparing `duplicity-1.2.3.dev43/po/zh_CN/duplicity.mo` & `duplicity-2.0.0rc0/po/zh_CN/duplicity.mo`

 * *Files 1% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Chinese Simplified\n"
 "Language: zh_CN\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
```

### Comparing `duplicity-1.2.3.dev43/po/en_PR.po` & `duplicity-2.0.0rc0/po/en_PR.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: English, Puerto Rico\n"
 "Language: en_PR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/vi_VN.po` & `duplicity-2.0.0rc0/po/vi_VN.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Vietnamese\n"
 "Language: vi_VN\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
@@ -1688,8 +1700,7 @@
 msgid "Touching %s"
 msgstr ""
 
 #: ../duplicity/path.py:639
 #, python-format
 msgid "Deleting tree %s"
 msgstr ""
-
```

### Comparing `duplicity-1.2.3.dev43/po/sv_SE.po` & `duplicity-2.0.0rc0/po/sv_SE.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Swedish\n"
 "Language: sv_SE\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index stämmer inte"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Anslutningen misslyckades. Kontrollera ditt lösenord: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "sökväg"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "filnamn"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "reguljärt_uttryck"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "tid"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "flaggor"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Körs i 'ignore errors'-läge på grund av %s; överväg om detta inte var avsett"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "antal"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "säkerhetskopia namn"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "kommando"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,241 +623,248 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "sekunder"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "tecken"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Använd säkerhetskopierings namn: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Fel på kommandorad: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Kör \"duplicity --help\" för hjälpskärmen."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "absolut_sökväg"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "antal"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "katalog"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "modul"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "lösenord"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "relativ_sökväg"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "någon_katalog"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "källkatalog"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "källans_url"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "målkatalog"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "målets url"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "användare"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "fjärr"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Kommandon:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "Den angivna arkivkatalogen \"%s\" finns inte, eller är inte en katalog"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "Singeringsnyckeln bör vara en 8, 16 alt. 40 tecken hex-sträng, som \"AA0E73D2\".\n"
 "Mottog \"%s\" istället."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Återställnings destinationskatalog %s finns redan.\n"
 "Skriver inte över."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "Verifiera att katalogen %s inte finns"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "Säkerhetskopiakatalogen %s finns inte."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Kommandoradvarning: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "GPG-binär är %s, version %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "Dålig URL '%s'.\n"
 "Exempel på URL-strängar är \"scp://user@host.net:1234/path\" och\n"
 "\"file:///usr/local\".  Se man-sida för mer information."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Huvudåtgärd: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1277,243 +1289,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: saknar %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Allvarligt fel: Inget manifest hittades för senaste säkerhetskopia"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Kedjans starttid: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Antal inneslutna säkerhetskopieringsuppsättningar: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Totalt antal inneslutna volymer: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Typ av säkerhetskopieringsuppsättning:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Tid:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Num volymer:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Fullständig"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr "Inkrementell"
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr "lokal"
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Samlingsstatus"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Ansluter med bakände: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Arkivkatalog: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Sekundär kedja %d av %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Hittade primär säkerhetskopieringskedja med matchande signaturkedja:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "Inga säkerhetskopieringskedjor med aktiva signaturer hittades"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Dessa kan tas bort genom att köra duplicity med kommandot \"cleanup\"."
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "Inga föräldralösa eller ofullständiga säkerhetskopieringsuppsättningar hittades."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Varning, förkastar senaste säkerhetskopieringsuppsättning därför att signaturfilen saknas."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Varning, hittade signaturer men inga motsvarande säkerhetskopieringsfiler"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Varning, hittade ofullständiga säkerhetskopieringsuppsättningar, förmodligen kvar från avbruten session"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Packa upp säkerhetskopieringskedjor från listan över filer: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "Filen %s är del av en känd uppsättning"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "Filen %s är inte del av en känd uppsättning; skapar ny uppsättning"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignorerar fil (avvisas av säkerhetskopieringsuppsättningar) \"%s\""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Hittade säkerhetskopieringskedjan %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "Lade till uppsättningen %s till den befintliga kedjan %s"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Hittade föräldralösa uppsättningen %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "Ingen signaturkedja för den begärda tiden. Använda äldsta tillgängliga kedjan, börjar vid tiden %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Fil: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Totalt antal säkerhetskopior: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Typ av filändring:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Patchar %s"
```

### Comparing `duplicity-1.2.3.dev43/po/es_EM.po` & `duplicity-2.0.0rc0/po/es_EM.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Spanish (Modern)\n"
 "Language: es_EM\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index no coinciden"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Hashes no coinciden"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Aviso: ignorando error tal como se pidió: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Publicando fichero de candado %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MultiBackend: falló al eliminar %s. Se probaron todos los almacenes de copias y ninguno funcionó"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Falló la conexión, compruebe su contraseña: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Faltan los módulos de Python «socket» o «ssl»."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "ruta"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nombre de archivo"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "expresión regular"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "hora"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opciones"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Ejecutando en modo «ignore errors» debido a %s; reconsidere esta opción si no es su intención"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "número"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nombre de respaldo"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "orden"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,242 +623,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "segundos"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "carácter"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Usando directorio de archivador: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Usando nombre de copia de seguridad: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Error de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Introduzca «duplicity --help» para tener ayuda en pantalla."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "ruta_absoluta"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nombre_cubo"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nombre_contenedor"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "recuento"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "directorio"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "módulo"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "otro.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "contraseña"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "puerto"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefijo"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "ruta_relativa"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "algun_dir"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "dir_origen"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_origen"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "dir_objetivo"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_objetivo"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "usuario"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "id_cuenta"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "clave_aplicación"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "remoto"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Motores y sus formatos de URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Órdenes:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "El directorio del archivador «%s» no existe, o no es un directorio"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "La clave de firma debería ser una cadena de 8, 16 o 40 caracteres hexadecimales , como «AA0E732D2».\n"
 "Se ha recibido «%s» en su lugar."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Restaurar directorio de destino %s ya existe.\n"
 "No sobrescribir."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "El directorio verificado %s no existe"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "El directorio de origen de respaldo %s no existe."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Aviso de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Las opciones de selección --exclude/--include\n"
 "actualmente funcionan solo cuando se respalda no al restaurar."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "El binario de GPG es %s, versión %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "URL erróneo «%s».\n"
 "Ejemplos de cadenas de URL son «scp://user@host.net:1234/path» \n"
 "y «file:///usr/local». Ver el manual para más información."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Acción principal: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "basis_file debe ser un archivo (verdadero) o un objeto cuyos atributos de archivo son el objeto del archivo verdadero subyacente"
 
@@ -1287,243 +1299,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: falta %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Error fatal: no se encontraron manifiestos para el respaldo más reciente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Error fatal: el manifiesto remoto no coincide con el local. Ni la configuración de copia de seguridad remota o el directorio del archivo local está dañado."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Error al procesar el manifiesto remoto (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Error fatal: ni el manifiesto remoto ni el local son legibles"
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Procesando manifiesto local %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Error al procesar el manifiesto remoto (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Procesando manifiesto remoto %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Preferir la configuración de copia de seguridad previa"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignorar la configuración de copia de seguridad incremental (start_time: %s; necesaria: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Añadida configuración de copia de seguridad incremental (start_time: %s / end_time: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Hora de inicio de la cadena: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Hora de terminación de la cadena: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Número de conjuntos de respaldo contenidos: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Número total de volúmenes contenidos: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Tipo de conjunto de respaldo"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Hora:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Número de volúmenes:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Completo"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Estado de la colección"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Conectar con el motor: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Directorio de archivador: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Cadena secundaria %d de %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Se encontró cadena de copia de seguridad primaria con cadena de firma coincidente:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "No encontró cadenas con firmas activas"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Esto se puede eliminar ejecutando duplicity con la orden «cleanup»"
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "No se han encontrado respaldos huérfanos o incompletos."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Aviso, descartando el último conjunto de respaldo, debido a la falta archivo de firma."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Aviso, se encontraron firmas pero no coinciden con los archivos de copia de seguridad"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Aviso, encontró conjuntos de copia de seguridad incompletos, probablemente de la sesión abortada"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Extrayendo cadenas de respaldo de la lista de archivos: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "El archivo %s es parte del conjunto conocido"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "El archivo %s no es parte de un conjunto conocido; creando un conjunto nuevo"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignorando archivo (rechazado por el conjunto) «%s»"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Se encontró una cadena de respaldo %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "conjunto %s añadido a la cadena %s preexistente"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Se encontró un conjunto huérfano %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "No hay cadena de firmas disponibles para la hora solicitada. Se está usando la cadena más antigua disponible, que comienza en %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Archivo: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Número total de copias de seguridad: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Tipo de cambio de archivo:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Parcheando %s"
```

### Comparing `duplicity-1.2.3.dev43/po/af_ZA.po` & `duplicity-2.0.0rc0/po/af_ZA.po`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Afrikaans\n"
 "Language: af_ZA\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,237 +619,244 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1258,243 +1270,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/es_PR.po` & `duplicity-2.0.0rc0/po/es_PR.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:50\n"
 "Last-Translator: \n"
 "Language-Team: Spanish, Puerto Rico\n"
 "Language: es_PR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n != 1);\n"
@@ -195,20 +195,20 @@
 msgid "end_index don't match"
 msgstr "end_index no coinciden"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr "Hashes no coinciden"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr "IGNORED_ERROR: Aviso: ignorando error tal como se pidió: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "Publicando fichero de candado %s"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -312,14 +312,19 @@
 msgstr "MultiBackend: falló al eliminar %s. Se probaron todos los almacenes de copias y ninguno funcionó"
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "Falló la conexión, compruebe su contraseña: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "Faltan los módulos de Python «socket» o «ssl»."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -492,67 +497,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr "ruta"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr "nombre de archivo"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr "expresión regular"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr "hora"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr "opciones"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr "Ejecutando en modo «ignore errors» debido a %s; reconsidere esta opción si no es su intención"
@@ -572,15 +577,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr "número"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "nombre de respaldo"
@@ -591,15 +596,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr "orden"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -618,242 +623,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr "segundos"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr "carácter"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "Usando directorio de archivador: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "Usando nombre de copia de seguridad: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "Error de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr "Introduzca «duplicity --help» para tener ayuda en pantalla."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "ruta_absoluta"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr "nombre_cubo"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr "nombre_contenedor"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr "recuento"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr "directorio"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr "módulo"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr "otro.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr "contraseña"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr "puerto"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr "prefijo"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "ruta_relativa"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr "algun_dir"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr "dir_origen"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr "url_origen"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr "dir_objetivo"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr "url_objetivo"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr "usuario"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr "id_cuenta"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr "clave_aplicación"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "remoto"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "Motores y sus formatos de URL:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr "Órdenes:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "El directorio del archivador «%s» no existe, o no es un directorio"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr "La clave de firma debería ser una cadena de 8, 16 o 40 caracteres hexadecimales , como «AA0E732D2».\n"
 "Se ha recibido «%s» en su lugar."
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "Restaurar directorio de destino %s ya existe.\n"
 "No sobrescribir."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "El directorio verificado %s no existe"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "El directorio de origen de respaldo %s no existe."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "Aviso de línea de órdenes: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr "Las opciones de selección --exclude/--include\n"
 "actualmente funcionan solo cuando se respalda no al restaurar."
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr "El binario de GPG es %s, versión %s"
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr "URL erróneo «%s».\n"
 "Ejemplos de cadenas de URL son «scp://user@host.net:1234/path» \n"
 "y «file:///usr/local». Ver el manual para más información."
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr "Acción principal: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr "basis_file debe ser un archivo (verdadero) o un objeto cuyos atributos de archivo son el objeto del archivo verdadero subyacente"
 
@@ -1287,243 +1299,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr "BackupSet.delete: falta %s"
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "Error fatal: no se encontraron manifiestos para el respaldo más reciente"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr "Error fatal: el manifiesto remoto no coincide con el local. Ni la configuración de copia de seguridad remota o el directorio del archivo local está dañado."
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr "Error al procesar el manifiesto remoto (%s): %s"
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "Error fatal: ni el manifiesto remoto ni el local son legibles"
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr "Procesando manifiesto local %s (%s)"
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr "Error al procesar el manifiesto remoto (%s): %s"
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr "Procesando manifiesto remoto %s (%s)"
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr "Preferir la configuración de copia de seguridad previa"
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr "Ignorar la configuración de copia de seguridad incremental (start_time: %s; necesaria: %s)"
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr "Añadida configuración de copia de seguridad incremental (start_time: %s / end_time: %s)"
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr "Hora de inicio de la cadena: "
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr "Hora de terminación de la cadena: "
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr "Número de conjuntos de respaldo contenidos: %d"
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr "Número total de volúmenes contenidos: %d"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "Tipo de conjunto de respaldo"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr "Hora:"
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr "Número de volúmenes:"
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr "Completo"
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "Estado de la colección"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "Conectar con el motor: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "Directorio de archivador: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr "Cadena secundaria %d de %d:"
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr "Se encontró cadena de copia de seguridad primaria con cadena de firma coincidente:"
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr "No encontró cadenas con firmas activas"
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr "Esto se puede eliminar ejecutando duplicity con la orden «cleanup»"
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr "No se han encontrado respaldos huérfanos o incompletos."
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr "Aviso, descartando el último conjunto de respaldo, debido a la falta archivo de firma."
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr "Aviso, se encontraron firmas pero no coinciden con los archivos de copia de seguridad"
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr "Aviso, encontró conjuntos de copia de seguridad incompletos, probablemente de la sesión abortada"
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr "Extrayendo cadenas de respaldo de la lista de archivos: %s"
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr "El archivo %s es parte del conjunto conocido"
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr "El archivo %s no es parte de un conjunto conocido; creando un conjunto nuevo"
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr "Ignorando archivo (rechazado por el conjunto) «%s»"
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr "Se encontró una cadena de respaldo %s"
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr "conjunto %s añadido a la cadena %s preexistente"
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr "Se encontró un conjunto huérfano %s"
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr "No hay cadena de firmas disponibles para la hora solicitada. Se está usando la cadena más antigua disponible, que comienza en %s."
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr "Archivo: %s"
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr "Número total de copias de seguridad: %d"
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr "Tipo de cambio de archivo:"
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr "Parcheando %s"
```

### Comparing `duplicity-1.2.3.dev43/po/Makevars` & `duplicity-2.0.0rc0/po/Makevars`

 * *Files identical despite different names*

### Comparing `duplicity-1.2.3.dev43/po/ko_KR.po` & `duplicity-2.0.0rc0/po/ko_KR.po`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:48\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: Korean\n"
 "Language: ko_KR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=1; plural=0;\n"
@@ -191,20 +191,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr "잠금 파일 %s 해제"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -308,14 +308,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr "연결에 실패했습니다, 비밀번호를 확인하시오: %s"
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr "소켓 또는 SSL Python 모듈이 없습니다."
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -488,67 +493,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
 msgstr ""
@@ -568,15 +573,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr "백업 이름"
@@ -587,15 +592,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -614,238 +619,245 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr "아카이브 디렉토리 사용: %s"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr "백업 이름 사용: %s"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr "커맨드 라인 오류: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr "절대 경로(_p)"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr "별칭"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr "상대 경로(_p)"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr "원격"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr "백엔드 및 해당 URL 형식:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr "지정된 아카이브 디렉토리 '%s'(은)는 존재하지 않거나, 디렉토리가 아닙니다"
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr "복원 대상 디렉토리 %s이(가) 이미 존재합니다.\n"
 "덮어쓰지 않습니다."
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr "%s 디렉토리가 존재하지 않는지 확인하시오"
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr "백업 소스 디렉터리 %s이(가) 없습니다."
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr "커맨드 라인 경고: %s"
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
@@ -1259,243 +1271,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr "치명적인 오류: 가장 최근 백업에 대한 매니페스트를 찾을 수 없습니다"
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
+msgstr ""
+
+#: ../duplicity/dup_collections.py:247
 msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr "치명적인 오류: 원격 및 로컬 매니페스트를 읽을 수 없습니다."
 
-#: ../duplicity/dup_collections.py:253
+#: ../duplicity/dup_collections.py:258
 #, python-format
 msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
-#, python-format
-msgid "Error processing remote manifest (%s): %s"
-msgstr ""
-
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr "백업 세트 유형:"
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr "수집 현황"
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr "백엔드와 연결: %s"
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr "아카이브 디렉토리: %s"
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/en_PR/duplicity.mo` & `duplicity-2.0.0rc0/po/nl_SR/duplicity.mo`

 * *Format-specific differences are supported for Gettext message catalogues but no file-specific differences were detected; falling back to a binary diff. file(1) reports: GNU message catalog (little endian), revision 0.0, 1 message, Project-Id-Version: duplicity*

 * *Files 11% similar despite different names*

```diff
@@ -1,34 +1,33 @@
 00000000: de12 0495 0000 0000 0100 0000 1c00 0000  ................
 00000010: 2400 0000 0300 0000 2c00 0000 0000 0000  $.......,.......
-00000020: 3800 0000 d801 0000 3900 0000 0100 0000  8.......9.......
+00000020: 3800 0000 d301 0000 3900 0000 0100 0000  8.......9.......
 00000030: 0000 0000 0000 0000 0050 726f 6a65 6374  .........Project
 00000040: 2d49 642d 5665 7273 696f 6e3a 2064 7570  -Id-Version: dup
 00000050: 6c69 6369 7479 0a52 6570 6f72 742d 4d73  licity.Report-Ms
 00000060: 6769 642d 4275 6773 2d54 6f3a 204b 656e  gid-Bugs-To: Ken
 00000070: 6e65 7468 204c 6f61 666d 616e 203c 6b65  neth Loafman <ke
 00000080: 6e6e 6574 6840 6c6f 6166 6d61 6e2e 636f  nneth@loafman.co
 00000090: 6d3e 0a50 4f2d 5265 7669 7369 6f6e 2d44  m>.PO-Revision-D
-000000a0: 6174 653a 2032 3032 332d 3031 2d32 3520  ate: 2023-01-25 
-000000b0: 3139 3a34 380a 4c61 7374 2d54 7261 6e73  19:48.Last-Trans
+000000a0: 6174 653a 2032 3032 332d 3035 2d30 3920  ate: 2023-05-09 
+000000b0: 3134 3a35 300a 4c61 7374 2d54 7261 6e73  14:50.Last-Trans
 000000c0: 6c61 746f 723a 200a 4c61 6e67 7561 6765  lator: .Language
-000000d0: 2d54 6561 6d3a 2045 6e67 6c69 7368 2c20  -Team: English, 
-000000e0: 5075 6572 746f 2052 6963 6f0a 4c61 6e67  Puerto Rico.Lang
-000000f0: 7561 6765 3a20 656e 5f50 520a 4d49 4d45  uage: en_PR.MIME
-00000100: 2d56 6572 7369 6f6e 3a20 312e 300a 436f  -Version: 1.0.Co
-00000110: 6e74 656e 742d 5479 7065 3a20 7465 7874  ntent-Type: text
-00000120: 2f70 6c61 696e 3b20 6368 6172 7365 743d  /plain; charset=
-00000130: 5554 462d 380a 436f 6e74 656e 742d 5472  UTF-8.Content-Tr
-00000140: 616e 7366 6572 2d45 6e63 6f64 696e 673a  ansfer-Encoding:
-00000150: 2038 6269 740a 506c 7572 616c 2d46 6f72   8bit.Plural-For
-00000160: 6d73 3a20 6e70 6c75 7261 6c73 3d32 3b20  ms: nplurals=2; 
-00000170: 706c 7572 616c 3d28 6e20 213d 2031 293b  plural=(n != 1);
-00000180: 0a58 2d43 726f 7764 696e 2d50 726f 6a65  .X-Crowdin-Proje
-00000190: 6374 3a20 6475 706c 6963 6974 790a 582d  ct: duplicity.X-
-000001a0: 4372 6f77 6469 6e2d 5072 6f6a 6563 742d  Crowdin-Project-
-000001b0: 4944 3a20 3533 3935 3038 0a58 2d43 726f  ID: 539508.X-Cro
-000001c0: 7764 696e 2d4c 616e 6775 6167 653a 2065  wdin-Language: e
-000001d0: 6e2d 5052 0a58 2d43 726f 7764 696e 2d46  n-PR.X-Crowdin-F
-000001e0: 696c 653a 202f 6d61 696e 2f70 6f2f 6475  ile: /main/po/du
-000001f0: 706c 6963 6974 792e 706f 740a 582d 4372  plicity.pot.X-Cr
-00000200: 6f77 6469 6e2d 4669 6c65 2d49 443a 2036  owdin-File-ID: 6
-00000210: 0a00                                     ..
+000000d0: 2d54 6561 6d3a 2044 7574 6368 2c20 5375  -Team: Dutch, Su
+000000e0: 7269 6e61 6d65 0a4c 616e 6775 6167 653a  riname.Language:
+000000f0: 206e 6c5f 5352 0a4d 494d 452d 5665 7273   nl_SR.MIME-Vers
+00000100: 696f 6e3a 2031 2e30 0a43 6f6e 7465 6e74  ion: 1.0.Content
+00000110: 2d54 7970 653a 2074 6578 742f 706c 6169  -Type: text/plai
+00000120: 6e3b 2063 6861 7273 6574 3d55 5446 2d38  n; charset=UTF-8
+00000130: 0a43 6f6e 7465 6e74 2d54 7261 6e73 6665  .Content-Transfe
+00000140: 722d 456e 636f 6469 6e67 3a20 3862 6974  r-Encoding: 8bit
+00000150: 0a50 6c75 7261 6c2d 466f 726d 733a 206e  .Plural-Forms: n
+00000160: 706c 7572 616c 733d 323b 2070 6c75 7261  plurals=2; plura
+00000170: 6c3d 286e 2021 3d20 3129 3b0a 582d 4372  l=(n != 1);.X-Cr
+00000180: 6f77 6469 6e2d 5072 6f6a 6563 743a 2064  owdin-Project: d
+00000190: 7570 6c69 6369 7479 0a58 2d43 726f 7764  uplicity.X-Crowd
+000001a0: 696e 2d50 726f 6a65 6374 2d49 443a 2035  in-Project-ID: 5
+000001b0: 3339 3530 380a 582d 4372 6f77 6469 6e2d  39508.X-Crowdin-
+000001c0: 4c61 6e67 7561 6765 3a20 6e6c 2d53 520a  Language: nl-SR.
+000001d0: 582d 4372 6f77 6469 6e2d 4669 6c65 3a20  X-Crowdin-File: 
+000001e0: 2f6d 6169 6e2f 706f 2f64 7570 6c69 6369  /main/po/duplici
+000001f0: 7479 2e70 6f74 0a58 2d43 726f 7764 696e  ty.pot.X-Crowdin
+00000200: 2d46 696c 652d 4944 3a20 360a 00         -File-ID: 6..
```

### Comparing `duplicity-1.2.3.dev43/po/duplicity.pot` & `duplicity-2.0.0rc0/po/duplicity.pot`

 * *Files 0% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 # FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
 #
 #, fuzzy
 msgid ""
 msgstr ""
 "Project-Id-Version: PACKAGE VERSION\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
 "PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
 "Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
 "Language-Team: LANGUAGE <LL@li.org>\n"
 "Language: \n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=CHARSET\n"
 "Content-Transfer-Encoding: 8bit\n"
@@ -198,20 +198,20 @@
 msgid "end_index don't match"
 msgstr ""
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
 msgstr ""
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
 msgstr ""
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
 msgstr ""
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
@@ -319,14 +319,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -512,67 +517,67 @@
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
 msgstr ""
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
 msgstr ""
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
 msgstr ""
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
 msgstr ""
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
 msgstr ""
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
 msgstr ""
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
 msgstr ""
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid ""
 "Running in 'ignore errors' mode due to %s; please re-consider if this was "
@@ -594,15 +599,15 @@
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
 msgstr ""
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
 msgstr ""
@@ -613,15 +618,15 @@
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
 msgstr ""
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
 msgstr ""
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
 msgstr ""
 
@@ -640,241 +645,249 @@
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
 msgstr ""
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
 msgstr ""
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid ""
+"Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr ""
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
 msgstr ""
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
 msgstr ""
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
 msgstr ""
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
 msgstr ""
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
 msgstr ""
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
 msgstr ""
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
 msgstr ""
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
 msgstr ""
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
 msgstr ""
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
 msgstr ""
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
 msgstr ""
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
 msgstr ""
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
 msgstr ""
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
 msgstr ""
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
 msgstr ""
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
 msgstr ""
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
 msgstr ""
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
 msgstr ""
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
 msgstr ""
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
 msgstr ""
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid ""
 "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid ""
 "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid ""
 "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid ""
 "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
 msgstr ""
 
 #: ../duplicity/librsync.py:196
 msgid ""
 "basis_file must be a (true) file or an object whose file attribute is the "
 "underlying true file object"
@@ -1313,248 +1326,248 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid ""
 "Fatal Error: Remote manifest does not match local one.  Either the remote "
 "backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid ""
 "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid ""
 "No signature chain for the requested time. Using oldest available chain, "
 "starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

### Comparing `duplicity-1.2.3.dev43/po/ro_RO.po` & `duplicity-2.0.0rc0/po/nl_NL.po`

 * *Files 10% similar despite different names*

```diff
@@ -1,79 +1,79 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"POT-Creation-Date: 2023-01-25 13:29-0600\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"POT-Creation-Date: 2023-05-09 09:37-0500\n"
+"PO-Revision-Date: 2023-05-28 07:27\n"
 "Last-Translator: \n"
-"Language-Team: Romanian\n"
-"Language: ro_RO\n"
+"Language-Team: Dutch\n"
+"Language: nl_NL\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
-"Plural-Forms: nplurals=3; plural=(n==1 ? 0 : (n==0 || (n%100>0 && n%100<20)) ? 1 : 2);\n"
+"Plural-Forms: nplurals=2; plural=(n != 1);\n"
 "X-Crowdin-Project: duplicity\n"
 "X-Crowdin-Project-ID: 539508\n"
-"X-Crowdin-Language: ro\n"
+"X-Crowdin-Language: nl\n"
 "X-Crowdin-File: /main/po/duplicity.pot\n"
 "X-Crowdin-File-ID: 6\n"
 
 #: ../bin/duplicity:106
 msgid "INT intercepted...exiting."
 msgstr ""
 
 #: ../bin/duplicity:114
 #, python-format
 msgid "GPG error detail: %s"
-msgstr ""
+msgstr "GPG-foutmelding: %s"
 
 #: ../bin/duplicity:124
 #, python-format
 msgid "User error detail: %s"
-msgstr ""
+msgstr "Gebruikersfoutmelding: %s"
 
 #: ../bin/duplicity:134
 #, python-format
 msgid "Backend error detail: %s"
-msgstr ""
+msgstr "Backendfoutmelding: %s"
 
 #: ../bin/rdiffdir:64 ../duplicity/commandline.py:239
 #, python-format
 msgid "Error opening file %s"
-msgstr ""
+msgstr "Fout tijdens openen van het bestand %s"
 
 #: ../bin/rdiffdir:131
 #, python-format
 msgid "File %s already exists, will not overwrite."
-msgstr ""
+msgstr "Het bestand %s bestaat al en zal niet niet worden overschreven."
 
 #: ../duplicity/tempdir.py:160
 #, python-format
 msgid "Using temporary directory %s"
-msgstr ""
+msgstr "Tijdelijke map %s wordt gebruikt"
 
 #: ../duplicity/tempdir.py:204
 #, python-format
 msgid "Registering (mktemp) temporary file %s"
 msgstr ""
 
 #: ../duplicity/tempdir.py:226
 #, python-format
 msgid "Registering (mkstemp) temporary file %s"
 msgstr ""
 
 #: ../duplicity/tempdir.py:258
 #, python-format
 msgid "Forgetting temporary file %s"
-msgstr ""
+msgstr "Tijdelijk bestand %s wordt vergeten"
 
 #: ../duplicity/tempdir.py:261
 #, python-format
 msgid "Attempt to forget unknown tempfile %s - this is probably a bug."
-msgstr ""
+msgstr "Poging om onbekend tijdelijk bestand %s te vergeten: dit is waarschijnlijk een bug."
 
 #: ../duplicity/tempdir.py:280
 #, python-format
 msgid "Removing still remembered temporary file %s"
 msgstr ""
 
 #: ../duplicity/tempdir.py:283
@@ -85,210 +85,214 @@
 #, python-format
 msgid "Cleanup of temporary directory %s failed - this is probably a bug."
 msgstr ""
 
 #: ../duplicity/backend.py:102
 #, python-format
 msgid "Import of %s %s"
-msgstr ""
+msgstr "Import van %s %s"
 
 #: ../duplicity/backend.py:211
 #, python-format
 msgid "Could not initialize backend: %s"
-msgstr ""
+msgstr "Kan backend niet initialiseren: %s"
 
 #: ../duplicity/backend.py:403
 #, python-format
 msgid "Backtrace of previous error: %s"
-msgstr ""
+msgstr "Backtrace van vorige foutmelding: %s"
 
 #: ../duplicity/backend.py:419
 #, python-format
 msgid "Giving up after %s attempts. %s: %s"
-msgstr ""
+msgstr "Opgegeven na %s pogingen. %s: %s"
 
 #: ../duplicity/backend.py:423
 #, python-format
 msgid "Attempt of %s Nr. %s failed. %s: %s"
-msgstr ""
+msgstr "Poging van %s no. %s mislukt. %s: %s"
 
 #: ../duplicity/backend.py:517
 #, python-format
 msgid "Reading results of '%s'"
-msgstr ""
+msgstr "Resultaten van '%s' aan het lezen"
 
 #: ../duplicity/backend.py:543
 #, python-format
 msgid "Writing %s"
-msgstr ""
+msgstr "%s aan het schrijven"
 
 #: ../duplicity/backend.py:584
 #, python-format
 msgid "File %s not found locally after get from backend"
-msgstr ""
+msgstr "Bestand %s niet lokaal gevonden na ophalen van backend"
 
 #: ../duplicity/manifest.py:99
 #, python-format
 msgid "Fatal Error: Backup source host has changed.\n"
 "Current hostname: %s\n"
 "Previous hostname: %s"
-msgstr ""
+msgstr "Cruciale fout: de hostnaam van de backupbron is veranderd.\n"
+"Huidige hostnaam: %s\n"
+"Vorige hostnaam: %s"
 
 #: ../duplicity/manifest.py:106
 #, python-format
 msgid "Fatal Error: Backup source directory has changed.\n"
 "Current directory: %s\n"
 "Previous directory: %s"
-msgstr ""
+msgstr "Cruciale fout: bronmap van de backup is veranderd.\n"
+"Huidige map: %s\n"
+"Vorige map: %s"
 
 #: ../duplicity/manifest.py:116
 msgid "Aborting because you may have accidentally tried to backup two different data sets to the same remote location, or using the same archive directory.  If this is not a mistake, use the --allow-source-mismatch switch to avoid seeing this message"
-msgstr ""
+msgstr "De operatie wordt geannuleerd, omdat u mogelijk per ongeluk een backup probeert te maken van twee verschillende datasets naar dezelfde externe locatie, of omdat u dezelfde archiefmap probeert te gebruiken. Als dit geen vergissing is, gebruik dan de schakelaar --allow-source-mismatch om dit bericht te negeren."
 
 #: ../duplicity/manifest.py:218
 #, python-format
 msgid "Found manifest volume %s"
-msgstr ""
+msgstr "Manifestvolume %s gevonden"
 
 #: ../duplicity/manifest.py:225
 #, python-format
 msgid "Found %s volumes in manifest"
-msgstr ""
+msgstr "%s volumes gevonden in manifest"
 
 #: ../duplicity/manifest.py:243
 #, python-format
 msgid "Manifest file '%s' is corrupt: File count says %d, File list contains %d"
-msgstr ""
+msgstr "Manifestbestand %s is corrupt: aantal bestanden is %d, maar de bestandslijst telt er %d."
 
 #: ../duplicity/manifest.py:262
 msgid "Manifests not equal because different volume numbers"
-msgstr ""
+msgstr "Manifesten niet gelijk: verschillende volumenummers"
 
 #: ../duplicity/manifest.py:267
 msgid "Manifests not equal because volume lists differ"
-msgstr ""
+msgstr "Manifesten niet gelijk: volumelijsten verschillen"
 
 #: ../duplicity/manifest.py:272
 msgid "Manifests not equal because hosts or directories differ"
-msgstr ""
+msgstr "Manifesten niet gelijk: hosts of mappen verschillen"
 
 #: ../duplicity/manifest.py:429
 msgid "Warning, found extra Volume identifier"
-msgstr ""
+msgstr "Waarschuwing: extra volumeidentifier gevonden"
 
 #: ../duplicity/manifest.py:455
 msgid "Other is not VolumeInfo"
 msgstr ""
 
 #: ../duplicity/manifest.py:458
 msgid "Volume numbers don't match"
-msgstr ""
+msgstr "Volumenummers komen niet overeen"
 
 #: ../duplicity/manifest.py:461
 msgid "start_indicies don't match"
-msgstr ""
+msgstr "start_indices komen niet overeen"
 
 #: ../duplicity/manifest.py:464
 msgid "end_index don't match"
-msgstr ""
+msgstr "end_index komen niet overeen"
 
 #: ../duplicity/manifest.py:471
 msgid "Hashes don't match"
-msgstr ""
+msgstr "Hashes komen niet overeen"
 
-#: ../duplicity/util.py:160 ../duplicity/dup_main.py:847
+#: ../duplicity/util.py:166 ../duplicity/dup_main.py:847
 #, python-format
 msgid "IGNORED_ERROR: Warning: ignoring error as requested: %s: %s"
-msgstr ""
+msgstr "IGNORED_ERROR: Waarschuwing: foutmelding wordt genegeerd zoals gevraagd: %s: %s"
 
-#: ../duplicity/util.py:227
+#: ../duplicity/util.py:233
 #, python-format
 msgid "Releasing lockfile %s"
-msgstr ""
+msgstr "Lockfile %s wordt losgelaten"
 
 #: ../duplicity/backends/pydrivebackend.py:181
 #, python-format
 msgid "PyDrive backend: multiple files called '%s'."
-msgstr ""
+msgstr "PyDrive-backend: meerdere bestanden heten '%s'."
 
 #: ../duplicity/backends/multibackend.py:96
 #, python-format
 msgid "MultiBackend: Could not parse query string %s: %s "
-msgstr ""
+msgstr "MultiBackend: kon querystring %s niet ontleden: %s "
 
 #: ../duplicity/backends/multibackend.py:105
 #, python-format
 msgid "MultiBackend: Invalid query string %s: more than one value for %s"
-msgstr ""
+msgstr "MultiBackend: querystring %s is ongeldig: meer dan één waarde voor %s"
 
 #: ../duplicity/backends/multibackend.py:110
 #, python-format
 msgid "MultiBackend: Invalid query string %s: unknown parameter %s"
-msgstr ""
+msgstr "MultiBackend: querystring %s is ongeldig: onbekende parameter %s"
 
 #: ../duplicity/backends/multibackend.py:160
 #: ../duplicity/backends/multibackend.py:165
 #, python-format
 msgid "MultiBackend: illegal value for %s: %s"
-msgstr ""
+msgstr "MultiBackend: ongeldige waarde voor %s: %s"
 
 #: ../duplicity/backends/multibackend.py:176
 #, python-format
 msgid "MultiBackend: Url %s"
-msgstr ""
+msgstr "MultiBackend: URL %s"
 
 #: ../duplicity/backends/multibackend.py:180
 #, python-format
 msgid "MultiBackend: Could not load config file %s: %s "
-msgstr ""
+msgstr "MultiBackend: kon configuratiebestand %s niet laden: %s "
 
 #: ../duplicity/backends/multibackend.py:189
 #, python-format
 msgid "MultiBackend: use store %s"
-msgstr ""
+msgstr "MultiBackend: gebruik store %s"
 
 #: ../duplicity/backends/multibackend.py:194
 #, python-format
 msgid "MultiBackend: set env %s = %s"
-msgstr ""
+msgstr "MultiBackend: zet omgevingsvariabele %s = %s"
 
 #: ../duplicity/backends/multibackend.py:207
 #, python-format
 msgid "Multibackend: register affinity for prefix %s"
-msgstr ""
+msgstr "MultiBackend: registreer affiniteit voor voorvoegsel %s"
 
 #: ../duplicity/backends/multibackend.py:248
 #, python-format
 msgid "MultiBackend: _put: write to store #%s (%s)"
-msgstr ""
+msgstr "MultiBackend: _put: schrijf naar store #%s (%s)"
 
 #: ../duplicity/backends/multibackend.py:261
 #, python-format
 msgid "MultiBackend: failed to write to store #%s (%s), try #%s, Exception: %s"
-msgstr ""
+msgstr "MultiBackend: poging om naar store #%s (%s) te schrijven is mislukt, probeer #%s. Foutmelding: %s"
 
 #: ../duplicity/backends/multibackend.py:268
 #, python-format
 msgid "MultiBackend: failed to write %s. Aborting process."
-msgstr ""
+msgstr "MultiBackend: schrijven naar %s mislukt. Proces wordt afgebroken."
 
 #: ../duplicity/backends/multibackend.py:275
 #, python-format
 msgid "MultiBackend: failed to write %s. Tried all backing stores and none succeeded"
-msgstr ""
+msgstr "MultiBackend: schrijven naar %s mislukt. Alle backend stores zijn geprobeerd en geen ervan slaagde."
 
 #: ../duplicity/backends/multibackend.py:294
 #, python-format
 msgid "MultiBackend: failed to get %s to %s from %s"
-msgstr ""
+msgstr "MultiBackend: kon %s naar %s van %s niet ophalen"
 
 #: ../duplicity/backends/multibackend.py:297
 #, python-format
 msgid "MultiBackend: failed to get %s. Tried all backing stores and none succeeded"
-msgstr ""
+msgstr "MultiBackend: ophalen van %s mislukt. Alle backend stores zijn geprobeerd en geen ervan slaagde."
 
 #: ../duplicity/backends/multibackend.py:307
 #, python-format
 msgid "MultiBackend: %s: %d files"
 msgstr ""
 
 #: ../duplicity/backends/multibackend.py:310
@@ -308,14 +312,19 @@
 msgstr ""
 
 #: ../duplicity/backends/giobackend.py:109
 #, python-format
 msgid "Connection failed, please check your password: %s"
 msgstr ""
 
+#: ../duplicity/backends/onedrivebackend.py:92
+#, python-format
+msgid "Attempt of initialize_oauth2_session Nr. %s failed. %s: %s"
+msgstr ""
+
 #: ../duplicity/backends/webdavbackend.py:67
 msgid "Missing socket or ssl python modules."
 msgstr ""
 
 #: ../duplicity/backends/webdavbackend.py:85
 #, python-format
 msgid "Cacert database file '%s' is not readable."
@@ -455,398 +464,405 @@
 #, python-format
 msgid "M %s"
 msgstr ""
 
 #: ../duplicity/diffdir.py:210
 #, python-format
 msgid "Comparing %s and %s"
-msgstr ""
+msgstr "%s en %s worden vergeleken"
 
 #: ../duplicity/diffdir.py:218
 #, python-format
 msgid "D %s"
-msgstr ""
+msgstr "D %s"
 
 #: ../duplicity/commandline.py:78
 #, python-format
 msgid "Warning: Option %s is pending deprecation and will be removed in version 2.0.\n"
 "Use of default filenames is strongly suggested."
-msgstr ""
+msgstr "Waarschuwing: optie %s wordt afgeschaft en zal worden verwijderd in versie 2.0. Het gebruik van standaardbestandsnamen wordt ten zeerste aangeraden."
 
 #: ../duplicity/commandline.py:84
 #, python-format
 msgid "Warning: Option %s is pending deprecation and will be removed in version 2.0.\n"
 "--include-filelist and --exclude-filelist now accept globbing characters and should be used instead."
-msgstr ""
+msgstr "Waarschuwing: optie %s wordt afgeschaft en zal worden verwijderd in versie 2.0. --include-filelist en --exclude-filelist accepteren nu globs en zouden gebruikt moeten worden."
 
 #: ../duplicity/commandline.py:94
 #, python-format
 msgid "Warning: Option %s is pending deprecation and will be removed in version 2.0.\n"
 "On many GNU/Linux systems, stdin is represented by /dev/stdin and\n"
 "--include-filelist=/dev/stdin or --exclude-filelist=/dev/stdin could\n"
 "be used as a substitute."
-msgstr ""
+msgstr "Waarschuwing: optie %s wordt afgeschaft en zal worden verwijderd in versie 2.0. Op veel GNU/Linux-systemen wordt stdin vertegenwoordigd door /dev/stdin en --include-filelist=/dev/stdin of --exclude-filelist=/dev/stdin kunnen worden gebruikt als alternatief."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. --archive-dir <path>
 #: ../duplicity/commandline.py:261 ../duplicity/commandline.py:271
 #: ../duplicity/commandline.py:292 ../duplicity/commandline.py:388
 #: ../duplicity/commandline.py:410 ../duplicity/commandline.py:421
 #: ../duplicity/commandline.py:669 ../duplicity/commandline.py:717
-#: ../duplicity/commandline.py:944
+#: ../duplicity/commandline.py:953
 msgid "path"
-msgstr ""
+msgstr "pad"
 
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a hidden GnuPG key. Example:
 #. --hidden-encrypt-key <gpg_key_id>
 #. Used in usage help to represent an ID for a GnuPG key. Example:
 #. --encrypt-key <gpg_key_id>
 #: ../duplicity/commandline.py:287 ../duplicity/commandline.py:294
 #: ../duplicity/commandline.py:416 ../duplicity/commandline.py:650
-#: ../duplicity/commandline.py:917
+#: ../duplicity/commandline.py:926
 msgid "gpg-key-id"
-msgstr ""
+msgstr "gpg-key-id"
 
 #. Used in usage help to represent a pattern for
 #. matching one or more files, as described in the documentation.
 #. Example:
 #. --exclude <pattern>
 #: ../duplicity/commandline.py:302 ../duplicity/commandline.py:444
-#: ../duplicity/commandline.py:950
+#: ../duplicity/commandline.py:959
 msgid "pattern"
-msgstr ""
+msgstr "patroon"
 
 #. Used in usage help to represent the name of a file. Example:
 #. --log-file <filename>
 #: ../duplicity/commandline.py:308 ../duplicity/commandline.py:317
 #: ../duplicity/commandline.py:324 ../duplicity/commandline.py:392
 #: ../duplicity/commandline.py:446 ../duplicity/commandline.py:453
-#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:913
+#: ../duplicity/commandline.py:466 ../duplicity/commandline.py:922
 msgid "filename"
-msgstr ""
+msgstr "bestandsnaam"
 
 #. Used in usage help to represent a regular expression (regexp).
 #: ../duplicity/commandline.py:331 ../duplicity/commandline.py:457
 msgid "regular_expression"
-msgstr ""
+msgstr "reguliere_expressie"
 
 #. Used in usage help to represent a time spec for a previous
 #. point in time, as described in the documentation. Example:
 #. duplicity remove-older-than time [options] target_url
 #: ../duplicity/commandline.py:335 ../duplicity/commandline.py:404
-#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:999
+#: ../duplicity/commandline.py:544 ../duplicity/commandline.py:1008
 msgid "time"
-msgstr ""
+msgstr "tijd"
 
 #. Used in usage help. (Should be consistent with the "Options:"
 #. header.) Example:
 #. duplicity [full|incremental] [options] source_dir target_url
 #: ../duplicity/commandline.py:412 ../duplicity/commandline.py:521
 #: ../duplicity/commandline.py:547 ../duplicity/commandline.py:658
-#: ../duplicity/commandline.py:932
+#: ../duplicity/commandline.py:941
 msgid "options"
-msgstr ""
+msgstr "opties"
 
 #: ../duplicity/commandline.py:430
 #, python-format
 msgid "Running in 'ignore errors' mode due to %s; please re-consider if this was not intended"
-msgstr ""
+msgstr "Wordt uitgevoerd in foutnegeermodus vanwege %s; bedenk alstublieft opnieuw of dit de bedoeling is"
 
 #. Used in usage help to represent an imap mailbox
 #: ../duplicity/commandline.py:442
 msgid "imap_mailbox"
-msgstr ""
+msgstr "imap_mailbox"
 
 #: ../duplicity/commandline.py:460
 msgid "file_descriptor"
-msgstr ""
+msgstr "bestandsomschrijving"
 
 #. Used in usage help to represent a desired number of
 #. something. Example:
 #. --num-retries <number>
 #: ../duplicity/commandline.py:475 ../duplicity/commandline.py:497
 #: ../duplicity/commandline.py:518 ../duplicity/commandline.py:524
 #: ../duplicity/commandline.py:530 ../duplicity/commandline.py:583
 #: ../duplicity/commandline.py:588 ../duplicity/commandline.py:592
 #: ../duplicity/commandline.py:615 ../duplicity/commandline.py:621
 #: ../duplicity/commandline.py:625 ../duplicity/commandline.py:699
 #: ../duplicity/commandline.py:712 ../duplicity/commandline.py:725
-#: ../duplicity/commandline.py:927
+#: ../duplicity/commandline.py:936
 msgid "number"
-msgstr ""
+msgstr "nummer"
 
 #. Used in usage help (noun)
 #: ../duplicity/commandline.py:478
 msgid "backup name"
-msgstr ""
+msgstr "backupnaam"
 
 #: ../duplicity/commandline.py:610
 msgid "policy"
-msgstr ""
+msgstr "beleid"
 
 #: ../duplicity/commandline.py:628
 msgid "Hot|Cool|Archive"
-msgstr ""
+msgstr "Hot|Cool|Archive"
 
 #. noun
 #: ../duplicity/commandline.py:631 ../duplicity/commandline.py:634
-#: ../duplicity/commandline.py:898
+#: ../duplicity/commandline.py:907
 msgid "command"
-msgstr ""
+msgstr "commando"
 
 #: ../duplicity/commandline.py:637
 msgid "pyrax|cloudfiles"
-msgstr ""
+msgstr "pyrax|cloudfiles"
 
 #: ../duplicity/commandline.py:661
 msgid "pem formatted bundle of certificate authorities"
-msgstr ""
+msgstr "PEM-geformatteerde bundel van certificaatautoriteiten"
 
 #: ../duplicity/commandline.py:662
 msgid "path to a folder with certificate authority files"
-msgstr ""
+msgstr "pad naar een map met certificaatautoriteitbestanden"
 
 #: ../duplicity/commandline.py:666
 msgid "extra headers for Webdav, like 'Cookie,name=value'"
-msgstr ""
+msgstr "extra headers voor WebDav, bijvoorbeeld: 'Cookie,naam=waarde'"
 
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #. Used in usage help. Example:
 #. --backend-retry-delay <seconds>
 #. Used in usage help. Example:
 #. --timeout <seconds>
 #: ../duplicity/commandline.py:674 ../duplicity/commandline.py:730
-#: ../duplicity/commandline.py:967
+#: ../duplicity/commandline.py:976
 msgid "seconds"
-msgstr ""
+msgstr "seconden"
 
 #. abbreviation for "character" (noun)
-#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:895
+#: ../duplicity/commandline.py:680 ../duplicity/commandline.py:904
 msgid "char"
-msgstr ""
+msgstr "char"
 
-#: ../duplicity/commandline.py:861
+#: ../duplicity/commandline.py:736
+#, python-format
+msgid "Warning: Option %s is dangerous in that it allows corrupted manifests to\n"
+"exist on the remote without being caught.  This could lead to problems\n"
+"such as the inability to recover the backup in the future."
+msgstr "Waarschuwing: optie %s is gevaarlijk, omdat het toestaat dat corrupte manifesten bestaan op de remote host zonder dat dit ondervangen wordt. Dit kan leiden tot problemen, bijvoorbeeld het niet meer in staat zijn de backup te herstellen in de toekomst."
+
+#: ../duplicity/commandline.py:870
 #, python-format
 msgid "Using archive dir: %s"
-msgstr ""
+msgstr "Archiefmap %s wordt gebruikt"
 
-#: ../duplicity/commandline.py:862
+#: ../duplicity/commandline.py:871
 #, python-format
 msgid "Using backup name: %s"
-msgstr ""
+msgstr "Backupnaam %s wordt gebruikt"
 
-#: ../duplicity/commandline.py:869
+#: ../duplicity/commandline.py:878
 #, python-format
 msgid "Command line error: %s"
-msgstr ""
+msgstr "Commandlinefout: %s"
 
-#: ../duplicity/commandline.py:870
+#: ../duplicity/commandline.py:879
 msgid "Enter 'duplicity --help' for help screen."
-msgstr ""
+msgstr "Typ 'duplicity --help' voor hulpinformatie."
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other_host[:port]//absolute_path
-#: ../duplicity/commandline.py:883
+#: ../duplicity/commandline.py:892
 msgid "absolute_path"
-msgstr ""
+msgstr "absoluut_pad"
 
 #. Used in usage help. Example:
 #. tahoe://alias/some_dir
-#: ../duplicity/commandline.py:887
+#: ../duplicity/commandline.py:896
 msgid "alias"
-msgstr ""
+msgstr "alias"
 
 #. Used in help to represent a "bucket name" for Amazon Web
 #. Services' Simple Storage Service (S3). Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:892
+#: ../duplicity/commandline.py:901
 msgid "bucket_name"
-msgstr ""
+msgstr "bucketnaam"
 
 #. Used in usage help to represent the name of a container in
 #. Amazon Web Services' Cloudfront. Example:
 #. cf+http://container_name
-#: ../duplicity/commandline.py:903
+#: ../duplicity/commandline.py:912
 msgid "container_name"
-msgstr ""
+msgstr "containernaam"
 
 #. noun
-#: ../duplicity/commandline.py:906
+#: ../duplicity/commandline.py:915
 msgid "count"
-msgstr ""
+msgstr "aantal"
 
 #. Used in usage help to represent the name of a file directory
-#: ../duplicity/commandline.py:909
+#: ../duplicity/commandline.py:918
 msgid "directory"
-msgstr ""
+msgstr "map"
 
 #. Used in usage help, e.g. to represent the name of a code
 #. module. Example:
 #. rsync://user[:password]@other.host[:port]::/module/some_dir
-#: ../duplicity/commandline.py:922
+#: ../duplicity/commandline.py:931
 msgid "module"
-msgstr ""
+msgstr "module"
 
 #. Used in usage help to represent an internet hostname. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:936
+#: ../duplicity/commandline.py:945
 msgid "other.host"
-msgstr ""
+msgstr "andere.host"
 
 #. Used in usage help. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:940
+#: ../duplicity/commandline.py:949
 msgid "password"
-msgstr ""
+msgstr "wachtwoord"
 
 #. Used in usage help to represent a TCP port number. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:954
+#: ../duplicity/commandline.py:963
 msgid "port"
-msgstr ""
+msgstr "poort"
 
 #. Used in usage help. This represents a string to be used as a
 #. prefix to names for backup files created by Duplicity. Example:
 #. s3://other.host/bucket_name[/prefix]
-#: ../duplicity/commandline.py:959
+#: ../duplicity/commandline.py:968
 msgid "prefix"
-msgstr ""
+msgstr "voorvoegsel"
 
 #. Used in usage help to represent a Unix-style path name. Example:
 #. rsync://user[:password]@other.host[:port]/relative_path
-#: ../duplicity/commandline.py:963
+#: ../duplicity/commandline.py:972
 msgid "relative_path"
-msgstr ""
+msgstr "relatief_pad"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. Example:
 #. file:///some_dir
-#: ../duplicity/commandline.py:972
+#: ../duplicity/commandline.py:981
 msgid "some_dir"
-msgstr ""
+msgstr "een_map"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory where files will be
 #. coming FROM. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:978
+#: ../duplicity/commandline.py:987
 msgid "source_dir"
-msgstr ""
+msgstr "doelmap"
 
 #. Used in usage help to represent a URL files will be coming
 #. FROM. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:983
+#: ../duplicity/commandline.py:992
 msgid "source_url"
-msgstr ""
+msgstr "bronurl"
 
 #. Used in usage help to represent the name of a single file
 #. directory or a Unix-style path to a directory. where files will be
 #. going TO. Example:
 #. duplicity [restore] [options] source_url target_dir
-#: ../duplicity/commandline.py:989
+#: ../duplicity/commandline.py:998
 msgid "target_dir"
-msgstr ""
+msgstr "doelmap"
 
 #. Used in usage help to represent a URL files will be going TO.
 #. Example:
 #. duplicity [full|incremental] [options] source_dir target_url
-#: ../duplicity/commandline.py:994
+#: ../duplicity/commandline.py:1003
 msgid "target_url"
-msgstr ""
+msgstr "doelurl"
 
 #. Used in usage help to represent a user name (i.e. login).
 #. Example:
 #. ftp://user[:password]@other.host[:port]/some_dir
-#: ../duplicity/commandline.py:1004
+#: ../duplicity/commandline.py:1013
 msgid "user"
-msgstr ""
+msgstr "gebruiker"
 
 #. account id for b2. Example: b2://account_id@bucket/
-#: ../duplicity/commandline.py:1007
+#: ../duplicity/commandline.py:1016
 msgid "account_id"
-msgstr ""
+msgstr "account_id"
 
 #. application_key for b2.
 #. Example: b2://account_id:application_key@bucket/
-#: ../duplicity/commandline.py:1011
+#: ../duplicity/commandline.py:1020
 msgid "application_key"
-msgstr ""
+msgstr "applicatiesleutel"
 
 #. remote name for rclone.
 #. Example: rclone://remote:/some_dir
-#: ../duplicity/commandline.py:1015 ../duplicity/dup_collections.py:516
+#: ../duplicity/commandline.py:1024 ../duplicity/dup_collections.py:521
 msgid "remote"
-msgstr ""
+msgstr "remote"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1034
+#: ../duplicity/commandline.py:1043
 msgid "Backends and their URL formats:"
-msgstr ""
+msgstr "Backends en hun URL-formaten:"
 
 #. Header in usage help
-#: ../duplicity/commandline.py:1072
+#: ../duplicity/commandline.py:1081
 msgid "Commands:"
-msgstr ""
+msgstr "Commando's:"
 
-#: ../duplicity/commandline.py:1099
+#: ../duplicity/commandline.py:1108
 #, python-format
 msgid "Specified archive directory '%s' does not exist, or is not a directory"
-msgstr ""
+msgstr "De gespecificeerde map %s bestaat niet, of is geen map."
 
-#: ../duplicity/commandline.py:1108
+#: ../duplicity/commandline.py:1117
 #, python-format
 msgid "Sign key should be an 8, 16 alt. 40 character hex string, like 'AA0E73D2'.\n"
 "Received '%s' instead."
 msgstr ""
 
-#: ../duplicity/commandline.py:1168
+#: ../duplicity/commandline.py:1177
 #, python-format
 msgid "Restore destination directory %s already exists.\n"
 "Will not overwrite."
 msgstr ""
 
-#: ../duplicity/commandline.py:1173
+#: ../duplicity/commandline.py:1182
 #, python-format
 msgid "Verify directory %s does not exist"
 msgstr ""
 
-#: ../duplicity/commandline.py:1179
+#: ../duplicity/commandline.py:1188
 #, python-format
 msgid "Backup source directory %s does not exist."
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 #, python-format
 msgid "Command line warning: %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1210
+#: ../duplicity/commandline.py:1219
 msgid "Selection options --exclude/--include\n"
 "currently work only when backing up,not restoring."
 msgstr ""
 
-#: ../duplicity/commandline.py:1246
+#: ../duplicity/commandline.py:1255
 #, python-format
 msgid "GPG binary is %s, version %s"
 msgstr ""
 
-#: ../duplicity/commandline.py:1273
+#: ../duplicity/commandline.py:1282
 #, python-format
 msgid "Bad URL '%s'.\n"
 "Examples of URL strings are \"scp://user@host.net:1234/path\" and\n"
 "\"file:///usr/local\".  See the man page for more information."
 msgstr ""
 
-#: ../duplicity/commandline.py:1303
+#: ../duplicity/commandline.py:1312
 msgid "Main action: "
-msgstr ""
+msgstr "Hoofdactie: "
 
 #: ../duplicity/librsync.py:196
 msgid "basis_file must be a (true) file or an object whose file attribute is the underlying true file object"
 msgstr ""
 
 #: ../duplicity/dup_time.py:63
 #, python-format
@@ -877,31 +893,31 @@
 
 #: ../duplicity/dup_main.py:168
 msgid "PASSPHRASE variable not set, asking user."
 msgstr ""
 
 #: ../duplicity/dup_main.py:183
 msgid "GnuPG passphrase for signing key:"
-msgstr ""
+msgstr "GnuPG-wachtwoord voor ondertekeningssleutel:"
 
 #: ../duplicity/dup_main.py:188
 msgid "GnuPG passphrase for decryption:"
-msgstr ""
+msgstr "GnuPG-wachtwoord ter ontsleuteling:"
 
 #: ../duplicity/dup_main.py:193
 msgid "Retype passphrase for signing key to confirm: "
-msgstr ""
+msgstr "Typ het wachtwoord voor de ondertekekeningssleutel opnieuw ter bevestiging: "
 
 #: ../duplicity/dup_main.py:195
 msgid "Retype passphrase for decryption to confirm: "
-msgstr ""
+msgstr "Typ het wachtwoord ter ontsleuteling opnieuw ter bevestiging: "
 
 #: ../duplicity/dup_main.py:198
 msgid "First and second passphrases do not match!  Please try again."
-msgstr ""
+msgstr "Eerste en tweede wachtwoorden komen niet overeen! Probeer het opnieuw."
 
 #: ../duplicity/dup_main.py:205
 msgid "Cannot use empty passphrase with symmetric encryption!  Please try again."
 msgstr ""
 
 #: ../duplicity/dup_main.py:263
 #, python-format
@@ -1258,243 +1274,243 @@
 msgid "BackupSet.delete: missing %s"
 msgstr ""
 
 #: ../duplicity/dup_collections.py:225
 msgid "Fatal Error: No manifests found for most recent backup"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:234
+#: ../duplicity/dup_collections.py:235
 msgid "Fatal Error: Remote manifest does not match local one.  Either the remote backup set or the local archive directory has been corrupted."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:242
-msgid "Fatal Error: Neither remote nor local manifest is readable."
+#: ../duplicity/dup_collections.py:240 ../duplicity/dup_collections.py:270
+#, python-format
+msgid "Error processing remote manifest (%s): %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:253
-#, python-format
-msgid "Processing local manifest %s (%s)"
+#: ../duplicity/dup_collections.py:247
+msgid "Fatal Error: Neither remote nor local manifest is readable."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:265
+#: ../duplicity/dup_collections.py:258
 #, python-format
-msgid "Error processing remote manifest (%s): %s"
+msgid "Processing local manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:267
+#: ../duplicity/dup_collections.py:272
 #, python-format
 msgid "Processing remote manifest %s (%s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:363
+#: ../duplicity/dup_collections.py:368
 msgid "Preferring Backupset over previous one!"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:366
+#: ../duplicity/dup_collections.py:371
 #, python-format
 msgid "Ignoring incremental Backupset (start_time: %s; needed: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:371
+#: ../duplicity/dup_collections.py:376
 #, python-format
 msgid "Added incremental Backupset (start_time: %s / end_time: %s)"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:441
+#: ../duplicity/dup_collections.py:446
 msgid "Chain start time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:442
+#: ../duplicity/dup_collections.py:447
 msgid "Chain end time: "
 msgstr ""
 
-#: ../duplicity/dup_collections.py:443
+#: ../duplicity/dup_collections.py:448
 #, python-format
 msgid "Number of contained backup sets: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:445
+#: ../duplicity/dup_collections.py:450
 #, python-format
 msgid "Total number of contained volumes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Type of backup set:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447 ../duplicity/dup_collections.py:1223
+#: ../duplicity/dup_collections.py:452 ../duplicity/dup_collections.py:1228
 msgid "Time:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:447
+#: ../duplicity/dup_collections.py:452
 msgid "Num volumes:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:451 ../duplicity/dup_collections.py:1229
+#: ../duplicity/dup_collections.py:456 ../duplicity/dup_collections.py:1234
 msgid "Full"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:454 ../duplicity/dup_collections.py:1231
+#: ../duplicity/dup_collections.py:459 ../duplicity/dup_collections.py:1236
 msgid "Incremental"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:514
+#: ../duplicity/dup_collections.py:519
 msgid "local"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:671
+#: ../duplicity/dup_collections.py:676
 msgid "Collection Status"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:673
+#: ../duplicity/dup_collections.py:678
 #, python-format
 msgid "Connecting with backend: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:675
+#: ../duplicity/dup_collections.py:680
 #, python-format
 msgid "Archive dir: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:677
+#: ../duplicity/dup_collections.py:682
 #, python-format
 msgid "Found %d secondary backup chain(s)."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:680
+#: ../duplicity/dup_collections.py:685
 #, python-format
 msgid "Secondary chain %d of %d:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:686
+#: ../duplicity/dup_collections.py:691
 msgid "Found primary backup chain with matching signature chain:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:690
+#: ../duplicity/dup_collections.py:695
 msgid "No backup chains with active signatures found"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:693
+#: ../duplicity/dup_collections.py:698
 #, python-format
 msgid "Also found %d backup set(s) not part of any chain,"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:695
+#: ../duplicity/dup_collections.py:700
 #, python-format
 msgid "and %d incomplete backup set(s)."
 msgstr ""
 
 #. "cleanup" is a hard-coded command, so do not translate it
-#: ../duplicity/dup_collections.py:698
+#: ../duplicity/dup_collections.py:703
 msgid "These may be deleted by running duplicity with the \"cleanup\" command."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:701
+#: ../duplicity/dup_collections.py:706
 msgid "No orphaned or incomplete backup sets found."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:717
+#: ../duplicity/dup_collections.py:722
 #, python-format
 msgid "%d file(s) exists on backend"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:725
+#: ../duplicity/dup_collections.py:730
 #, python-format
 msgid "%d file(s) exists in cache"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:776
+#: ../duplicity/dup_collections.py:781
 msgid "Warning, discarding last backup set, because of missing signature file."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:799
+#: ../duplicity/dup_collections.py:804
 msgid "Warning, found the following local orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:804
+#: ../duplicity/dup_collections.py:809
 msgid "Warning, found the following remote orphaned signature file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:809
+#: ../duplicity/dup_collections.py:814
 msgid "Warning, found signatures but no corresponding backup files"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:813
+#: ../duplicity/dup_collections.py:818
 msgid "Warning, found incomplete backup sets, probably left from aborted session"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:817
+#: ../duplicity/dup_collections.py:822
 msgid "Warning, found the following orphaned backup file(s):"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:830
+#: ../duplicity/dup_collections.py:835
 #, python-format
 msgid "Extracting backup chains from list of files: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:842
+#: ../duplicity/dup_collections.py:847
 #, python-format
 msgid "File %s is part of known set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:845
+#: ../duplicity/dup_collections.py:850
 #, python-format
 msgid "File %s is not part of a known set; creating new set"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:850
+#: ../duplicity/dup_collections.py:855
 #, python-format
 msgid "Ignoring file (rejected by backup set) '%s'"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:866
+#: ../duplicity/dup_collections.py:871
 #, python-format
 msgid "Found backup chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:871
+#: ../duplicity/dup_collections.py:876
 #, python-format
 msgid "Added set %s to pre-existing chain %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:875
+#: ../duplicity/dup_collections.py:880
 #, python-format
 msgid "Found orphaned set %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1025
+#: ../duplicity/dup_collections.py:1030
 #, python-format
 msgid "No signature chain for the requested time. Using oldest available chain, starting at time %s."
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1221
+#: ../duplicity/dup_collections.py:1226
 #, python-format
 msgid "File: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1222
+#: ../duplicity/dup_collections.py:1227
 #, python-format
 msgid "Total number of backup: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1223 ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1228 ../duplicity/dup_collections.py:1254
 msgid "Type of file change:"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1247
+#: ../duplicity/dup_collections.py:1252
 #, python-format
 msgid " Backup set time: %s"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1248
+#: ../duplicity/dup_collections.py:1253
 #, python-format
 msgid "Total number of changes: %d"
 msgstr ""
 
-#: ../duplicity/dup_collections.py:1249
+#: ../duplicity/dup_collections.py:1254
 msgid "File:"
 msgstr ""
 
 #: ../duplicity/patchdir.py:83 ../duplicity/patchdir.py:88
 #, python-format
 msgid "Patching %s"
 msgstr ""
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `duplicity-1.2.3.dev43/po/fr_FR/duplicity.mo` & `duplicity-2.0.0rc0/po/fr_FR/duplicity.mo`

 * *Files 0% similar despite different names*

#### msgunfmt {}

```diff
@@ -1,12 +1,12 @@
 msgid ""
 msgstr ""
 "Project-Id-Version: duplicity\n"
 "Report-Msgid-Bugs-To: Kenneth Loafman <kenneth@loafman.com>\n"
-"PO-Revision-Date: 2023-01-25 19:47\n"
+"PO-Revision-Date: 2023-05-09 14:49\n"
 "Last-Translator: \n"
 "Language-Team: French\n"
 "Language: fr_FR\n"
 "MIME-Version: 1.0\n"
 "Content-Type: text/plain; charset=UTF-8\n"
 "Content-Transfer-Encoding: 8bit\n"
 "Plural-Forms: nplurals=2; plural=(n > 1);\n"
```

### Comparing `duplicity-1.2.3.dev43/duplicity.egg-info/PKG-INFO` & `duplicity-2.0.0rc0/duplicity.egg-info/PKG-INFO`

 * *Files 10% similar despite different names*

```diff
@@ -1,83 +1,67 @@
 Metadata-Version: 2.1
 Name: duplicity
-Version: 1.2.3.dev43
+Version: 2.0.0rc0
 Summary: Encrypted backup using rsync algorithm
 Home-page: http://duplicity.us
 Author: Ben Escoto <ben@emrose.org>
 Author-email: ben@emrose.org
 Maintainer: Kenneth Loafman <kenneth@loafman.com>
 Maintainer-email: kenneth@loafman.com
 Platform: any
 Classifier: Development Status :: 6 - Mature
 Classifier: Environment :: Console
 Classifier: License :: OSI Approved :: GNU General Public License v2 (GPLv2)
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: POSIX
 Classifier: Programming Language :: C
-Classifier: Programming Language :: Python :: 2
-Classifier: Programming Language :: Python :: 2.7
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.5
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Topic :: System :: Archiving :: Backup
-Requires-Python: >2.6, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, <4
+Requires-Python: >=3.8, <4
 Description-Content-Type: text/plain
 License-File: COPYING
 
 # INSTALLATION
 
 Thank you for trying duplicity.  To install, run:
-
 ```
-python setup.py install
+python3 setup.py install
 ```
 
 The build process can be also be run separately:
-
 ```
-python setup.py build
+python3 setup.py build
 ```
 
-If you want to use python 3 replace `python` with `python3`
-
 The default prefix is /usr, so files are put in /usr/bin,
 /usr/share/man/, etc.  An alternate prefix can be specified
 using the --prefix=<prefix> option.  For example:
-
 ```
-python setup.py install --prefix=/usr/local
+python3 setup.py install --prefix=/usr/local
 export PYTHONPATH='/usr/local/lib/python.x/site-packages/'
 /usr/local/bin/duplicity -V`
 ```
 
 # REQUIREMENTS
 
- * Python 2.7, or 3.5 to 3.10
+ * Python 3.8 to 3.10
  * librsync v0.9.6 or later
  * GnuPG for encryption
  * see `requirements.txt` for complete list
 
 If you install from the source package, you will also need:
 
  * Python development files, normally found in module 'python-dev'.
  * librsync development files, normally found in module 'librsync-dev'.
  
 Install python modules by performing the following command in duplicity's root directory:
-
-```
-pip install -r requirements.txt
-```
-or:
-
 ```
 pip3 install -r requirements.txt
 ```
 if you're using python3
 
 # DEVELOPMENT
```

### Comparing `duplicity-1.2.3.dev43/duplicity.egg-info/SOURCES.txt` & `duplicity-2.0.0rc0/duplicity.egg-info/SOURCES.txt`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,28 @@
 .gitchangelog.rc
 .gitignore
 .gitlab-ci.yml
+.pylintrc
 CHANGELOG.md
 CONTRIBUTING.md
 COPYING
 Makefile
 README-LOG.md
 README-REPO.md
 README-SNAP.md
 README-TESTING.md
 README.md
 crowdin.yml
-pylintrc
 readthedocs.yaml
 requirements.txt
 setup.cfg
 setup.py
 tox.ini
 bin/duplicity
 bin/duplicity.1
-bin/rdiffdir
-bin/rdiffdir.1
 debian/changelog
 debian/compat
 debian/control
 debian/copyright
 debian/rules
 debian/source/format
 docs/README.md
@@ -32,15 +30,17 @@
 docs/index.rst
 docs/modules.rst
 duplicity/__init__.py
 duplicity/_librsyncmodule.c
 duplicity/asyncscheduler.py
 duplicity/backend.py
 duplicity/cached_ops.py
-duplicity/commandline.py
+duplicity/cli_data.py
+duplicity/cli_main.py
+duplicity/cli_util.py
 duplicity/config.py
 duplicity/diffdir.py
 duplicity/dup_collections.py
 duplicity/dup_main.py
 duplicity/dup_temp.py
 duplicity/dup_threading.py
 duplicity/dup_time.py
@@ -66,16 +66,14 @@
 duplicity.egg-info/PKG-INFO
 duplicity.egg-info/SOURCES.txt
 duplicity.egg-info/dependency_links.txt
 duplicity.egg-info/requires.txt
 duplicity.egg-info/top_level.txt
 duplicity/backends/README
 duplicity/backends/__init__.py
-duplicity/backends/_boto_multi.py
-duplicity/backends/_boto_single.py
 duplicity/backends/_cf_cloudfiles.py
 duplicity/backends/_cf_pyrax.py
 duplicity/backends/adbackend.py
 duplicity/backends/azurebackend.py
 duplicity/backends/b2backend.py
 duplicity/backends/boxbackend.py
 duplicity/backends/cfbackend.py
@@ -99,15 +97,14 @@
 duplicity/backends/onedrivebackend.py
 duplicity/backends/par2backend.py
 duplicity/backends/pcabackend.py
 duplicity/backends/pydrivebackend.py
 duplicity/backends/rclonebackend.py
 duplicity/backends/rsyncbackend.py
 duplicity/backends/s3_boto3_backend.py
-duplicity/backends/s3_boto_backend.py
 duplicity/backends/slatebackend.py
 duplicity/backends/ssh_paramiko_backend.py
 duplicity/backends/ssh_pexpect_backend.py
 duplicity/backends/swiftbackend.py
 duplicity/backends/sxbackend.py
 duplicity/backends/tahoebackend.py
 duplicity/backends/webdavbackend.py
@@ -213,16 +210,14 @@
 po/zh_SG/duplicity.mo
 po/zh_TW/duplicity.mo
 snap/snapcraft.yaml
 snap/local/debug.sh
 snap/local/launcher.sh
 testing/__init__.py
 testing/conftest.py
-testing/find_unadorned_strings.py
-testing/fix_unadorned_strings.py
 testing/run-tests
 testing/test_code.py
 testing/testfiles.tar.gz
 testing/docker/.env
 testing/docker/.gitignore
 testing/docker/build.sh
 testing/docker/docker-compose.yml
@@ -238,16 +233,14 @@
 testing/docker/ftp_server/pureftpd.passwd
 testing/docker/ssh_server/Dockerfile
 testing/functional/__init__.py
 testing/functional/test_badupload.py
 testing/functional/test_cleanup.py
 testing/functional/test_final.py
 testing/functional/test_log.py
-testing/functional/test_rdiffdir.py
-testing/functional/test_replicate.py
 testing/functional/test_restart.py
 testing/functional/test_selection.py
 testing/functional/test_verify.py
 testing/gnupg/README
 testing/gnupg/gpg-agent.conf
 testing/gnupg/gpg.conf
 testing/gnupg/pubring.gpg
@@ -280,26 +273,26 @@
 testing/manual/issue79.json
 testing/manual/issue79.sh
 testing/manual/issue98.sh
 testing/manual/manual-ctrl-c-test.sh
 testing/manual/rootfiles.tar.gz
 testing/manual/roottest.py
 testing/manual/run-coverage.sh
-testing/manual/stdin_test.sh
 testing/manual/test_config.py.tmpl
 testing/overrides/__init__.py
 testing/overrides/bin/hsi
 testing/overrides/bin/lftp
 testing/overrides/bin/ncftpget
 testing/overrides/bin/ncftpls
 testing/overrides/bin/ncftpput
 testing/overrides/bin/tahoe
 testing/unit/__init__.py
 testing/unit/test_backend.py
 testing/unit/test_backend_instance.py
+testing/unit/test_cli_main.py
 testing/unit/test_collections.py
 testing/unit/test_diffdir.py
 testing/unit/test_dup_temp.py
 testing/unit/test_dup_time.py
 testing/unit/test_file_naming.py
 testing/unit/test_globmatch.py
 testing/unit/test_gpg.py
@@ -310,13 +303,14 @@
 testing/unit/test_path.py
 testing/unit/test_selection.py
 testing/unit/test_statistics.py
 testing/unit/test_tarfile.py
 testing/unit/test_tempdir.py
 testing/unit/test_util.py
 tools/installsnap
+tools/list_python_files
 tools/makechangelog
 tools/makepip
 tools/makesnap
 tools/pushsnap
 tools/release-prep
 tools/testsnap
```

### Comparing `duplicity-1.2.3.dev43/setup.py` & `duplicity-2.0.0rc0/setup.py`

 * *Files 16% similar despite different names*

```diff
@@ -16,375 +16,359 @@
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 # General Public License for more details.
 #
 # You should have received a copy of the GNU General Public License
 # along with duplicity; if not, write to the Free Software Foundation,
 # Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 
-from __future__ import print_function
-
 import os
+import glob
 import re
 import shutil
 import subprocess
 import sys
 import time
 
 from distutils.command.build_scripts import build_scripts
 from distutils.command.install_data import install_data
 from setuptools import setup, Extension
 from setuptools.command.build_ext import build_ext
 from setuptools.command.install import install
 from setuptools.command.sdist import sdist
 from setuptools.command.test import test
+from setuptools_scm import get_version
 
 
 # check that we can function here
-if not ((sys.version_info[0] == 2 and sys.version_info[1] >= 7) or
-        (sys.version_info[0] == 3 and sys.version_info[1] >= 5)):
-    print(u"Sorry, duplicity requires version 2.7 or version 3.5 or later of Python.")
+if not (sys.version_info[0] == 3 and sys.version_info[1] >= 8):
+    print("Sorry, duplicity requires version 3.8 or later of Python3.")
     sys.exit(1)
 
 
+Version = "2.0.0b2"
 scm_version_args = {
-    u'tag_regex': r'^(?P<prefix>rel.)?(?P<version>[^\+]+)(?P<suffix>.*)?$',
-    u'local_scheme': u'no-local-version',
+    'tag_regex': r'^(?P<prefix>rel.)?(?P<version>[^\+]+)(?P<suffix>.*)?$',
+    'local_scheme': 'no-local-version',
+    'fallback_version': Version,
     }
-
 try:
     from setuptools_scm import get_version  # pylint: disable=import-error
     Version = get_version(**scm_version_args)
 except Exception as e:
-    Version = u"1.2.3dev"
-    print(u"Unable to get SCM version: %s\ndefaulting to %s" % (str(e), Version))
-Reldate = time.strftime(u"%B %d, %Y", time.gmtime(int(os.environ.get(u'SOURCE_DATE_EPOCH', time.time()))))
+    print(f"Unable to get SCM version: {str(e)}\n"
+          f"Defaulting to {Version}")
+Reldate = time.strftime("%B %d, %Y", time.gmtime(int(os.environ.get('SOURCE_DATE_EPOCH', time.time()))))
 
 
 # READTHEDOCS uses setup.py sdist but can't handle extensions
 ext_modules = list()
 incdir_list = list()
 libdir_list = list()
-if not os.environ.get(u'READTHEDOCS') == u'True':
+if not os.environ.get('READTHEDOCS') == 'True':
     # set incdir and libdir for librsync
-    if os.name == u'posix':
-        LIBRSYNC_DIR = os.environ.get(u'LIBRSYNC_DIR', u'')
+    if os.name == 'posix':
+        LIBRSYNC_DIR = os.environ.get('LIBRSYNC_DIR', '')
         args = sys.argv[:]
         for arg in args:
-            if arg.startswith(u'--librsync-dir='):
-                LIBRSYNC_DIR = arg.split(u'=')[1]
+            if arg.startswith('--librsync-dir='):
+                LIBRSYNC_DIR = arg.split('=')[1]
                 sys.argv.remove(arg)
         if LIBRSYNC_DIR:
-            incdir_list = [os.path.join(LIBRSYNC_DIR, u'include')]
-            libdir_list = [os.path.join(LIBRSYNC_DIR, u'lib')]
+            incdir_list = [os.path.join(LIBRSYNC_DIR, 'include')]
+            libdir_list = [os.path.join(LIBRSYNC_DIR, 'lib')]
 
     # build the librsync extension
     ext_modules=[Extension(name=r"duplicity._librsync",
                            sources=[r"duplicity/_librsyncmodule.c"],
                            include_dirs=incdir_list,
                            library_dirs=libdir_list,
-                           libraries=[u"rsync"])]
+                           libraries=["rsync"])]
 
 
 def get_data_files():
-    u"""gen list of data files"""
+    """gen list of data files"""
 
     # static data files
     data_files = [
-            (u'share/man/man1',
+            ('share/man/man1',
                 [
-                u'bin/duplicity.1',
-                u'bin/rdiffdir.1'
+                'bin/duplicity.1',
                 ]
             ),
-            (u'share/doc/duplicity-%s' % Version,
+            (f'share/doc/duplicity-{Version}',
                 [
-                u'CHANGELOG.md',
-                u'CONTRIBUTING.md',
-                u'COPYING',
-                u'README.md',
-                u'README-LOG.md',
-                u'README-REPO.md',
-                u'README-TESTING.md',
+                'CHANGELOG.md',
+                'CONTRIBUTING.md',
+                'COPYING',
+                'README.md',
+                'README-LOG.md',
+                'README-REPO.md',
+                'README-TESTING.md',
                 ],
             ),
         ]
 
     # short circuit fot READTHEDOCS
-    if os.environ.get(u'READTHEDOCS') == u'True':
+    if os.environ.get('READTHEDOCS') == 'True':
         return data_files
 
     # msgfmt the translation files
-    assert os.path.exists(u"po"), u"Missing 'po' directory."
+    assert os.path.exists("po"), "Missing 'po' directory."
 
-    if os.path.exists(u'po/LINGUAS'):
-        linguas = open(u'po/LINGUAS').readlines()
-        for line in linguas:
-            langs = line.split()
-            for lang in langs:
-                try:
-                    os.mkdir(os.path.join(u"po", lang))
-                except os.error:
-                    pass
-                assert not os.system(u"cp po/%s.po po/%s" % (lang, lang)), lang
-                assert not os.system(u"msgfmt po/%s.po -o po/%s/duplicity.mo" % (lang, lang)), lang
+    linguas = glob.glob('po/*.po')
+    for lang in linguas:
+        lang = lang[3:-3]
+        try:
+            os.mkdir(os.path.join("po", lang))
+        except os.error:
+            pass
+        assert not os.system(f"cp po/{lang}.po po/{lang}"), lang
+        assert not os.system(f"msgfmt po/{lang}.po -o po/{lang}/duplicity.mo"), lang
 
-    for root, dirs, files in os.walk(u"po"):
+    for root, dirs, files in os.walk("po"):
         for file in files:
             path = os.path.join(root, file)
-            if path.endswith(u"duplicity.mo"):
+            if path.endswith("duplicity.mo"):
                 lang = os.path.split(root)[-1]
                 data_files.append(
-                    (u'share/locale/%s/LC_MESSAGES' % lang,
-                     [u"po/%s/duplicity.mo" % lang]))
+                    (f'share/locale/{lang}/LC_MESSAGES',
+                     [f"po/{lang}/duplicity.mo"]))
 
     return data_files
 
 
 def VersionedCopy(source, dest):
-    u"""
+    """
     Copy source to dest, substituting $version with version
     $reldate with today's date, i.e. December 28, 2008.
     """
-    with open(source, u"rt") as fd:
+    with open(source, "rt") as fd:
         buffer = fd.read()
 
-    buffer = re.sub(u"\$version", Version, buffer)
-    buffer = re.sub(u"\$reldate", Reldate, buffer)
+    buffer = re.sub("\$version", Version, buffer)
+    buffer = re.sub("\$reldate", Reldate, buffer)
 
-    with open(dest, u"wt") as fd:
+    with open(dest, "wt") as fd:
         fd.write(buffer)
 
 
 def cleanup():
-    if os.path.exists(u'po/LINGUAS'):
-        linguas = open(u'po/LINGUAS').readlines()
+    if os.path.exists('po/LINGUAS'):
+        linguas = open('po/LINGUAS').readlines()
         for line in linguas:
             langs = line.split()
             for lang in langs:
                 try:
-                    shutil.rmtree(os.path.join(u"po", lang))
+                    shutil.rmtree(os.path.join("po", lang))
                 except Exception:
                     pass
 
 
 class SdistCommand(sdist):
 
     def run(self):
         sdist.run(self)
 
-        orig = u"%s/duplicity-%s.tar.gz" % (self.dist_dir, Version)
-        tardir = u"duplicity-%s" % Version
-        tarfile = u"%s/duplicity-%s.tar.gz" % (self.dist_dir, Version)
+        orig = f"{self.dist_dir}/duplicity-{Version}.tar.gz"
+        tardir = f"duplicity-{Version}"
+        tarball = f"{self.dist_dir}/duplicity-{Version}.tar.gz"
 
-        assert not os.system(u"tar -xf %s" % orig)
+        assert not os.system(f"tar -xf {orig}")
         assert not os.remove(orig)
 
         # make sure executables are
-        assert not os.chmod(os.path.join(tardir, u"setup.py"), 0o755)
-        assert not os.chmod(os.path.join(tardir, u"bin", u"duplicity"), 0o755)
-        assert not os.chmod(os.path.join(tardir, u"bin", u"rdiffdir"), 0o755)
+        assert not os.chmod(os.path.join(tardir, "setup.py"), 0o755)
+        assert not os.chmod(os.path.join(tardir, "bin", "duplicity"), 0o755)
 
         # recopy the unversioned files and add correct version
-        VersionedCopy(os.path.join(u"bin", u"duplicity.1"),
-                      os.path.join(tardir, u"bin", u"duplicity.1"))
-        VersionedCopy(os.path.join(u"bin", u"rdiffdir.1"),
-                      os.path.join(tardir, u"bin", u"rdiffdir.1"))
-        VersionedCopy(os.path.join(u"duplicity", u"__init__.py"),
-                      os.path.join(tardir, u"duplicity", u"__init__.py"))
-        VersionedCopy(os.path.join(u"snap", u"snapcraft.yaml"),
-                      os.path.join(tardir, u"snap", u"snapcraft.yaml"))
+        VersionedCopy(os.path.join("bin", "duplicity.1"),
+                      os.path.join(tardir, "bin", "duplicity.1"))
+        VersionedCopy(os.path.join("duplicity", "__init__.py"),
+                      os.path.join(tardir, "duplicity", "__init__.py"))
+        VersionedCopy(os.path.join("snap", "snapcraft.yaml"),
+                      os.path.join(tardir, "snap", "snapcraft.yaml"))
 
         # set COPYFILE_DISABLE to disable appledouble file creation
-        os.environ[u'COPYFILE_DISABLE'] = u'true'
+        os.environ['COPYFILE_DISABLE'] = 'true'
 
-        # make the new tarfile and remove tardir
-        assert not os.system(u"""tar czf %s \
+        # make the new tarball and remove tardir
+        assert not os.system(f"""tar czf {tarball} \
                                  --exclude '.*' \
                                  --exclude Makefile \
                                  --exclude debian \
                                  --exclude docs \
                                  --exclude readthedocs.yaml \
                                  --exclude testing/docker \
                                  --exclude testing/manual \
                                  --exclude tools \
-                                  %s
-                              """ % (tarfile, tardir))
+                                 {tardir}
+                              """)
         assert not shutil.rmtree(tardir)
 
 
 class TestCommand(test):
 
     def run(self):
         # Make sure all modules are ready
-        build_cmd = self.get_finalized_command(u"build_py")
+        build_cmd = self.get_finalized_command("build_py")
         build_cmd.run()
         # And make sure our scripts are ready
-        build_scripts_cmd = self.get_finalized_command(u"build_scripts")
+        build_scripts_cmd = self.get_finalized_command("build_scripts")
         build_scripts_cmd.run()
 
         # make symlinks for test data
         if build_cmd.build_lib != top_dir:
-            for path in [u'source_files.tar.gz', u'gnupg']:
-                src = os.path.join(top_dir, u'testing', path)
-                target = os.path.join(build_cmd.build_lib, u'testing', path)
+            for path in ['source_files.tar.gz', 'gnupg']:
+                src = os.path.join(top_dir, 'testing', path)
+                target = os.path.join(build_cmd.build_lib, 'testing', path)
                 try:
                     os.symlink(src, target)
                 except Exception:
                     pass
 
-        os.environ[u'PATH'] = u"%s:%s" % (
-            os.path.abspath(build_scripts_cmd.build_dir),
-            os.environ.get(u'PATH'))
+        os.environ['PATH'] = f"{os.path.abspath(build_scripts_cmd.build_dir)}:{os.environ.get('PATH')}"
 
         test.run(self)
 
         cleanup()
 
 
 class InstallCommand(install):
 
     def run(self):
         # Normally, install will call build().  But we want to delete the
         # testing dir between building and installing.  So we manually build
         # and mark ourselves to skip building when we run() for real.
-        self.run_command(u'build')
+        self.run_command('build')
         self.skip_build = True
 
         # remove testing dir
         top_dir = os.path.dirname(os.path.abspath(__file__))
         if self.build_lib != top_dir:
-            testing_dir = os.path.join(self.build_lib, u'testing')
+            testing_dir = os.path.join(self.build_lib, 'testing')
             shutil.rmtree(testing_dir)
 
         install.run(self)
 
 
 class InstallDataCommand(install_data):
 
     def run(self):
         install_data.run(self)
 
         # version the man pages
         for tup in self.data_files:
             base, filenames = tup
-            if base == u'share/man/man1':
+            if base == 'share/man/man1':
                 for fn in filenames:
                     fn = os.path.split(fn)[-1]
                     path = os.path.join(self.install_dir, base, fn)
                     VersionedCopy(path, path)
 
 class BuildExtCommand(build_ext):
-    u"""Build extension modules."""
+    """Build extension modules."""
 
     def run(self):
         # build the _librsync.so module
-        print(u"Building extension for librsync...")
+        print("Building extension for librsync...")
         self.inplace = True
         build_ext.run(self)
 
 
-with open(u"README.md") as fh:
+with open("README.md") as fh:
     long_description = fh.read()
 
 
-setup(name=u"duplicity",
+setup(name="duplicity",
     version=Version,
-    description=u"Encrypted backup using rsync algorithm",
+    description="Encrypted backup using rsync algorithm",
     long_description=long_description,
-    long_description_content_type=u"text/plain",
-    author=u"Ben Escoto <ben@emrose.org>",
-    author_email=u"ben@emrose.org",
-    maintainer=u"Kenneth Loafman <kenneth@loafman.com>",
-    maintainer_email=u"kenneth@loafman.com",
-    url=u"http://duplicity.us",
-    python_requires=u">2.6, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, <4",
-    platforms=[u"any"],
+    long_description_content_type="text/plain",
+    author="Ben Escoto <ben@emrose.org>",
+    author_email="ben@emrose.org",
+    maintainer="Kenneth Loafman <kenneth@loafman.com>",
+    maintainer_email="kenneth@loafman.com",
+    url="http://duplicity.us",
+    python_requires=">=3.8, <4",
+    platforms=["any"],
     packages=[
-        u"duplicity",
-        u"duplicity.backends",
-        u"duplicity.backends.pyrax_identity",
-        u"testing",
-        u"testing.functional",
-        u"testing.unit",
+        "duplicity",
+        "duplicity.backends",
+        "duplicity.backends.pyrax_identity",
+        "testing",
+        "testing.functional",
+        "testing.unit",
         ],
     package_dir={
-        u"duplicity": u"duplicity",
-        u"duplicity.backends": u"duplicity/backends",
+        "duplicity": "duplicity",
+        "duplicity.backends": "duplicity/backends",
         },
     package_data={
-        u"testing": [
-            u"testing/gnupg",
-            u"testing/gnupg/.gpg-v21-migrated",
-            u"testing/gnupg/README",
-            u"testing/gnupg/gpg-agent.conf",
-            u"testing/gnupg/gpg.conf",
-            u"testing/gnupg/private-keys-v1.d",
-            u"testing/gnupg/private-keys-v1.d/1DBE767B921015FD5466978BAC968320E5BF6812.key",
-            u"testing/gnupg/private-keys-v1.d/4572B9686180E88EA52ED65F1416E486F7A8CAF5.key",
-            u"testing/gnupg/private-keys-v1.d/7229722CD5A4726D5CC5588034ADA07429FDECAB.key",
-            u"testing/gnupg/private-keys-v1.d/910D6B4035D3FEE3DA5960C1EE573C5F9ECE2B8D.key",
-            u"testing/gnupg/private-keys-v1.d/B29B24778338E7F20437B21704EA434E522BC1FE.key",
-            u"testing/gnupg/private-keys-v1.d/D2DF6D795DFD90DB4F7A109970F506692731CA67.key",
-            u"testing/gnupg/pubring.gpg",
-            u"testing/gnupg/random_seed",
-            u"testing/gnupg/secring.gpg",
-            u"testing/gnupg/trustdb.gpg",
-            u"testing/overrides",
-            u"testing/overrides/__init__.py",
-            u"testing/overrides/bin",
-            u"testing/overrides/bin/hsi",
-            u"testing/overrides/bin/lftp",
-            u"testing/overrides/bin/ncftpget",
-            u"testing/overrides/bin/ncftpls",
-            u"testing/overrides/bin/ncftpput",
-            u"testing/overrides/bin/tahoe",
+        "testing": [
+            "testing/gnupg",
+            "testing/gnupg/.gpg-v21-migrated",
+            "testing/gnupg/README",
+            "testing/gnupg/gpg-agent.conf",
+            "testing/gnupg/gpg.conf",
+            "testing/gnupg/private-keys-v1.d",
+            "testing/gnupg/private-keys-v1.d/1DBE767B921015FD5466978BAC968320E5BF6812.key",
+            "testing/gnupg/private-keys-v1.d/4572B9686180E88EA52ED65F1416E486F7A8CAF5.key",
+            "testing/gnupg/private-keys-v1.d/7229722CD5A4726D5CC5588034ADA07429FDECAB.key",
+            "testing/gnupg/private-keys-v1.d/910D6B4035D3FEE3DA5960C1EE573C5F9ECE2B8D.key",
+            "testing/gnupg/private-keys-v1.d/B29B24778338E7F20437B21704EA434E522BC1FE.key",
+            "testing/gnupg/private-keys-v1.d/D2DF6D795DFD90DB4F7A109970F506692731CA67.key",
+            "testing/gnupg/pubring.gpg",
+            "testing/gnupg/random_seed",
+            "testing/gnupg/secring.gpg",
+            "testing/gnupg/trustdb.gpg",
+            "testing/overrides",
+            "testing/overrides/__init__.py",
+            "testing/overrides/bin",
+            "testing/overrides/bin/hsi",
+            "testing/overrides/bin/lftp",
+            "testing/overrides/bin/ncftpget",
+            "testing/overrides/bin/ncftpls",
+            "testing/overrides/bin/ncftpput",
+            "testing/overrides/bin/tahoe",
         ],
     },
     ext_modules=ext_modules,
     scripts=[
-        u"bin/rdiffdir",
-        u"bin/duplicity",
+        "bin/duplicity",
         ],
     data_files=get_data_files(),
     include_package_data=True,
     install_requires=[
-        u"fasteners",
-        u"future",
+        "fasteners",
         ],
     tests_require=[
-        u"fasteners",
-        u"future",
-        u"mock",
-        u"pexpect",
-        u"pytest",
-        u"pytest-runner",
+        "fasteners",
+        "mock",
+        "pexpect",
+        "pytest",
+        "pytest-runner",
         ],
-    test_suite=u"testing",
+    test_suite="testing",
     cmdclass={
-        u"build_ext": BuildExtCommand,
-        u"install": InstallCommand,
-        u"install_data": InstallDataCommand,
-        u"sdist": SdistCommand,
-        u"test": TestCommand,
+        "build_ext": BuildExtCommand,
+        "install": InstallCommand,
+        "install_data": InstallDataCommand,
+        "sdist": SdistCommand,
+        "test": TestCommand,
         },
     classifiers=[
-        u"Development Status :: 6 - Mature",
-        u"Environment :: Console",
-        u"License :: OSI Approved :: GNU General Public License v2 (GPLv2)",
-        u"Operating System :: MacOS",
-        u"Operating System :: POSIX",
-        u"Programming Language :: C",
-        u"Programming Language :: Python :: 2",
-        u"Programming Language :: Python :: 2.7",
-        u"Programming Language :: Python :: 3",
-        u"Programming Language :: Python :: 3.5",
-        u"Programming Language :: Python :: 3.6",
-        u"Programming Language :: Python :: 3.7",
-        u"Programming Language :: Python :: 3.8",
-        u"Programming Language :: Python :: 3.9",
-        u"Programming Language :: Python :: 3.10",
-        u"Programming Language :: Python :: 3.11",
-        u"Topic :: System :: Archiving :: Backup"
+        "Development Status :: 6 - Mature",
+        "Environment :: Console",
+        "License :: OSI Approved :: GNU General Public License v2 (GPLv2)",
+        "Operating System :: MacOS",
+        "Operating System :: POSIX",
+        "Programming Language :: C",
+        "Programming Language :: Python :: 3",
+        "Programming Language :: Python :: 3.8",
+        "Programming Language :: Python :: 3.9",
+        "Programming Language :: Python :: 3.10",
+        "Programming Language :: Python :: 3.11",
+        "Topic :: System :: Archiving :: Backup"
         ],
     )
 
 cleanup()
```

### Comparing `duplicity-1.2.3.dev43/README.md` & `duplicity-2.0.0rc0/README.md`

 * *Files 9% similar despite different names*

```diff
@@ -1,52 +1,41 @@
 # INSTALLATION
 
 Thank you for trying duplicity.  To install, run:
-
 ```
-python setup.py install
+python3 setup.py install
 ```
 
 The build process can be also be run separately:
-
 ```
-python setup.py build
+python3 setup.py build
 ```
 
-If you want to use python 3 replace `python` with `python3`
-
 The default prefix is /usr, so files are put in /usr/bin,
 /usr/share/man/, etc.  An alternate prefix can be specified
 using the --prefix=<prefix> option.  For example:
-
 ```
-python setup.py install --prefix=/usr/local
+python3 setup.py install --prefix=/usr/local
 export PYTHONPATH='/usr/local/lib/python.x/site-packages/'
 /usr/local/bin/duplicity -V`
 ```
 
 # REQUIREMENTS
 
- * Python 2.7, or 3.5 to 3.10
+ * Python 3.8 to 3.10
  * librsync v0.9.6 or later
  * GnuPG for encryption
  * see `requirements.txt` for complete list
 
 If you install from the source package, you will also need:
 
  * Python development files, normally found in module 'python-dev'.
  * librsync development files, normally found in module 'librsync-dev'.
  
 Install python modules by performing the following command in duplicity's root directory:
-
-```
-pip install -r requirements.txt
-```
-or:
-
 ```
 pip3 install -r requirements.txt
 ```
 if you're using python3
 
 # DEVELOPMENT
```

### Comparing `duplicity-1.2.3.dev43/README-REPO.md` & `duplicity-2.0.0rc0/README-REPO.md`

 * *Files 5% similar despite different names*

```diff
@@ -14,19 +14,14 @@
     - You will see "duplicity $version" instead of the normal version number.
     - Versioning comes during the release.
 
 Use PYTHONPATH to set the path each time that you use the binaries:
 
 `PYTHONPATH=$DUP_ROOT bin/duplicity`
 
-or
-
-`PYTHONPATH=$DUP_ROOT bin/rdiffdir`
-
-
 ## Getting a versioned copy of duplicity
 
 Duplicity source is versioned by **git tags** and **setuptools-scm** with help from `./setup.py sdist --dist-dir=.`.
 The following should suffice to give you versioned source.
 
 So, for version 0.8.21:
 ```
```

### Comparing `duplicity-1.2.3.dev43/README-TESTING.md` & `duplicity-2.0.0rc0/README-TESTING.md`

 * *Files identical despite different names*

